diff -Nuarp ruby-3.0.5.a/abrt.c ruby-3.0.5.b/abrt.c
--- ruby-3.0.5.a/abrt.c	1969-12-31 19:00:00.000000000 -0500
+++ ruby-3.0.5.b/abrt.c	2023-02-02 23:11:35.057989673 -0500
@@ -0,0 +1,12 @@
+#include "internal.h"
+
+void
+Init_abrt(void)
+{
+  rb_eval_string(
+    "  begin\n"
+    "    require 'abrt'\n"
+    "  rescue LoadError\n"
+    "  end\n"
+  );
+}
diff -Nuarp ruby-3.0.5.a/addr2line.c ruby-3.0.5.b/addr2line.c
--- ruby-3.0.5.a/addr2line.c	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/addr2line.c	2023-02-02 23:11:43.497056685 -0500
@@ -159,11 +159,12 @@ typedef struct obj_info {
     struct dwarf_section debug_info;
     struct dwarf_section debug_line;
     struct dwarf_section debug_ranges;
+    struct dwarf_section debug_rnglists;
     struct dwarf_section debug_str;
     struct obj_info *next;
 } obj_info_t;
 
-#define DWARF_SECTION_COUNT 5
+#define DWARF_SECTION_COUNT 6
 
 static struct dwarf_section *
 obj_dwarf_section_at(obj_info_t *obj, int n)
@@ -173,6 +174,7 @@ obj_dwarf_section_at(obj_info_t *obj, in
         &obj->debug_info,
         &obj->debug_line,
         &obj->debug_ranges,
+        &obj->debug_rnglists,
         &obj->debug_str
     };
     if (n < 0 || DWARF_SECTION_COUNT <= n) {
@@ -411,7 +413,7 @@ parse_debug_line_cu(int num_traces, void
 	    FILL_LINE();
 	    break;
 	case DW_LNS_advance_pc:
-	    a = uleb128((char **)&p);
+	    a = uleb128((char **)&p) * header.minimum_instruction_length;
 	    addr += a;
 	    break;
 	case DW_LNS_advance_line: {
@@ -451,7 +453,7 @@ parse_debug_line_cu(int num_traces, void
 	    /* isa = (unsigned int)*/(void)uleb128((char **)&p);
 	    break;
 	case 0:
-	    a = *(unsigned char *)p++;
+	    a = uleb128((char **)&p);
 	    op = *p++;
 	    switch (op) {
 	    case DW_LNE_end_sequence:
@@ -808,6 +810,18 @@ enum
     DW_FORM_addrx4 = 0x2c
 };
 
+/* Range list entry encodings */
+enum {
+    DW_RLE_end_of_list = 0x00,
+    DW_RLE_base_addressx = 0x01,
+    DW_RLE_startx_endx = 0x02,
+    DW_RLE_startx_length = 0x03,
+    DW_RLE_offset_pair = 0x04,
+    DW_RLE_base_address = 0x05,
+    DW_RLE_start_end = 0x06,
+    DW_RLE_start_length = 0x07
+};
+
 enum {
     VAL_none = 0,
     VAL_cstr = 1,
@@ -962,6 +976,23 @@ debug_info_reader_init(DebugInfoReader *
 }
 
 static void
+di_skip_die_attributes(char **p)
+{
+    for (;;) {
+        uint64_t at = uleb128(p);
+        uint64_t form = uleb128(p);
+        if (!at && !form) break;
+        switch (form) {
+          default:
+            break;
+          case DW_FORM_implicit_const:
+            sleb128(p);
+            break;
+        }
+    }
+}
+
+static void
 di_read_debug_abbrev_cu(DebugInfoReader *reader)
 {
     uint64_t prev = 0;
@@ -975,12 +1006,7 @@ di_read_debug_abbrev_cu(DebugInfoReader
         prev = abbrev_number;
         uleb128(&p); /* tag */
         p++; /* has_children */
-        /* skip content */
-        for (;;) {
-            uint64_t at = uleb128(&p);
-            uint64_t form = uleb128(&p);
-            if (!at && !form) break;
-        }
+        di_skip_die_attributes(&p);
     }
 }
 
@@ -1244,12 +1270,7 @@ di_find_abbrev(DebugInfoReader *reader,
     /* skip 255th record */
     uleb128(&p); /* tag */
     p++; /* has_children */
-    /* skip content */
-    for (;;) {
-        uint64_t at = uleb128(&p);
-        uint64_t form = uleb128(&p);
-        if (!at && !form) break;
-    }
+    di_skip_die_attributes(&p);
     for (uint64_t n = uleb128(&p); abbrev_number != n; n = uleb128(&p)) {
         if (n == 0) {
             fprintf(stderr,"%d: Abbrev Number %"PRId64" not found\n",__LINE__, abbrev_number);
@@ -1257,12 +1278,7 @@ di_find_abbrev(DebugInfoReader *reader,
         }
         uleb128(&p); /* tag */
         p++; /* has_children */
-        /* skip content */
-        for (;;) {
-            uint64_t at = uleb128(&p);
-            uint64_t form = uleb128(&p);
-            if (!at && !form) break;
-        }
+        di_skip_die_attributes(&p);
     }
     return p;
 }
@@ -1390,6 +1406,21 @@ ranges_set(ranges_t *ptr, DebugInfoValue
     }
 }
 
+static uint64_t
+read_dw_form_addr(DebugInfoReader *reader, char **ptr)
+{
+    char *p = *ptr;
+    *ptr = p + reader->format;
+    if (reader->format == 4) {
+        return read_uint32(&p);
+    } else if (reader->format == 8) {
+        return read_uint64(&p);
+    } else {
+        fprintf(stderr,"unknown address_size:%d", reader->address_size);
+        abort();
+    }
+}
+
 static uintptr_t
 ranges_include(DebugInfoReader *reader, ranges_t *ptr, uint64_t addr)
 {
@@ -1403,8 +1434,50 @@ ranges_include(DebugInfoReader *reader,
     }
     else if (ptr->ranges_set) {
         /* TODO: support base address selection entry */
-        char *p = reader->obj->debug_ranges.ptr + ptr->ranges;
+        char *p;
         uint64_t base = ptr->low_pc_set ? ptr->low_pc : reader->current_low_pc;
+        if (reader->obj->debug_rnglists.ptr) {
+            p = reader->obj->debug_rnglists.ptr + ptr->ranges;
+            for (;;) {
+                uint8_t rle = read_uint8(&p);
+                uintptr_t base_address = 0;
+                uintptr_t from, to;
+                if (rle == DW_RLE_end_of_list) break;
+                switch (rle) {
+                  case DW_RLE_base_addressx:
+                    uleb128(&p);
+                    break;
+                  case DW_RLE_startx_endx:
+                    uleb128(&p);
+                    uleb128(&p);
+                    break;
+                  case DW_RLE_startx_length:
+                    uleb128(&p);
+                    uleb128(&p);
+                    break;
+                  case DW_RLE_offset_pair:
+                    from = base_address + uleb128(&p);
+                    to = base_address + uleb128(&p);
+                    if (base + from <= addr && addr < base + to) {
+                        return from;
+                    }
+                    break;
+                  case DW_RLE_base_address:
+                    base_address = read_dw_form_addr(reader, &p);
+                    break;
+                  case DW_RLE_start_end:
+                    read_dw_form_addr(reader, &p);
+                    read_dw_form_addr(reader, &p);
+                    break;
+                  case DW_RLE_start_length:
+                    read_dw_form_addr(reader, &p);
+                    uleb128(&p);
+                    break;
+                }
+            }
+            return false;
+        }
+        p = reader->obj->debug_ranges.ptr + ptr->ranges;
         for (;;) {
             uintptr_t from = read_uintptr(&p);
             uintptr_t to = read_uintptr(&p);
@@ -1750,6 +1823,7 @@ fill_lines(int num_traces, void **traces
                     ".debug_info",
                     ".debug_line",
                     ".debug_ranges",
+                    ".debug_rnglists",
                     ".debug_str"
                 };
 
@@ -2006,6 +2080,7 @@ found_mach_header:
                     "__debug_info",
                     "__debug_line",
                     "__debug_ranges",
+                    "__debug_rnglists",
                     "__debug_str"
                 };
                 struct LP(segment_command) *scmd = (struct LP(segment_command) *)lcmd;
diff -Nuarp ruby-3.0.5.a/addr2line.c.orig ruby-3.0.5.b/addr2line.c.orig
--- ruby-3.0.5.a/addr2line.c.orig	1969-12-31 19:00:00.000000000 -0500
+++ ruby-3.0.5.b/addr2line.c.orig	2023-02-02 23:10:58.549699738 -0500
@@ -0,0 +1,2723 @@
+/**********************************************************************
+
+  addr2line.c -
+
+  $Author$
+
+  Copyright (C) 2010 Shinichiro Hamaji
+
+**********************************************************************/
+
+#if defined(__clang__)
+#pragma clang diagnostic ignored "-Wgnu-empty-initializer"
+#pragma clang diagnostic ignored "-Wgcc-compat"
+#endif
+
+#include "ruby/internal/config.h"
+#include "ruby/defines.h"
+#include "ruby/missing.h"
+#include "addr2line.h"
+
+#include <stdio.h>
+#include <errno.h>
+
+#ifdef HAVE_LIBPROC_H
+#include <libproc.h>
+#endif
+
+#include "ruby/internal/stdbool.h"
+
+#if defined(USE_ELF) || defined(HAVE_MACH_O_LOADER_H)
+
+#include <fcntl.h>
+#include <limits.h>
+#include <stdio.h>
+#include <stdint.h>
+#include <stdlib.h>
+#include <string.h>
+#include <sys/mman.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <unistd.h>
+
+/* Make alloca work the best possible way.  */
+#ifdef __GNUC__
+# ifndef alloca
+#  define alloca __builtin_alloca
+# endif
+#else
+# ifdef HAVE_ALLOCA_H
+#  include <alloca.h>
+# else
+#  ifdef _AIX
+#pragma alloca
+#  else
+#   ifndef alloca		/* predefined by HP cc +Olibcalls */
+void *alloca();
+#   endif
+#  endif /* AIX */
+# endif	/* HAVE_ALLOCA_H */
+#endif /* __GNUC__ */
+
+#ifdef HAVE_DLADDR
+# include <dlfcn.h>
+#endif
+
+#ifdef HAVE_MACH_O_LOADER_H
+# include <crt_externs.h>
+# include <mach-o/fat.h>
+# include <mach-o/loader.h>
+# include <mach-o/nlist.h>
+# include <mach-o/stab.h>
+#endif
+
+#ifdef USE_ELF
+# ifdef __OpenBSD__
+#  include <elf_abi.h>
+# else
+#  include <elf.h>
+# endif
+
+#ifndef ElfW
+# if SIZEOF_VOIDP == 8
+#  define ElfW(x) Elf64##_##x
+# else
+#  define ElfW(x) Elf32##_##x
+# endif
+#endif
+#ifndef ELF_ST_TYPE
+# if SIZEOF_VOIDP == 8
+#  define ELF_ST_TYPE ELF64_ST_TYPE
+# else
+#  define ELF_ST_TYPE ELF32_ST_TYPE
+# endif
+#endif
+#endif
+
+#ifdef SHF_COMPRESSED
+# if defined(ELFCOMPRESS_ZLIB) && defined(HAVE_LIBZ)
+   /* FreeBSD 11.0 lacks ELFCOMPRESS_ZLIB */
+#  include <zlib.h>
+#  define SUPPORT_COMPRESSED_DEBUG_LINE
+# endif
+#else /* compatibility with glibc < 2.22 */
+# define SHF_COMPRESSED 0
+#endif
+
+#ifndef PATH_MAX
+#define PATH_MAX 4096
+#endif
+
+#define DW_LNS_copy                     0x01
+#define DW_LNS_advance_pc               0x02
+#define DW_LNS_advance_line             0x03
+#define DW_LNS_set_file                 0x04
+#define DW_LNS_set_column               0x05
+#define DW_LNS_negate_stmt              0x06
+#define DW_LNS_set_basic_block          0x07
+#define DW_LNS_const_add_pc             0x08
+#define DW_LNS_fixed_advance_pc         0x09
+#define DW_LNS_set_prologue_end         0x0a /* DWARF3 */
+#define DW_LNS_set_epilogue_begin       0x0b /* DWARF3 */
+#define DW_LNS_set_isa                  0x0c /* DWARF3 */
+
+/* Line number extended opcode name. */
+#define DW_LNE_end_sequence             0x01
+#define DW_LNE_set_address              0x02
+#define DW_LNE_define_file              0x03
+#define DW_LNE_set_discriminator        0x04  /* DWARF4 */
+
+PRINTF_ARGS(static int kprintf(const char *fmt, ...), 1, 2);
+
+typedef struct line_info {
+    const char *dirname;
+    const char *filename;
+    const char *path; /* object path */
+    int line;
+
+    uintptr_t base_addr;
+    uintptr_t saddr;
+    const char *sname; /* function name */
+
+    struct line_info *next;
+} line_info_t;
+
+struct dwarf_section {
+    char *ptr;
+    size_t size;
+    uint64_t flags;
+};
+
+typedef struct obj_info {
+    const char *path; /* object path */
+    char *mapped;
+    size_t mapped_size;
+    void *uncompressed;
+    uintptr_t base_addr;
+    uintptr_t vmaddr;
+    struct dwarf_section debug_abbrev;
+    struct dwarf_section debug_info;
+    struct dwarf_section debug_line;
+    struct dwarf_section debug_ranges;
+    struct dwarf_section debug_str;
+    struct obj_info *next;
+} obj_info_t;
+
+#define DWARF_SECTION_COUNT 5
+
+static struct dwarf_section *
+obj_dwarf_section_at(obj_info_t *obj, int n)
+{
+    struct dwarf_section *ary[] = {
+        &obj->debug_abbrev,
+        &obj->debug_info,
+        &obj->debug_line,
+        &obj->debug_ranges,
+        &obj->debug_str
+    };
+    if (n < 0 || DWARF_SECTION_COUNT <= n) {
+        abort();
+    }
+    return ary[n];
+}
+
+struct debug_section_definition {
+    const char *name;
+    struct dwarf_section *dwarf;
+};
+
+/* Avoid consuming stack as this module may be used from signal handler */
+static char binary_filename[PATH_MAX + 1];
+
+static unsigned long
+uleb128(char **p)
+{
+    unsigned long r = 0;
+    int s = 0;
+    for (;;) {
+	unsigned char b = *(unsigned char *)(*p)++;
+	if (b < 0x80) {
+	    r += (unsigned long)b << s;
+	    break;
+	}
+	r += (b & 0x7f) << s;
+	s += 7;
+    }
+    return r;
+}
+
+static long
+sleb128(char **p)
+{
+    long r = 0;
+    int s = 0;
+    for (;;) {
+	unsigned char b = *(unsigned char *)(*p)++;
+	if (b < 0x80) {
+	    if (b & 0x40) {
+		r -= (0x80 - b) << s;
+	    }
+	    else {
+		r += (b & 0x3f) << s;
+	    }
+	    break;
+	}
+	r += (b & 0x7f) << s;
+	s += 7;
+    }
+    return r;
+}
+
+static const char *
+get_nth_dirname(unsigned long dir, char *p)
+{
+    if (!dir--) {
+	return "";
+    }
+    while (dir--) {
+	while (*p) p++;
+	p++;
+	if (!*p) {
+	    kprintf("Unexpected directory number %lu in %s\n",
+		    dir, binary_filename);
+	    return "";
+	}
+    }
+    return p;
+}
+
+static void
+fill_filename(int file, char *include_directories, char *filenames, line_info_t *line, obj_info_t *obj)
+{
+    int i;
+    char *p = filenames;
+    char *filename;
+    unsigned long dir;
+    for (i = 1; i <= file; i++) {
+	filename = p;
+	if (!*p) {
+	    /* Need to output binary file name? */
+	    kprintf("Unexpected file number %d in %s at %tx\n",
+		    file, binary_filename, filenames - obj->mapped);
+	    return;
+	}
+	while (*p) p++;
+	p++;
+	dir = uleb128(&p);
+	/* last modified. */
+	uleb128(&p);
+	/* size of the file. */
+	uleb128(&p);
+
+	if (i == file) {
+	    line->filename = filename;
+	    line->dirname = get_nth_dirname(dir, include_directories);
+	}
+    }
+}
+
+static void
+fill_line(int num_traces, void **traces, uintptr_t addr, int file, int line,
+	  char *include_directories, char *filenames,
+	  obj_info_t *obj, line_info_t *lines, int offset)
+{
+    int i;
+    addr += obj->base_addr - obj->vmaddr;
+    for (i = offset; i < num_traces; i++) {
+	uintptr_t a = (uintptr_t)traces[i];
+	/* We assume one line code doesn't result >100 bytes of native code.
+       We may want more reliable way eventually... */
+	if (addr < a && a < addr + 100) {
+	    fill_filename(file, include_directories, filenames, &lines[i], obj);
+	    lines[i].line = line;
+	}
+    }
+}
+
+struct LineNumberProgramHeader {
+    uint64_t unit_length;
+    uint16_t version;
+    uint8_t format; /* 4 or 8 */
+    uint64_t header_length;
+    uint8_t minimum_instruction_length;
+    uint8_t maximum_operations_per_instruction;
+    uint8_t default_is_stmt;
+    int8_t line_base;
+    uint8_t line_range;
+    uint8_t opcode_base;
+    /* uint8_t standard_opcode_lengths[opcode_base-1]; */
+    const char *include_directories;
+    const char *filenames;
+    const char *cu_start;
+    const char *cu_end;
+};
+
+static int
+parse_debug_line_header(const char **pp, struct LineNumberProgramHeader *header)
+{
+    const char *p = *pp;
+    header->unit_length = *(uint32_t *)p;
+    p += sizeof(uint32_t);
+
+    header->format = 4;
+    if (header->unit_length == 0xffffffff) {
+	header->unit_length = *(uint64_t *)p;
+	p += sizeof(uint64_t);
+        header->format = 8;
+    }
+
+    header->cu_end = p + header->unit_length;
+
+    header->version = *(uint16_t *)p;
+    p += sizeof(uint16_t);
+    if (header->version > 4) return -1;
+
+    header->header_length = header->format == 4 ? *(uint32_t *)p : *(uint64_t *)p;
+    p += header->format;
+    header->cu_start = p + header->header_length;
+
+    header->minimum_instruction_length = *(uint8_t *)p++;
+
+    if (header->version >= 4) {
+        /* maximum_operations_per_instruction = *(uint8_t *)p; */
+        if (*p != 1) return -1; /* For non-VLIW architectures, this field is 1 */
+        p++;
+    }
+
+    header->default_is_stmt = *(uint8_t *)p++;
+    header->line_base = *(int8_t *)p++;
+    header->line_range = *(uint8_t *)p++;
+    header->opcode_base = *(uint8_t *)p++;
+    /* header->standard_opcode_lengths = (uint8_t *)p - 1; */
+    p += header->opcode_base - 1;
+
+    header->include_directories = p;
+
+    /* temporary measure for compress-debug-sections */
+    if (p >= header->cu_end) return -1;
+
+    /* skip include directories */
+    while (*p) {
+	p = memchr(p, '\0', header->cu_end - p);
+	if (!p) return -1;
+	p++;
+    }
+    p++;
+
+    header->filenames = p;
+
+    *pp = header->cu_start;
+
+    return 0;
+}
+
+static int
+parse_debug_line_cu(int num_traces, void **traces, char **debug_line,
+		obj_info_t *obj, line_info_t *lines, int offset)
+{
+    const char *p = (const char *)*debug_line;
+    struct LineNumberProgramHeader header;
+
+    /* The registers. */
+    unsigned long addr = 0;
+    unsigned int file = 1;
+    unsigned int line = 1;
+    /* unsigned int column = 0; */
+    int is_stmt;
+    /* int basic_block = 0; */
+    /* int end_sequence = 0; */
+    /* int prologue_end = 0; */
+    /* int epilogue_begin = 0; */
+    /* unsigned int isa = 0; */
+
+    if (parse_debug_line_header(&p, &header))
+        return -1;
+    is_stmt = header.default_is_stmt;
+
+#define FILL_LINE()						    \
+    do {							    \
+	fill_line(num_traces, traces, addr, file, line,		    \
+                  (char *)header.include_directories,               \
+                  (char *)header.filenames,                         \
+		  obj, lines, offset);				    \
+	/*basic_block = prologue_end = epilogue_begin = 0;*/	    \
+    } while (0)
+
+    while (p < header.cu_end) {
+	unsigned long a;
+	unsigned char op = *p++;
+	switch (op) {
+	case DW_LNS_copy:
+	    FILL_LINE();
+	    break;
+	case DW_LNS_advance_pc:
+	    a = uleb128((char **)&p);
+	    addr += a;
+	    break;
+	case DW_LNS_advance_line: {
+	    long a = sleb128((char **)&p);
+	    line += a;
+	    break;
+	}
+	case DW_LNS_set_file:
+	    file = (unsigned int)uleb128((char **)&p);
+	    break;
+	case DW_LNS_set_column:
+	    /*column = (unsigned int)*/(void)uleb128((char **)&p);
+	    break;
+	case DW_LNS_negate_stmt:
+	    is_stmt = !is_stmt;
+	    break;
+	case DW_LNS_set_basic_block:
+	    /*basic_block = 1; */
+	    break;
+	case DW_LNS_const_add_pc:
+	    a = ((255UL - header.opcode_base) / header.line_range) *
+		header.minimum_instruction_length;
+	    addr += a;
+	    break;
+	case DW_LNS_fixed_advance_pc:
+	    a = *(uint16_t *)p;
+	    p += sizeof(uint16_t);
+	    addr += a;
+	    break;
+	case DW_LNS_set_prologue_end:
+	    /* prologue_end = 1; */
+	    break;
+	case DW_LNS_set_epilogue_begin:
+	    /* epilogue_begin = 1; */
+	    break;
+	case DW_LNS_set_isa:
+	    /* isa = (unsigned int)*/(void)uleb128((char **)&p);
+	    break;
+	case 0:
+	    a = *(unsigned char *)p++;
+	    op = *p++;
+	    switch (op) {
+	    case DW_LNE_end_sequence:
+		/* end_sequence = 1; */
+		FILL_LINE();
+		addr = 0;
+		file = 1;
+		line = 1;
+		/* column = 0; */
+		is_stmt = header.default_is_stmt;
+		/* end_sequence = 0; */
+		/* isa = 0; */
+		break;
+	    case DW_LNE_set_address:
+		addr = *(unsigned long *)p;
+		p += sizeof(unsigned long);
+		break;
+	    case DW_LNE_define_file:
+		kprintf("Unsupported operation in %s\n",
+			binary_filename);
+		break;
+	    case DW_LNE_set_discriminator:
+		/* TODO:currently ignore */
+		uleb128((char **)&p);
+		break;
+	    default:
+		kprintf("Unknown extended opcode: %d in %s\n",
+			op, binary_filename);
+	    }
+	    break;
+	default: {
+            uint8_t adjusted_opcode = op - header.opcode_base;
+            uint8_t operation_advance = adjusted_opcode / header.line_range;
+            /* NOTE: this code doesn't support VLIW */
+            addr += operation_advance * header.minimum_instruction_length;
+            line += header.line_base + (adjusted_opcode % header.line_range);
+	    FILL_LINE();
+	}
+	}
+    }
+    *debug_line = (char *)p;
+    return 0;
+}
+
+static int
+parse_debug_line(int num_traces, void **traces,
+		 char *debug_line, unsigned long size,
+		 obj_info_t *obj, line_info_t *lines, int offset)
+{
+    char *debug_line_end = debug_line + size;
+    while (debug_line < debug_line_end) {
+	if (parse_debug_line_cu(num_traces, traces, &debug_line, obj, lines, offset))
+	    return -1;
+    }
+    if (debug_line != debug_line_end) {
+	kprintf("Unexpected size of .debug_line in %s\n",
+		binary_filename);
+    }
+    return 0;
+}
+
+/* read file and fill lines */
+static uintptr_t
+fill_lines(int num_traces, void **traces, int check_debuglink,
+	   obj_info_t **objp, line_info_t *lines, int offset);
+
+static void
+append_obj(obj_info_t **objp)
+{
+    obj_info_t *newobj = calloc(1, sizeof(obj_info_t));
+    if (*objp) (*objp)->next = newobj;
+    *objp = newobj;
+}
+
+#ifdef USE_ELF
+/* Ideally we should check 4 paths to follow gnu_debuglink:
+ *
+ *   - /usr/lib/debug/.build-id/ab/cdef1234.debug
+ *   - /usr/bin/ruby.debug
+ *   - /usr/bin/.debug/ruby.debug
+ *   - /usr/lib/debug/usr/bin/ruby.debug.
+ *
+ * but we handle only two cases for now as the two formats are
+ * used by some linux distributions.
+ *
+ * See GDB's info for detail.
+ * https://sourceware.org/gdb/onlinedocs/gdb/Separate-Debug-Files.html
+ */
+
+// check the path pattern of "/usr/lib/debug/usr/bin/ruby.debug"
+static void
+follow_debuglink(const char *debuglink, int num_traces, void **traces,
+		 obj_info_t **objp, line_info_t *lines, int offset)
+{
+    static const char global_debug_dir[] = "/usr/lib/debug";
+    const size_t global_debug_dir_len = sizeof(global_debug_dir) - 1;
+    char *p;
+    obj_info_t *o1 = *objp, *o2;
+    size_t len;
+
+    p = strrchr(binary_filename, '/');
+    if (!p) {
+	return;
+    }
+    p[1] = '\0';
+
+    len = strlen(binary_filename);
+    if (len >= PATH_MAX - global_debug_dir_len)
+	len = PATH_MAX - global_debug_dir_len - 1;
+    memmove(binary_filename + global_debug_dir_len, binary_filename, len);
+    memcpy(binary_filename, global_debug_dir, global_debug_dir_len);
+    len += global_debug_dir_len;
+    strlcpy(binary_filename + len, debuglink, PATH_MAX - len);
+
+    append_obj(objp);
+    o2 = *objp;
+    o2->base_addr = o1->base_addr;
+    o2->path = o1->path;
+    fill_lines(num_traces, traces, 0, objp, lines, offset);
+}
+
+// check the path pattern of "/usr/lib/debug/.build-id/ab/cdef1234.debug"
+static void
+follow_debuglink_build_id(const char *build_id, size_t build_id_size, int num_traces, void **traces,
+                          obj_info_t **objp, line_info_t *lines, int offset)
+{
+    static const char global_debug_dir[] = "/usr/lib/debug/.build-id/";
+    const size_t global_debug_dir_len = sizeof(global_debug_dir) - 1;
+    char *p;
+    obj_info_t *o1 = *objp, *o2;
+    size_t i;
+
+    if (PATH_MAX < global_debug_dir_len + 1 + build_id_size * 2 + 6) return;
+
+    memcpy(binary_filename, global_debug_dir, global_debug_dir_len);
+    p = binary_filename + global_debug_dir_len;
+    for (i = 0; i < build_id_size; i++) {
+        static const char tbl[] = "0123456789abcdef";
+        unsigned char n = build_id[i];
+        *p++ = tbl[n / 16];
+        *p++ = tbl[n % 16];
+        if (i == 0) *p++ = '/';
+    }
+    strcpy(p, ".debug");
+
+    append_obj(objp);
+    o2 = *objp;
+    o2->base_addr = o1->base_addr;
+    o2->path = o1->path;
+    fill_lines(num_traces, traces, 0, objp, lines, offset);
+}
+#endif
+
+enum
+{
+    DW_TAG_compile_unit = 0x11,
+    DW_TAG_inlined_subroutine = 0x1d,
+    DW_TAG_subprogram = 0x2e,
+};
+
+/* Attributes encodings */
+enum
+{
+    DW_AT_sibling = 0x01,
+    DW_AT_location = 0x02,
+    DW_AT_name = 0x03,
+    /* Reserved 0x04 */
+    /* Reserved 0x05 */
+    /* Reserved 0x06 */
+    /* Reserved 0x07 */
+    /* Reserved 0x08 */
+    DW_AT_ordering = 0x09,
+    /* Reserved 0x0a */
+    DW_AT_byte_size = 0x0b,
+    /* Reserved 0x0c */
+    DW_AT_bit_size = 0x0d,
+    /* Reserved 0x0e */
+    /* Reserved 0x0f */
+    DW_AT_stmt_list = 0x10,
+    DW_AT_low_pc = 0x11,
+    DW_AT_high_pc = 0x12,
+    DW_AT_language = 0x13,
+    /* Reserved 0x14 */
+    DW_AT_discr = 0x15,
+    DW_AT_discr_value = 0x16,
+    DW_AT_visibility = 0x17,
+    DW_AT_import = 0x18,
+    DW_AT_string_length = 0x19,
+    DW_AT_common_reference = 0x1a,
+    DW_AT_comp_dir = 0x1b,
+    DW_AT_const_value = 0x1c,
+    DW_AT_containing_type = 0x1d,
+    DW_AT_default_value = 0x1e,
+    /* Reserved 0x1f */
+    DW_AT_inline = 0x20,
+    DW_AT_is_optional = 0x21,
+    DW_AT_lower_bound = 0x22,
+    /* Reserved 0x23 */
+    /* Reserved 0x24 */
+    DW_AT_producer = 0x25,
+    /* Reserved 0x26 */
+    DW_AT_prototyped = 0x27,
+    /* Reserved 0x28 */
+    /* Reserved 0x29 */
+    DW_AT_return_addr = 0x2a,
+    /* Reserved 0x2b */
+    DW_AT_start_scope = 0x2c,
+    /* Reserved 0x2d */
+    DW_AT_bit_stride = 0x2e,
+    DW_AT_upper_bound = 0x2f,
+    /* Reserved 0x30 */
+    DW_AT_abstract_origin = 0x31,
+    DW_AT_accessibility = 0x32,
+    DW_AT_address_class = 0x33,
+    DW_AT_artificial = 0x34,
+    DW_AT_base_types = 0x35,
+    DW_AT_calling_convention = 0x36,
+    DW_AT_count = 0x37,
+    DW_AT_data_member_location = 0x38,
+    DW_AT_decl_column = 0x39,
+    DW_AT_decl_file = 0x3a,
+    DW_AT_decl_line = 0x3b,
+    DW_AT_declaration = 0x3c,
+    DW_AT_discr_list = 0x3d,
+    DW_AT_encoding = 0x3e,
+    DW_AT_external = 0x3f,
+    DW_AT_frame_base = 0x40,
+    DW_AT_friend = 0x41,
+    DW_AT_identifier_case = 0x42,
+    /* Reserved 0x43 */
+    DW_AT_namelist_item = 0x44,
+    DW_AT_priority = 0x45,
+    DW_AT_segment = 0x46,
+    DW_AT_specification = 0x47,
+    DW_AT_static_link = 0x48,
+    DW_AT_type = 0x49,
+    DW_AT_use_location = 0x4a,
+    DW_AT_variable_parameter = 0x4b,
+    DW_AT_virtuality = 0x4c,
+    DW_AT_vtable_elem_location = 0x4d,
+    DW_AT_allocated = 0x4e,
+    DW_AT_associated = 0x4f,
+    DW_AT_data_location = 0x50,
+    DW_AT_byte_stride = 0x51,
+    DW_AT_entry_pc = 0x52,
+    DW_AT_use_UTF8 = 0x53,
+    DW_AT_extension = 0x54,
+    DW_AT_ranges = 0x55,
+    DW_AT_trampoline = 0x56,
+    DW_AT_call_column = 0x57,
+    DW_AT_call_file = 0x58,
+    DW_AT_call_line = 0x59,
+    DW_AT_description = 0x5a,
+    DW_AT_binary_scale = 0x5b,
+    DW_AT_decimal_scale = 0x5c,
+    DW_AT_small = 0x5d,
+    DW_AT_decimal_sign = 0x5e,
+    DW_AT_digit_count = 0x5f,
+    DW_AT_picture_string = 0x60,
+    DW_AT_mutable = 0x61,
+    DW_AT_threads_scaled = 0x62,
+    DW_AT_explicit = 0x63,
+    DW_AT_object_pointer = 0x64,
+    DW_AT_endianity = 0x65,
+    DW_AT_elemental = 0x66,
+    DW_AT_pure = 0x67,
+    DW_AT_recursive = 0x68,
+    DW_AT_signature = 0x69,
+    DW_AT_main_subprogram = 0x6a,
+    DW_AT_data_bit_offset = 0x6b,
+    DW_AT_const_expr = 0x6c,
+    DW_AT_enum_class = 0x6d,
+    DW_AT_linkage_name = 0x6e,
+    DW_AT_string_length_bit_size = 0x6f,
+    DW_AT_string_length_byte_size = 0x70,
+    DW_AT_rank = 0x71,
+    DW_AT_str_offsets_base = 0x72,
+    DW_AT_addr_base = 0x73,
+    DW_AT_rnglists_base = 0x74,
+    /* Reserved 0x75 */
+    DW_AT_dwo_name = 0x76,
+    DW_AT_reference = 0x77,
+    DW_AT_rvalue_reference = 0x78,
+    DW_AT_macros = 0x79,
+    DW_AT_call_all_calls = 0x7a,
+    DW_AT_call_all_source_calls = 0x7b,
+    DW_AT_call_all_tail_calls = 0x7c,
+    DW_AT_call_return_pc = 0x7d,
+    DW_AT_call_value = 0x7e,
+    DW_AT_call_origin = 0x7f,
+    DW_AT_call_parameter = 0x80,
+    DW_AT_call_pc = 0x81,
+    DW_AT_call_tail_call = 0x82,
+    DW_AT_call_target = 0x83,
+    DW_AT_call_target_clobbered = 0x84,
+    DW_AT_call_data_location = 0x85,
+    DW_AT_call_data_value = 0x86,
+    DW_AT_noreturn = 0x87,
+    DW_AT_alignment = 0x88,
+    DW_AT_export_symbols = 0x89,
+    DW_AT_deleted = 0x8a,
+    DW_AT_defaulted = 0x8b,
+    DW_AT_loclists_base = 0x8c,
+    DW_AT_lo_user = 0x2000,
+    DW_AT_hi_user = 0x3fff
+};
+
+/* Attribute form encodings */
+enum
+{
+    DW_FORM_addr = 0x01,
+    /* Reserved 0x02 */
+    DW_FORM_block2 = 0x03,
+    DW_FORM_block4 = 0x04,
+    DW_FORM_data2 = 0x05,
+    DW_FORM_data4 = 0x06,
+    DW_FORM_data8 = 0x07,
+    DW_FORM_string = 0x08,
+    DW_FORM_block = 0x09,
+    DW_FORM_block1 = 0x0a,
+    DW_FORM_data1 = 0x0b,
+    DW_FORM_flag = 0x0c,
+    DW_FORM_sdata = 0x0d,
+    DW_FORM_strp = 0x0e,
+    DW_FORM_udata = 0x0f,
+    DW_FORM_ref_addr = 0x10,
+    DW_FORM_ref1 = 0x11,
+    DW_FORM_ref2 = 0x12,
+    DW_FORM_ref4 = 0x13,
+    DW_FORM_ref8 = 0x14,
+    DW_FORM_ref_udata = 0x15,
+    DW_FORM_indirect = 0x16,
+    DW_FORM_sec_offset = 0x17,
+    DW_FORM_exprloc = 0x18,
+    DW_FORM_flag_present = 0x19,
+    DW_FORM_strx = 0x1a,
+    DW_FORM_addrx = 0x1b,
+    DW_FORM_ref_sup4 = 0x1c,
+    DW_FORM_strp_sup = 0x1d,
+    DW_FORM_data16 = 0x1e,
+    DW_FORM_line_strp = 0x1f,
+    DW_FORM_ref_sig8 = 0x20,
+    DW_FORM_implicit_const = 0x21,
+    DW_FORM_loclistx = 0x22,
+    DW_FORM_rnglistx = 0x23,
+    DW_FORM_ref_sup8 = 0x24,
+    DW_FORM_strx1 = 0x25,
+    DW_FORM_strx2 = 0x26,
+    DW_FORM_strx3 = 0x27,
+    DW_FORM_strx4 = 0x28,
+    DW_FORM_addrx1 = 0x29,
+    DW_FORM_addrx2 = 0x2a,
+    DW_FORM_addrx3 = 0x2b,
+    DW_FORM_addrx4 = 0x2c
+};
+
+enum {
+    VAL_none = 0,
+    VAL_cstr = 1,
+    VAL_data = 2,
+    VAL_uint = 3,
+    VAL_int = 4
+};
+
+# define ABBREV_TABLE_SIZE 256
+typedef struct {
+    obj_info_t *obj;
+    char *file;
+    char *current_cu;
+    uint64_t current_low_pc;
+    char *debug_line_cu_end;
+    char *debug_line_files;
+    char *debug_line_directories;
+    char *p;
+    char *cu_end;
+    char *pend;
+    char *q0;
+    char *q;
+    int format; // 4 or 8
+    uint8_t address_size;
+    int level;
+    char *abbrev_table[ABBREV_TABLE_SIZE];
+} DebugInfoReader;
+
+typedef struct {
+    ptrdiff_t pos;
+    int tag;
+    int has_children;
+} DIE;
+
+typedef struct {
+    union {
+        char *ptr;
+        uint64_t uint64;
+        int64_t int64;
+    } as;
+    uint64_t off;
+    uint64_t at;
+    uint64_t form;
+    size_t size;
+    int type;
+} DebugInfoValue;
+
+/* TODO: Big Endian */
+#define MERGE_2INTS(a,b,sz) (((uint64_t)(b)<<sz)|(a))
+
+static uint16_t
+get_uint16(const uint8_t *p)
+{
+    return (uint16_t)MERGE_2INTS(p[0],p[1],8);
+}
+
+static uint32_t
+get_uint32(const uint8_t *p)
+{
+    return (uint32_t)MERGE_2INTS(get_uint16(p),get_uint16(p+2),16);
+}
+
+static uint64_t
+get_uint64(const uint8_t *p)
+{
+    return MERGE_2INTS(get_uint32(p),get_uint32(p+4),32);
+}
+
+static uint8_t
+read_uint8(char **ptr)
+{
+    const unsigned char *p = (const unsigned char *)*ptr;
+    *ptr = (char *)(p + 1);
+    return *p;
+}
+
+static uint16_t
+read_uint16(char **ptr)
+{
+    const unsigned char *p = (const unsigned char *)*ptr;
+    *ptr = (char *)(p + 2);
+    return get_uint16(p);
+}
+
+static uint32_t
+read_uint24(char **ptr)
+{
+    const unsigned char *p = (const unsigned char *)*ptr;
+    *ptr = (char *)(p + 3);
+    return (*p << 16) | get_uint16(p+1);
+}
+
+static uint32_t
+read_uint32(char **ptr)
+{
+    const unsigned char *p = (const unsigned char *)*ptr;
+    *ptr = (char *)(p + 4);
+    return get_uint32(p);
+}
+
+static uint64_t
+read_uint64(char **ptr)
+{
+    const unsigned char *p = (const unsigned char *)*ptr;
+    *ptr = (char *)(p + 8);
+    return get_uint64(p);
+}
+
+static uintptr_t
+read_uintptr(char **ptr)
+{
+    const unsigned char *p = (const unsigned char *)*ptr;
+    *ptr = (char *)(p + SIZEOF_VOIDP);
+#if SIZEOF_VOIDP == 8
+    return get_uint64(p);
+#else
+    return get_uint32(p);
+#endif
+}
+
+static uint64_t
+read_uint(DebugInfoReader *reader)
+{
+    if (reader->format == 4) {
+        return read_uint32(&reader->p);
+    } else { /* 64 bit */
+        return read_uint64(&reader->p);
+    }
+}
+
+static uint64_t
+read_uleb128(DebugInfoReader *reader)
+{
+    return uleb128(&reader->p);
+}
+
+static int64_t
+read_sleb128(DebugInfoReader *reader)
+{
+    return sleb128(&reader->p);
+}
+
+static void
+debug_info_reader_init(DebugInfoReader *reader, obj_info_t *obj)
+{
+    reader->file = obj->mapped;
+    reader->obj = obj;
+    reader->p = obj->debug_info.ptr;
+    reader->pend = obj->debug_info.ptr + obj->debug_info.size;
+    reader->debug_line_cu_end = obj->debug_line.ptr;
+    reader->current_low_pc = 0;
+}
+
+static void
+di_read_debug_abbrev_cu(DebugInfoReader *reader)
+{
+    uint64_t prev = 0;
+    char *p = reader->q0;
+    for (;;) {
+        uint64_t abbrev_number = uleb128(&p);
+        if (abbrev_number <= prev) break;
+        if (abbrev_number < ABBREV_TABLE_SIZE) {
+            reader->abbrev_table[abbrev_number] = p;
+        }
+        prev = abbrev_number;
+        uleb128(&p); /* tag */
+        p++; /* has_children */
+        /* skip content */
+        for (;;) {
+            uint64_t at = uleb128(&p);
+            uint64_t form = uleb128(&p);
+            if (!at && !form) break;
+        }
+    }
+}
+
+static int
+di_read_debug_line_cu(DebugInfoReader *reader)
+{
+    const char *p;
+    struct LineNumberProgramHeader header;
+
+    p = (const char *)reader->debug_line_cu_end;
+    if (parse_debug_line_header(&p, &header))
+        return -1;
+
+    reader->debug_line_cu_end = (char *)header.cu_end;
+    reader->debug_line_directories = (char *)header.include_directories;
+    reader->debug_line_files = (char *)header.filenames;
+
+    return 0;
+}
+
+static void
+set_uint_value(DebugInfoValue *v, uint64_t n)
+{
+    v->as.uint64 = n;
+    v->type = VAL_uint;
+}
+
+static void
+set_int_value(DebugInfoValue *v, int64_t n)
+{
+    v->as.int64 = n;
+    v->type = VAL_int;
+}
+
+static void
+set_cstr_value(DebugInfoValue *v, char *s)
+{
+    v->as.ptr = s;
+    v->off = 0;
+    v->type = VAL_cstr;
+}
+
+static void
+set_cstrp_value(DebugInfoValue *v, char *s, uint64_t off)
+{
+    v->as.ptr = s;
+    v->off = off;
+    v->type = VAL_cstr;
+}
+
+static void
+set_data_value(DebugInfoValue *v, char *s)
+{
+    v->as.ptr = s;
+    v->type = VAL_data;
+}
+
+static const char *
+get_cstr_value(DebugInfoValue *v)
+{
+    if (v->as.ptr) {
+        return v->as.ptr + v->off;
+    } else {
+        return NULL;
+    }
+}
+
+static void
+debug_info_reader_read_value(DebugInfoReader *reader, uint64_t form, DebugInfoValue *v)
+{
+    switch (form) {
+      case DW_FORM_addr:
+        if (reader->address_size == 4) {
+            set_uint_value(v, read_uint32(&reader->p));
+        } else if (reader->address_size == 8) {
+            set_uint_value(v, read_uint64(&reader->p));
+        } else {
+            fprintf(stderr,"unknown address_size:%d", reader->address_size);
+            abort();
+        }
+        break;
+      case DW_FORM_block2:
+        v->size = read_uint16(&reader->p);
+        set_data_value(v, reader->p);
+        reader->p += v->size;
+        break;
+      case DW_FORM_block4:
+        v->size = read_uint32(&reader->p);
+        set_data_value(v, reader->p);
+        reader->p += v->size;
+        break;
+      case DW_FORM_data2:
+        set_uint_value(v, read_uint16(&reader->p));
+        break;
+      case DW_FORM_data4:
+        set_uint_value(v, read_uint32(&reader->p));
+        break;
+      case DW_FORM_data8:
+        set_uint_value(v, read_uint64(&reader->p));
+        break;
+      case DW_FORM_string:
+        v->size = strlen(reader->p);
+        set_cstr_value(v, reader->p);
+        reader->p += v->size + 1;
+        break;
+      case DW_FORM_block:
+        v->size = uleb128(&reader->p);
+        set_data_value(v, reader->p);
+        reader->p += v->size;
+        break;
+      case DW_FORM_block1:
+        v->size = read_uint8(&reader->p);
+        set_data_value(v, reader->p);
+        reader->p += v->size;
+        break;
+      case DW_FORM_data1:
+        set_uint_value(v, read_uint8(&reader->p));
+        break;
+      case DW_FORM_flag:
+        set_uint_value(v, read_uint8(&reader->p));
+        break;
+      case DW_FORM_sdata:
+        set_int_value(v, read_sleb128(reader));
+        break;
+      case DW_FORM_strp:
+        set_cstrp_value(v, reader->obj->debug_str.ptr, read_uint(reader));
+        break;
+      case DW_FORM_udata:
+        set_uint_value(v, read_uleb128(reader));
+        break;
+      case DW_FORM_ref_addr:
+        if (reader->address_size == 4) {
+            set_uint_value(v, read_uint32(&reader->p));
+        } else if (reader->address_size == 8) {
+            set_uint_value(v, read_uint64(&reader->p));
+        } else {
+            fprintf(stderr,"unknown address_size:%d", reader->address_size);
+            abort();
+        }
+        break;
+      case DW_FORM_ref1:
+        set_uint_value(v, read_uint8(&reader->p));
+        break;
+      case DW_FORM_ref2:
+        set_uint_value(v, read_uint16(&reader->p));
+        break;
+      case DW_FORM_ref4:
+        set_uint_value(v, read_uint32(&reader->p));
+        break;
+      case DW_FORM_ref8:
+        set_uint_value(v, read_uint64(&reader->p));
+        break;
+      case DW_FORM_ref_udata:
+        set_uint_value(v, uleb128(&reader->p));
+        break;
+      case DW_FORM_indirect:
+        /* TODO: read the referred value */
+        set_uint_value(v, uleb128(&reader->p));
+        break;
+      case DW_FORM_sec_offset:
+        set_uint_value(v, read_uint(reader)); /* offset */
+        /* addrptr: debug_addr */
+        /* lineptr: debug_line */
+        /* loclist: debug_loclists */
+        /* loclistptr: debug_loclists */
+        /* macptr: debug_macro */
+        /* rnglist: debug_rnglists */
+        /* rnglistptr: debug_rnglists */
+        /* stroffsetsptr: debug_str_offsets */
+        break;
+      case DW_FORM_exprloc:
+        v->size = (size_t)read_uleb128(reader);
+        set_data_value(v, reader->p);
+        reader->p += v->size;
+        break;
+      case DW_FORM_flag_present:
+        set_uint_value(v, 1);
+        break;
+      case DW_FORM_strx:
+        set_uint_value(v, uleb128(&reader->p));
+        break;
+      case DW_FORM_addrx:
+        /* TODO: read .debug_addr */
+        set_uint_value(v, uleb128(&reader->p));
+        break;
+      case DW_FORM_ref_sup4:
+        set_uint_value(v, read_uint32(&reader->p));
+        break;
+      case DW_FORM_strp_sup:
+        set_uint_value(v, read_uint(reader));
+        /* *p = reader->sup_file + reader->sup_str->sh_offset + ret; */
+        break;
+      case DW_FORM_data16:
+        v->size = 16;
+        set_data_value(v, reader->p);
+        reader->p += v->size;
+        break;
+      case DW_FORM_line_strp:
+        set_uint_value(v, read_uint(reader));
+        /* *p = reader->file + reader->line->sh_offset + ret; */
+        break;
+      case DW_FORM_ref_sig8:
+        set_uint_value(v, read_uint64(&reader->p));
+        break;
+      case DW_FORM_implicit_const:
+        set_int_value(v, sleb128(&reader->q));
+        break;
+      case DW_FORM_loclistx:
+        set_uint_value(v, read_uleb128(reader));
+        break;
+      case DW_FORM_rnglistx:
+        set_uint_value(v, read_uleb128(reader));
+        break;
+      case DW_FORM_ref_sup8:
+        set_uint_value(v, read_uint64(&reader->p));
+        break;
+      case DW_FORM_strx1:
+        set_uint_value(v, read_uint8(&reader->p));
+        break;
+      case DW_FORM_strx2:
+        set_uint_value(v, read_uint16(&reader->p));
+        break;
+      case DW_FORM_strx3:
+        set_uint_value(v, read_uint24(&reader->p));
+        break;
+      case DW_FORM_strx4:
+        set_uint_value(v, read_uint32(&reader->p));
+        break;
+      case DW_FORM_addrx1:
+        set_uint_value(v, read_uint8(&reader->p));
+        break;
+      case DW_FORM_addrx2:
+        set_uint_value(v, read_uint16(&reader->p));
+        break;
+      case DW_FORM_addrx3:
+        set_uint_value(v, read_uint24(&reader->p));
+        break;
+      case DW_FORM_addrx4:
+        set_uint_value(v, read_uint32(&reader->p));
+        break;
+      case 0:
+        goto fail;
+        break;
+    }
+    return;
+
+  fail:
+    fprintf(stderr, "%d: unsupported form: %#"PRIx64"\n", __LINE__, form);
+    exit(1);
+}
+
+/* find abbrev in current compilation unit */
+static char *
+di_find_abbrev(DebugInfoReader *reader, uint64_t abbrev_number)
+{
+    char *p;
+    if (abbrev_number < ABBREV_TABLE_SIZE) {
+        return reader->abbrev_table[abbrev_number];
+    }
+    p = reader->abbrev_table[ABBREV_TABLE_SIZE-1];
+    /* skip 255th record */
+    uleb128(&p); /* tag */
+    p++; /* has_children */
+    /* skip content */
+    for (;;) {
+        uint64_t at = uleb128(&p);
+        uint64_t form = uleb128(&p);
+        if (!at && !form) break;
+    }
+    for (uint64_t n = uleb128(&p); abbrev_number != n; n = uleb128(&p)) {
+        if (n == 0) {
+            fprintf(stderr,"%d: Abbrev Number %"PRId64" not found\n",__LINE__, abbrev_number);
+            exit(1);
+        }
+        uleb128(&p); /* tag */
+        p++; /* has_children */
+        /* skip content */
+        for (;;) {
+            uint64_t at = uleb128(&p);
+            uint64_t form = uleb128(&p);
+            if (!at && !form) break;
+        }
+    }
+    return p;
+}
+
+#if 0
+static void
+hexdump0(const unsigned char *p, size_t n)
+{
+    size_t i;
+    fprintf(stderr, "     0  1  2  3  4  5  6  7  8  9  A  B  C  D  E  F\n");
+    for (i=0; i < n; i++){
+        switch (i & 15) {
+          case 0:
+            fprintf(stderr, "%02zd: %02X ", i/16, p[i]);
+            break;
+          case 15:
+            fprintf(stderr, "%02X\n", p[i]);
+            break;
+          default:
+            fprintf(stderr, "%02X ", p[i]);
+            break;
+        }
+    }
+    if ((i & 15) != 15) {
+        fprintf(stderr, "\n");
+    }
+}
+#define hexdump(p,n) hexdump0((const unsigned char *)p, n)
+
+static void
+div_inspect(DebugInfoValue *v)
+{
+    switch (v->type) {
+      case VAL_uint:
+        fprintf(stderr,"%d: type:%d size:%zx v:%lx\n",__LINE__,v->type,v->size,v->as.uint64);
+        break;
+      case VAL_int:
+        fprintf(stderr,"%d: type:%d size:%zx v:%ld\n",__LINE__,v->type,v->size,(int64_t)v->as.uint64);
+        break;
+      case VAL_cstr:
+        fprintf(stderr,"%d: type:%d size:%zx v:'%s'\n",__LINE__,v->type,v->size,v->as.ptr);
+        break;
+      case VAL_data:
+        fprintf(stderr,"%d: type:%d size:%zx v:\n",__LINE__,v->type,v->size);
+        hexdump(v->as.ptr, 16);
+        break;
+    }
+}
+#endif
+
+static DIE *
+di_read_die(DebugInfoReader *reader, DIE *die)
+{
+    uint64_t abbrev_number = uleb128(&reader->p);
+    if (abbrev_number == 0) {
+        reader->level--;
+        return NULL;
+    }
+
+    reader->q = di_find_abbrev(reader, abbrev_number);
+
+    die->pos = reader->p - reader->obj->debug_info.ptr - 1;
+    die->tag = (int)uleb128(&reader->q); /* tag */
+    die->has_children = *reader->q++; /* has_children */
+    if (die->has_children) {
+        reader->level++;
+    }
+    return die;
+}
+
+static DebugInfoValue *
+di_read_record(DebugInfoReader *reader, DebugInfoValue *vp)
+{
+    uint64_t at = uleb128(&reader->q);
+    uint64_t form = uleb128(&reader->q);
+    if (!at || !form) return NULL;
+    vp->at = at;
+    vp->form = form;
+    debug_info_reader_read_value(reader, form, vp);
+    return vp;
+}
+
+static void
+di_skip_records(DebugInfoReader *reader)
+{
+    for (;;) {
+        DebugInfoValue v = {{}};
+        uint64_t at = uleb128(&reader->q);
+        uint64_t form = uleb128(&reader->q);
+        if (!at || !form) return;
+        debug_info_reader_read_value(reader, form, &v);
+    }
+}
+
+typedef struct {
+    uint64_t low_pc;
+    uint64_t high_pc;
+    uint64_t ranges;
+    bool low_pc_set;
+    bool high_pc_set;
+    bool ranges_set;
+} ranges_t;
+
+static void
+ranges_set(ranges_t *ptr, DebugInfoValue *v)
+{
+    switch (v->at) {
+      case DW_AT_low_pc:
+        ptr->low_pc = v->as.uint64;
+        ptr->low_pc_set = true;
+        break;
+      case DW_AT_high_pc:
+        if (v->form == DW_FORM_addr) {
+            ptr->high_pc = v->as.uint64;
+        }
+        else {
+            ptr->high_pc = ptr->low_pc + v->as.uint64;
+        }
+        ptr->high_pc_set = true;
+        break;
+      case DW_AT_ranges:
+        ptr->ranges = v->as.uint64;
+        ptr->ranges_set = true;
+        break;
+    }
+}
+
+static uintptr_t
+ranges_include(DebugInfoReader *reader, ranges_t *ptr, uint64_t addr)
+{
+    if (ptr->high_pc_set) {
+        if (ptr->ranges_set || !ptr->low_pc_set) {
+            exit(1);
+        }
+        if (ptr->low_pc <= addr && addr <= ptr->high_pc) {
+            return (uintptr_t)ptr->low_pc;
+        }
+    }
+    else if (ptr->ranges_set) {
+        /* TODO: support base address selection entry */
+        char *p = reader->obj->debug_ranges.ptr + ptr->ranges;
+        uint64_t base = ptr->low_pc_set ? ptr->low_pc : reader->current_low_pc;
+        for (;;) {
+            uintptr_t from = read_uintptr(&p);
+            uintptr_t to = read_uintptr(&p);
+            if (!from && !to) break;
+            if (from == UINTPTR_MAX) {
+                /* base address selection entry */
+                base = to;
+            }
+            else if (base + from <= addr && addr < base + to) {
+                return from;
+            }
+        }
+    }
+    else if (ptr->low_pc_set) {
+        if (ptr->low_pc == addr) {
+            return (uintptr_t)ptr->low_pc;
+        }
+    }
+    return false;
+}
+
+#if 0
+static void
+ranges_inspect(DebugInfoReader *reader, ranges_t *ptr)
+{
+    if (ptr->high_pc_set) {
+        if (ptr->ranges_set || !ptr->low_pc_set) {
+            fprintf(stderr,"low_pc_set:%d high_pc_set:%d ranges_set:%d\n",ptr->low_pc_set,ptr->high_pc_set,ptr->ranges_set);
+            exit(1);
+        }
+        fprintf(stderr,"low_pc:%"PRIx64" high_pc:%"PRIx64"\n",ptr->low_pc,ptr->high_pc);
+    }
+    else if (ptr->ranges_set) {
+        char *p = reader->obj->debug_ranges.ptr + ptr->ranges;
+        fprintf(stderr,"low_pc:%"PRIx64" ranges:%"PRIx64" %lx ",ptr->low_pc,ptr->ranges, p-reader->obj->mapped);
+        for (;;) {
+            uintptr_t from = read_uintptr(&p);
+            uintptr_t to = read_uintptr(&p);
+            if (!from && !to) break;
+            fprintf(stderr,"%"PRIx64"-%"PRIx64" ",ptr->low_pc+from,ptr->low_pc+to);
+        }
+        fprintf(stderr,"\n");
+    }
+    else if (ptr->low_pc_set) {
+        fprintf(stderr,"low_pc:%"PRIx64"\n",ptr->low_pc);
+    }
+    else {
+        fprintf(stderr,"empty\n");
+    }
+}
+#endif
+
+static int
+di_read_cu(DebugInfoReader *reader)
+{
+    uint64_t unit_length;
+    uint16_t version;
+    uint64_t debug_abbrev_offset;
+    reader->format = 4;
+    reader->current_cu = reader->p;
+    unit_length = read_uint32(&reader->p);
+    if (unit_length == 0xffffffff) {
+        unit_length = read_uint64(&reader->p);
+        reader->format = 8;
+    }
+    reader->cu_end = reader->p + unit_length;
+    version = read_uint16(&reader->p);
+    if (version > 5) {
+        return -1;
+    }
+    else if (version == 5) {
+        /* unit_type = */ read_uint8(&reader->p);
+        reader->address_size = read_uint8(&reader->p);
+        debug_abbrev_offset = read_uint(reader);
+    }
+    else {
+        debug_abbrev_offset = read_uint(reader);
+        reader->address_size = read_uint8(&reader->p);
+    }
+    reader->q0 = reader->obj->debug_abbrev.ptr + debug_abbrev_offset;
+
+    reader->level = 0;
+    di_read_debug_abbrev_cu(reader);
+    if (di_read_debug_line_cu(reader)) return -1;
+
+#if defined(__GNUC__) && !defined(__clang__) && !defined(__INTEL_COMPILER_BUILD_DATE)
+    /* Though DWARF specifies "the applicable base address defaults to the base
+       address of the compilation unit", but GCC seems to use zero as default */
+#else
+    do {
+        DIE die;
+
+        if (!di_read_die(reader, &die)) continue;
+
+        if (die.tag != DW_TAG_compile_unit) {
+            di_skip_records(reader);
+            break;
+        }
+
+        /* enumerate abbrev */
+        for (;;) {
+            DebugInfoValue v = {{}};
+            if (!di_read_record(reader, &v)) break;
+            switch (v.at) {
+              case DW_AT_low_pc:
+                reader->current_low_pc = v.as.uint64;
+                break;
+            }
+        }
+    } while (0);
+#endif
+    return 0;
+}
+
+static void
+read_abstract_origin(DebugInfoReader *reader, uint64_t abstract_origin, line_info_t *line)
+{
+    char *p = reader->p;
+    char *q = reader->q;
+    int level = reader->level;
+    DIE die;
+
+    reader->p = reader->current_cu + abstract_origin;
+    if (!di_read_die(reader, &die)) goto finish;
+
+    /* enumerate abbrev */
+    for (;;) {
+        DebugInfoValue v = {{}};
+        if (!di_read_record(reader, &v)) break;
+        switch (v.at) {
+          case DW_AT_name:
+            line->sname = get_cstr_value(&v);
+            break;
+        }
+    }
+
+  finish:
+    reader->p = p;
+    reader->q = q;
+    reader->level = level;
+}
+
+static void
+debug_info_read(DebugInfoReader *reader, int num_traces, void **traces,
+         line_info_t *lines, int offset) {
+    while (reader->p < reader->cu_end) {
+        DIE die;
+        ranges_t ranges = {};
+        line_info_t line = {};
+
+        if (!di_read_die(reader, &die)) continue;
+        /* fprintf(stderr,"%d:%tx: <%d>\n",__LINE__,die.pos,reader->level,die.tag); */
+
+        if (die.tag != DW_TAG_subprogram && die.tag != DW_TAG_inlined_subroutine) {
+          skip_die:
+            di_skip_records(reader);
+            continue;
+        }
+
+        /* enumerate abbrev */
+        for (;;) {
+            DebugInfoValue v = {{}};
+            /* ptrdiff_t pos = reader->p - reader->p0; */
+            if (!di_read_record(reader, &v)) break;
+            /* fprintf(stderr,"\n%d:%tx: AT:%lx FORM:%lx\n",__LINE__,pos,v.at,v.form); */
+            /* div_inspect(&v); */
+            switch (v.at) {
+              case DW_AT_name:
+                line.sname = get_cstr_value(&v);
+                break;
+              case DW_AT_call_file:
+                fill_filename((int)v.as.uint64, reader->debug_line_directories, reader->debug_line_files, &line, reader->obj);
+                break;
+              case DW_AT_call_line:
+                line.line = (int)v.as.uint64;
+                break;
+              case DW_AT_low_pc:
+              case DW_AT_high_pc:
+              case DW_AT_ranges:
+                ranges_set(&ranges, &v);
+                break;
+              case DW_AT_declaration:
+                goto skip_die;
+              case DW_AT_inline:
+                /* 1 or 3 */
+                break; /* goto skip_die; */
+              case DW_AT_abstract_origin:
+                read_abstract_origin(reader, v.as.uint64, &line);
+                break; /* goto skip_die; */
+            }
+        }
+        /* ranges_inspect(reader, &ranges); */
+        /* fprintf(stderr,"%d:%tx: %x ",__LINE__,diepos,die.tag); */
+        for (int i=offset; i < num_traces; i++) {
+            uintptr_t addr = (uintptr_t)traces[i];
+            uintptr_t offset = addr - reader->obj->base_addr + reader->obj->vmaddr;
+            uintptr_t saddr = ranges_include(reader, &ranges, offset);
+            if (saddr) {
+                /* fprintf(stderr, "%d:%tx: %d %lx->%lx %x %s: %s/%s %d %s %s %s\n",__LINE__,die.pos, i,addr,offset, die.tag,line.sname,line.dirname,line.filename,line.line,reader->obj->path,line.sname,lines[i].sname); */
+                if (lines[i].sname) {
+                    line_info_t *lp = malloc(sizeof(line_info_t));
+                    memcpy(lp, &lines[i], sizeof(line_info_t));
+                    lines[i].next = lp;
+                    lp->dirname = line.dirname;
+                    lp->filename = line.filename;
+                    lp->line = line.line;
+                    lp->saddr = 0;
+                }
+                lines[i].path = reader->obj->path;
+                lines[i].base_addr = line.base_addr;
+                lines[i].sname = line.sname;
+                lines[i].saddr = saddr + reader->obj->base_addr - reader->obj->vmaddr;
+            }
+        }
+    }
+}
+
+#ifdef USE_ELF
+static unsigned long
+uncompress_debug_section(ElfW(Shdr) *shdr, char *file, char **ptr)
+{
+    *ptr = NULL;
+#ifdef SUPPORT_COMPRESSED_DEBUG_LINE
+    ElfW(Chdr) *chdr = (ElfW(Chdr) *)(file + shdr->sh_offset);
+    unsigned long destsize = chdr->ch_size;
+    int ret = 0;
+
+    if (chdr->ch_type != ELFCOMPRESS_ZLIB) {
+	/* unsupported compression type */
+	return 0;
+    }
+
+    *ptr = malloc(destsize);
+    if (!*ptr) return 0;
+    ret = uncompress((Bytef *)*ptr, &destsize,
+	    (const Bytef*)chdr + sizeof(ElfW(Chdr)),
+            shdr->sh_size - sizeof(ElfW(Chdr)));
+    if (ret != Z_OK) goto fail;
+    return destsize;
+
+fail:
+    free(*ptr);
+    *ptr = NULL;
+#endif
+    return 0;
+}
+
+/* read file and fill lines */
+static uintptr_t
+fill_lines(int num_traces, void **traces, int check_debuglink,
+	   obj_info_t **objp, line_info_t *lines, int offset)
+{
+    int i, j;
+    char *shstr;
+    ElfW(Ehdr) *ehdr;
+    ElfW(Shdr) *shdr, *shstr_shdr;
+    ElfW(Shdr) *gnu_debuglink_shdr = NULL;
+    ElfW(Shdr) *note_gnu_build_id = NULL;
+    int fd;
+    off_t filesize;
+    char *file;
+    ElfW(Shdr) *symtab_shdr = NULL, *strtab_shdr = NULL;
+    ElfW(Shdr) *dynsym_shdr = NULL, *dynstr_shdr = NULL;
+    obj_info_t *obj = *objp;
+    uintptr_t dladdr_fbase = 0;
+
+    fd = open(binary_filename, O_RDONLY);
+    if (fd < 0) {
+	goto fail;
+    }
+    filesize = lseek(fd, 0, SEEK_END);
+    if (filesize < 0) {
+	int e = errno;
+	close(fd);
+	kprintf("lseek: %s\n", strerror(e));
+	goto fail;
+    }
+#if SIZEOF_OFF_T > SIZEOF_SIZE_T
+    if (filesize > (off_t)SIZE_MAX) {
+	close(fd);
+	kprintf("Too large file %s\n", binary_filename);
+	goto fail;
+    }
+#endif
+    lseek(fd, 0, SEEK_SET);
+    /* async-signal unsafe */
+    file = (char *)mmap(NULL, (size_t)filesize, PROT_READ, MAP_SHARED, fd, 0);
+    if (file == MAP_FAILED) {
+	int e = errno;
+	close(fd);
+	kprintf("mmap: %s\n", strerror(e));
+	goto fail;
+    }
+    close(fd);
+
+    ehdr = (ElfW(Ehdr) *)file;
+    if (memcmp(ehdr->e_ident, "\177ELF", 4) != 0) {
+	/*
+	 * Huh? Maybe filename was overridden by setproctitle() and
+	 * it match non-elf file.
+	 */
+	goto fail;
+    }
+    obj->mapped = file;
+    obj->mapped_size = (size_t)filesize;
+
+    shdr = (ElfW(Shdr) *)(file + ehdr->e_shoff);
+
+    shstr_shdr = shdr + ehdr->e_shstrndx;
+    shstr = file + shstr_shdr->sh_offset;
+
+    for (i = 0; i < ehdr->e_shnum; i++) {
+        char *section_name = shstr + shdr[i].sh_name;
+	switch (shdr[i].sh_type) {
+	  case SHT_STRTAB:
+	    if (!strcmp(section_name, ".strtab")) {
+		strtab_shdr = shdr + i;
+	    }
+	    else if (!strcmp(section_name, ".dynstr")) {
+		dynstr_shdr = shdr + i;
+	    }
+	    break;
+	  case SHT_SYMTAB:
+	    /* if (!strcmp(section_name, ".symtab")) */
+	    symtab_shdr = shdr + i;
+	    break;
+	  case SHT_DYNSYM:
+	    /* if (!strcmp(section_name, ".dynsym")) */
+	    dynsym_shdr = shdr + i;
+	    break;
+          case SHT_NOTE:
+            if (!strcmp(section_name, ".note.gnu.build-id")) {
+                note_gnu_build_id = shdr + i;
+            }
+            break;
+	  case SHT_PROGBITS:
+	    if (!strcmp(section_name, ".gnu_debuglink")) {
+		gnu_debuglink_shdr = shdr + i;
+	    }
+            else {
+                const char *debug_section_names[] = {
+                    ".debug_abbrev",
+                    ".debug_info",
+                    ".debug_line",
+                    ".debug_ranges",
+                    ".debug_str"
+                };
+
+                for (j=0; j < DWARF_SECTION_COUNT; j++) {
+                    struct dwarf_section *s = obj_dwarf_section_at(obj, j);
+
+                    if (strcmp(section_name, debug_section_names[j]) != 0)
+                        continue;
+
+                    s->ptr = file + shdr[i].sh_offset;
+                    s->size = shdr[i].sh_size;
+                    s->flags = shdr[i].sh_flags;
+                    if (s->flags & SHF_COMPRESSED) {
+                        s->size = uncompress_debug_section(&shdr[i], file, &s->ptr);
+                        if (!s->size) goto fail;
+                    }
+                    break;
+                }
+            }
+	    break;
+	}
+    }
+
+    if (offset == -1) {
+	/* main executable */
+	offset = 0;
+	if (dynsym_shdr && dynstr_shdr) {
+	    char *strtab = file + dynstr_shdr->sh_offset;
+	    ElfW(Sym) *symtab = (ElfW(Sym) *)(file + dynsym_shdr->sh_offset);
+	    int symtab_count = (int)(dynsym_shdr->sh_size / sizeof(ElfW(Sym)));
+            void *handle = dlopen(NULL, RTLD_NOW|RTLD_LOCAL);
+            if (handle) {
+                for (j = 0; j < symtab_count; j++) {
+                    ElfW(Sym) *sym = &symtab[j];
+                    Dl_info info;
+                    void *s;
+                    if (ELF_ST_TYPE(sym->st_info) != STT_FUNC || sym->st_size == 0) continue;
+                    s = dlsym(handle, strtab + sym->st_name);
+                    if (s && dladdr(s, &info)) {
+                        obj->base_addr = dladdr_fbase;
+                        dladdr_fbase = (uintptr_t)info.dli_fbase;
+                        break;
+                    }
+                }
+                dlclose(handle);
+            }
+	    if (ehdr->e_type == ET_EXEC) {
+		obj->base_addr = 0;
+	    }
+	    else {
+		/* PIE (position-independent executable) */
+		obj->base_addr = dladdr_fbase;
+	    }
+	}
+    }
+
+    if (obj->debug_info.ptr && obj->debug_abbrev.ptr) {
+        DebugInfoReader reader;
+        debug_info_reader_init(&reader, obj);
+        i = 0;
+        while (reader.p < reader.pend) {
+            /* fprintf(stderr, "%d:%tx: CU[%d]\n", __LINE__, reader.p - reader.obj->debug_info.ptr, i++); */
+            if (di_read_cu(&reader)) goto use_symtab;
+            debug_info_read(&reader, num_traces, traces, lines, offset);
+        }
+    }
+    else {
+        /* This file doesn't have dwarf, use symtab or dynsym */
+use_symtab:
+        if (!symtab_shdr) {
+            /* This file doesn't have symtab, use dynsym instead */
+            symtab_shdr = dynsym_shdr;
+            strtab_shdr = dynstr_shdr;
+        }
+
+        if (symtab_shdr && strtab_shdr) {
+            char *strtab = file + strtab_shdr->sh_offset;
+            ElfW(Sym) *symtab = (ElfW(Sym) *)(file + symtab_shdr->sh_offset);
+            int symtab_count = (int)(symtab_shdr->sh_size / sizeof(ElfW(Sym)));
+            for (j = 0; j < symtab_count; j++) {
+                ElfW(Sym) *sym = &symtab[j];
+                uintptr_t saddr = (uintptr_t)sym->st_value + obj->base_addr;
+                if (ELF_ST_TYPE(sym->st_info) != STT_FUNC) continue;
+                for (i = offset; i < num_traces; i++) {
+                    uintptr_t d = (uintptr_t)traces[i] - saddr;
+                    if (lines[i].line > 0 || d > (uintptr_t)sym->st_size)
+                        continue;
+                    /* fill symbol name and addr from .symtab */
+                    if (!lines[i].sname) lines[i].sname = strtab + sym->st_name;
+                    lines[i].saddr = saddr;
+                    lines[i].path  = obj->path;
+                    lines[i].base_addr = obj->base_addr;
+                }
+            }
+        }
+    }
+
+    if (!obj->debug_line.ptr) {
+	/* This file doesn't have .debug_line section,
+	   let's check .gnu_debuglink section instead. */
+	if (gnu_debuglink_shdr && check_debuglink) {
+	    follow_debuglink(file + gnu_debuglink_shdr->sh_offset,
+			     num_traces, traces,
+			     objp, lines, offset);
+	}
+        if (note_gnu_build_id && check_debuglink) {
+            ElfW(Nhdr) *nhdr = (ElfW(Nhdr)*) (file + note_gnu_build_id->sh_offset);
+            const char *build_id = (char *)(nhdr + 1) + nhdr->n_namesz;
+            follow_debuglink_build_id(build_id, nhdr->n_descsz,
+			       num_traces, traces,
+			       objp, lines, offset);
+        }
+	goto finish;
+    }
+
+    if (parse_debug_line(num_traces, traces,
+            obj->debug_line.ptr,
+            obj->debug_line.size,
+            obj, lines, offset) == -1)
+        goto fail;
+
+finish:
+    return dladdr_fbase;
+fail:
+    return (uintptr_t)-1;
+}
+#else /* Mach-O */
+/* read file and fill lines */
+static uintptr_t
+fill_lines(int num_traces, void **traces, int check_debuglink,
+        obj_info_t **objp, line_info_t *lines, int offset)
+{
+# ifdef __LP64__
+#  define LP(x) x##_64
+# else
+#  define LP(x) x
+# endif
+    int fd;
+    off_t filesize;
+    char *file, *p = NULL;
+    obj_info_t *obj = *objp;
+    struct LP(mach_header) *header;
+    uintptr_t dladdr_fbase = 0;
+
+    {
+        char *s = binary_filename;
+        char *base = strrchr(binary_filename, '/')+1;
+        size_t max = PATH_MAX;
+        size_t size = strlen(binary_filename);
+        size_t basesize = size - (base - binary_filename);
+        s += size;
+        max -= size;
+        p = s;
+        size = strlcpy(s, ".dSYM/Contents/Resources/DWARF/", max);
+        if (size == 0) goto fail;
+        s += size;
+        max -= size;
+        if (max <= basesize) goto fail;
+        memcpy(s, base, basesize);
+        s[basesize] = 0;
+
+        fd = open(binary_filename, O_RDONLY);
+        if (fd < 0) {
+            *p = 0; /* binary_filename becomes original file name */
+            fd = open(binary_filename, O_RDONLY);
+            if (fd < 0) {
+                goto fail;
+            }
+        }
+    }
+
+    filesize = lseek(fd, 0, SEEK_END);
+    if (filesize < 0) {
+        int e = errno;
+        close(fd);
+        kprintf("lseek: %s\n", strerror(e));
+        goto fail;
+    }
+#if SIZEOF_OFF_T > SIZEOF_SIZE_T
+    if (filesize > (off_t)SIZE_MAX) {
+        close(fd);
+        kprintf("Too large file %s\n", binary_filename);
+        goto fail;
+    }
+#endif
+    lseek(fd, 0, SEEK_SET);
+    /* async-signal unsafe */
+    file = (char *)mmap(NULL, (size_t)filesize, PROT_READ, MAP_SHARED, fd, 0);
+    if (file == MAP_FAILED) {
+        int e = errno;
+        close(fd);
+        kprintf("mmap: %s\n", strerror(e));
+        goto fail;
+    }
+    close(fd);
+
+    obj->mapped = file;
+    obj->mapped_size = (size_t)filesize;
+
+    header = (struct LP(mach_header) *)file;
+    if (header->magic == LP(MH_MAGIC)) {
+        /* non universal binary */
+        p = file;
+    }
+    else if (header->magic == FAT_CIGAM) {
+        struct LP(mach_header) *mhp = _NSGetMachExecuteHeader();
+        struct fat_header *fat = (struct fat_header *)file;
+        char *q = file + sizeof(*fat);
+        uint32_t nfat_arch = __builtin_bswap32(fat->nfat_arch);
+        /* fprintf(stderr,"%d: fat:%s %d\n",__LINE__, binary_filename,nfat_arch); */
+        for (uint32_t i = 0; i < nfat_arch; i++) {
+            struct fat_arch *arch = (struct fat_arch *)q;
+            cpu_type_t cputype = __builtin_bswap32(arch->cputype);
+            cpu_subtype_t cpusubtype = __builtin_bswap32(arch->cpusubtype);
+            uint32_t offset = __builtin_bswap32(arch->offset);
+            /* fprintf(stderr,"%d: fat %d %x/%x %x/%x\n",__LINE__, i, mhp->cputype,mhp->cpusubtype, cputype,cpusubtype); */
+            if (mhp->cputype == cputype &&
+                    (cpu_subtype_t)(mhp->cpusubtype & ~CPU_SUBTYPE_MASK) == cpusubtype) {
+                p = file + offset;
+                file = p;
+                header = (struct LP(mach_header) *)p;
+                if (header->magic == LP(MH_MAGIC)) {
+                    goto found_mach_header;
+                }
+                break;
+            }
+            q += sizeof(*arch);
+        }
+        kprintf("'%s' is not a Mach-O universal binary file!\n",binary_filename);
+        close(fd);
+        goto fail;
+    }
+    else {
+        kprintf("'%s' is not a "
+# ifdef __LP64__
+                "64"
+# else
+                "32"
+# endif
+                "-bit Mach-O file!\n",binary_filename);
+        close(fd);
+        goto fail;
+    }
+found_mach_header:
+    p += sizeof(*header);
+
+    for (uint32_t i = 0; i < (uint32_t)header->ncmds; i++) {
+        struct load_command *lcmd = (struct load_command *)p;
+        switch (lcmd->cmd) {
+          case LP(LC_SEGMENT):
+            {
+                static const char *debug_section_names[] = {
+                    "__debug_abbrev",
+                    "__debug_info",
+                    "__debug_line",
+                    "__debug_ranges",
+                    "__debug_str"
+                };
+                struct LP(segment_command) *scmd = (struct LP(segment_command) *)lcmd;
+                if (strcmp(scmd->segname, "__TEXT") == 0) {
+                    obj->vmaddr = scmd->vmaddr;
+                }
+                else if (strcmp(scmd->segname, "__DWARF") == 0) {
+                    p += sizeof(struct LP(segment_command));
+                    for (uint64_t i = 0; i < scmd->nsects; i++) {
+                        struct LP(section) *sect = (struct LP(section) *)p;
+                        p += sizeof(struct LP(section));
+                        for (int j=0; j < DWARF_SECTION_COUNT; j++) {
+                            struct dwarf_section *s = obj_dwarf_section_at(obj, j);
+
+                            if (strcmp(sect->sectname, debug_section_names[j]) != 0)
+                                continue;
+
+                            s->ptr = file + sect->offset;
+                            s->size = sect->size;
+                            s->flags = sect->flags;
+                            if (s->flags & SHF_COMPRESSED) {
+                                goto fail;
+                            }
+                            break;
+                        }
+                    }
+                }
+            }
+            break;
+
+          case LC_SYMTAB:
+            {
+                struct symtab_command *cmd = (struct symtab_command *)lcmd;
+                struct LP(nlist) *nl = (struct LP(nlist) *)(file + cmd->symoff);
+                char *strtab = file + cmd->stroff, *sname = 0;
+                uint32_t j;
+                uintptr_t saddr = 0;
+                /* kprintf("[%2d]: %x/symtab %p\n", i, cmd->cmd, p); */
+                for (j = 0; j < cmd->nsyms; j++) {
+                    uintptr_t symsize, d;
+                    struct LP(nlist) *e = &nl[j];
+                        /* kprintf("[%2d][%4d]: %02x/%x/%x: %s %llx\n", i, j, e->n_type,e->n_sect,e->n_desc,strtab+e->n_un.n_strx,e->n_value); */
+                    if (e->n_type != N_FUN) continue;
+                    if (e->n_sect) {
+                        saddr = (uintptr_t)e->n_value + obj->base_addr - obj->vmaddr;
+                        sname = strtab + e->n_un.n_strx;
+                        /* kprintf("[%2d][%4d]: %02x/%x/%x: %s %llx\n", i, j, e->n_type,e->n_sect,e->n_desc,strtab+e->n_un.n_strx,e->n_value); */
+                        continue;
+                    }
+                    for (int k = offset; k < num_traces; k++) {
+                        d = (uintptr_t)traces[k] - saddr;
+                        symsize = e->n_value;
+                        /* kprintf("%lx %lx %lx\n",saddr,symsize,traces[k]); */
+                        if (lines[k].line > 0 || d > (uintptr_t)symsize)
+                            continue;
+                        /* fill symbol name and addr from .symtab */
+                        if (!lines[k].sname) lines[k].sname = sname;
+                        lines[k].saddr = saddr;
+                        lines[k].path  = obj->path;
+                        lines[k].base_addr = obj->base_addr;
+                    }
+                }
+            }
+        }
+        p += lcmd->cmdsize;
+    }
+
+    if (obj->debug_info.ptr && obj->debug_abbrev.ptr) {
+        DebugInfoReader reader;
+        debug_info_reader_init(&reader, obj);
+        while (reader.p < reader.pend) {
+            if (di_read_cu(&reader)) goto fail;
+            debug_info_read(&reader, num_traces, traces, lines, offset);
+        }
+    }
+
+    if (parse_debug_line(num_traces, traces,
+            obj->debug_line.ptr,
+            obj->debug_line.size,
+            obj, lines, offset) == -1)
+        goto fail;
+
+    return dladdr_fbase;
+fail:
+    return (uintptr_t)-1;
+}
+#endif
+
+#define HAVE_MAIN_EXE_PATH
+#if defined(__FreeBSD__)
+# include <sys/sysctl.h>
+#endif
+/* ssize_t main_exe_path(void)
+ *
+ * store the path of the main executable to `binary_filename`,
+ * and returns strlen(binary_filename).
+ * it is NUL terminated.
+ */
+#if defined(__linux__) || defined(__NetBSD__)
+static ssize_t
+main_exe_path(void)
+{
+# if defined(__linux__)
+#  define PROC_SELF_EXE "/proc/self/exe"
+# elif defined(__NetBSD__)
+#  define PROC_SELF_EXE "/proc/curproc/exe"
+# endif
+    ssize_t len = readlink(PROC_SELF_EXE, binary_filename, PATH_MAX);
+    if (len < 0) return 0;
+    binary_filename[len] = 0;
+    return len;
+}
+#elif defined(__FreeBSD__)
+static ssize_t
+main_exe_path(void)
+{
+    int mib[4] = {CTL_KERN, KERN_PROC, KERN_PROC_PATHNAME, -1};
+    size_t len = PATH_MAX;
+    int err = sysctl(mib, 4, binary_filename, &len, NULL, 0);
+    if (err) {
+	kprintf("Can't get the path of ruby");
+	return -1;
+    }
+    len--; /* sysctl sets strlen+1 */
+    return len;
+}
+#elif defined(HAVE_LIBPROC_H)
+static ssize_t
+main_exe_path(void)
+{
+    int len = proc_pidpath(getpid(), binary_filename, PATH_MAX);
+    if (len == 0) return 0;
+    binary_filename[len] = 0;
+    return len;
+}
+#else
+#undef HAVE_MAIN_EXE_PATH
+#endif
+
+static void
+print_line0(line_info_t *line, void *address)
+{
+    uintptr_t addr = (uintptr_t)address;
+    uintptr_t d = addr - line->saddr;
+    if (!address) {
+        /* inlined */
+        if (line->dirname && line->dirname[0]) {
+            kprintf("%s(%s) %s/%s:%d\n", line->path, line->sname, line->dirname, line->filename, line->line);
+        }
+        else {
+            kprintf("%s(%s) %s:%d\n", line->path, line->sname, line->filename, line->line);
+        }
+    }
+    else if (!line->path) {
+        kprintf("[0x%"PRIxPTR"]\n", addr);
+    }
+    else if (!line->saddr || !line->sname) {
+        kprintf("%s(0x%"PRIxPTR") [0x%"PRIxPTR"]\n", line->path, addr-line->base_addr, addr);
+    }
+    else if (line->line <= 0) {
+        kprintf("%s(%s+0x%"PRIxPTR") [0x%"PRIxPTR"]\n", line->path, line->sname,
+                d, addr);
+    }
+    else if (!line->filename) {
+        kprintf("%s(%s+0x%"PRIxPTR") [0x%"PRIxPTR"] ???:%d\n", line->path, line->sname,
+                d, addr, line->line);
+    }
+    else if (line->dirname && line->dirname[0]) {
+        kprintf("%s(%s+0x%"PRIxPTR") [0x%"PRIxPTR"] %s/%s:%d\n", line->path, line->sname,
+                d, addr, line->dirname, line->filename, line->line);
+    }
+    else {
+        kprintf("%s(%s+0x%"PRIxPTR") [0x%"PRIxPTR"] %s:%d\n", line->path, line->sname,
+                d, addr, line->filename, line->line);
+    }
+}
+
+static void
+print_line(line_info_t *line, void *address)
+{
+    print_line0(line, address);
+    if (line->next) {
+        print_line(line->next, NULL);
+    }
+}
+
+void
+rb_dump_backtrace_with_lines(int num_traces, void **traces)
+{
+    int i;
+    /* async-signal unsafe */
+    line_info_t *lines = (line_info_t *)calloc(num_traces, sizeof(line_info_t));
+    obj_info_t *obj = NULL;
+    /* 2 is NULL + main executable */
+    void **dladdr_fbases = (void **)calloc(num_traces+2, sizeof(void *));
+#ifdef HAVE_MAIN_EXE_PATH
+    char *main_path = NULL; /* used on printing backtrace */
+    ssize_t len;
+    if ((len = main_exe_path()) > 0) {
+	main_path = (char *)alloca(len + 1);
+	if (main_path) {
+	    uintptr_t addr;
+	    memcpy(main_path, binary_filename, len+1);
+	    append_obj(&obj);
+	    obj->path = main_path;
+	    addr = fill_lines(num_traces, traces, 1, &obj, lines, -1);
+	    if (addr != (uintptr_t)-1) {
+		dladdr_fbases[0] = (void *)addr;
+	    }
+	}
+    }
+#endif
+
+    /* fill source lines by reading dwarf */
+    for (i = 0; i < num_traces; i++) {
+	Dl_info info;
+	if (lines[i].line) continue;
+	if (dladdr(traces[i], &info)) {
+	    const char *path;
+	    void **p;
+
+	    /* skip symbols which is in already checked objects */
+	    /* if the binary is strip-ed, this may effect */
+	    for (p=dladdr_fbases; *p; p++) {
+		if (*p == info.dli_fbase) {
+		    lines[i].path = info.dli_fname;
+		    lines[i].sname = info.dli_sname;
+		    goto next_line;
+		}
+	    }
+	    *p = info.dli_fbase;
+
+	    append_obj(&obj);
+	    obj->base_addr = (uintptr_t)info.dli_fbase;
+	    path = info.dli_fname;
+	    obj->path = path;
+	    lines[i].path = path;
+            lines[i].sname = info.dli_sname;
+            lines[i].saddr = (uintptr_t)info.dli_saddr;
+	    strlcpy(binary_filename, path, PATH_MAX);
+	    if (fill_lines(num_traces, traces, 1, &obj, lines, i) == (uintptr_t)-1)
+		break;
+	}
+next_line:
+	continue;
+    }
+
+    /* output */
+    for (i = 0; i < num_traces; i++) {
+        print_line(&lines[i], traces[i]);
+
+	/* FreeBSD's backtrace may show _start and so on */
+	if (lines[i].sname && strcmp("main", lines[i].sname) == 0)
+	    break;
+    }
+
+    /* free */
+    while (obj) {
+	obj_info_t *o = obj;
+        for (i=0; i < DWARF_SECTION_COUNT; i++) {
+            struct dwarf_section *s = obj_dwarf_section_at(obj, i);
+            if (s->flags & SHF_COMPRESSED) {
+                free(s->ptr);
+            }
+        }
+	if (obj->mapped_size) {
+	    munmap(obj->mapped, obj->mapped_size);
+	}
+	obj = o->next;
+	free(o);
+    }
+    for (i = 0; i < num_traces; i++) {
+        line_info_t *line = lines[i].next;
+        while (line) {
+            line_info_t *l = line;
+            line = line->next;
+            free(l);
+        }
+    }
+    free(lines);
+    free(dladdr_fbases);
+}
+
+/* From FreeBSD's lib/libstand/printf.c */
+/*-
+ * Copyright (c) 1986, 1988, 1991, 1993
+ *	The Regents of the University of California.  All rights reserved.
+ * (c) UNIX System Laboratories, Inc.
+ * All or some portions of this file are derived from material licensed
+ * to the University of California by American Telephone and Telegraph
+ * Co. or Unix System Laboratories, Inc. and are reproduced herein with
+ * the permission of UNIX System Laboratories, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 4. Neither the name of the University nor the names of its contributors
+ *    may be used to endorse or promote products derived from this software
+ *    without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ *
+ *	@(#)subr_prf.c	8.3 (Berkeley) 1/21/94
+ */
+
+#include <stdarg.h>
+#define MAXNBUF (sizeof(intmax_t) * CHAR_BIT + 1)
+static inline int toupper(int c) { return ('A' <= c && c <= 'Z') ? (c&0x5f) : c; }
+#define    hex2ascii(hex)  (hex2ascii_data[hex])
+static const char hex2ascii_data[] = "0123456789abcdefghijklmnopqrstuvwxyz";
+static inline int imax(int a, int b) { return (a > b ? a : b); }
+static int kvprintf(char const *fmt, void (*func)(int), void *arg, int radix, va_list ap);
+
+static void putce(int c)
+{
+    char s[1];
+    ssize_t ret;
+
+    s[0] = (char)c;
+    ret = write(2, s, 1);
+    (void)ret;
+}
+
+static int
+kprintf(const char *fmt, ...)
+{
+	va_list ap;
+	int retval;
+
+	va_start(ap, fmt);
+	retval = kvprintf(fmt, putce, NULL, 10, ap);
+	va_end(ap);
+	return retval;
+}
+
+/*
+ * Put a NUL-terminated ASCII number (base <= 36) in a buffer in reverse
+ * order; return an optional length and a pointer to the last character
+ * written in the buffer (i.e., the first character of the string).
+ * The buffer pointed to by `nbuf' must have length >= MAXNBUF.
+ */
+static char *
+ksprintn(char *nbuf, uintmax_t num, int base, int *lenp, int upper)
+{
+	char *p, c;
+
+	p = nbuf;
+	*p = '\0';
+	do {
+		c = hex2ascii(num % base);
+		*++p = upper ? toupper(c) : c;
+	} while (num /= base);
+	if (lenp)
+		*lenp = (int)(p - nbuf);
+	return (p);
+}
+
+/*
+ * Scaled down version of printf(3).
+ *
+ * Two additional formats:
+ *
+ * The format %b is supported to decode error registers.
+ * Its usage is:
+ *
+ *	printf("reg=%b\n", regval, "<base><arg>*");
+ *
+ * where <base> is the output base expressed as a control character, e.g.
+ * \10 gives octal; \20 gives hex.  Each arg is a sequence of characters,
+ * the first of which gives the bit number to be inspected (origin 1), and
+ * the next characters (up to a control character, i.e. a character <= 32),
+ * give the name of the register.  Thus:
+ *
+ *	kvprintf("reg=%b\n", 3, "\10\2BITTWO\1BITONE\n");
+ *
+ * would produce output:
+ *
+ *	reg=3<BITTWO,BITONE>
+ *
+ * XXX:  %D  -- Hexdump, takes pointer and separator string:
+ *		("%6D", ptr, ":")   -> XX:XX:XX:XX:XX:XX
+ *		("%*D", len, ptr, " " -> XX XX XX XX ...
+ */
+static int
+kvprintf(char const *fmt, void (*func)(int), void *arg, int radix, va_list ap)
+{
+#define PCHAR(c) {int cc=(c); if (func) (*func)(cc); else *d++ = cc; retval++; }
+	char nbuf[MAXNBUF];
+	char *d;
+	const char *p, *percent, *q;
+	unsigned char *up;
+	int ch, n;
+	uintmax_t num;
+	int base, lflag, qflag, tmp, width, ladjust, sharpflag, neg, sign, dot;
+	int cflag, hflag, jflag, tflag, zflag;
+	int dwidth, upper;
+	char padc;
+	int stop = 0, retval = 0;
+
+	num = 0;
+	if (!func)
+		d = (char *) arg;
+	else
+		d = NULL;
+
+	if (fmt == NULL)
+		fmt = "(fmt null)\n";
+
+	if (radix < 2 || radix > 36)
+		radix = 10;
+
+	for (;;) {
+		padc = ' ';
+		width = 0;
+		while ((ch = (unsigned char)*fmt++) != '%' || stop) {
+			if (ch == '\0')
+				return (retval);
+			PCHAR(ch);
+		}
+		percent = fmt - 1;
+		qflag = 0; lflag = 0; ladjust = 0; sharpflag = 0; neg = 0;
+		sign = 0; dot = 0; dwidth = 0; upper = 0;
+		cflag = 0; hflag = 0; jflag = 0; tflag = 0; zflag = 0;
+reswitch:	switch (ch = (unsigned char)*fmt++) {
+		case '.':
+			dot = 1;
+			goto reswitch;
+		case '#':
+			sharpflag = 1;
+			goto reswitch;
+		case '+':
+			sign = 1;
+			goto reswitch;
+		case '-':
+			ladjust = 1;
+			goto reswitch;
+		case '%':
+			PCHAR(ch);
+			break;
+		case '*':
+			if (!dot) {
+				width = va_arg(ap, int);
+				if (width < 0) {
+					ladjust = !ladjust;
+					width = -width;
+				}
+			} else {
+				dwidth = va_arg(ap, int);
+			}
+			goto reswitch;
+		case '0':
+			if (!dot) {
+				padc = '0';
+				goto reswitch;
+			}
+		case '1': case '2': case '3': case '4':
+		case '5': case '6': case '7': case '8': case '9':
+				for (n = 0;; ++fmt) {
+					n = n * 10 + ch - '0';
+					ch = *fmt;
+					if (ch < '0' || ch > '9')
+						break;
+				}
+			if (dot)
+				dwidth = n;
+			else
+				width = n;
+			goto reswitch;
+		case 'b':
+			num = (unsigned int)va_arg(ap, int);
+			p = va_arg(ap, char *);
+			for (q = ksprintn(nbuf, num, *p++, NULL, 0); *q;)
+				PCHAR(*q--);
+
+			if (num == 0)
+				break;
+
+			for (tmp = 0; *p;) {
+				n = *p++;
+				if (num & (1 << (n - 1))) {
+					PCHAR(tmp ? ',' : '<');
+					for (; (n = *p) > ' '; ++p)
+						PCHAR(n);
+					tmp = 1;
+				} else
+					for (; *p > ' '; ++p)
+						continue;
+			}
+			if (tmp)
+				PCHAR('>');
+			break;
+		case 'c':
+			PCHAR(va_arg(ap, int));
+			break;
+		case 'D':
+			up = va_arg(ap, unsigned char *);
+			p = va_arg(ap, char *);
+			if (!width)
+				width = 16;
+			while(width--) {
+				PCHAR(hex2ascii(*up >> 4));
+				PCHAR(hex2ascii(*up & 0x0f));
+				up++;
+				if (width)
+					for (q=p;*q;q++)
+						PCHAR(*q);
+			}
+			break;
+		case 'd':
+		case 'i':
+			base = 10;
+			sign = 1;
+			goto handle_sign;
+		case 'h':
+			if (hflag) {
+				hflag = 0;
+				cflag = 1;
+			} else
+				hflag = 1;
+			goto reswitch;
+		case 'j':
+			jflag = 1;
+			goto reswitch;
+		case 'l':
+			if (lflag) {
+				lflag = 0;
+				qflag = 1;
+			} else
+				lflag = 1;
+			goto reswitch;
+		case 'n':
+			if (jflag)
+				*(va_arg(ap, intmax_t *)) = retval;
+			else if (qflag)
+				*(va_arg(ap, int64_t *)) = retval;
+			else if (lflag)
+				*(va_arg(ap, long *)) = retval;
+			else if (zflag)
+				*(va_arg(ap, size_t *)) = retval;
+			else if (hflag)
+				*(va_arg(ap, short *)) = retval;
+			else if (cflag)
+				*(va_arg(ap, char *)) = retval;
+			else
+				*(va_arg(ap, int *)) = retval;
+			break;
+		case 'o':
+			base = 8;
+			goto handle_nosign;
+		case 'p':
+			base = 16;
+			sharpflag = (width == 0);
+			sign = 0;
+			num = (uintptr_t)va_arg(ap, void *);
+			goto number;
+		case 'q':
+			qflag = 1;
+			goto reswitch;
+		case 'r':
+			base = radix;
+			if (sign)
+				goto handle_sign;
+			goto handle_nosign;
+		case 's':
+			p = va_arg(ap, char *);
+			if (p == NULL)
+				p = "(null)";
+			if (!dot)
+				n = (int)strlen (p);
+			else
+				for (n = 0; n < dwidth && p[n]; n++)
+					continue;
+
+			width -= n;
+
+			if (!ladjust && width > 0)
+				while (width--)
+					PCHAR(padc);
+			while (n--)
+				PCHAR(*p++);
+			if (ladjust && width > 0)
+				while (width--)
+					PCHAR(padc);
+			break;
+		case 't':
+			tflag = 1;
+			goto reswitch;
+		case 'u':
+			base = 10;
+			goto handle_nosign;
+		case 'X':
+			upper = 1;
+		case 'x':
+			base = 16;
+			goto handle_nosign;
+		case 'y':
+			base = 16;
+			sign = 1;
+			goto handle_sign;
+		case 'z':
+			zflag = 1;
+			goto reswitch;
+handle_nosign:
+			sign = 0;
+			if (jflag)
+				num = va_arg(ap, uintmax_t);
+			else if (qflag)
+				num = va_arg(ap, uint64_t);
+			else if (tflag)
+				num = va_arg(ap, ptrdiff_t);
+			else if (lflag)
+				num = va_arg(ap, unsigned long);
+			else if (zflag)
+				num = va_arg(ap, size_t);
+			else if (hflag)
+				num = (unsigned short)va_arg(ap, int);
+			else if (cflag)
+				num = (unsigned char)va_arg(ap, int);
+			else
+				num = va_arg(ap, unsigned int);
+			goto number;
+handle_sign:
+			if (jflag)
+				num = va_arg(ap, intmax_t);
+			else if (qflag)
+				num = va_arg(ap, int64_t);
+			else if (tflag)
+				num = va_arg(ap, ptrdiff_t);
+			else if (lflag)
+				num = va_arg(ap, long);
+			else if (zflag)
+				num = va_arg(ap, ssize_t);
+			else if (hflag)
+				num = (short)va_arg(ap, int);
+			else if (cflag)
+				num = (char)va_arg(ap, int);
+			else
+				num = va_arg(ap, int);
+number:
+			if (sign && (intmax_t)num < 0) {
+				neg = 1;
+				num = -(intmax_t)num;
+			}
+			p = ksprintn(nbuf, num, base, &n, upper);
+			tmp = 0;
+			if (sharpflag && num != 0) {
+				if (base == 8)
+					tmp++;
+				else if (base == 16)
+					tmp += 2;
+			}
+			if (neg)
+				tmp++;
+
+			if (!ladjust && padc == '0')
+				dwidth = width - tmp;
+			width -= tmp + imax(dwidth, n);
+			dwidth -= n;
+			if (!ladjust)
+				while (width-- > 0)
+					PCHAR(' ');
+			if (neg)
+				PCHAR('-');
+			if (sharpflag && num != 0) {
+				if (base == 8) {
+					PCHAR('0');
+				} else if (base == 16) {
+					PCHAR('0');
+					PCHAR('x');
+				}
+			}
+			while (dwidth-- > 0)
+				PCHAR('0');
+
+			while (*p)
+				PCHAR(*p--);
+
+			if (ladjust)
+				while (width-- > 0)
+					PCHAR(' ');
+
+			break;
+		default:
+			while (percent < fmt)
+				PCHAR(*percent++);
+			/*
+			 * Since we ignore an formatting argument it is no
+			 * longer safe to obey the remaining formatting
+			 * arguments as the arguments will no longer match
+			 * the format specs.
+			 */
+			stop = 1;
+			break;
+		}
+	}
+#undef PCHAR
+}
+#else /* defined(USE_ELF) */
+#error not supported
+#endif
diff -Nuarp ruby-3.0.5.a/common.mk ruby-3.0.5.b/common.mk
--- ruby-3.0.5.a/common.mk	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/common.mk	2023-02-02 23:11:35.058989681 -0500
@@ -81,7 +81,8 @@ ENC_MK        = enc.mk
 MAKE_ENC      = -f $(ENC_MK) V="$(V)" UNICODE_HDR_DIR="$(UNICODE_HDR_DIR)" \
 		RUBY="$(MINIRUBY)" MINIRUBY="$(MINIRUBY)" $(mflags)
 
-COMMONOBJS    = array.$(OBJEXT) \
+COMMONOBJS    = abrt.$(OBJEXT) \
+                array.$(OBJEXT) \
 		ast.$(OBJEXT) \
 		bignum.$(OBJEXT) \
 		class.$(OBJEXT) \
diff -Nuarp ruby-3.0.5.a/configure.ac ruby-3.0.5.b/configure.ac
--- ruby-3.0.5.a/configure.ac	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/configure.ac	2023-02-02 23:12:42.032521533 -0500
@@ -107,7 +107,7 @@ RUBY_BASE_NAME=`echo ruby | sed "$progra
 RUBYW_BASE_NAME=`echo rubyw | sed "$program_transform_name"`
 AC_SUBST(RUBY_BASE_NAME)
 AC_SUBST(RUBYW_BASE_NAME)
-AC_SUBST(RUBY_VERSION_NAME, '${RUBY_BASE_NAME}-${ruby_version}')
+AC_SUBST(RUBY_VERSION_NAME, '${RUBY_BASE_NAME}-${ruby_version_dir_name}')
 
 dnl checks for alternative programs
 AC_CANONICAL_BUILD
@@ -1935,6 +1935,7 @@ AC_CHECK_FUNCS(lstat)
 AC_CHECK_FUNCS(lutimes)
 AC_CHECK_FUNCS(malloc_usable_size)
 AC_CHECK_FUNCS(malloc_size)
+AC_CHECK_FUNCS(malloc_trim)
 AC_CHECK_FUNCS(mblen)
 AC_CHECK_FUNCS(memalign)
 AC_CHECK_FUNCS(memset_s)
@@ -1944,6 +1945,7 @@ AC_CHECK_FUNCS(memmem)
 AC_CHECK_FUNCS(mkfifo)
 AC_CHECK_FUNCS(mknod)
 AC_CHECK_FUNCS(mktime)
+AC_CHECK_FUNCS(mmap)
 AC_CHECK_FUNCS(openat)
 AC_CHECK_FUNCS(pipe2)
 AC_CHECK_FUNCS(poll)
@@ -2666,6 +2668,21 @@ main(int argc, char *argv[])
 	rb_cv_fork_with_pthread=yes)])
     test x$rb_cv_fork_with_pthread = xyes || AC_DEFINE(CANNOT_FORK_WITH_PTHREAD)
 ])
+
+AC_CHECK_HEADERS([sys/user.h])
+AS_IF([test "x$ac_cv_func_mmap" = xyes], [
+    AC_CACHE_CHECK([whether PAGE_SIZE is compile-time const], rb_cv_const_page_size,
+	[malloc_headers=`sed -n '/MALLOC_HEADERS_BEGIN/,/MALLOC_HEADERS_END/p' ${srcdir}/gc.c`
+	AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[$malloc_headers
+            typedef char conftest_page[PAGE_SIZE];
+        ]], [[]])],
+        [rb_cv_const_page_size=yes],
+        [rb_cv_const_page_size=no])])
+])
+AS_IF([test "x$rb_cv_const_page_size" = xyes],
+    [AC_DEFINE(HAVE_CONST_PAGE_SIZE, 1)],
+    [AC_DEFINE(HAVE_CONST_PAGE_SIZE, 0)]
+)
 }
 
 : "runtime section" && {
@@ -3188,7 +3205,7 @@ AS_IF([test x"${exec_prefix}" != xNONE],
     RUBY_EXEC_PREFIX=$ac_default_prefix
 ])
 pat=`echo "${RUBY_EXEC_PREFIX}" | tr -c '\012' .`'\(.*\)'
-for var in bindir libdir rubylibprefix; do
+for var in bindir includedir libdir rubylibprefix; do
     eval val='"$'$var'"'
     AS_CASE(["$val"], ["${RUBY_EXEC_PREFIX}"*], [val='${exec_prefix}'"`expr \"$val\" : \"$pat\"`"])
     eval $var='"$val"'
@@ -3259,6 +3276,11 @@ AS_IF([test ${multiarch+set}], [
 ])
 
 archlibdir='${libdir}/${arch}'
+AC_ARG_WITH(archlibdir,
+	    AS_HELP_STRING([--with-archlibdir=DIR],
+			   [prefix for libruby [[LIBDIR/ARCH]]]),
+	    [archlibdir="$withval"])
+
 sitearchlibdir='${libdir}/${sitearch}'
 archincludedir='${includedir}/${arch}'
 sitearchincludedir='${includedir}/${sitearch}'
@@ -3856,9 +3878,6 @@ AS_CASE(["$target_os"],
     rubyw_install_name='$(RUBYW_INSTALL_NAME)'
     ])
 
-rubylibdir='${rubylibprefix}/${ruby_version}'
-rubyarchdir=${multiarch+'${rubyarchprefix}/${ruby_version}'}${multiarch-'${rubylibdir}/${arch}'}
-
 rubyarchprefix=${multiarch+'${archlibdir}/${RUBY_BASE_NAME}'}${multiarch-'${rubylibprefix}/${arch}'}
 AC_ARG_WITH(rubyarchprefix,
 	    AS_HELP_STRING([--with-rubyarchprefix=DIR],
@@ -3881,56 +3900,67 @@ AC_ARG_WITH(ridir,
 AC_SUBST(ridir)
 AC_SUBST(RI_BASE_NAME)
 
-AC_ARG_WITH(ruby-version,
-	    AS_HELP_STRING([--with-ruby-version=STR], [ruby version string for version specific directories [[full]] (full|minor|STR)]),
-            [ruby_version=$withval],
-            [ruby_version=full])
 unset RUBY_LIB_VERSION
-unset RUBY_LIB_VERSION_STYLE
-AS_CASE(["$ruby_version"],
-  [full],  [RUBY_LIB_VERSION_STYLE='3	/* full */'],
-  [minor], [RUBY_LIB_VERSION_STYLE='2	/* minor */'])
-AS_IF([test ${RUBY_LIB_VERSION_STYLE+set}], [
-    {
-    echo "#define RUBY_LIB_VERSION_STYLE $RUBY_LIB_VERSION_STYLE"
-    echo '#define STRINGIZE(x) x'
-    test -f revision.h -o -f "${srcdir}/revision.h" || echo '#define RUBY_REVISION 0'
-    echo '#include "version.h"'
-    echo 'ruby_version=RUBY_LIB_VERSION'
-    } > conftest.c
-    ruby_version="`$CPP -I. -I"${srcdir}" -I"${srcdir}/include" conftest.c | sed '/^ruby_version=/!d;s/ //g'`"
-    eval $ruby_version
-], [test -z "${ruby_version}"], [
-    AC_MSG_ERROR([No ruby version, No place for bundled libraries])
-], [
-    RUBY_LIB_VERSION="${ruby_version}"
-])
+RUBY_LIB_VERSION_STYLE='3	/* full */'
+{
+echo "#define RUBY_LIB_VERSION_STYLE $RUBY_LIB_VERSION_STYLE"
+echo '#define STRINGIZE(x) x'
+test -f revision.h -o -f "${srcdir}/revision.h" || echo '#define RUBY_REVISION 0'
+echo '#include "version.h"'
+echo 'ruby_version=RUBY_LIB_VERSION'
+} > conftest.c
+ruby_version="`$CPP -I. -I"${srcdir}" -I"${srcdir}/include" conftest.c | sed '/^ruby_version=/!d;s/ //g'`"
+eval $ruby_version
+
+RUBY_LIB_VERSION="${ruby_version}"
+
 AC_SUBST(RUBY_LIB_VERSION_STYLE)
 AC_SUBST(RUBY_LIB_VERSION)
 
+AC_ARG_WITH(ruby-version,
+	    AS_HELP_STRING([--with-ruby-version=STR], [ruby version string for version specific directories [[full]] (full|STR)]),
+            [ruby_version_dir_name=$withval],
+            [ruby_version_dir_name=full])
+AS_CASE(["$ruby_version_dir_name"],
+  [full], [ruby_version_dir_name='${ruby_version}'])
+
+ruby_version_dir=/'${ruby_version_dir_name}'
+
+if test -z "${ruby_version_dir_name}"; then
+    unset ruby_version_dir
+    AC_DEFINE(RUBY_LIB_VERSION_BLANK, 1)
+fi
+
+rubylibdir='${rubylibprefix}'${ruby_version_dir}
+rubyarchdir=${multiarch+'${rubyarchprefix}'${ruby_version_dir}}${multiarch-'${rubylibdir}/${arch}'}
+
 AC_ARG_WITH(sitedir,
 	    AS_HELP_STRING([--with-sitedir=DIR], [site libraries in DIR [[RUBY_LIB_PREFIX/site_ruby]], "no" to disable site directory]),
             [sitedir=$withval],
             [sitedir='${rubylibprefix}/site_ruby'])
-sitelibdir='${sitedir}/${ruby_version}'
+sitelibdir='${sitedir}'${ruby_version_dir}
 
 AC_ARG_WITH(sitearchdir,
 	    AS_HELP_STRING([--with-sitearchdir=DIR],
 			   [architecture dependent site libraries in DIR [[SITEDIR/SITEARCH]], "no" to disable site directory]),
             [sitearchdir=$withval],
-            [sitearchdir=${multiarch+'${rubysitearchprefix}/site_ruby/${ruby_version}'}${multiarch-'${sitelibdir}/${sitearch}'}])
+            [sitearchdir=${multiarch+'${rubysitearchprefix}/site_ruby'${ruby_version_dir}}${multiarch-'${sitelibdir}/${sitearch}'}])
 
 AC_ARG_WITH(vendordir,
 	    AS_HELP_STRING([--with-vendordir=DIR], [vendor libraries in DIR [[RUBY_LIB_PREFIX/vendor_ruby]], "no" to disable vendor directory]),
             [vendordir=$withval],
             [vendordir='${rubylibprefix}/vendor_ruby'])
-vendorlibdir='${vendordir}/${ruby_version}'
+vendorlibdir='${vendordir}'${ruby_version_dir}
 
 AC_ARG_WITH(vendorarchdir,
 	    AS_HELP_STRING([--with-vendorarchdir=DIR],
 			   [architecture dependent vendor libraries in DIR [[VENDORDIR/SITEARCH]], "no" to disable vendor directory]),
             [vendorarchdir=$withval],
-            [vendorarchdir=${multiarch+'${rubysitearchprefix}/vendor_ruby/${ruby_version}'}${multiarch-'${vendorlibdir}/${sitearch}'}])
+            [vendorarchdir=${multiarch+'${rubysitearchprefix}/vendor_ruby'${ruby_version_dir}}${multiarch-'${vendorlibdir}/${sitearch}'}])
+
+AC_ARG_WITH(rubygemsdir,
+           AS_HELP_STRING([--with-rubygemsdir=DIR], [custom rubygems directory]),
+            [rubygemsdir=$withval])
 
 AS_IF([test "${LOAD_RELATIVE+set}"], [
     AC_DEFINE_UNQUOTED(LOAD_RELATIVE, $LOAD_RELATIVE)
@@ -3947,6 +3977,7 @@ AC_SUBST(sitearchincludedir)dnl
 AC_SUBST(arch)dnl
 AC_SUBST(sitearch)dnl
 AC_SUBST(ruby_version)dnl
+AC_SUBST(ruby_version_dir_name)dnl
 AC_SUBST(rubylibdir)dnl
 AC_SUBST(rubyarchdir)dnl
 AC_SUBST(sitedir)dnl
@@ -3955,10 +3986,13 @@ AC_SUBST(sitearchdir)dnl
 AC_SUBST(vendordir)dnl
 AC_SUBST(vendorlibdir)dnl
 AC_SUBST(vendorarchdir)dnl
+AC_SUBST(rubygemsdir)dnl
 
 AC_SUBST(CONFIGURE, "`echo $0 | sed 's|.*/||'`")dnl
 AC_SUBST(configure_args, "`echo "${ac_configure_args}" | sed 's/\\$/$$/g'`")dnl
 
+target_cpu=`echo $target_cpu | sed s/i.86/i386/`
+
 AS_IF([test "${universal_binary-no}" = yes ], [
     arch="universal-${target_os}"
     AS_IF([test "${rb_cv_architecture_available}" = yes], [
diff -Nuarp ruby-3.0.5.a/configure.ac.orig ruby-3.0.5.b/configure.ac.orig
--- ruby-3.0.5.a/configure.ac.orig	1969-12-31 19:00:00.000000000 -0500
+++ ruby-3.0.5.b/configure.ac.orig	2023-02-02 23:11:20.954877667 -0500
@@ -0,0 +1,4266 @@
+dnl Process this file with autoconf to produce a configure script.
+AC_INIT
+{
+AC_CONFIG_AUX_DIR(tool)
+
+AC_PREREQ(2.67)
+
+tooldir="$srcdir/tool"
+
+AC_DISABLE_OPTION_CHECKING
+
+m4_include([tool/m4/_colorize_result_prepare.m4])
+m4_include([tool/m4/ac_msg_result.m4])
+m4_include([tool/m4/colorize_result.m4])
+m4_include([tool/m4/ruby_append_option.m4])
+m4_include([tool/m4/ruby_append_options.m4])
+m4_include([tool/m4/ruby_check_builtin_func.m4])
+m4_include([tool/m4/ruby_check_builtin_setjmp.m4])
+m4_include([tool/m4/ruby_check_printf_prefix.m4])
+m4_include([tool/m4/ruby_check_setjmp.m4])
+m4_include([tool/m4/ruby_check_signedness.m4])
+m4_include([tool/m4/ruby_check_sizeof.m4])
+m4_include([tool/m4/ruby_check_sysconf.m4])
+m4_include([tool/m4/ruby_cppoutfile.m4])
+m4_include([tool/m4/ruby_decl_attribute.m4])
+m4_include([tool/m4/ruby_default_arch.m4])
+m4_include([tool/m4/ruby_define_if.m4])
+m4_include([tool/m4/ruby_defint.m4])
+m4_include([tool/m4/ruby_dtrace_available.m4])
+m4_include([tool/m4/ruby_dtrace_postprocess.m4])
+m4_include([tool/m4/ruby_func_attribute.m4])
+m4_include([tool/m4/ruby_mingw32.m4])
+m4_include([tool/m4/ruby_prepend_option.m4])
+m4_include([tool/m4/ruby_prog_gnu_ld.m4])
+m4_include([tool/m4/ruby_replace_funcs.m4])
+m4_include([tool/m4/ruby_replace_type.m4])
+m4_include([tool/m4/ruby_rm_recursive.m4])
+m4_include([tool/m4/ruby_setjmp_type.m4])
+m4_include([tool/m4/ruby_stack_grow_direction.m4])
+m4_include([tool/m4/ruby_try_cflags.m4])
+m4_include([tool/m4/ruby_try_cxxflags.m4])
+m4_include([tool/m4/ruby_try_ldflags.m4])
+m4_include([tool/m4/ruby_universal_arch.m4])
+m4_include([tool/m4/ruby_werror_flag.m4])
+
+AC_ARG_VAR([cflags], [additional CFLAGS (ignored when CFLAGS is given)])
+AC_ARG_VAR([cppflags], [additional CPPFLAGS (ignored when CPPFLAGS is given)])
+AC_ARG_VAR([cxxflags], [additional CXXFLAGS (ignored when CXXFLAGS is given)])
+
+: "environment section" && {
+HAVE_BASERUBY=yes
+BASERUBY_VERSION=
+AC_ARG_WITH(baseruby,
+	AS_HELP_STRING([--with-baseruby=RUBY], [use RUBY as baseruby; RUBY is the pathname of ruby]),
+	[AS_CASE(["$withval"],
+	    [*ruby*],[BASERUBY=$withval],
+	    [no],[HAVE_BASERUBY=no],
+	    [AC_MSG_ERROR(need ruby)])
+	],
+	[
+		AC_PATH_PROG([BASERUBY], [ruby], [false])
+	])
+AS_IF([test "$HAVE_BASERUBY" != no -a "`RUBYOPT=- $BASERUBY --disable=gems -e 'print 42 if RUBY_VERSION > "2.2"' 2>/dev/null`" = 42], [
+    BASERUBY="$BASERUBY --disable=gems"
+    BASERUBY_VERSION=`$BASERUBY -v`
+    $BASERUBY -C "$srcdir" tool/downloader.rb -d tool -e gnu config.guess config.sub >&AS_MESSAGE_FD
+], [
+    BASERUBY="echo executable host ruby is required.  use --with-baseruby option.; false"
+    HAVE_BASERUBY=no
+])
+AC_SUBST(BASERUBY)
+AC_SUBST(HAVE_BASERUBY)
+
+: ${GIT=git}
+HAVE_GIT=yes
+AC_ARG_WITH(git,
+	AS_HELP_STRING([--without-git], [never use git]),
+	[AS_CASE([$withval],
+	    [no],  [GIT=never-use HAVE_GIT=no],
+	    [yes], [],
+	    [GIT=$withval])])
+AS_IF([test x"$HAVE_GIT" = xyes], [command -v "$GIT" > /dev/null || HAVE_GIT=no])
+AC_SUBST(GIT)
+AC_SUBST(HAVE_GIT)
+
+eval `sed -n -e ['s/^@%:@define RUBY_[A-Z_]*VERSION_\([A-Z][A-Z][A-Z_0-9]*\) \([0-9][0-9]*\)$/\1=\2/p'] \
+      -e ['s/^@%:@define \(RUBY_PATCHLEVEL\) \(.*\)/\1=\2/p'] \
+     $srcdir/include/ruby/version.h $srcdir/version.h`
+for v in MAJOR MINOR TEENY; do
+    AS_IF([eval "test \"\$$v\" = ''"], [
+	AC_MSG_ERROR(could not determine $v number from version.h)
+    ])
+done
+AC_SUBST(MAJOR)
+AC_SUBST(MINOR)
+AC_SUBST(TEENY)
+AC_SUBST(RUBY_API_VERSION, '$(MAJOR).$(MINOR)')
+AC_SUBST(RUBY_PROGRAM_VERSION, '$(MAJOR).$(MINOR).$(TEENY)')
+
+AS_IF([test "$program_prefix" = NONE], [
+  program_prefix=
+])
+AS_IF([test "$prefix" -ef .], [
+  AC_MSG_ERROR(--prefix cannot be the current working directory.)
+])
+RUBY_BASE_NAME=`echo ruby | sed "$program_transform_name"`
+RUBYW_BASE_NAME=`echo rubyw | sed "$program_transform_name"`
+AC_SUBST(RUBY_BASE_NAME)
+AC_SUBST(RUBYW_BASE_NAME)
+AC_SUBST(RUBY_VERSION_NAME, '${RUBY_BASE_NAME}-${ruby_version_dir_name}')
+
+dnl checks for alternative programs
+AC_CANONICAL_BUILD
+AC_CANONICAL_HOST
+AC_CANONICAL_TARGET
+AC_ARG_PROGRAM
+RUBY_RM_RECURSIVE
+AC_ARG_WITH(gcc,
+	AS_HELP_STRING([--without-gcc], [never use gcc]),
+	[
+	AS_CASE([$withval],
+	    [no],  [: ${CC=cc}],
+	    [yes], [: ${CC=gcc}],
+	           [CC=$withval])])
+dnl If the user switches compilers, we can't believe the cache
+AS_IF([test ! -z "$ac_cv_prog_CC" -a ! -z "$CC" -a "$CC" != "$ac_cv_prog_CC"], [
+  AC_MSG_ERROR(cached CC is different -- throw away $cache_file
+(it is also a good idea to do 'make clean' before compiling))
+])
+AS_CASE(["${build_os}"], [linux*|cygwin*], [
+    AC_CHECK_TOOLS([CC], [gcc clang cc])
+], [
+    # OpenBSD wants to prefer cc over gcc.
+    # See https://github.com/ruby/ruby/pull/2443
+    AC_CHECK_TOOLS([CC], [cl.exe clang cc gcc c99 /usr/ucb/cc])
+])
+
+AC_ARG_VAR([AR],       [Archiver command])
+AC_ARG_VAR([AS],       [Assembler command])
+AC_ARG_VAR([CC],       [C compiler command])
+AC_ARG_VAR([CXX],      [C++ compiler command])
+AC_ARG_VAR([LD],       [Linker command])
+AC_ARG_VAR([NM],       [Symbol list command])
+AC_ARG_VAR([OBJCOPY],  [Objcopy command])
+AC_ARG_VAR([OBJDUMP],  [Objdump command])
+AC_ARG_VAR([RANLIB],   [Ranlib command])
+AC_ARG_VAR([STRIP],    [Strip command])
+
+# We don't want to bother things like `ccache gcc`, `clang -shared-libgcc`, ...
+set rb_dummy ${CC}
+rb_CC=$2
+AS_CASE(["/${rb_CC} "],
+[*@<:@\ /@:>@"cc "*], [
+    # Don't try g++/clang++ when CC=cc
+    AC_CHECK_TOOLS([CXX],    [cl.exe CC c++])
+],
+[*icc*],              [
+    # Intel C++ has interprocedural optimizations.  It tends to come with its
+    # own linker etc.
+    AC_CHECK_TOOL([AR],      [`echo "${rb_CC}" | sed s/icc/xiar/`])
+    AC_CHECK_TOOL([CXX],     [`echo "${rb_CC}" | sed s/icc/icpc/`])
+    AC_CHECK_TOOL([LD],      [`echo "${rb_CC}" | sed s/icc/xild/`])
+],
+[*gcc*],              [
+    # Dito for GCC.
+    AC_CHECK_TOOL([LD],      [`echo "${rb_CC}" | sed s/gcc/ld/`])
+    AC_CHECK_TOOL([AR],      [`echo "${rb_CC}" | sed s/gcc/gcc-ar/`])
+    AC_CHECK_TOOL([CXX],     [`echo "${rb_CC}" | sed s/gcc/g++/`])
+    AC_CHECK_TOOL([NM],      [`echo "${rb_CC}" | sed s/gcc/gcc-nm/`])
+    AC_CHECK_TOOL([RANLIB],  [`echo "${rb_CC}" | sed s/gcc/gcc-ranlib/`])
+],
+[*clang*],            [
+    # Dito for LLVM.  Note however that llvm-as is a LLVM-IR to LLVM bitcode
+    # assembler that does not target your machine native binary.
+    : ${LD:="${CC}"}         # ... try -fuse-ld=lld ?
+    AC_CHECK_TOOL([AR],      [`echo "${rb_CC}" | sed s/clang/llvm-ar/`])
+#   AC_CHECK_TOOL([AS],      [`echo "${rb_CC}" | sed s/clang/llvm-as/`])
+    AC_CHECK_TOOL([CXX],     [`echo "${rb_CC}" | sed s/clang/clang++/`])
+    AC_CHECK_TOOL([NM],      [`echo "${rb_CC}" | sed s/clang/llvm-nm/`])
+    AC_CHECK_TOOL([OBJCOPY], [`echo "${rb_CC}" | sed s/clang/llvm-objcopy/`])
+    AC_CHECK_TOOL([OBJDUMP], [`echo "${rb_CC}" | sed s/clang/llvm-objdump/`])
+    AC_CHECK_TOOL([RANLIB],  [`echo "${rb_CC}" | sed s/clang/llvm-ranlib/`])
+    AC_CHECK_TOOL([STRIP],   [`echo "${rb_CC}" | sed s/clang/llvm-strip/`])
+])
+AS_UNSET(rb_CC)
+AS_UNSET(rb_dummy)
+
+AS_CASE(["${build_os}"],
+[solaris*], [
+    AC_PATH_TOOL([LD], [ld], [/usr/ccs/bin/ld], [/usr/ccs/bin:$PATH])
+],
+[aix*], [
+    AC_PATH_TOOL([NM], [nm], [/usr/ccs/bin/nm], [/usr/ccs/bin:$PATH])
+])
+AS_CASE(["${target_os}"],
+[cygwin*|mingw*], [
+    ac_cv_prog_ac_ct_OBJCOPY=":"
+])
+
+rb_test_CFLAGS=${CFLAGS+yes}
+rb_test_CXXFLAGS=${CXXFLAGS+yes}
+
+# BSD's ports and MacPorts prefix GNU binutils with 'g'
+
+dnl Seems necessarily in order to add -std=gnu99 option for gcc 4.9.
+m4_version_prereq([2.70], [], [AC_PROG_CC_C99])
+
+AC_PROG_CXX
+AC_PROG_CPP
+AC_PROG_RANLIB
+AC_CHECK_TOOLS([AR],      [gar ar])
+AC_CHECK_TOOLS([AS],      [gas as])
+AC_CHECK_TOOLS([LD],      [gld ld]) # ... try gold ?
+AC_CHECK_TOOLS([NM],      [gnm nm])
+AC_CHECK_TOOLS([OBJCOPY], [gobjcopy objcopy])
+AC_CHECK_TOOLS([OBJDUMP], [gobjdump objdump])
+AC_CHECK_TOOLS([STRIP],   [gstrip strip], [:])
+
+AS_IF([test ! $rb_test_CFLAGS], [AS_UNSET(CFLAGS)]); AS_UNSET(rb_test_CFLAGS)
+AS_IF([test ! $rb_test_CXXFLAGS], [AS_UNSET(CXXFLAGS)]); AS_UNSET(rb_save_CXXFLAGS)
+
+AS_IF([test "${CXX}" = "g++" -a -z "${GXX}"], [
+    # AC_PROG_CXX sets $CXX to "g++" when it purposefully finds that there is
+    # _no_ g++.  This brain-damaged design must be worked around.  Thankfully,
+    # similar thing doesn't happen for AC_PROG_CC.
+    rb_there_is_in_fact_no_gplusplus_but_autoconf_is_cheating_us=true
+])
+
+test x"$target_alias" = x &&
+target_os=`echo $target_os | sed 's/linux-gnu$/linux/;s/linux-gnu/linux-/'`
+ac_install_sh='' # unusable for extension libraries.
+
+AC_ARG_WITH(os-version-style,
+	AS_HELP_STRING([--with-os-version-style=TYPE],
+		       [OS version number for target and target_os [[full]]]
+		       [(full|teeny|minor+0|minor|major+0|major|none)]),
+	[os_version_style=$withval],
+	[os_version_style=full
+	    AS_CASE($target_os, [[*[0-9].*]],
+		[AS_CASE([`/usr/bin/ruby -e 'puts RUBY_PLATFORM' 2>/dev/null`],
+		    [[*-*[0-9].*.0]], [os_version_style=minor+0],
+		    [[*-*[0-9].*.*]], [os_version_style=full],
+		    [[*-*[0-9].0]  ], [os_version_style=major+0],
+		    [[*-*[0-9].*]  ], [os_version_style=minor],
+		    [[*-*[0-9]]    ], [os_version_style=major],
+		)])
+	])
+os_version_style_transform=
+AS_CASE("${os_version_style}",
+	[full|teeny], [],
+	[minor+0], [os_version_style_transform=['s/\([0-9]\.[0-9][0-9]*\)\.[0-9][.0-9]*$/\1.0/']],
+	[minor],   [os_version_style_transform=['s/\([0-9]\.[0-9][0-9]*\)\.[0-9][.0-9]*$/\1/']],
+	[major+0], [os_version_style_transform=['s/\([0-9]\)\.[0-9][.0-9]*$/\1.0/']],
+	[major],   [os_version_style_transform=['s/\([0-9]\)\.[0-9][.0-9]*$/\1/']],
+	[none],    [os_version_style_transform=['s/[0-9]*\.[0-9][.0-9]*$//']],
+	[AC_MSG_ERROR(unknown --with-os-version-style: $withval)])
+AS_IF([test -z "$target_alias" -a -n "$os_version_style_transform"],
+	[
+	target=`echo ${target} | sed "$os_version_style_transform"`
+	target_os=`echo ${target_os} | sed "$os_version_style_transform"`
+	])
+
+AC_ARG_WITH(arch,
+	AS_HELP_STRING([--with-arch=ARCHS],
+		       [build an Apple/NeXT Multi Architecture Binary (MAB);
+                          ARCHS is a comma-delimited list of architectures for
+                          which to build; if this option is disabled or omitted
+			  entirely, then the package will be built only for the
+			  target platform]),
+       [target_archs="$withval"], [unset target_archs])
+
+AC_ARG_ENABLE(load-relative,
+       AS_HELP_STRING([--enable-load-relative], [resolve load paths at run time]),
+       [load_relative=$enableval])
+
+# checks for UNIX variants that set C preprocessor variables
+AC_USE_SYSTEM_EXTENSIONS
+
+dnl Checks for programs.
+
+cflagspat=
+test -z "$optflags" ||
+    cflagspat="$cflagspat;s|"`eval echo '"'"${optflags}"'"' | sed 's/[[][|.*]]/\\&/g;s/^ */ /;s/ *$/ /'`'| |g'
+test -z "$debugflags" ||
+    cflagspat="$cflagspat;s|"`eval echo '"'"${debugflags}"'"' | sed 's/[[][|.*]]/\\&/g;s/^ */ /;s/ *$/ /'`'| |g'
+test -z "$warnflags" ||
+    cflagspat="$cflagspat;s|"`eval echo '"'"${warnflags}"'"' | sed 's/[[][|.*]]/\\&/g;s/^ */ /;s/ *$/ /'`'| |g'
+AS_IF([test -z "${CFLAGS+set}"], [
+    cflags=`echo " $cflags " | sed "$cflagspat;s/^ *//;s/ *$//"`
+    orig_cflags="$cflags"
+    cflags="$cflags "'${optflags} ${debugflags} ${warnflags}'
+])
+dnl AS_IF([test -z "${CXXFLAGS+set}"], [
+dnl     cxxflags=`echo " $cxxflags " | sed "$cflagspat;s/^ *//;s/ *$//"`
+dnl     orig_cxxflags="$cxxflags"
+dnl     cxxflags="$cxxflags "'${optflags} ${debugflags} ${warnflags}'
+dnl ])
+
+AS_CASE(["$host_os:$build_os"],
+[darwin*:darwin*], [
+    # Following Apple deployed clang are broken
+    # clang version 1.0 (http://llvm.org/svn/llvm-project/cfe/tags/Apple/clang-23 exported)
+    # Apple clang version 2.0 (tags/Apple/clang-137) (based on LLVM 2.9svn)
+    # Apple clang version 2.1 (tags/Apple/clang-163.7.1) (based on LLVM 3.0svn)
+    AC_PREPROC_IFELSE(
+	[AC_LANG_PROGRAM([
+	    @%:@if defined __APPLE_CC__ && defined __clang_major__ && __clang_major__ < 3
+	    @%:@error premature clang
+	    @%:@endif
+	])],
+	[],
+	[AC_MSG_ERROR([clang version 3.0 or later is required])])
+])
+
+AS_CASE(["$target_os"],
+[darwin*], [
+    AC_MSG_CHECKING(if minimum required OS X version is supported)
+    AC_PREPROC_IFELSE([AC_LANG_SOURCE([[@%:@include <AvailabilityMacros.h>
+	@%:@if MAC_OS_X_VERSION_MIN_REQUIRED < __MAC_10_5
+	@%:@error pre OS X 10.5
+	[!<===== pre OS X 10.5 =====>]
+	@%:@endif
+	]])],
+	[macosx_min_required=yes],
+	[AC_MSG_RESULT(no)
+	AC_MSG_ERROR([Unsupported OS X version is required])])
+    AC_MSG_RESULT(${macosx_min_required})
+])
+
+RUBY_MINGW32
+AC_SUBST(GCC)
+AC_SUBST(LD)
+AS_IF([test "$GCC" = yes], [
+    linker_flag=-Wl,
+    : ${optflags=-O3}
+    gcc_major=`echo =__GNUC__ | $CC -E -xc - | sed '/^=/!d;s///'`
+    gcc_minor=`echo =__GNUC_MINOR__ | $CC -E -xc - | sed '/^=/!d;s///'`
+    test -n "$gcc_major" || gcc_major=0
+    test -n "$gcc_minor" || gcc_minor=0
+    icc_version=`echo =__ICC | $CC -E -xc - | sed '/^=/!d;s///;/^__ICC/d'`
+    test -n "$icc_version" || icc_version=0
+    # RUBY_APPEND_OPTIONS(XCFLAGS, ["-include ruby/config.h" "-include ruby/missing.h"])
+], [
+    linker_flag=
+])
+
+AS_IF([test "$GCC" = yes -a "$gcc_major" -lt 3 ], [
+    AC_MSG_ERROR([too old GCC])
+])
+
+RUBY_PROG_GNU_LD
+RUBY_CPPOUTFILE
+
+: ${OUTFLAG='-o '}
+: ${COUTFLAG=${OUTFLAG}}
+: ${CSRCFLAG=''}
+AC_SUBST(OUTFLAG)
+AC_SUBST(COUTFLAG)
+AC_SUBST(CSRCFLAG)
+
+: ${MJIT_CC=$CC}
+AS_IF([test "x$cross_compiling" = xno], [
+    AC_PATH_PROG([MJIT_CC], ${MJIT_CC})
+
+    # if $CC is in /usr/lib/ccache/$CC, search original $CC (disable ccache)
+    AS_IF([echo $RUBY_DEBUG | grep ci > /dev/null &&
+           echo $MJIT_CC | grep ^/usr/lib/ccache > /dev/null], [
+           PATH=`echo $PATH | sed "s/\/usr\/lib\/ccache://"` MJIT_CC=`which $CC`])
+
+    AS_CASE([$target_os],
+	[*mingw*], [command -v cygpath > /dev/null && MJIT_CC=`cygpath -ma $MJIT_CC`])
+    shift 2
+    MJIT_CC="$MJIT_CC${1+ }$*"
+])
+
+AS_CASE(["$build_os"],
+  [darwin1*.*], [
+    # Xcode linker warns for deprecated architecture and wrongly
+    # installed TBD files.
+    CC_WRAPPER=""
+    echo 'int main(void) {return 0;}' > conftest.c
+    AS_IF([$CC -framework Foundation -o conftest conftest.c 2>&1 |
+	   grep '^ld: warning: text-based stub file' >/dev/null], [
+	CC_WRAPPER=`cd -P "${tooldir}" && pwd`/darwin-cc
+	CC="$CC_WRAPPER $CC"
+    ])
+    rm -fr conftest*
+  ])
+
+cc_version=
+for option in --version -v -V -qversion; do
+    cc_version_message=`$CC $option 2>&1`
+    cc_version_status=$?
+    AS_CASE($cc_version_status, [0], [:], [continue])
+    AS_CASE($cc_version_message, [*Warning*], [continue])
+    cc_version='$(CC) '$option
+    break
+done
+AC_SUBST(CC_VERSION, $cc_version)
+AC_SUBST(CC_VERSION_MESSAGE, $cc_version_message)
+
+: ${DLDFLAGS="$LDFLAGS"}
+
+RUBY_UNIVERSAL_ARCH
+AS_IF([test "$target_cpu" != "$host_cpu" -a "$GCC" = yes -a "$cross_compiling" = no -a "${universal_binary:-no}" = no], [
+    RUBY_DEFAULT_ARCH("$target_cpu")
+])
+host_os=$target_os
+host_vendor=$target_vendor
+host_cpu=$target_cpu
+host=$target
+host_alias=$target_alias
+
+AC_CACHE_CHECK([for $AR flags], [rb_cv_arflags], [
+    AS_IF([$AR rcD conftest.a > /dev/null 2>&1 && rm conftest.a],
+	[rb_cv_arflags=rcD], [rb_cv_arflags=rcu])
+])
+AC_SUBST(ARFLAGS, ["$rb_cv_arflags "])
+AC_SUBST(ASFLAGS)
+
+AS_CASE(["$target_os"],
+[cygwin*|mingw*], [
+    AC_CHECK_TOOL(WINDRES, windres)
+    AC_CHECK_TOOL(DLLWRAP, dllwrap)
+    target=`echo $target | sed "s/^$target_cpu-/-/"`
+    target_alias=`echo $target_alias | sed "s/^$target_cpu-/-/"`
+    target_cpu=`echo $target_cpu | sed s/i.86/i386/`
+    AS_CASE(["$target"], [-*], [ target="$target_cpu${target}"])
+    AS_CASE(["$target_alias"], [-*], [ target_alias="$target_cpu${target_alias}"])
+    AS_CASE(["$target_os"],
+    [mingw*], [
+	test "$rb_cv_msvcrt" = "" && unset rb_cv_msvcrt
+	AC_CACHE_CHECK(for mingw32 runtime DLL, rb_cv_msvcrt, [
+	AC_LINK_IFELSE([AC_LANG_PROGRAM([[@%:@include <stdio.h>]],
+		    [[FILE* volatile f = stdin; return 0;]])],
+		    [rb_cv_msvcrt=`$OBJDUMP -p conftest$ac_exeext |
+				   tr A-Z a-z |
+				   sed -n '/^[[ 	]]*dll name: \(msvc.*\)\.dll$/{s//\1/p;q;}'`],
+		    [rb_cv_msvcrt=msvcrt])
+	test "$rb_cv_msvcrt" = "" && rb_cv_msvcrt=msvcrt])
+	RT_VER=`echo "$rb_cv_msvcrt" | tr -cd [0-9]`
+	test "$RT_VER" = "" && RT_VER=60
+	AC_DEFINE_UNQUOTED(RUBY_MSVCRT_VERSION, $RT_VER)
+	sysconfdir=
+    ])
+    : ${enable_shared=yes}
+    ],
+[hiuxmpp*], [AC_DEFINE(__HIUX_MPP__)])    # by TOYODA Eizi <toyoda@npd.kishou.go.jp>
+
+AC_PROG_LN_S
+AC_PROG_MAKE_SET
+AC_PROG_INSTALL
+AC_PROG_MKDIR_P
+AS_IF([test "x$MKDIR_P" = "x -d"], [
+  AS_IF([test x"$as_mkdir_p" != xfalse], [
+    MKDIR_P='mkdir -p'
+    echo "use 'mkdir -p' as MKDIR_P"
+  ], [
+    AC_MSG_ERROR([mkdir -p is required])
+  ])
+])
+MAKEDIRS="$MKDIR_P"
+AC_SUBST(MAKEDIRS)
+
+AC_CHECK_PROG([DTRACE], [${ac_tool_prefix}dtrace], [${ac_tool_prefix}dtrace])
+AS_IF([test "$cross_compiling:$ac_cv_prog_DTRACE" = no: -a -n "$ac_tool_prefix"], [
+    AC_CHECK_PROG([DTRACE], [dtrace], [dtrace])
+])
+
+AC_CHECK_PROGS(DOT, dot)
+AC_CHECK_PROGS(DOXYGEN, doxygen)
+
+for prog in ${ac_tool_prefix:+${ac_tool_prefix}pkg-config} pkg-config; do
+    AC_CHECK_PROG(PKG_CONFIG, $prog, [$prog], [], [],
+        [`"$as_dir/$ac_word$ac_exec_ext" --print-errors --version > /dev/null 2>&1 || echo "$as_dir/$ac_word$ac_exec_ext"`])
+    test -z "${PKG_CONFIG}" || break
+done
+
+AC_MSG_CHECKING([whether it is Android])
+AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
+	@%:@ifdef __ANDROID__
+	@%:@error android
+	@%:@endif
+]], [[]])],
+[AC_MSG_RESULT(no)],
+[
+	AC_MSG_RESULT(yes)
+	target_os=${target_os}-android
+	AC_MSG_CHECKING([for Android API version])
+        # hacky workaround: https://github.com/termux/termux-packages/issues/6176
+        rb_android_api=`getprop ro.build.version.sdk`
+        AC_MSG_RESULT($rb_android_api)
+        RUBY_APPEND_OPTIONS(CPPFLAGS, -D__ANDROID_API__=$rb_android_api -Wno-macro-redefined)
+])
+
+AC_SUBST(RM, ['rm -f'])
+AC_SUBST(CP, ['cp'])
+RMDIRS='$(top_srcdir)/tool/rmdirs'
+RMDIR=rmdir
+mkdir "rmdirs_$$_test" "rmdirs_$$_test/a"
+rmdir --ignore-fail-on-non-empty "rmdirs_$$_test" 2>/dev/null &&
+RMDIR='rmdir --ignore-fail-on-non-empty'
+$RMDIR -p "rmdirs_$$_test/a" 2>/dev/null &&
+{ test -d "rmdirs_$$_test" || RMDIRS="$RMDIR -p"; }
+rmdir "rmdirs_$$_test/a" "rmdirs_$$_test" 2>/dev/null
+AC_SUBST(RMDIR)
+AC_SUBST(RMDIRS)
+AC_SUBST(RMALL, ['rm -fr'])
+
+AC_MSG_CHECKING([for cd using physical directory])
+rm -fr conf$$.dir
+mkdir conf$$.dir &&
+(cd conf$$.dir && mkdir src build && cd src &&
+$as_ln_s ../build . > /dev/null 2>&1 && cd build &&
+for chdir in 'cd -P' 'PWD= cd'; do
+    /bin/sh -c "$chdir ../src && echo '$chdir' > cdcmd" 2> /dev/null && break
+done)
+AS_IF([test -f conf$$.dir/src/cdcmd], [
+    read CHDIR < conf$$.dir/src/cdcmd 2> /dev/null
+], [
+    CHDIR=cd
+])
+rm -fr conf$$.dir
+AC_MSG_RESULT([$CHDIR])
+AC_SUBST(CHDIR)
+}
+
+: "compiler section" && {
+RUBY_WERROR_FLAG([
+    AC_MSG_CHECKING([whether CFLAGS is valid])
+    AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[]], [[]])],
+	[AC_MSG_RESULT(yes)],
+	[
+	AC_MSG_RESULT(no)
+	AC_MSG_ERROR([something wrong with CFLAGS="$CFLAGS"])
+	]
+    )
+
+    AC_MSG_CHECKING([whether LDFLAGS is valid])
+    {
+	mkdir tmp.$$.try_link &&
+	cd tmp.$$.try_link &&
+	cp ../confdefs.h . &&
+	echo '<?xml?><plist><dict><key>CFBundleIdentifier</key><string></string></dict></plist>' > Info.plist &&
+	:
+    } || AC_MSG_ERROR([failed to make temporary directory])
+    AC_LINK_IFELSE([AC_LANG_PROGRAM([[]], [[]])],
+	[AC_MSG_RESULT(yes)],
+	[
+	cd .. && rm -fr tmp.$$.try_link
+	AC_MSG_RESULT(no)
+	AC_MSG_ERROR([something wrong with LDFLAGS="$LDFLAGS"])
+	]
+    )
+    cd .. && rm -fr tmp.$$.try_link
+])
+
+: ${RPATHFLAG=''}
+rpathflag=''
+AS_IF([test x"${RPATHFLAG}" = x], [
+    AS_CASE(["$target_os"],
+	[hpux*], [AS_IF([test "$rb_cv_prog_gnu_ld" = no], [rpathflag='+b '])],
+	[aix*], [rpathflag='-blibpath:'],
+	[for rpathflag in -R "-rpath "; do
+	    AS_CASE("$rpathflag",
+		    [*" "], [AS_CASE(["${linker_flag}"],
+				     [*,], [rpathflag=`echo "$rpathflag" | tr ' ' ,`])])
+	    rpathflag="${linker_flag}${rpathflag}"
+	    RUBY_TRY_LDFLAGS([${rpathflag}.], [], [rpathflag=])
+	    AS_IF([test "x${rpathflag}" != x], [])
+        done])
+], [
+    rpathflag=`echo "$RPATHFLAG" | sed 's/%.*//'`
+])
+
+RUBY_TRY_CFLAGS(-fdeclspec, [
+  RUBY_APPEND_OPTIONS(CC, -fdeclspec)
+  RUBY_APPEND_OPTIONS(MJIT_CC, -fdeclspec)
+])
+RUBY_TRY_CXXFLAGS(-fdeclspec, [RUBY_APPEND_OPTIONS(CXX, -fdeclspec)])
+
+AS_CASE([$RUBY_PATCHLEVEL], [-*],
+	[RUBY_DEVEL=yes], [RUBY_DEVEL=no])
+particular_werror_flags=$RUBY_DEVEL
+AC_ARG_ENABLE(werror,
+	AS_HELP_STRING([--disable-werror],
+		       [don't make warnings into errors
+		       even if a compiler support -Werror feature
+		       [[disabled by default unless development version]]]),
+	[particular_werror_flags=$enableval])
+
+rb_cv_warnflags="$warnflags"
+AS_CASE(["$GCC:${warnflags+set}:${extra_warnflags:+set}:"],
+[yes::*|yes:*:set:], [# GCC && (!warnflags || extra_warnflags)
+    AS_IF([test $gcc_major -ge 4], [
+	extra_warnflags="$extra_warnflags -Werror=extra-tokens"
+    ])
+    AS_IF([test $gcc_major -ge 5 -a $gcc_major -le 6], [
+	extra_warnflags="$extra_warnflags -Wno-maybe-uninitialized"
+    ])
+    # ICC doesn't support -Werror=
+    AS_IF([test $icc_version -gt 0], [
+	particular_werror_flags=no
+    ])
+    for wflag in \
+		 -Werror=deprecated-declarations \
+		 -Werror=division-by-zero \
+		 -Werror=duplicated-cond \
+		 -Werror=implicit-function-declaration \
+		 -Werror=implicit-int \
+		 -Werror=misleading-indentation \
+		 -Werror=pointer-arith \
+		 -Werror=shorten-64-to-32 \
+		 -Werror=write-strings \
+		 -Wimplicit-fallthrough=0 \
+		 -Wmissing-noreturn \
+		 -Wno-cast-function-type \
+		 -Wno-constant-logical-operand \
+		 -Wno-long-long \
+		 -Wno-missing-field-initializers \
+		 -Wno-overlength-strings \
+		 -Wno-packed-bitfield-compat \
+		 -Wno-parentheses-equality \
+		 -Wno-self-assign \
+		 -Wno-tautological-compare \
+		 -Wno-unused-parameter \
+		 -Wno-unused-value \
+		 -Wsuggest-attribute=format \
+		 -Wsuggest-attribute=noreturn \
+		 -Wunused-variable \
+		 -diag-disable=175,188,1684,2259,2312 \
+		 $extra_warnflags \
+		 ; do
+	AS_IF([test "$particular_werror_flags" != yes], [
+	    wflag=`echo x$wflag | sed 's/^x-Werror=/-W/;s/^x//'`
+	])
+	ok=no
+	RUBY_TRY_CFLAGS($wflag, [
+	    RUBY_APPEND_OPTIONS(warnflags, $wflag)
+	    ok=yes
+	])
+	AS_CASE([$ok:$wflag], [no:-Werror=*], [
+	    wflag=`echo x$wflag | sed 's/^x-Werror=/-W/'`
+	    RUBY_TRY_CFLAGS($wflag, [
+		RUBY_APPEND_OPTIONS(warnflags, $wflag)
+		particular_werror_flags=no
+	    ])
+	])
+    done
+    AS_CASE([" $warnflags "],[*" -Wno-missing-field-initializers "*], [wflag="-Wall -Wextra"],
+                             [wflag=-Wall])
+    RUBY_TRY_CFLAGS($wflag, [warnflags="$wflag${warnflags+ $warnflags}"])
+    # Disable warnflags while conftest. -Werror=* flags might make bad OS capability guess.
+    rb_cv_warnflags="$warnflags"
+    warnflags=
+])
+RUBY_TRY_CFLAGS(-Qunused-arguments, [RUBY_APPEND_OPTIONS(rb_cv_wsuppress_flags, -Qunused-arguments)])
+AC_COMPILE_IFELSE([
+    AC_LANG_PROGRAM([
+@%:@if !(defined(__SUNPRO_C)||defined(__SUNPRO_CC))
+@%:@error not sunpro
+@%:@endif],[])], [
+    for e in \
+        E_STATEMENT_NOT_REACHED \
+        E_INIT_SIGN_EXTEND \
+        E_INIT_DOES_NOT_FIT \
+        E_INITIALIZATION_TYPE_MISMATCH
+    do
+        RUBY_TRY_CFLAGS([-erroff=${e}], [
+            RUBY_APPEND_OPTIONS(rb_cv_warnflags, [-erroff=${e}])
+        ])
+    done
+])
+
+AC_ARG_WITH(compress-debug-sections,
+	AS_HELP_STRING([--with-compress-debug-sections=type],
+	    [enable debug section compression]),
+	[compress_debug_sections=$withval], [compress_debug_sections=])
+
+AS_IF([test "$GCC" = yes], [
+    # -D_FORTIFY_SOURCE
+    # When defined _FORTIFY_SOURCE, glibc enables some additional sanity
+    # argument check. The performance drop is very little and Ubuntu enables
+    # _FORTIFY_SOURCE=2 by default. So, let's support it for protecting us from
+    # a mistake of silly C extensions.
+
+    # TODO: check if link succeeds with _FORTIFY_SOURCE=2.
+    AS_CASE(["$target_os"],
+    [mingw*], [
+	fortify_source=no
+    ])
+    AC_ARG_ENABLE(fortify_source,
+		  AS_HELP_STRING([--disable-fortify-source],
+				 [disable -D_FORTIFY_SOURCE=2 option, which causes link error on mingw]),
+		  [fortify_source=$enableval])
+    AS_IF([test "x$fortify_source" != xno], [
+        RUBY_TRY_CFLAGS([$optflags -D_FORTIFY_SOURCE=2], [RUBY_APPEND_OPTION(XCFLAGS, -D_FORTIFY_SOURCE=2)], [],
+                        [@%:@include <stdio.h>])
+    ])
+
+    : ${MJIT_HEADER_FLAGS='-P -dD'}
+
+    # -fstack-protector
+    AS_CASE(["$target_os"],
+    [mingw*|haiku*], [
+	stack_protector=no
+    ])
+    AS_IF([test -z "${stack_protector+set}"], [
+	AS_FOR(option, opt, [-fstack-protector-strong -fstack-protector], [
+	    RUBY_TRY_CFLAGS(option, [stack_protector=yes])
+	    AS_IF([test "x$stack_protector" = xyes], [
+		RUBY_TRY_LDFLAGS(option, [], [stack_protector=])
+	    ])
+	    AS_IF([test "x$stack_protector" = xyes], [stack_protector=option; break])
+	])
+    ])
+    AS_CASE(["$stack_protector"], [-*], [
+	RUBY_APPEND_OPTION(XCFLAGS, $stack_protector)
+	RUBY_APPEND_OPTION(XLDFLAGS, $stack_protector)
+	RUBY_APPEND_OPTION(LDFLAGS, $stack_protector)
+    ])
+
+    AS_CASE("${compress_debug_sections:-zlib}",
+    [none|no], [], [
+    RUBY_TRY_LDFLAGS(${linker_flag}--compress-debug-sections=${compress_debug_sections:-zlib},
+		     [compress_debug_sections=${compress_debug_sections:-zlib}],
+		     [compress_debug_sections=no])
+    ])
+    AS_IF([test "x$compress_debug_sections" != xno], [
+	RUBY_APPEND_OPTION(DLDFLAGS, ${linker_flag}--compress-debug-sections=$compress_debug_sections)
+    ])
+
+    AS_CASE(["$target_os"],[mingw*], [
+      # On  Windows  platforms,   system  provided  headers  are  VC++
+      # optimized.  That  is, C++  habits are often  contaminated into
+      # various  headers.  Most frequent  situation is  the use  of //
+      # comments.   We  bypass  ANSI   C  mode  for  them.   Otherwise
+      # extension libs cannot include those headers.
+
+      # Since math.h in some mingw64 wrongly declares frexp and modf
+      # to be pure, the variables pointed by the second arguments are
+      # considered uninitialized unexpectedly.
+      AC_CACHE_CHECK([whether frexp and modf are broken],
+	rb_cv_mingw64_broken_frexp_modf,
+	[
+	  save_CFLAGS="$CFLAGS"
+	  AS_IF([test "$particular_werror_flags" = "yes"], [
+	    CFLAGS="$CFLAGS -Werror=uninitialized"
+	  ], [
+	    CFLAGS="$CFLAGS -Werror -Wuninitialized"
+	  ])
+	  AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[@%:@include <math.h>
+	    int foo(double x)
+	    {
+	      int exp;
+	      frexp(x, &exp);
+	      return exp;
+	    }]], [[if (foo(0.0)) return 1;]])],
+	    [rb_cv_mingw64_broken_frexp_modf=no],
+	    [rb_cv_mingw64_broken_frexp_modf=yes])
+	  CFLAGS="$save_CFLAGS"
+	])
+      AS_IF([test "$rb_cv_mingw64_broken_frexp_modf" = yes], [
+	AC_DEFINE(RUBY_MINGW64_BROKEN_FREXP_MODF)
+      ])
+    ],
+    [cygwin*|darwin*|netbsd*], [
+      # need lgamma_r(), finite()
+    ])
+
+    # ANSI (no XCFLAGS because this is C only)
+    AS_CASE(["$target_os"],
+    [solaris*], [
+      # Because "-std=gnu99" affects existence of functions on Solaris,
+      # "-std=gnu99" will be appended to CPPFLAGS.
+	for ansi_options in -std=gnu99; do
+	    RUBY_TRY_CFLAGS(${ansi_options}, [
+		RUBY_APPEND_OPTIONS(CPPFLAGS, ${ansi_options})
+	    ], [ansi_options=])
+	    test "x${ansi_options}" = x || break
+	done
+    ],
+    [
+      # ANSI (no XCFLAGS because this is C only)
+      rb_tmp_std_check=`echo $CC $CFLAGS $optflags $warnflags $debugflags | fgrep std= | tr -d  '\015'`
+      AS_IF([test "x$rb_tmp_std_check" = "x"],
+      [
+	for ansi_options in -std=gnu99; do
+	    RUBY_TRY_CFLAGS(${ansi_options}, [
+		RUBY_APPEND_OPTIONS(warnflags, ${ansi_options})
+		RUBY_APPEND_OPTIONS(strict_warnflags, ${ansi_options})
+	    ], [ansi_options=])
+	    test "x${ansi_options}" = x || break
+	done
+      ])
+    ])
+
+    # suppress annoying -Wstrict-overflow warnings
+    RUBY_TRY_CFLAGS(-fno-strict-overflow, [RUBY_APPEND_OPTION(XCFLAGS, -fno-strict-overflow)])
+
+    test "${debugflags+set}" || {RUBY_TRY_CFLAGS(-ggdb3, [debugflags=-ggdb3])}
+    test "${debugflags+set}" || {RUBY_TRY_CFLAGS(-ggdb, [debugflags=-ggdb])}
+    test "${debugflags+set}" || {RUBY_TRY_CFLAGS(-g3, [debugflags=-g3])}
+])
+test $ac_cv_prog_cc_g = yes && : ${debugflags=-g}
+AS_IF([test "x$RUBY_DEVEL" = xyes], [RUBY_APPEND_OPTION(XCFLAGS, -DRUBY_DEVEL=1)])
+
+AS_IF([test "$GCC" = ""], [
+    AS_CASE(["$target_os"],[aix*],[warnflags="$warnflags -qinfo=por" rb_cv_warnflags="$rb_cv_warnflags -qinfo=por"])
+])
+AS_IF([test "$GCC" = yes], [
+    AS_IF([test "$gcc_major" -ge 4], [
+	RUBY_TRY_CFLAGS(-fvisibility=hidden, [visibility_option=yes], [visibility_option=no])
+    ])
+    AC_SUBST(WERRORFLAG, "-Werror")
+    AS_IF([test "$visibility_option" = yes], [
+	RUBY_APPEND_OPTION(XCFLAGS, -fvisibility=hidden)
+	AC_DEFINE(RUBY_SYMBOL_EXPORT_BEGIN, [_Pragma("GCC visibility push(default)")])
+	AC_DEFINE(RUBY_SYMBOL_EXPORT_END,   [_Pragma("GCC visibility pop")])
+    ], [
+	RUBY_TRY_LDFLAGS([-Wl,-unexported_symbol,_Init_*], [visibility_option=ld], [visibility_option=no])
+    ])
+    test "$visibility_option" = no || OBJCOPY=:
+])
+
+AS_IF([test "$GCC" = yes], [
+    # optflags
+
+    AS_CASE(["$target_os"], [mingw*], [
+	RUBY_TRY_CFLAGS(-fno-omit-frame-pointer, [optflags="${optflags+$optflags }-fno-omit-frame-pointer"])
+	RUBY_TRY_CFLAGS(-static-libgcc, [static_libgcc=yes], [static_libgcc=no])
+	AS_IF([test "$static_libgcc" = yes], [
+	    RUBY_APPEND_OPTION(EXTLDFLAGS, -static-libgcc)
+	])
+    ])
+
+    # disable fast-math
+    for oflag in -fno-fast-math; do
+	RUBY_TRY_CFLAGS($oflag, [RUBY_APPEND_OPTION(CFLAGS, $oflag)])
+    done
+    for oflag in -fexcess-precision=standard -fp-model\ precise; do
+	RUBY_TRY_CFLAGS($oflag, [RUBY_APPEND_OPTION(XCFLAGS, $oflag)])
+    done
+])
+
+AS_CASE(["$target_cpu"], [[i[3-6]86*]], [
+    AC_CACHE_CHECK([for __sync_val_compare_and_swap], [rb_cv_gcc_compiler_cas], [
+	AC_LINK_IFELSE([AC_LANG_PROGRAM([[unsigned long atomic_var;]],
+	    [[__sync_val_compare_and_swap(&atomic_var, 0, 1);]])],
+	    [rb_cv_gcc_compiler_cas=yes],
+	    [
+	    save_CFLAGS="$CFLAGS" CFLAGS="$CFLAGS -march=i486"
+	    AC_LINK_IFELSE([AC_LANG_PROGRAM([[unsigned long atomic_var;]],
+		[[__sync_val_compare_and_swap(&atomic_var, 0, 1);]])],
+		[rb_cv_gcc_compiler_cas=i486],
+		[rb_cv_gcc_compiler_cas=no])
+	    CFLAGS="$save_CFLAGS"
+	    ])
+    ])
+    AS_IF([test "$rb_cv_gcc_compiler_cas" = i486], [ARCH_FLAG="-march=i486"])
+])
+
+AC_ARG_WITH(opt-dir,
+	AS_HELP_STRING([--with-opt-dir=DIR-LIST],
+		       [add optional headers and libraries directories separated by $PATH_SEPARATOR]),
+	[
+		val=`echo "$PATH_SEPARATOR$withval" | sed "s|$PATH_SEPARATOR\([[^$PATH_SEPARATOR]*]\)| -I\1/include|g;s/^ //"`
+		CPPFLAGS="$CPPFLAGS $val"
+		val=`echo "$PATH_SEPARATOR$withval" | sed "s|$PATH_SEPARATOR\([[^$PATH_SEPARATOR]*]\)| -L\1/lib${rpathflag:+ $rpathflag\\\\1/lib}|g;s/^ //"`
+		LDFLAGS="$LDFLAGS $val"
+		LDFLAGS_OPTDIR="$val"
+		OPT_DIR="$withval"
+	], [OPT_DIR=])
+
+test -z "${ac_env_CFLAGS_set}" -a -n "${cflags+set}" && eval CFLAGS="\"$cflags $ARCH_FLAG\""
+test -z "${ac_env_CXXFLAGS_set}" -a -n "${cxxflags+set}" && eval CXXFLAGS="\"$cxxflags $ARCH_FLAG\""
+}
+
+AC_CACHE_CHECK([whether compiler has statement and declarations in expressions],
+  rb_cv_have_stmt_and_decl_in_expr,
+  [AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[]],[[ __extension__ ({ int a = 0; a; }); ]])],
+  [rb_cv_have_stmt_and_decl_in_expr=yes],
+  [rb_cv_have_stmt_and_decl_in_expr=no])])
+AS_IF([test "$rb_cv_have_stmt_and_decl_in_expr" = yes], [
+  AC_DEFINE(HAVE_STMT_AND_DECL_IN_EXPR)
+])
+
+: "header and library section" && {
+AC_ARG_WITH(winnt-ver,
+  AS_HELP_STRING([--with-winnt-ver=0xXXXX], [target Windows NT version (default to 0x0600)]),
+  [with_winnt_ver="$withval"], [with_winnt_ver="0x0600"])
+AS_CASE(["$target_os"],
+[mingw*], [
+  RUBY_APPEND_OPTION(CPPFLAGS, -D_WIN32_WINNT=$with_winnt_ver)
+  RUBY_APPEND_OPTION(CPPFLAGS, -D__MINGW_USE_VC2005_COMPAT)
+])
+
+AS_CASE(["$target_os"],
+[freebsd*], [
+  AC_CACHE_CHECK([whether pthread should be enabled by default],
+    rb_cv_enable_pthread_default,
+    [AC_PREPROC_IFELSE([AC_LANG_SOURCE([[
+#include <osreldate.h>
+#if __FreeBSD_version < 502102
+#error pthread should be disabled on this platform
+#endif
+      ]])],
+      rb_cv_enable_pthread_default=yes,
+      rb_cv_enable_pthread_default=no)])
+  enable_pthread=$rb_cv_enable_pthread_default
+  ],
+[mingw*], [
+  enable_pthread=no
+  ],
+[
+  enable_pthread=yes
+  ])
+
+dnl Checks for libraries.
+AS_CASE(["$target_os"],[*bsd*|dragonfly*],[],[ac_cv_func_daemon=no])
+
+AS_UNSET(ORIG_LIBS)
+POSTLINK=:
+AC_SUBST(POSTLINK)
+AS_CASE(["$target_os"],
+[nextstep*], [	],
+[openstep*], [	],
+[rhapsody*], [	],
+[darwin*], [
+		ORIG_LIBS="$LIBS"
+		RUBY_PREPEND_OPTION(LIBS, -lobjc)
+		RUBY_APPEND_OPTIONS(CPPFLAGS, -D_XOPEN_SOURCE -D_DARWIN_C_SOURCE -D_DARWIN_UNLIMITED_SELECT -D_REENTRANT)
+		AC_CACHE_CHECK([whether syscall(2) is deprecated], rb_cv_syscall_deprecated,
+		    [RUBY_WERROR_FLAG([
+			AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[@%:@include <unistd.h>]],
+							   [[if (syscall(0)) return 1;]])],
+			    [rb_cv_syscall_deprecated=no],
+			    [rb_cv_syscall_deprecated=yes])])])
+		AS_IF([test $rb_cv_syscall_deprecated = yes], [
+		    ac_cv_func___syscall=no
+		    ac_cv_func_syscall=no
+		    ac_cv_header_sys_syscall_h=no
+		    ac_cv_header_syscall_h=no
+		])
+		ac_cv_func_getcontext=no
+		ac_cv_func_setcontext=no
+		incs=`$CC -v -E -xc - < /dev/null 2>&1 | sed ['1,/^@%:@include </d;s/^ *//;s|[^./][^/]*/\.\./||g;/\/include$/!d;s||/lib|;/\/usr\/lib/d']`
+		for d in `$CC -print-search-dirs | sed -e '/^libraries: */!d;s///' | tr : '\012' | fgrep -v /../ | sed -n 's|^\(/.*/lib\)/$|\1|p'`; do
+		    incs=`echo "$incs" | fgrep -v "$d"`
+		done
+		for d in $incs; do
+		    test -d "$d" && RUBY_APPEND_OPTIONS(LDFLAGS, "-L$d")
+		done
+		ac_cv_type_getgroups=gid_t # getgroups() on Rosetta fills garbage
+		ac_cv_lib_crypt_crypt=no
+		ac_cv_func_fdatasync=no # Mac OS X wrongly reports it has fdatasync()
+		ac_cv_func_vfork=no
+		AS_IF([test $gcc_major -lt 4 -o \( $gcc_major -eq 4 -a $gcc_minor -lt 3 \)], [
+		    ac_cv_func___builtin_setjmp=no
+		])
+		with_setjmp_type=sigsetjmp # to hijack SIGCHLD handler
+		AC_CACHE_CHECK(for broken crypt with 8bit chars, rb_cv_broken_crypt,
+		    [AC_RUN_IFELSE([AC_LANG_SOURCE([[
+#include <stdio.h>
+#include <unistd.h>
+#include <string.h>
+
+void
+broken_crypt(const char *salt, const char *buf1, const char *buf2)
+{
+#if 0
+    printf("%.2x%.2x: %s -> %s\n", (unsigned char)salt[0], (unsigned char)salt[1],
+	   buf1+2, buf2+2);
+#endif
+}
+
+int
+main()
+{
+    int i;
+    char salt[2], buf[256], *s;
+    for (i = 0; i < 128*128; i++) {
+	salt[0] = 0x80 | (i & 0x7f);
+	salt[1] = 0x80 | (i >> 7);
+	strcpy(buf, crypt("", salt));
+	if (strcmp(buf, s = crypt("", salt))) {
+	    broken_crypt(salt, buf, s);
+	    return 1;
+	}
+    }
+    salt[0] = salt[1] = ' ';
+    strcpy(buf, crypt("", salt));
+    salt[0] = salt[1] = 0x80 | ' ';
+    if (strcmp(buf, s = crypt("", salt))) {
+	broken_crypt(salt, buf, s);
+	return 1;
+    }
+    return 0;
+}
+]])],
+		    rb_cv_broken_crypt=no,
+		    rb_cv_broken_crypt=yes,
+		    rb_cv_broken_crypt=yes)])
+		AS_IF([test "$rb_cv_broken_crypt" = yes], [
+		   AC_DEFINE(BROKEN_CRYPT, 1)
+		])
+		POSTLINK=""
+		AC_CHECK_PROGS(codesign, codesign)
+		AC_CHECK_PROGS(dsymutil, dsymutil)
+		AS_IF([test -n "$codesign"], [
+		    POSTLINK="{ test -z '\$(RUBY_CODESIGN)' || $codesign -s '\$(RUBY_CODESIGN)' -f \$@; }${POSTLINK:+; $POSTLINK}"
+		])
+		AS_IF([test -n "$dsymutil"], [
+		    POSTLINK="$dsymutil \$@${POSTLINK:+; $POSTLINK}"
+		])
+		AS_IF([test -n "${POSTLINK}"], [
+		    LINK_SO="$LINK_SO
+\$(POSTLINK)"
+		])
+		AC_CHECK_HEADERS(crt_externs.h, [], [], [
+		    #include <crt_externs.h>
+		])
+		],
+[hpux*], [	LIBS="-lm $LIBS"
+		ac_cv_c_inline=no],
+[solaris*], [	LIBS="-lm $LIBS"
+		ac_cv_func_vfork=no
+		AC_MSG_CHECKING(whether _XOPEN_SOURCE is already given)
+		AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[#include <unistd.h>
+			#ifndef _XOPEN_SOURCE
+			#error _XOPEN_SOURCE is not defined
+			#endif
+			]], [[]])],
+		        [given_xopen_source=yes], [given_xopen_source=no])
+		AC_MSG_RESULT($given_xopen_source)
+		AS_IF([test $given_xopen_source = no], [
+		  AC_MSG_CHECKING(appropriate _XOPEN_SOURCE value to define)
+		  define_xopen_source=""
+		  for tmp_xpg in 7 6 5; do
+		    AS_IF([test x"$define_xopen_source" != x], [
+		      break
+		    ])
+		    RUBY_WERROR_FLAG([AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
+			#define _XOPEN_SOURCE ${tmp_xpg}00
+			#include <unistd.h>
+			#ifndef _XPG${tmp_xpg}
+			#error _XPG${tmp_xpg} should be defined by _XOPEN_SOURCE=${tmp_xpg}00
+			#endif
+			]], [[]])],
+			[define_xopen_source=${tmp_xpg}00], [])
+			])
+		  done
+		  AS_IF([test x"$define_xopen_source" = x], [
+		    define_xopen_source=no
+		  ])
+		  AC_MSG_RESULT($define_xopen_source)
+		  AS_IF([test x"$define_xopen_source" != xno], [
+		    RUBY_APPEND_OPTIONS(CPPFLAGS, -D_XOPEN_SOURCE=$define_xopen_source)
+		    # _XOPEN_SOURCE should not be defined for C++ on Solaris.
+		    RUBY_APPEND_OPTIONS(CXXFLAGS, -U_XOPEN_SOURCE)
+		  ])
+		])
+		],
+[haiku*], [
+		LIBS="$LIBS" # m lib is include in root
+		],
+[cygwin*], [	ac_cv_header_langinfo_h=yes
+		RUBY_APPEND_OPTIONS(CPPFLAGS, -D_XOPEN_SOURCE -D_GNU_SOURCE)
+		AC_CHECK_FUNCS(cygwin_conv_path)
+		AC_LIBOBJ([langinfo])
+		],
+[mingw*], [	LIBS="-lshell32 -lws2_32 -liphlpapi -limagehlp -lshlwapi $LIBS"
+		ac_cv_header_a_out_h=no
+		ac_cv_header_pwd_h=no
+		ac_cv_header_utime_h=no
+		ac_cv_header_sys_ioctl_h=no
+		ac_cv_header_sys_param_h=no
+		ac_cv_header_sys_resource_h=no
+		ac_cv_header_sys_select_h=no
+		ac_cv_header_sys_time_h=no
+		ac_cv_header_sys_times_h=no
+		ac_cv_header_sys_socket_h=no
+		ac_cv_func_lstat=yes
+		ac_cv_func_times=yes
+		ac_cv_func_waitpid=yes
+		ac_cv_func_fsync=yes
+		ac_cv_func_seekdir=yes
+		ac_cv_func_telldir=yes
+		ac_cv_func_lchown=yes
+		ac_cv_func_link=yes
+		ac_cv_func_readlink=yes
+		ac_cv_func_symlink=yes
+		ac_cv_lib_crypt_crypt=no
+		ac_cv_func_getpgrp_void=no
+		ac_cv_func_memcmp_working=yes
+		ac_cv_lib_dl_dlopen=no
+		rb_cv_binary_elf=no
+		rb_cv_negative_time_t=no
+		ac_cv_func_fcntl=yes
+		ac_cv_func_flock=yes
+		ac_cv_func_gmtime_r=yes
+		rb_cv_large_fd_select=yes
+		ac_cv_type_struct_timeval=yes
+                ac_cv_func_clock_gettime=yes
+                ac_cv_func_clock_getres=yes
+		ac_cv_func_malloc_usable_size=no
+		ac_cv_type_off_t=yes
+		ac_cv_sizeof_off_t=8
+		AS_IF([test "$target_cpu" = x64], [
+		    ac_cv_func___builtin_setjmp=yes
+		    ac_cv_func_round=no
+		    rb_cv_coroutine=yes
+		])
+		ac_cv_func_tgamma=no
+		rb_cv_negative_time_t=yes
+		AC_CHECK_TYPE([NET_LUID], [], [],
+			      [@%:@include <winsock2.h>
+			      @%:@include <iphlpapi.h>])
+		AS_IF([test x"$ac_cv_type_NET_LUID" = xyes], [
+		    AC_DEFINE(HAVE_TYPE_NET_LUID, 1)
+		])
+		AC_CHECK_FUNCS(_gmtime64_s)
+		AC_CHECK_FUNCS(_wfreopen_s)
+		AC_LIBOBJ([langinfo])
+		],
+[bsdi*], [	LIBS="-lm $LIBS"
+		AC_DEFINE(BROKEN_SETREUID, 1)
+		AC_DEFINE(BROKEN_SETREGID, 1)
+                ac_cv_sizeof_rlim_t=8],
+[freebsd*], [	LIBS="-lm $LIBS"
+		ac_cv_func_getpeername=no
+		ac_cv_func_getsockname=no
+		ac_cv_func_shutdown=no
+		ac_cv_func_close=no
+		],
+[netbsd*], [	LIBS="-lm $LIBS"
+		],
+[dragonfly*], [	LIBS="-lm $LIBS"
+		],
+[aix*],[	LIBS="-lm $LIBS"
+		ac_cv_func_round=no
+		ac_cv_func___builtin_setjmp=no
+		],
+[linux*],[	LIBS="-lm $LIBS"
+		# __builtin_longjmp in ppc64* Linux does not restore
+		# the TOC register (r2), which is problematic
+		# when a global exit happens from JITted .so code.
+		AS_CASE(["$target_cpu"], [powerpc64*], [
+			ac_cv_func___builtin_setjmp=no
+		])
+		# With gcc-8's -fcf-protection, MJIT's __builtin_longjmp fails.
+		AS_CASE(["$CC $CFLAGS "], [*" -fcf-protection "*], [cf_protection=yes], [cf_protection=no])
+		AS_IF([test "$cf_protection" = yes], [
+			ac_cv_func___builtin_setjmp=no
+		])
+		],
+[	LIBS="-lm $LIBS"])
+: ${ORIG_LIBS=$LIBS}
+
+AS_IF([test -n "${rb_there_is_in_fact_no_gplusplus_but_autoconf_is_cheating_us}"], [
+    AC_MSG_NOTICE([Test skipped due to lack of a C++ compiler.])
+],
+[test -n "${CXX}"], [
+    RUBY_WERROR_FLAG([
+        AC_MSG_CHECKING([whether CXXFLAGS is valid])
+        AC_LANG_PUSH(C++)
+        AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[@%:@include <cstdio>]], [[]])],
+	    [AC_MSG_RESULT(yes)],[
+            AC_MSG_RESULT(no)
+            # The message mentions CXXFLAGS, but CPPFLAGS might also affects.
+            AC_MSG_WARN([something wrong with CXXFLAGS="$CXXFLAGS"])
+            CXX=false
+        ])
+        AC_LANG_POP(C++)
+    ])
+])
+
+AC_CHECK_LIB(crypt, crypt)      # glibc (GNU/Linux, GNU/Hurd, GNU/kFreeBSD)
+AC_CHECK_LIB(dl, dlopen)	# Dynamic linking for SunOS/Solaris and SYSV
+AC_CHECK_LIB(dld, shl_load)	# Dynamic linking for HP-UX
+AC_CHECK_LIB(socket, shutdown)  # SunOS/Solaris
+
+dnl Checks for header files.
+AC_HEADER_DIRENT
+dnl AC_HEADER_STDC has been checked in AC_USE_SYSTEM_EXTENSIONS
+AC_HEADER_STDBOOL
+AC_HEADER_SYS_WAIT
+
+AC_CHECK_HEADERS(a.out.h)
+AC_CHECK_HEADERS(atomic.h)
+AC_CHECK_HEADERS(copyfile.h)
+AC_CHECK_HEADERS(direct.h)
+AC_CHECK_HEADERS(grp.h)
+AC_CHECK_HEADERS(fcntl.h)
+AC_CHECK_HEADERS(float.h)
+AC_CHECK_HEADERS(ieeefp.h)
+AC_CHECK_HEADERS(intrinsics.h)
+AC_CHECK_HEADERS(langinfo.h)
+AC_CHECK_HEADERS(limits.h)
+AC_CHECK_HEADERS(locale.h)
+AC_CHECK_HEADERS(malloc.h)
+AC_CHECK_HEADERS(malloc/malloc.h)
+AC_CHECK_HEADERS(malloc_np.h)
+AC_CHECK_HEADERS(net/socket.h)
+AC_CHECK_HEADERS(process.h)
+AC_CHECK_HEADERS(pwd.h)
+AC_CHECK_HEADERS(sanitizer/asan_interface.h)
+AC_CHECK_HEADERS(sanitizer/msan_interface.h)
+AC_CHECK_HEADERS(setjmpex.h)
+AC_CHECK_HEADERS(stdalign.h)
+AC_CHECK_HEADERS(sys/attr.h)
+AC_CHECK_HEADERS(sys/eventfd.h)
+AC_CHECK_HEADERS(sys/fcntl.h)
+AC_CHECK_HEADERS(sys/file.h)
+AC_CHECK_HEADERS(sys/id.h)
+AC_CHECK_HEADERS(sys/ioctl.h)
+AC_CHECK_HEADERS(sys/mkdev.h)
+AC_CHECK_HEADERS(sys/param.h)
+AC_CHECK_HEADERS(sys/prctl.h)
+AC_CHECK_HEADERS(sys/resource.h)
+AC_CHECK_HEADERS(sys/select.h)
+AC_CHECK_HEADERS(sys/sendfile.h)
+AC_CHECK_HEADERS(sys/socket.h)
+AC_CHECK_HEADERS(sys/syscall.h)
+AC_CHECK_HEADERS(sys/sysmacros.h)
+AC_CHECK_HEADERS(sys/time.h)
+AC_CHECK_HEADERS(sys/times.h)
+AC_CHECK_HEADERS(sys/uio.h)
+AC_CHECK_HEADERS(sys/utime.h)
+AC_CHECK_HEADERS(syscall.h)
+AC_CHECK_HEADERS(time.h)
+AC_CHECK_HEADERS(ucontext.h)
+AC_CHECK_HEADERS(utime.h)
+AS_CASE("$target_cpu", [x64|x86_64|i[3-6]86*], [
+  AC_CHECK_HEADERS(x86intrin.h)
+])
+
+AC_ARG_WITH([gmp],
+  [AS_HELP_STRING([--without-gmp],
+    [disable GNU GMP to accelerate Bignum operations])],
+  [],
+  [with_gmp=yes])
+AS_IF([test "x$with_gmp" != xno],
+  [AC_CHECK_HEADERS(gmp.h)
+   AS_IF([test "x$ac_cv_header_gmp_h" != xno],
+     AC_SEARCH_LIBS([__gmpz_init], [gmp],
+       [AC_DEFINE(HAVE_LIBGMP, 1)]))])
+
+AC_ARG_WITH([jemalloc],
+  [AS_HELP_STRING([--with-jemalloc],[use jemalloc allocator])],
+  [with_jemalloc=$withval], [with_jemalloc=no])
+AS_IF([test "x$with_jemalloc" != xno],[
+  AC_SEARCH_LIBS([malloc_conf], [jemalloc],
+    [
+      AC_DEFINE(HAVE_LIBJEMALLOC, 1)
+      with_jemalloc=yes
+    ],
+    [test x$with_jemalloc = xyes && with_jemalloc=no])
+  AC_CHECK_HEADER(jemalloc/jemalloc.h, [
+    AC_DEFINE(RUBY_ALTERNATIVE_MALLOC_HEADER, [<jemalloc/jemalloc.h>])
+  ],
+  [test x$with_jemalloc = xyes && with_jemalloc=no])
+  AS_IF([test "x$with_jemalloc" != xyes], [
+    AC_CACHE_CHECK([for jemalloc with JEMALLOC_MANGLE], rb_cv_jemalloc_demangle,
+      [AC_LINK_IFELSE([AC_LANG_PROGRAM([@%:@define JEMALLOC_MANGLE 1
+      @%:@ifdef RUBY_ALTERNATIVE_MALLOC_HEADER
+      @%:@include RUBY_ALTERNATIVE_MALLOC_HEADER
+      @%:@else
+      @%:@include <jemalloc.h>
+      @%:@endif], [return !&malloc_conf])],
+      [rb_cv_jemalloc_demangle=yes],
+      [rb_cv_jemalloc_demangle=no])
+    ])
+  ])
+  AS_IF([test "x$rb_cv_jemalloc_demangle" = xyes], [
+    AC_DEFINE(JEMALLOC_MANGLE)
+    with_jemalloc=yes
+  ])
+  AS_CASE(["$with_jemalloc"],
+    [yes],
+    [
+      AC_DEFINE(HAVE_MALLOC_CONF)
+      ac_cv_func_malloc_usable_size=yes
+    ],
+    [no],
+    [AC_MSG_ERROR([jemalloc requested but not found])
+  ])
+])
+
+dnl check for large file stuff
+mv confdefs.h confdefs1.h
+: > confdefs.h
+AC_SYS_LARGEFILE
+# On 32-bit Solaris, it is safe to define _LARGEFILE_SOURCE
+# which is not added by AC_SYS_LARGEFILE.
+AS_IF([test x"$enable_largefile" != xno], [
+  AS_CASE(["$target_os"], [solaris*], [
+    AC_MSG_CHECKING([wheather _LARGEFILE_SOURCE should be defined])
+    AS_CASE(["${ac_cv_sys_file_offset_bits}:${ac_cv_sys_large_files}"],
+      ["64:"|"64:no"|"64:unknown"], [
+	# insert _LARGEFILE_SOURCE before _FILE_OFFSET_BITS line
+	# that is the same order as "getconf LFS_CFLAGS" output
+	mv confdefs.h largefile0.h
+	: > confdefs.h
+	AC_DEFINE(_LARGEFILE_SOURCE)
+	cat largefile0.h >> confdefs.h
+	rm largefile0.h
+	AC_MSG_RESULT([yes])
+      ], [AC_MSG_RESULT([no])])
+  ])
+])
+mv confdefs.h largefile.h
+mv confdefs1.h confdefs.h
+cat largefile.h >> confdefs.h
+
+AS_CASE(["$target_os"],
+    [aix*], [
+    AS_CASE(["$target_cpu:$ac_cv_sys_large_files"],
+	[ppc64:*|powerpc64:*], [],
+	[*:no|*:unknown], [],
+	[
+	    # AIX currently does not support a 32-bit call to posix_fadvise()
+	    # if _LARGE_FILES is defined.
+	    ac_cv_func_posix_fadvise=no
+	])
+    ])
+
+AC_C_BIGENDIAN
+AC_C_CONST
+AC_C_CHAR_UNSIGNED
+AC_C_INLINE
+AC_C_VOLATILE
+AC_C_TYPEOF
+AC_C_RESTRICT
+
+AS_CASE(":$ac_cv_c_const:$ac_cv_c_volatile:",
+    [*:no:*], [AC_MSG_ERROR(ANSI C-conforming const and volatile are mandatory)])
+
+AC_CHECK_TYPES([long long, off_t])
+
+AC_CACHE_CHECK([char bit], [rb_cv_char_bit],
+    [test "$universal_binary" = yes && cross_compiling=yes
+    AC_COMPUTE_INT([rb_cv_char_bit], [CHAR_BIT],
+	[AC_INCLUDES_DEFAULT([@%:@include <limits.h>])], [rb_cv_char_bit=8])
+    test "$universal_binary" = yes && cross_compiling=$real_cross_compiling])
+
+RUBY_CHECK_SIZEOF(int, [], [ILP])
+RUBY_CHECK_SIZEOF(short)
+RUBY_CHECK_SIZEOF(long, [int], [ILP LP])
+RUBY_CHECK_SIZEOF(long long)
+RUBY_CHECK_SIZEOF(__int64, [8], [ILP LP])
+RUBY_CHECK_SIZEOF(__int128, [16], [ILP LP])
+RUBY_CHECK_SIZEOF(off_t)
+RUBY_CHECK_SIZEOF(void*, [int long "long long"], [ILP LP LLP])
+RUBY_CHECK_SIZEOF(float)
+RUBY_CHECK_SIZEOF(double)
+RUBY_CHECK_SIZEOF(time_t, [long "long long"], [], [@%:@include <time.h>])
+RUBY_CHECK_SIZEOF(clock_t, [], [], [@%:@include <time.h>])
+
+AC_CACHE_CHECK(packed struct attribute, rb_cv_packed_struct,
+    [rb_cv_packed_struct=no
+    for mac in \
+	"__pragma(pack(push, 1)) x __pragma(pack(pop))" \
+	"x __attribute__((packed))" \
+	; do
+	AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[@%:@define PACKED_STRUCT(x) $mac
+			PACKED_STRUCT(struct { int a; });]], [[]])],
+		[rb_cv_packed_struct=$mac; break])
+    done])
+AS_IF([test "$rb_cv_packed_struct" != no], [
+    AC_DEFINE_UNQUOTED([PACKED_STRUCT(x)], [$rb_cv_packed_struct])
+    RUBY_TRY_CFLAGS(-Wno-address-of-packed-member, [AC_DEFINE(USE_UNALIGNED_MEMBER_ACCESS)])
+], [
+    AC_DEFINE_UNQUOTED([PACKED_STRUCT(x)], x)
+])
+
+AS_IF([test "x$ac_cv_type_long_long" = xyes], [
+    RUBY_CHECK_PRINTF_PREFIX(long long, ll I64, LL)
+], [test "x$ac_cv_type___int64" = xyes], [
+    RUBY_CHECK_PRINTF_PREFIX(__int64, ll I64, LL)
+])
+
+RUBY_REPLACE_TYPE(pid_t, int, PIDT)
+RUBY_REPLACE_TYPE(uid_t, int, UIDT)
+RUBY_REPLACE_TYPE(gid_t, int, GIDT)
+RUBY_REPLACE_TYPE(time_t, [], TIMET, [@%:@include <time.h>])
+RUBY_REPLACE_TYPE(dev_t, [int long "long long"], DEVT)
+RUBY_REPLACE_TYPE(mode_t, ["unsigned short" "unsigned int" long], MODET, [@%:@include <sys/stat.h>])
+RUBY_REPLACE_TYPE(rlim_t, [int long "long long"], RLIM, [
+@%:@ifdef HAVE_SYS_TYPES_H
+@%:@include <sys/types.h>
+@%:@endif
+@%:@ifdef HAVE_SYS_TYPES_H
+@%:@include <sys/time.h>
+@%:@endif
+@%:@include <sys/resource.h>
+])
+RUBY_REPLACE_TYPE(off_t, [], OFFT)
+RUBY_REPLACE_TYPE(clockid_t, [], CLOCKID, [@%:@ifdef HAVE_TIME_H
+@%:@ include <time.h>
+@%:@endif
+@%:@ifdef HAVE_SYS_TIME_H
+@%:@ include <sys/time.h>
+@%:@endif])
+
+# __VA_ARGS__ is also tested in AC_PROG_CC_C99 since autoconf 2.60a (around
+# 2006). The check below is redundant and should always success.  Remain not
+# deleted for backward compat.
+AC_CACHE_CHECK(for variable length macro, rb_cv_va_args_macro,
+  [AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
+int foo(const char*);
+@%:@define FOO(...) foo(@%:@__VA_ARGS__)
+]], [[FOO(1);FOO(1,2);FOO(1,2,3);]])],
+  rb_cv_va_args_macro=yes,
+  rb_cv_va_args_macro=no)])
+AS_IF([test "$rb_cv_va_args_macro" = yes], [
+  AC_DEFINE(HAVE_VA_ARGS_MACRO)
+])
+
+# We want C11's  `_Alignof`.  GCC (and alike) have  `__alignof__`, which behave
+# slightly differently  than the  C11's.  We cannot  use `__alignof__`  for our
+# purpose.   The problem  is, however,  that  old gcc  and old  clang had  both
+# implemented `_Alignof` as  a synonym of `__alignof__`.  They are  not what we
+# want.  We have to check sanity.
+#
+# See also: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=52023
+# See also: https://bugs.llvm.org/show_bug.cgi?id=26547
+AC_CACHE_CHECK([if _Alignof() works], rb_cv_have__alignof,[
+    rb_cv_have__alignof=no
+    RUBY_WERROR_FLAG([
+        AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
+            @%:@ifdef HAVE_STDALIGN_H
+            @%:@include <stdalign.h>
+            @%:@endif
+            @%:@ifdef STDC_HEADERS
+            @%:@include <stddef.h>
+            @%:@endif
+            @%:@ifndef __GNUC__
+            @%:@define __extension__
+            @%:@endif
+        ]], [[
+            typedef struct conftest_tag {
+                char _;
+                double d;
+            } T;
+            static int conftest_ary@<:@
+                offsetof(T, d) == __extension__ _Alignof(double)
+                ? 1 : -1
+            @:>@;
+            return conftest_ary@<:@0@:>@;
+        ]])],[
+            rb_cv_have__alignof=yes
+        ],[])
+    ])
+])
+AS_IF([test "$rb_cv_have__alignof" != no], [
+    AC_DEFINE(HAVE__ALIGNOF)
+])
+
+RUBY_FUNC_ATTRIBUTE(__const__, CONSTFUNC)
+RUBY_FUNC_ATTRIBUTE(__pure__, PUREFUNC)
+RUBY_FUNC_ATTRIBUTE(__noreturn__, NORETURN)
+RUBY_FUNC_ATTRIBUTE(__deprecated__, DEPRECATED)
+RUBY_FUNC_ATTRIBUTE(__deprecated__("by "@%:@n), DEPRECATED_BY(n,x), rb_cv_func_deprecated_by)
+RUBY_FUNC_ATTRIBUTE(__noinline__, NOINLINE)
+RUBY_FUNC_ATTRIBUTE(__always_inline__, ALWAYS_INLINE)
+RUBY_FUNC_ATTRIBUTE(__no_sanitize__(san), NO_SANITIZE(san, x), rb_cv_func_no_sanitize)
+RUBY_FUNC_ATTRIBUTE(__no_sanitize_address__, NO_SANITIZE_ADDRESS)
+RUBY_FUNC_ATTRIBUTE(__no_address_safety_analysis__, NO_ADDRESS_SAFETY_ANALYSIS)
+RUBY_FUNC_ATTRIBUTE(__warn_unused_result__, WARN_UNUSED_RESULT)
+RUBY_FUNC_ATTRIBUTE(__unused__, MAYBE_UNUSED)
+RUBY_FUNC_ATTRIBUTE(__error__ mesg, ERRORFUNC(mesg,x), rb_cv_func___error__)
+RUBY_FUNC_ATTRIBUTE(__warning__ mesg, WARNINGFUNC(mesg,x), rb_cv_func___warning__)
+RUBY_FUNC_ATTRIBUTE(__weak__, WEAK, rb_cv_func_weak)
+AS_IF([test "$rb_cv_func_weak" != x], [
+   AC_DEFINE(HAVE_FUNC_WEAK)
+])
+
+AC_CACHE_CHECK([for __attribute__((__depreacted__(msg))) in C++],
+  rb_cv_CentOS6_CXX_workaround,
+  RUBY_WERROR_FLAG([
+    AC_LANG_PUSH([C++])
+    AC_COMPILE_IFELSE(
+      [AC_LANG_PROGRAM(
+        [],
+        [__attribute__((__deprecated__("message"))) int conftest(...);])],
+      [rb_cv_CentOS6_CXX_workaround=yes],
+      [rb_cv_CentOS6_CXX_workaround=no])
+    AC_LANG_POP()]))
+AS_IF([test "$rb_cv_CentOS6_CXX_workaround" != no],[
+  AC_DEFINE([RUBY_CXX_DEPRECATED(msg)],
+    [__attribute__((__deprecated__(msg)))])])
+
+AC_CACHE_CHECK([for std::nullptr_t], rb_cv_CXX_nullptr, [
+  AC_LANG_PUSH([C++])
+  AC_COMPILE_IFELSE(
+    [AC_LANG_PROGRAM(
+      [@%:@include <cstddef>],
+      [static std::nullptr_t const *const conftest = nullptr;])],
+    [rb_cv_CXX_nullptr=yes],
+    [rb_cv_CXX_nullptr=no])
+  AC_LANG_POP()])
+AS_IF([test "$rb_cv_CXX_nullptr" != no],[AC_DEFINE(HAVE_NULLPTR)])
+
+if_i386=${universal_binary+[defined __i386__]}
+RUBY_FUNC_ATTRIBUTE(__stdcall__,  FUNC_STDCALL,  rb_cv_func_stdcall,  ${if_i386})
+RUBY_FUNC_ATTRIBUTE(__cdecl__,    FUNC_CDECL,    rb_cv_func_cdecl,    ${if_i386})
+RUBY_FUNC_ATTRIBUTE(__fastcall__, FUNC_FASTCALL, rb_cv_func_fastcall, ${if_i386})
+RUBY_FUNC_ATTRIBUTE(__optimize__("O0"), FUNC_UNOPTIMIZED, rb_cv_func_unoptimized)
+RUBY_FUNC_ATTRIBUTE(__optimize__("-Os","-fomit-frame-pointer"), FUNC_MINIMIZED, rb_cv_func_minimized)
+
+AS_IF([test "$GCC" = yes], [
+    AC_CACHE_CHECK([for function alias], [rb_cv_gcc_function_alias],
+	[rb_cv_gcc_function_alias=no
+	for a in alias weak,alias; do
+	    AC_LINK_IFELSE([AC_LANG_PROGRAM([[void foo(void) {}
+		void bar(void) __attribute__(($a("foo")));]], [[bar()]])],
+		[rb_cv_gcc_function_alias=$a; break])
+	done])
+    AS_IF([test "$rb_cv_gcc_function_alias" != no], [
+	AC_DEFINE(HAVE_ATTRIBUTE_FUNCTION_ALIAS)
+	AC_DEFINE_UNQUOTED([RUBY_ALIAS_FUNCTION_TYPE(type, prot, name, args)],
+			   [type prot __attribute__(($rb_cv_gcc_function_alias(@%:@name)));])
+	AC_DEFINE_UNQUOTED([RUBY_ALIAS_FUNCTION_VOID(prot, name, args)],
+			   [RUBY_ALIAS_FUNCTION_TYPE(void, prot, name, args)])
+    ])
+
+    AC_CACHE_CHECK([for __atomic builtins], [rb_cv_gcc_atomic_builtins], [
+	AC_LINK_IFELSE([AC_LANG_PROGRAM([[unsigned int atomic_var;]],
+		    [[
+			__atomic_exchange_n(&atomic_var, 0, __ATOMIC_SEQ_CST);
+			__atomic_exchange_n(&atomic_var, 1, __ATOMIC_SEQ_CST);
+			__atomic_fetch_add(&atomic_var, 1, __ATOMIC_SEQ_CST);
+			__atomic_fetch_sub(&atomic_var, 1, __ATOMIC_SEQ_CST);
+			__atomic_or_fetch(&atomic_var, 1, __ATOMIC_SEQ_CST);
+		    ]])],
+		    [rb_cv_gcc_atomic_builtins=yes],
+		    [rb_cv_gcc_atomic_builtins=no])])
+    AS_IF([test "$rb_cv_gcc_atomic_builtins" = yes], [
+	AC_DEFINE(HAVE_GCC_ATOMIC_BUILTINS)
+    ])
+
+    AC_CACHE_CHECK([for __sync builtins], [rb_cv_gcc_sync_builtins], [
+	AC_LINK_IFELSE([AC_LANG_PROGRAM([[unsigned int atomic_var;]],
+		    [[
+			__sync_lock_test_and_set(&atomic_var, 0);
+			__sync_lock_test_and_set(&atomic_var, 1);
+			__sync_fetch_and_add(&atomic_var, 1);
+			__sync_fetch_and_sub(&atomic_var, 1);
+			__sync_or_and_fetch(&atomic_var, 1);
+			__sync_val_compare_and_swap(&atomic_var, 0, 1);
+		    ]])],
+		    [rb_cv_gcc_sync_builtins=yes],
+		    [rb_cv_gcc_sync_builtins=no])])
+    AS_IF([test "$rb_cv_gcc_sync_builtins" = yes], [
+	AC_DEFINE(HAVE_GCC_SYNC_BUILTINS)
+    ])
+])
+
+    AC_CACHE_CHECK(for __builtin_unreachable, rb_cv_func___builtin_unreachable,
+    [RUBY_WERROR_FLAG(
+    [AC_LINK_IFELSE([AC_LANG_PROGRAM([[volatile int zero;]],
+	[[if (zero) __builtin_unreachable();]])],
+	[rb_cv_func___builtin_unreachable=yes],
+	[rb_cv_func___builtin_unreachable=no])
+    ])
+    ])
+    AS_IF([test "$rb_cv_func___builtin_unreachable" = yes], [
+	AC_DEFINE_UNQUOTED(UNREACHABLE, [__builtin_unreachable()])
+    ])
+
+AC_CACHE_CHECK(for exported function attribute, rb_cv_func_exported, [
+rb_cv_func_exported=no
+RUBY_WERROR_FLAG([
+for mac in '__attribute__ ((__visibility__("default")))' '__declspec(dllexport)'; do
+  AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[@%:@define RUBY_FUNC_EXPORTED $mac extern
+    RUBY_FUNC_EXPORTED void conftest_attribute_check(void);]], [[]])],
+    [rb_cv_func_exported="$mac"; break])
+done
+])])
+AS_IF([test "$rb_cv_func_exported" != no], [
+    AC_DEFINE_UNQUOTED(RUBY_FUNC_EXPORTED, [$rb_cv_func_exported extern])
+])
+RUBY_DECL_ATTRIBUTE([__nonnull__(n)], [RUBY_FUNC_NONNULL(n,x)], [rb_cv_func_nonnull],
+                    [], [function], [
+@%:@define x int conftest_attribute_check(void *p)
+@%:@define n 1
+])
+
+RUBY_APPEND_OPTION(XCFLAGS, -DRUBY_EXPORT)
+
+AC_ARG_ENABLE(mathn,
+    AS_HELP_STRING([--enable-mathn], [enable canonicalization for mathn]),
+    [AC_MSG_ERROR([mathn support has been dropped])])
+
+AC_CACHE_CHECK(for function name string predefined identifier,
+    rb_cv_function_name_string,
+    [AS_CASE(["$target_os"],[openbsd*],[
+      rb_cv_function_name_string=__func__
+     ],[
+     rb_cv_function_name_string=no
+      RUBY_WERROR_FLAG([
+        for func in __func__ __FUNCTION__; do
+            AC_LINK_IFELSE([AC_LANG_PROGRAM([[@%:@include <stdio.h>]],
+			 		    [[puts($func);]])],
+            [rb_cv_function_name_string=$func
+            break])
+        done
+      ])])]
+)
+AS_IF([test "$rb_cv_function_name_string" != no], [
+    AC_DEFINE_UNQUOTED(RUBY_FUNCTION_NAME_STRING, [$rb_cv_function_name_string])
+])
+
+AC_CACHE_CHECK(if enum over int is allowed, rb_cv_enum_over_int, [
+    rb_cv_enum_over_int=no
+    AS_IF([test "x$ac_cv_type_long_long" = xyes], [
+	type="unsigned long long" max="ULLONG_MAX"
+    ], [
+	type="unsigned long" max="ULONG_MAX"
+    ])
+    RUBY_WERROR_FLAG([
+        AC_COMPILE_IFELSE([
+            AC_LANG_BOOL_COMPILE_TRY([
+                    @%:@include <limits.h>
+                    enum {conftest_max = $max};
+                ], [
+                    (conftest_max == $max) &&
+                    (sizeof(conftest_max) == sizeof($type))
+                ]
+	    )],
+	    [rb_cv_enum_over_int=yes],
+	    [rb_cv_enum_over_int=no]
+	)
+    ])
+])
+AS_IF([test $rb_cv_enum_over_int = yes], [
+    AC_DEFINE(ENUM_OVER_INT, 1)
+])
+
+dnl Check whether we need to define sys_nerr locally
+AC_CHECK_DECLS([sys_nerr], [], [], [$ac_includes_default
+@%:@include <errno.h>])
+
+AC_CHECK_DECLS([getenv])
+
+AS_CASE(["$target_cpu"],
+[alpha*|sh4|sh4el|sh4eb], [AS_CASE(["$target_os"::"$GCC"],
+		[*::yes],  # gcc
+			[CFLAGS="-mieee $CFLAGS"],
+		[osf*],    # ccc
+			[CFLAGS="-ieee $CFLAGS"],
+		)],
+[sparc*], [AC_LIBOBJ([sparc])])
+
+ac_cv_header_net_socket_h=${ac_cv_header_net_socket_h=no}
+AS_IF([test "$ac_cv_header_net_socket_h" = yes], [
+    ac_cv_header_sys_socket_h=${ac_cv_header_sys_socket_h=no}
+], [
+    ac_cv_header_sys_socket_h=${ac_cv_header_sys_socket_h=yes}
+])
+
+
+AC_TYPE_SIZE_T
+RUBY_CHECK_SIGNEDNESS(size_t, [AC_MSG_ERROR(size_t is signed)], [],
+		      [@%:@include <sys/types.h>])
+RUBY_CHECK_SIZEOF(size_t, [int long void*], [], [@%:@include <sys/types.h>])
+RUBY_CHECK_SIZEOF(ptrdiff_t, size_t, [], [@%:@include <stddef.h>])
+RUBY_CHECK_PRINTF_PREFIX(size_t, z)
+RUBY_CHECK_PRINTF_PREFIX(ptrdiff_t, t)
+AC_CHECK_MEMBERS([struct stat.st_blksize])
+AC_CHECK_MEMBERS([struct stat.st_blocks])
+AC_CHECK_MEMBERS([struct stat.st_rdev])
+RUBY_CHECK_SIZEOF([struct stat.st_size], [off_t int long "long long"], [], [@%:@include <sys/stat.h>])
+AS_IF([test "$ac_cv_member_struct_stat_st_blocks" = yes], [
+    RUBY_CHECK_SIZEOF([struct stat.st_blocks], [off_t int long "long long"], [], [@%:@include <sys/stat.h>])
+])
+RUBY_CHECK_SIZEOF([struct stat.st_ino], [long "long long"], [], [@%:@include <sys/stat.h>])
+AC_CHECK_MEMBERS([struct stat.st_atim])
+AC_CHECK_MEMBERS([struct stat.st_atimespec])
+AC_CHECK_MEMBERS([struct stat.st_atimensec])
+AC_CHECK_MEMBERS([struct stat.st_mtim])
+AC_CHECK_MEMBERS([struct stat.st_mtimespec])
+AC_CHECK_MEMBERS([struct stat.st_mtimensec])
+AC_CHECK_MEMBERS([struct stat.st_ctim])
+AC_CHECK_MEMBERS([struct stat.st_ctimespec])
+AC_CHECK_MEMBERS([struct stat.st_ctimensec])
+AC_CHECK_MEMBERS([struct stat.st_birthtimespec])
+AS_IF([test "x$ac_cv_member_struct_stat_st_birthtimespec" != xyes],
+    [AC_CHECK_MEMBERS([struct statx.stx_btime])])
+
+AC_CHECK_TYPES([struct timeval], [], [], [@%:@ifdef HAVE_TIME_H
+@%:@include <time.h>
+@%:@endif
+@%:@ifdef HAVE_SYS_TIME_H
+@%:@include <sys/time.h>
+@%:@endif])
+
+AS_IF([test "${ac_cv_type_struct_timeval}" = yes], [
+    RUBY_CHECK_SIZEOF([struct timeval.tv_sec], [time_t long "long long"], [],
+		      [@%:@ifdef HAVE_TIME_H
+@%:@include <time.h>
+@%:@endif
+@%:@ifdef HAVE_SYS_TIME_H
+@%:@include <sys/time.h>
+@%:@endif])
+    AS_CASE(${ac_cv_sizeof_struct_timeval_tv_sec},
+	    [SIZEOF_INT], [t=int],
+	    [SIZEOF_LONG], [t=long],
+	    [SIZEOF_LONG_LONG], [t=LONG_LONG],
+	    [t=])
+    AS_IF([test "${t}" != ""], [
+	AC_DEFINE_UNQUOTED(TYPEOF_TIMEVAL_TV_SEC, [$t])
+    ])
+])
+
+AC_CHECK_TYPES([struct timespec], [], [], [@%:@ifdef HAVE_TIME_H
+@%:@include <time.h>
+@%:@endif
+@%:@ifdef HAVE_SYS_TIME_H
+@%:@include <sys/time.h>
+@%:@endif])
+
+AC_CHECK_TYPES([struct timezone], [], [], [@%:@ifdef HAVE_TIME_H
+@%:@ include <time.h>
+@%:@endif
+@%:@ifdef HAVE_SYS_TIME_H
+@%:@ include <sys/time.h>
+@%:@endif])
+
+AC_CACHE_VAL([rb_cv_large_fd_select],
+    [AC_CHECK_TYPE(fd_mask, [rb_cv_large_fd_select=yes], [rb_cv_large_fd_select=no], [AC_INCLUDES_DEFAULT([])
+@%:@ifdef HAVE_SYS_SELECT_H
+@%:@ include <sys/select.h>
+@%:@endif])])
+AS_IF([test "$rb_cv_large_fd_select" = yes], [
+    AC_DEFINE(HAVE_RB_FD_INIT, 1)
+])
+
+RUBY_DEFINT(int8_t, 1)
+RUBY_DEFINT(uint8_t, 1, unsigned)
+RUBY_DEFINT(int16_t, 2)
+RUBY_DEFINT(uint16_t, 2, unsigned)
+RUBY_DEFINT(int32_t, 4)
+RUBY_DEFINT(uint32_t, 4, unsigned)
+RUBY_DEFINT(int64_t, 8)
+RUBY_DEFINT(uint64_t, 8, unsigned)
+RUBY_DEFINT(int128_t, 16)
+RUBY_DEFINT(uint128_t, 16, unsigned)
+RUBY_DEFINT(intptr_t, void*)
+RUBY_DEFINT(uintptr_t, void*, unsigned)
+AS_IF([test "x$rb_cv_type_intptr_t" != xno], [
+    RUBY_CHECK_PRINTF_PREFIX(intptr_t, '' ll I64 l, PTR)
+])
+RUBY_DEFINT(ssize_t, size_t, [], [@%:@include <sys/types.h>])	dnl may differ from int, so not use AC_TYPE_SSIZE_T.
+AS_IF([test "x$rb_cv_type_int64_t" != xno], [
+    RUBY_CHECK_PRINTF_PREFIX(int64_t, ll I64 l, 64)
+])
+
+AC_CACHE_CHECK(for stack end address, rb_cv_stack_end_address,
+[rb_cv_stack_end_address=no
+  AC_LINK_IFELSE([AC_LANG_PROGRAM(
+      [[extern void *__libc_stack_end;]],
+      [[if (!__libc_stack_end) return 1;]])],
+    [rb_cv_stack_end_address="__libc_stack_end"])
+])
+AS_IF([test $rb_cv_stack_end_address != no], [
+  AC_DEFINE_UNQUOTED(STACK_END_ADDRESS, $rb_cv_stack_end_address)
+])
+
+dnl Checks for library functions.
+AC_TYPE_GETGROUPS
+AS_CASE(["${target_cpu}-${target_os}:${target_archs}"],
+[powerpc-darwin*], [
+  AC_LIBSOURCES(alloca.c)
+  AC_SUBST([ALLOCA], [\${LIBOBJDIR}alloca.${ac_objext}])
+  AC_DEFINE(C_ALLOCA)
+  AC_DEFINE_UNQUOTED(alloca, alloca)
+  ],
+[universal-darwin*:*ppc*], [
+  AC_LIBSOURCES(alloca.c)
+  AC_SUBST([ALLOCA], [\${LIBOBJDIR}alloca.${ac_objext}])
+  RUBY_DEFINE_IF([defined __powerpc__], C_ALLOCA, 1)
+  RUBY_DEFINE_IF([defined __powerpc__], alloca, alloca)
+  ],
+[
+  AC_FUNC_ALLOCA
+  ])
+AS_IF([test "x$ALLOCA" = "x"], [
+    AC_CACHE_CHECK([for dynamic size alloca], rb_cv_dynamic_alloca, [
+    for chk in ok __chkstk; do
+	AC_LINK_IFELSE([AC_LANG_PROGRAM([[
+	    @%:@ifdef HAVE_ALLOCA_H
+	    @%:@include <alloca.h>
+	    @%:@endif
+	    void $chk() {}
+	    int dynamic_alloca_test;
+	    int dynamic_alloca_result;]],
+	    [[dynamic_alloca_result = alloca(dynamic_alloca_test) != 0;]])],
+	    [rb_cv_dynamic_alloca=$chk; break])
+    done])
+    AS_IF([test "x$rb_cv_dynamic_alloca" = "x__chkstk"], [
+	AC_DEFINE_UNQUOTED(RUBY_ALLOCA_CHKSTK, _$rb_cv_dynamic_alloca)
+	AS_CASE("$target_cpu",
+	[x64|x86_64], [
+	    AC_SUBST([ALLOCA], [\${LIBOBJDIR}x86_64-chkstk.${ac_objext}])
+	],)
+    ])
+])
+AC_FUNC_MEMCMP
+
+AS_CASE(["$target_os"],[freebsd*],[
+	 AC_DEFINE(BROKEN_CLOSE)
+	 AC_REPLACE_FUNCS(close)
+	 ])
+
+AC_REPLACE_FUNCS(acosh)
+AC_REPLACE_FUNCS(cbrt)
+AC_REPLACE_FUNCS(crypt)
+AC_REPLACE_FUNCS(dup2)
+AC_REPLACE_FUNCS(erf)
+AC_REPLACE_FUNCS(explicit_bzero)
+AC_REPLACE_FUNCS(ffs)
+AC_REPLACE_FUNCS(flock)
+AC_REPLACE_FUNCS(hypot)
+AC_REPLACE_FUNCS(lgamma_r)
+AC_REPLACE_FUNCS(memmove)
+AC_REPLACE_FUNCS(nan)
+AC_REPLACE_FUNCS(nextafter)
+AC_REPLACE_FUNCS(setproctitle)
+AC_REPLACE_FUNCS(strchr)
+AC_REPLACE_FUNCS(strerror)
+AC_REPLACE_FUNCS(strlcat)
+AC_REPLACE_FUNCS(strlcpy)
+AC_REPLACE_FUNCS(strstr)
+AC_REPLACE_FUNCS(tgamma)
+
+RUBY_REPLACE_FUNC([finite], [@%:@include <math.h>])
+RUBY_REPLACE_FUNC([isinf], [@%:@include <math.h>])
+RUBY_REPLACE_FUNC([isnan], [@%:@include <math.h>])
+
+# for missing/setproctitle.c
+AS_CASE(["$target_os"],
+[aix* | k*bsd*-gnu | kopensolaris*-gnu | linux* | darwin*], [AC_DEFINE(SPT_TYPE,SPT_REUSEARGV)],
+[hpux*], [AC_DEFINE(SPT_TYPE,SPT_PSTAT) ],
+[])
+AC_CHECK_HEADERS(sys/pstat.h)
+
+
+AC_CACHE_CHECK(for signbit, rb_cv_have_signbit,
+  [AC_LINK_IFELSE([AC_LANG_PROGRAM([[
+#include <math.h>
+]], [[int v = signbit(-0.0);]])],
+	rb_cv_have_signbit=yes,
+	rb_cv_have_signbit=no)])
+AS_IF([test "$rb_cv_have_signbit" = yes], [
+  AC_DEFINE(HAVE_SIGNBIT)
+], [
+  AC_LIBOBJ([signbit])
+])
+
+AC_FUNC_FORK
+
+AC_CHECK_FUNCS(__syscall)
+AC_CHECK_FUNCS(_longjmp)		# used for AC_ARG_WITH(setjmp-type)
+# we don't use _setjmp if _longjmp doesn't exist.
+test x$ac_cv_func__longjmp = xno && ac_cv_func__setjmp=no
+AC_CHECK_FUNCS(arc4random_buf)
+AC_CHECK_FUNCS(atan2l atan2f)
+AC_CHECK_FUNCS(chroot)
+AC_CHECK_FUNCS(chsize)
+AC_CHECK_FUNCS(clock_gettime)
+AC_CHECK_FUNCS(copy_file_range)
+AC_CHECK_FUNCS(cosh)
+AC_CHECK_FUNCS(crypt_r)
+AC_CHECK_FUNCS(daemon)
+AC_CHECK_FUNCS(dirfd)
+AC_CHECK_FUNCS(dl_iterate_phdr)
+AC_CHECK_FUNCS(dlopen)
+AC_CHECK_FUNCS(dladdr)
+AC_CHECK_FUNCS(dup)
+AC_CHECK_FUNCS(dup3)
+AC_CHECK_FUNCS(eaccess)
+AC_CHECK_FUNCS(endgrent)
+AC_CHECK_FUNCS(eventfd)
+AC_CHECK_FUNCS(explicit_memset)
+AC_CHECK_FUNCS(fcopyfile)
+AC_CHECK_FUNCS(fchmod)
+AC_CHECK_FUNCS(fchown)
+AC_CHECK_FUNCS(fcntl)
+AC_CHECK_FUNCS(fdatasync)
+AC_CHECK_FUNCS(fdopendir)
+AC_CHECK_FUNCS(fgetattrlist)
+AC_CHECK_FUNCS(fmod)
+AC_CHECK_FUNCS(fstatat)
+AC_CHECK_FUNCS(fsync)
+AC_CHECK_FUNCS(ftruncate)
+AC_CHECK_FUNCS(ftruncate64)		# used for Win32 platform
+AC_CHECK_FUNCS(getattrlist)
+AC_CHECK_FUNCS(getcwd)
+AC_CHECK_FUNCS(getgidx)
+AC_CHECK_FUNCS(getgrnam)
+AC_CHECK_FUNCS(getgrnam_r)
+AC_CHECK_FUNCS(getgroups)
+AC_CHECK_FUNCS(getlogin)
+AC_CHECK_FUNCS(getlogin_r)
+AC_CHECK_FUNCS(getpgid)
+AC_CHECK_FUNCS(getpgrp)
+AC_CHECK_FUNCS(getpriority)
+AC_CHECK_FUNCS(getpwnam)
+AC_CHECK_FUNCS(getpwnam_r)
+AC_CHECK_FUNCS(getpwuid)
+AC_CHECK_FUNCS(getpwuid_r)
+AC_CHECK_FUNCS(getrandom)
+AC_CHECK_FUNCS(getresgid)
+AC_CHECK_FUNCS(getresuid)
+AC_CHECK_FUNCS(getrlimit)
+AC_CHECK_FUNCS(getsid)
+AC_CHECK_FUNCS(gettimeofday)		# for making ac_cv_func_gettimeofday
+AC_CHECK_FUNCS(getuidx)
+AC_CHECK_FUNCS(gmtime_r)
+AC_CHECK_FUNCS(grantpt)
+AC_CHECK_FUNCS(initgroups)
+AC_CHECK_FUNCS(ioctl)
+AC_CHECK_FUNCS(isfinite)
+AC_CHECK_FUNCS(issetugid)
+AC_CHECK_FUNCS(killpg)
+AC_CHECK_FUNCS(lchmod)
+AC_CHECK_FUNCS(lchown)
+AC_CHECK_FUNCS(link)
+AC_CHECK_FUNCS(llabs)
+AC_CHECK_FUNCS(lockf)
+AC_CHECK_FUNCS(log2)
+AC_CHECK_FUNCS(lstat)
+AC_CHECK_FUNCS(lutimes)
+AC_CHECK_FUNCS(malloc_usable_size)
+AC_CHECK_FUNCS(malloc_size)
+AC_CHECK_FUNCS(mblen)
+AC_CHECK_FUNCS(memalign)
+AC_CHECK_FUNCS(memset_s)
+AC_CHECK_FUNCS(writev)
+AC_CHECK_FUNCS(memrchr)
+AC_CHECK_FUNCS(memmem)
+AC_CHECK_FUNCS(mkfifo)
+AC_CHECK_FUNCS(mknod)
+AC_CHECK_FUNCS(mktime)
+AC_CHECK_FUNCS(openat)
+AC_CHECK_FUNCS(pipe2)
+AC_CHECK_FUNCS(poll)
+AC_CHECK_FUNCS(posix_fadvise)
+AC_CHECK_FUNCS(posix_memalign)
+AC_CHECK_FUNCS(ppoll)
+AC_CHECK_FUNCS(pread)
+AC_CHECK_FUNCS(pwrite)
+AC_CHECK_FUNCS(qsort_r)
+AC_CHECK_FUNCS(qsort_s)
+AC_CHECK_FUNCS(readlink)
+AC_CHECK_FUNCS(realpath)
+AC_CHECK_FUNCS(round)
+AC_CHECK_FUNCS(sched_getaffinity)
+AC_CHECK_FUNCS(seekdir)
+AC_CHECK_FUNCS(select_large_fdset)
+AC_CHECK_FUNCS(sendfile)
+AC_CHECK_FUNCS(setegid)
+AC_CHECK_FUNCS(setenv)
+AC_CHECK_FUNCS(seteuid)
+AC_CHECK_FUNCS(setgid)
+AC_CHECK_FUNCS(setgroups)
+AC_CHECK_FUNCS(setpgid)
+AC_CHECK_FUNCS(setpgrp)
+AC_CHECK_FUNCS(setregid)
+AC_CHECK_FUNCS(setresgid)
+AC_CHECK_FUNCS(setresuid)
+AC_CHECK_FUNCS(setreuid)
+AC_CHECK_FUNCS(setrgid)
+AC_CHECK_FUNCS(setrlimit)
+AC_CHECK_FUNCS(setruid)
+AC_CHECK_FUNCS(setsid)
+AC_CHECK_FUNCS(setuid)
+AC_CHECK_FUNCS(shutdown)
+AC_CHECK_FUNCS(sigaction)
+AC_CHECK_FUNCS(sigaltstack)
+AC_CHECK_FUNCS(sigprocmask)
+AC_CHECK_FUNCS(sinh)
+AC_CHECK_FUNCS(spawnv)
+AC_CHECK_FUNCS(symlink)
+AC_CHECK_FUNCS(syscall)
+AC_CHECK_FUNCS(sysconf)
+AC_CHECK_FUNCS(tanh)
+AC_CHECK_FUNCS(telldir)
+AC_CHECK_FUNCS(timegm)
+AC_CHECK_FUNCS(times)
+AC_CHECK_FUNCS(truncate)
+AC_CHECK_FUNCS(truncate64)		# used for Win32
+AC_CHECK_FUNCS(unsetenv)
+AC_CHECK_FUNCS(utimensat)
+AC_CHECK_FUNCS(utimes)
+AC_CHECK_FUNCS(wait4)
+AC_CHECK_FUNCS(waitpid)
+AC_CHECK_FUNCS(__cospi)
+AC_CHECK_FUNCS(__sinpi)
+
+AS_IF([test "x$ac_cv_member_struct_statx_stx_btime" = xyes],
+    [AC_CHECK_FUNCS(statx)])
+
+AS_CASE(["$ac_cv_func_memset_s:$ac_cv_func_qsort_s"], [*yes*],
+    [RUBY_DEFINE_IF([!defined __STDC_WANT_LIB_EXT1__], [__STDC_WANT_LIB_EXT1__], 1)])
+
+AS_IF([test "$ac_cv_func_getcwd" = yes], [
+    AC_CACHE_CHECK(if getcwd allocates buffer if NULL is given, [rb_cv_getcwd_malloc],
+	[AC_RUN_IFELSE([AC_LANG_SOURCE([[
+@%:@include <stddef.h>
+@%:@include <stdio.h>
+@%:@ifdef HAVE_UNISTD_H
+@%:@include <unistd.h>
+@%:@endif
+@%:@ifndef EXIT_SUCCESS
+@%:@define EXIT_SUCCESS 0
+@%:@endif
+@%:@ifndef EXIT_FAILURE
+@%:@define EXIT_FAILURE 1
+@%:@endif
+
+int
+main(int argc, char **argv)
+{
+    if (!getcwd(NULL, 0)) return EXIT_FAILURE;
+    return EXIT_SUCCESS;
+}
+]])],
+	    rb_cv_getcwd_malloc=yes,
+	    rb_cv_getcwd_malloc=no,
+	    AS_CASE($target_os,
+		[linux*|darwin*|*bsd|cygwin*|mingw*|mswin*],
+		[rb_cv_getcwd_malloc=yes],
+		[rb_cv_getcwd_malloc=no]))])
+    AS_IF([test "$rb_cv_getcwd_malloc" = no], [AC_DEFINE(NO_GETCWD_MALLOC, 1)])
+])
+
+AS_IF([test "$ac_cv_func_crypt_r" = yes],
+    [AC_CHECK_HEADERS(crypt.h)])
+AS_IF([test "$ac_cv_func_crypt_r:$ac_cv_header_crypt_h" = yes:yes],
+    [AC_CHECK_MEMBERS([struct crypt_data.initialized], [], [],
+		      [AC_INCLUDES_DEFAULT([@%:@include <crypt.h>])])])
+
+RUBY_CHECK_BUILTIN_FUNC(__builtin_alloca_with_align, [__builtin_alloca_with_align(1, 4096)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_assume_aligned, [__builtin_assume_aligned((void*)32, 32)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_bswap16, [__builtin_bswap16(0)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_bswap32, [__builtin_bswap32(0)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_bswap64, [__builtin_bswap64(0)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_popcount, [__builtin_popcount(0)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_popcountll, [__builtin_popcountll(0)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_clz, [__builtin_clz(0)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_clzl, [__builtin_clzl(0)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_clzll, [__builtin_clzll(0)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_ctz, [__builtin_ctz(0)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_ctzll, [__builtin_ctzll(0)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_add_overflow, [int x;__builtin_add_overflow(0,0,&x)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_sub_overflow, [int x;__builtin_sub_overflow(0,0,&x)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_mul_overflow, [int x;__builtin_mul_overflow(0,0,&x)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_mul_overflow_p, [__builtin_mul_overflow_p(0,0,(int)0)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_constant_p, [__builtin_constant_p(0)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_choose_expr, [
+    [int x[__extension__(__builtin_choose_expr(1, 1, -1))]];
+    [int y[__extension__(__builtin_choose_expr(0, -1, 1))]];
+    ])
+AS_IF([test x$rb_cv_builtin___builtin_choose_expr = xyes], [
+    RUBY_CHECK_BUILTIN_FUNC(__builtin_choose_expr_constant_p, [
+    [int x[__extension__(__builtin_choose_expr(__builtin_constant_p(1), 1, -1))]];
+    [int y[__extension__(__builtin_choose_expr(__builtin_constant_p(foo), -1, 1))]];
+    ])
+])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_types_compatible_p, [__builtin_types_compatible_p(int, int)])
+RUBY_CHECK_BUILTIN_FUNC(__builtin_trap, [__builtin_trap()])
+
+AS_IF([test "$ac_cv_func_qsort_r" != no], [
+  AC_CACHE_CHECK(whether qsort_r is GNU version, rb_cv_gnu_qsort_r,
+    [AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
+@%:@include <stdlib.h>
+void (qsort_r)(void *base, size_t nmemb, size_t size,
+	    int (*compar)(const void *, const void *, void *),
+	    void *arg);
+]], [[ ]])],
+      [rb_cv_gnu_qsort_r=yes],
+      [rb_cv_gnu_qsort_r=no])
+  ])
+  AC_CACHE_CHECK(whether qsort_r is BSD version, rb_cv_bsd_qsort_r,
+    [AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
+@%:@include <stdlib.h>
+void (qsort_r)(void *base, size_t nmemb, size_t size,
+	     void *arg, int (*compar)(void *, const void *, const void *));
+]], [[ ]])],
+      [rb_cv_bsd_qsort_r=yes],
+      [rb_cv_bsd_qsort_r=no])
+  ])
+  AS_CASE("$rb_cv_gnu_qsort_r:$rb_cv_bsd_qsort_r",
+  [yes:no], [
+    AC_DEFINE(HAVE_GNU_QSORT_R, 1)
+  ],
+  [no:yes], [
+    AC_DEFINE(HAVE_BSD_QSORT_R, 1)
+  ])
+])
+
+AC_CACHE_CHECK(whether atan2 handles Inf as C99, rb_cv_atan2_inf_c99, [
+    AS_IF([test $ac_cv_func_atan2f:$ac_cv_func_atan2l = yes:yes], [
+	AC_RUN_IFELSE([AC_LANG_SOURCE([[
+@%:@include <math.h>
+@%:@ifdef HAVE_UNISTD_H
+@%:@include <unistd.h>
+@%:@endif
+@%:@ifndef EXIT_SUCCESS
+@%:@define EXIT_SUCCESS 0
+@%:@endif
+@%:@ifndef EXIT_FAILURE
+@%:@define EXIT_FAILURE 1
+@%:@endif
+
+int
+main(int argc, char **argv)
+{
+    if (fabs(atan2(INFINITY, INFINITY) - M_PI_4) <= 0.01) return EXIT_SUCCESS;
+    return EXIT_FAILURE;
+}
+]])],
+	[rb_cv_atan2_inf_c99=yes],
+	[rb_cv_atan2_inf_c99=no],
+	[AS_CASE($target_os, [mingw*|mswin*], [rb_cv_atan2_inf_c99=no], [rb_cv_atan2_inf_c99=yes])]
+	)
+    ], [rb_cv_atan2_inf_c99=no])
+])
+AS_IF([test "x$rb_cv_atan2_inf_c99" = xyes], [AC_DEFINE(ATAN2_INF_C99)])
+
+# Some platform need -lrt for clock_gettime, but the other don't.
+AS_IF([test x"$ac_cv_func_clock_gettime" != xyes], [
+    # glibc 2.17 moves clock_* functions from librt to the main C library.
+    # http://sourceware.org/ml/libc-announce/2012/msg00001.html
+    AC_CHECK_LIB(rt, clock_gettime)
+    AS_IF([test x"$ac_cv_lib_rt_clock_gettime" = xyes], [
+	AC_DEFINE(HAVE_CLOCK_GETTIME, 1)
+    ])
+])
+AC_CHECK_FUNCS(clock_getres) # clock_getres should be tested after clock_gettime test including librt test.
+AC_CHECK_LIB([rt], [timer_create])
+AC_CHECK_LIB([rt], [timer_settime])
+AS_IF([test x"$ac_cv_lib_rt_timer_create" = xyes], [
+    AC_DEFINE(HAVE_TIMER_CREATE, 1)
+])
+AS_IF([test x"$ac_cv_lib_rt_timer_settime" = xyes], [
+    AC_DEFINE(HAVE_TIMER_SETTIME, 1)
+])
+
+AC_CACHE_CHECK(for unsetenv returns a value, rb_cv_unsetenv_return_value,
+  [AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
+#include <stdlib.h>
+]], [[int v = unsetenv("foo");]])],
+	rb_cv_unsetenv_return_value=yes,
+	rb_cv_unsetenv_return_value=no)])
+AS_IF([test "$rb_cv_unsetenv_return_value" = no], [
+  AC_DEFINE(VOID_UNSETENV)
+])
+
+# End of setjmp check.
+
+AC_ARG_ENABLE(setreuid,
+       AS_HELP_STRING([--enable-setreuid], [use setreuid()/setregid() according to need even if obsolete]),
+       [use_setreuid=$enableval])
+AS_IF([test "$use_setreuid" = yes], [
+    AC_DEFINE(USE_SETREUID)
+    AC_DEFINE(USE_SETREGID)
+])
+AC_STRUCT_TIMEZONE
+AC_CACHE_CHECK(for struct tm.tm_gmtoff, rb_cv_member_struct_tm_tm_gmtoff,
+  [AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
+@%:@define _BSD_SOURCE
+@%:@define _DEFAULT_SOURCE
+@%:@include <time.h>
+    ]],
+    [[struct tm t; t.tm_gmtoff = 3600;]])],
+  [rb_cv_member_struct_tm_tm_gmtoff=yes],
+  [rb_cv_member_struct_tm_tm_gmtoff=no])])
+AS_IF([test "$rb_cv_member_struct_tm_tm_gmtoff" = yes], [
+  AC_DEFINE(HAVE_STRUCT_TM_TM_GMTOFF)
+])
+AC_CACHE_CHECK(for external int daylight, rb_cv_have_daylight,
+  [AC_LINK_IFELSE([AC_LANG_PROGRAM([[#include <time.h>
+  int i;]],
+	[[i = daylight;]])],
+	rb_cv_have_daylight=yes,
+	rb_cv_have_daylight=no)])
+AS_IF([test "$rb_cv_have_daylight" = yes], [
+  AC_DEFINE(HAVE_DAYLIGHT)
+])
+
+AC_CACHE_CHECK(for negative time_t for gmtime(3), rb_cv_negative_time_t,
+  [AC_RUN_IFELSE([AC_LANG_SOURCE([[
+#include <stdlib.h>
+#include <time.h>
+
+void
+check(tm, y, m, d, h, s)
+    struct tm *tm;
+    int y, m, d, h, s;
+{
+    if (!tm ||
+	tm->tm_year != y ||
+	tm->tm_mon  != m-1 ||
+	tm->tm_mday != d ||
+	tm->tm_hour != h ||
+	tm->tm_sec  != s) {
+	exit(1);
+    }
+}
+
+int
+main()
+{
+   time_t t = -1;
+   struct tm *tm;
+
+   check(gmtime(&t), 69, 12, 31, 23, 59);
+   t = ~(time_t)0 << 31;
+   check(gmtime(&t), 1, 12, 13, 20, 52);
+   return 0;
+}
+]])],
+	rb_cv_negative_time_t=yes,
+	rb_cv_negative_time_t=no,
+	rb_cv_negative_time_t=yes)])
+AS_IF([test "$rb_cv_negative_time_t" = yes], [
+  AC_DEFINE(NEGATIVE_TIME_T)
+])
+
+# [ruby-dev:40910] overflow of time on FreeBSD
+# http://www.freebsd.org/cgi/query-pr.cgi?pr=145341
+AC_CACHE_CHECK(for localtime(3) overflow correctly, rb_cv_localtime_overflow,
+  [AC_RUN_IFELSE([AC_LANG_SOURCE([[
+#include <stdlib.h>
+#include <time.h>
+
+void
+check(time_t t1)
+{
+    struct tm *tm;
+    time_t t2;
+    tm = localtime(&t1);
+    if (!tm)
+	return; /* overflow detected.  ok. */
+    t2 = mktime(tm);
+    if (t1 == t2)
+        return; /* round-trip.  ok. */
+    exit(1);
+}
+
+int
+main()
+{
+    time_t t;
+    if (~(time_t)0 <= 0) {
+        t = (((time_t)1) << (sizeof(time_t) * 8 - 2));
+        t |= t - 1;
+    }
+    else {
+        t = ~(time_t)0;
+    }
+    check(t);
+    return 0;
+}
+]])],
+	rb_cv_localtime_overflow=yes,
+	rb_cv_localtime_overflow=no,
+	rb_cv_localtime_overflow=no)])
+AS_IF([test "$rb_cv_localtime_overflow" = no], [
+  AC_DEFINE(LOCALTIME_OVERFLOW_PROBLEM)
+])
+
+AS_IF([test "$ac_cv_func_sigprocmask" = yes && test "$ac_cv_func_sigaction" = yes], [
+   AC_DEFINE(POSIX_SIGNAL)
+], [
+  AC_CHECK_FUNCS(sigsetmask)
+  AC_CACHE_CHECK(for BSD signal semantics, rb_cv_bsd_signal,
+    [AC_RUN_IFELSE([AC_LANG_SOURCE([[
+#include <stdio.h>
+#include <signal.h>
+
+void
+sig_handler(dummy)
+     int dummy;
+{
+}
+
+int
+main()
+{
+  signal(SIGINT, sig_handler);
+  kill(getpid(), SIGINT);
+  kill(getpid(), SIGINT);
+  return 0;
+}
+]])],
+	rb_cv_bsd_signal=yes,
+	rb_cv_bsd_signal=no,
+	rb_cv_bsd_signal=$ac_cv_func_sigsetmask)])
+  AS_IF([test "$rb_cv_bsd_signal" = yes], [
+    AC_DEFINE(BSD_SIGNAL)
+  ])
+])
+
+AC_CHECK_TYPES([sig_t],[],[],[@%:@include <signal.h>])
+
+AS_IF([test "$ac_cv_func_getpgid" = no], [
+  # AC_FUNC_GETPGRP fails when cross-compiling with old autoconf.
+  # autoconf is changed between 2.52d and 2.52f?
+  # http://lists.gnu.org/archive/html/bug-gnu-utils/2001-09/msg00181.html
+  # "autoconf cleanup for AC_FUNC_GETPGRP and GETPGRP_VOID"
+AC_FUNC_GETPGRP
+])
+AS_IF([test "$ac_cv_func_setpgid:$ac_cv_func_setpgrp" = no:yes], [
+  # AC_FUNC_SETPGRP fails when cross-compiling.  (until autoconf 2.69?)
+  # https://lists.gnu.org/archive/html/bug-autoconf/2013-02/msg00002.html
+  # "AC_FUNC_SETPGRP fails to work properly when cross-compiling"
+AC_FUNC_SETPGRP
+])
+
+AS_IF([test x"$ac_cv_func_dirfd" = xno], [
+  AS_CASE(["$target_os"],[solaris*],
+          [AC_CHECK_MEMBERS([DIR.d_fd, DIR.dd_fd],,,[
+#include <sys/types.h>
+#include <dirent.h>
+])])
+])
+
+AC_CACHE_CHECK(whether right shift preserve sign bit, rb_cv_rshift_sign,
+    [AC_COMPILE_IFELSE([AC_LANG_BOOL_COMPILE_TRY([], [(-1==(-1>>1))])],
+	rb_cv_rshift_sign=yes,
+	rb_cv_rshift_sign=no)])
+AS_IF([test "$rb_cv_rshift_sign" = yes], [
+  AC_DEFINE(RSHIFT(x,y), ((x)>>(int)(y)))
+], [
+  AC_DEFINE(RSHIFT(x,y), (((x)<0) ? ~((~(x))>>(int)(y)) : (x)>>(int)(y)))
+])
+
+AS_IF([test "$ac_cv_func_copy_file_range" = no], [
+  AC_CACHE_CHECK([for copy_file_range],
+    rb_cv_use_copy_file_range,
+    [AC_RUN_IFELSE([AC_LANG_SOURCE([[
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <sys/syscall.h>
+#include <fcntl.h>
+#include <unistd.h>
+
+#ifndef O_TMPFILE
+  #define O_TMPFILE __O_TMPFILE
+#endif
+
+int
+main()
+{
+#ifdef __NR_copy_file_range
+   int ret, fd_in, fd_out;
+   fd_in = open("/tmp", O_TMPFILE|O_RDWR, S_IRUSR);
+   fd_out = open("/tmp", O_TMPFILE|O_WRONLY, S_IWUSR);
+   ret = syscall(__NR_copy_file_range, fd_in, NULL, fd_out, NULL, 0, 0);
+   close(fd_in);
+   close(fd_out);
+   if (ret == -1) { return 1; }
+   return 0;
+#else
+   return 1;
+#endif
+}
+  ]])],
+    [rb_cv_use_copy_file_range=yes],
+    [rb_cv_use_copy_file_range=no],
+    [rb_cv_use_copy_file_range=no])])
+])
+AS_CASE(["$ac_cv_func_copy_file_range:$rb_cv_use_copy_file_range"], [*yes*], [
+  AC_DEFINE(USE_COPY_FILE_RANGE)
+])
+
+AS_CASE(["$ac_cv_func_gettimeofday:$ac_cv_func_clock_gettime"],
+[*yes*], [],
+[
+    AC_MSG_ERROR(clock_gettime() or gettimeofday() must exist)
+])
+
+AS_IF([test "$ac_cv_func_sysconf" = yes], [
+  RUBY_CHECK_SYSCONF(CLK_TCK)
+])
+
+AS_IF([test "${universal_binary-no}" = yes ], [
+    archflagpat=`eval echo '"'"${ARCH_FLAG}"'"' | sed 's/[[][|.*]]/\\&/g'`
+    save_CFLAGS="$CFLAGS" new_cflags=`echo "$CFLAGS" | sed "s|$archflagpat"'||'`
+    save_LDFLAGS="$LDFLAGS" new_ldflags=`echo "$LDFLAGS" | sed "s|$archflagpat"'||'`
+    stack_dir=
+    for archs in ${universal_archnames}; do
+	archs=`echo $archs | sed 's/=.*//'`
+	CFLAGS="$new_cflags -arch $archs"
+	LDFLAGS="$new_ldflags -arch $archs"
+	RUBY_STACK_GROW_DIRECTION($archs, dir)
+	AS_IF([test x$stack_dir = x], [
+	    stack_dir=$dir
+	], [test x$stack_dir != x$dir], [
+	    stack_dir=no
+	])
+    done
+    CFLAGS="$save_CFLAGS" LDFLAGS="$save_LDFLAGS"
+    AS_IF([test x$stack_dir = xno], [
+	for archs in ${universal_archnames}; do
+	    archs=`echo $archs | sed 's/=.*//'`
+	    eval dir=\$[rb_cv_stack_grow_dir_]AS_TR_SH([$archs])
+	    RUBY_DEFINE_IF([defined __${archs}__], STACK_GROW_DIRECTION, $dir)
+	done
+    ], [
+	AC_DEFINE_UNQUOTED(STACK_GROW_DIRECTION, $stack_dir)
+    ])
+], [
+    RUBY_STACK_GROW_DIRECTION($target_cpu, dir)
+    AC_DEFINE_UNQUOTED(STACK_GROW_DIRECTION, $dir)
+])
+
+AC_ARG_WITH(coroutine,
+    AS_HELP_STRING([--with-coroutine=IMPLEMENTATION], [specify the coroutine implementation to use]),
+    [rb_cv_coroutine=$withval])
+AS_CASE([$rb_cv_coroutine], [yes|''], [
+    AC_MSG_CHECKING(native coroutine implementation for ${target_cpu}-${target_os})
+    rb_cv_coroutine=
+    AS_CASE(["$target_cpu-$target_os"],
+        [x*64-darwin*], [
+            rb_cv_coroutine=amd64
+        ],
+        [arm64-darwin*], [
+            rb_cv_coroutine=arm64
+        ],
+        [x*64-linux*], [
+            AS_CASE(["$ac_cv_sizeof_voidp"],
+                [8], [ rb_cv_coroutine=amd64 ],
+                [4], [ rb_cv_coroutine=x86 ],
+                dnl unknown pointer size, bail out as no Context.h soon.
+            )
+        ],
+        [*86-linux*], [
+            rb_cv_coroutine=x86
+        ],
+        [x64-mingw32], [
+            rb_cv_coroutine=win64
+        ],
+        [*86-mingw32], [
+            rb_cv_coroutine=win32
+        ],
+        [arm*-linux*], [
+            rb_cv_coroutine=arm32
+        ],
+        [aarch64-linux*], [
+            rb_cv_coroutine=arm64
+        ],
+        [powerpc64le-linux*], [
+            rb_cv_coroutine=ppc64le
+        ],
+        [x86_64-openbsd*], [
+            rb_cv_coroutine=amd64
+        ],
+        [i386-openbsd*], [
+            rb_cv_coroutine=x86
+        ],
+        [*-openbsd*], [
+            rb_cv_coroutine=copy
+        ],
+        [*-haiku*], [
+            rb_cv_coroutine=copy
+        ],
+        [
+            rb_cv_coroutine=ucontext
+        ]
+    )
+    AC_MSG_RESULT(${rb_cv_coroutine})
+])
+COROUTINE_H=coroutine/$rb_cv_coroutine/Context.h
+AS_IF([test ! -f "$srcdir/$COROUTINE_H"],
+      [AC_MSG_ERROR('$rb_cv_coroutine' is not supported as coroutine)])
+AS_CASE([$rb_cv_coroutine],
+    [copy|ucontext], [
+        COROUTINE_SRC=coroutine/$rb_cv_coroutine/Context.c
+    ],
+    [
+        COROUTINE_SRC=coroutine/$rb_cv_coroutine/Context.'$(ASMEXT)'
+    ]
+)
+AC_DEFINE_UNQUOTED(COROUTINE_H, ["$COROUTINE_H"])
+AC_SUBST(X_COROUTINE_H, [$COROUTINE_H])
+AC_SUBST(X_COROUTINE_SRC, [$COROUTINE_SRC])
+
+AS_IF([test x"$enable_pthread" = xyes], [
+    for pthread_lib in thr pthread pthreads c c_r root; do
+	AC_CHECK_LIB($pthread_lib, pthread_create,
+		     rb_with_pthread=yes, rb_with_pthread=no)
+	AS_IF([test "$rb_with_pthread" = "yes"], [break])
+    done
+    AS_IF([test x"$rb_with_pthread" = xyes], [
+	AC_DEFINE(_REENTRANT)
+	AC_DEFINE(_THREAD_SAFE)
+	AC_DEFINE(HAVE_LIBPTHREAD)
+	AC_CHECK_HEADERS(pthread_np.h, [], [], [@%:@include <pthread.h>])
+	AS_CASE(["$pthread_lib:$target_os"],
+		[c:*], [],
+		[root:*], [],
+		[c_r:*|*:openbsd*|*:mirbsd*],  [LIBS="-pthread $LIBS"],
+		[LIBS="-l$pthread_lib $LIBS"])
+    ], [
+	AC_MSG_WARN("Don't know how to find pthread library on your system -- thread support disabled")
+    ])
+    AC_CACHE_CHECK([whether pthread_t is scalar type], [rb_cv_scalar_pthread_t], [
+	AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
+	    @%:@include <pthread.h>
+	    ]], [[
+	    pthread_t thread_id;
+	    thread_id = 0;
+	    if (!thread_id) return 0;
+	    ]])],[rb_cv_scalar_pthread_t=yes],[rb_cv_scalar_pthread_t=no])
+    ])
+    AS_IF([test x"$rb_cv_scalar_pthread_t" = xyes], [
+	: # RUBY_CHECK_SIZEOF(pthread_t, [void* int long], [], [@%:@include <pthread.h>])
+    ], [
+	AC_DEFINE(NON_SCALAR_THREAD_ID)
+    ])
+    AC_CHECK_FUNCS(sched_yield pthread_attr_setinheritsched \
+	pthread_attr_get_np pthread_attr_getstack pthread_attr_getguardsize \
+	pthread_get_stackaddr_np pthread_get_stacksize_np \
+	thr_stksegment pthread_stackseg_np pthread_getthrds_np \
+	pthread_condattr_setclock \
+	pthread_sigmask pthread_setname_np pthread_set_name_np)
+    AS_CASE(["$target_os"],[aix*],[ac_cv_func_pthread_getattr_np=no],[AC_CHECK_FUNCS(pthread_getattr_np)])
+    set_current_thread_name=
+    AS_IF([test "$ac_cv_func_pthread_setname_np" = yes], [
+	AC_CACHE_CHECK([arguments of pthread_setname_np], [rb_cv_func_pthread_setname_np_arguments],
+	    [rb_cv_func_pthread_setname_np_arguments=
+	    # Linux,AIX,  (pthread_self(), name)
+	    # NetBSD (pthread_self(), \"%s\", name)
+	    # Darwin (name)
+	    for mac in \
+		"(pthread_self(), name)" \
+		"(pthread_self(), \"%s\", name)" \
+		"(name)" \
+		; do
+		AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
+		    @%:@include <pthread.h>
+		    @%:@ifdef HAVE_PTHREAD_NP_H
+		    @%:@include <pthread_np.h>
+		    @%:@endif
+		    @%:@define SET_THREAD_NAME(name) pthread_setname_np${mac}
+		    ]],
+		    [[if (SET_THREAD_NAME("conftest")) return 1;]])],
+		    [rb_cv_func_pthread_setname_np_arguments="${mac}"
+		    break])
+	    done
+	    ]
+	)
+	AS_IF([test -n "${rb_cv_func_pthread_setname_np_arguments}"], [
+	    set_current_thread_name="pthread_setname_np${rb_cv_func_pthread_setname_np_arguments}"
+	])
+    ], [test "$ac_cv_func_pthread_set_name_np" = yes], [
+	set_current_thread_name="pthread_set_name_np(pthread_self(), name)"
+    ])
+    AS_IF([test -n "$set_current_thread_name"], [
+	AC_DEFINE_UNQUOTED(SET_CURRENT_THREAD_NAME(name), $set_current_thread_name)
+	AS_CASE([$set_current_thread_name],
+	    [*'pthread_self()'*], [
+		set_another_thread_name=`echo "$set_current_thread_name" | sed 's/pthread_self()/thid/'`
+		AC_DEFINE_UNQUOTED(SET_ANOTHER_THREAD_NAME(thid,name), $set_another_thread_name)
+	    ])
+    ])
+])
+
+AS_IF([test x"$ac_cv_header_ucontext_h" = xno], [
+    AC_CACHE_CHECK([if signal.h defines ucontext_t], [rb_cv_ucontext_in_signal_h],
+	[AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[@%:@include <signal.h>]],
+					    [[size_t size = sizeof(ucontext_t);]])],
+	[rb_cv_ucontext_in_signal_h=yes], [rb_cv_ucontext_in_signal_h=no])])
+    AS_IF([test x"$rb_cv_ucontext_in_signal_h" = xyes], [
+	    AC_DEFINE_UNQUOTED(UCONTEXT_IN_SIGNAL_H, 1)
+    ])
+])
+AS_IF([test x"$ac_cv_header_ucontext_h" = xyes -o x"$rb_cv_ucontext_in_signal_h" = xyes], [
+    AC_CACHE_CHECK([if mcontext_t is a pointer], [rb_cv_mcontext_t_ptr],
+	[AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
+	    @%:@include <signal.h>
+	    @%:@ifdef HAVE_UCONTEXT_H
+	    @%:@include <ucontext.h>
+	    @%:@endif
+        mcontext_t test(mcontext_t mc) {return mc+1;}
+	  ]],
+	  [[test(0);]])],
+	[rb_cv_mcontext_t_ptr=yes], [rb_cv_mcontext_t_ptr=no])])
+    AS_IF([test x"$rb_cv_mcontext_t_ptr" = xyes], [
+	AC_DEFINE_UNQUOTED(DEFINE_MCONTEXT_PTR(mc, uc), mcontext_t mc = (uc)->uc_mcontext)
+    ], [
+	AC_DEFINE_UNQUOTED(DEFINE_MCONTEXT_PTR(mc, uc), mcontext_t *mc = &(uc)->uc_mcontext)
+    ])
+    AS_IF([test x"$rb_with_pthread" = xyes], [
+	AC_CHECK_FUNCS(getcontext setcontext)
+    ])
+])
+
+AS_IF([test "$ac_cv_func_fork_works" = "yes" -a "$rb_with_pthread" = "yes"], [
+    AC_CACHE_CHECK([if fork works with pthread], rb_cv_fork_with_pthread,
+	[AC_RUN_IFELSE([AC_LANG_SOURCE([[
+#include <stdlib.h>
+#include <unistd.h>
+#include <pthread.h>
+#include <stdio.h>
+#include <sys/types.h>
+#include <sys/wait.h>
+#include <signal.h>
+#ifndef EXIT_SUCCESS
+#define EXIT_SUCCESS 0
+#endif
+#ifndef EXIT_FAILURE
+#define EXIT_FAILURE 1
+#endif
+
+void *
+thread_func(void *dmy)
+{
+    return dmy;
+}
+
+int
+use_threads(void)
+{
+    pthread_t tid;
+    if (pthread_create(&tid, 0, thread_func, 0) != 0) {
+	return -1;
+    }
+    if (pthread_join(tid, 0) != 0) {
+	return -1;
+    }
+    return 0;
+}
+
+int
+main(int argc, char *argv[])
+{
+    pid_t pid;
+    if (use_threads()) return EXIT_FAILURE;
+    pid = fork();
+
+    if (pid) {
+	int loc;
+	sleep(1);
+	if (waitpid(pid, &loc, WNOHANG) == 0) {
+	    kill(pid, SIGKILL);
+	    return EXIT_FAILURE;
+	}
+        if (!WIFEXITED(loc) || WEXITSTATUS(loc) != EXIT_SUCCESS)
+           return EXIT_FAILURE;
+    }
+    else {
+	if (use_threads()) return EXIT_FAILURE;
+    }
+
+    return EXIT_SUCCESS;
+}]])],
+	rb_cv_fork_with_pthread=yes,
+	rb_cv_fork_with_pthread=no,
+	rb_cv_fork_with_pthread=yes)])
+    test x$rb_cv_fork_with_pthread = xyes || AC_DEFINE(CANNOT_FORK_WITH_PTHREAD)
+])
+}
+
+: "runtime section" && {
+dnl wheather use dln_a_out or not
+AC_ARG_WITH(dln-a-out,
+	AS_HELP_STRING([--with-dln-a-out], [use dln_a_out if possible]),
+	[
+	AS_CASE([$withval],
+	[yes], [
+	    AS_IF([test "$enable_shared" = yes], [
+		AC_MSG_ERROR(dln_a_out can not make shared library)
+	    ])
+	    with_dln_a_out=yes],
+	[
+	    with_dln_a_out=no])], [with_dln_a_out=no])
+
+AC_CACHE_CHECK(whether ELF binaries are produced, rb_cv_binary_elf,
+[AC_LINK_IFELSE([AC_LANG_PROGRAM([[]], [[]])],[
+AS_CASE(["`head -1 conftest$EXEEXT | tr -dc '\177ELF' | tr '\177' .`"],
+[.ELF*], [rb_cv_binary_elf=yes], [rb_cv_binary_elf=no])],
+rb_cv_binary_elf=no)])
+
+AS_IF([test "$rb_cv_binary_elf" = yes], [
+  AC_DEFINE(USE_ELF)
+  AS_IF([test "$with_dln_a_out" = yes], [
+    AC_MSG_ERROR(dln_a_out does not work with ELF)
+  ])
+  AC_CHECK_HEADERS([elf.h elf_abi.h])
+  AS_IF([test $ac_cv_header_elf_h = yes -o $ac_cv_header_elf_abi_h = yes], [
+    AC_LIBOBJ([addr2line])
+    AC_CHECK_LIB([z], [uncompress])
+  ])
+])
+
+AC_CHECK_HEADERS([mach-o/loader.h])
+AS_IF([test "$ac_cv_header_mach_o_loader_h" = yes], [
+  AC_LIBOBJ([addr2line])
+])
+
+AS_CASE(["$target_os"],
+[linux* | gnu* | k*bsd*-gnu | bsdi* | kopensolaris*-gnu], [
+    AS_IF([test "$rb_cv_binary_elf" = no], [
+	with_dln_a_out=yes
+    ], [
+	LDFLAGS="$LDFLAGS -rdynamic"
+    ])])
+LIBEXT=a
+
+AC_ARG_WITH(mjit-tabs,
+    AS_HELP_STRING([--without-mjit-tabs], [expand tabs in mjit header]),
+    [AS_IF([test $withval = no], [MJIT_TABS=false])])
+AC_SUBST(MJIT_TABS)dnl
+AC_SUBST(DLDFLAGS)dnl
+AC_SUBST(ARCH_FLAG)dnl
+AC_SUBST(MJIT_HEADER_FLAGS)dnl
+AC_SUBST(MJIT_HEADER_INSTALL_DIR)dnl
+AC_SUBST(MJIT_CC)dnl
+AS_IF([test "$GCC" = "yes"], [
+    AS_CASE(["$target_os"],[aix*],[mjit_std_cflag="-std=gnu99"])
+])
+AC_SUBST(MJIT_CFLAGS, [${MJIT_CFLAGS-"-w ${mjit_std_cflag} ${orig_cflags}"}])dnl
+AC_SUBST(MJIT_OPTFLAGS, [${MJIT_OPTFLAGS-'$(optflags)'}])dnl
+AC_SUBST(MJIT_DEBUGFLAGS, [${MJIT_DEBUGFLAGS-'$(debugflags)'}])dnl
+AC_SUBST(MJIT_LDSHARED)dnl
+
+AC_SUBST(STATIC)dnl
+AC_SUBST(CCDLFLAGS)dnl
+AC_SUBST(LDSHARED)dnl
+AC_SUBST(LDSHAREDXX)dnl
+AC_SUBST(DLEXT)dnl
+AC_SUBST(DLEXT2)dnl
+AC_SUBST(LIBEXT)dnl
+AC_SUBST(ASMEXT, S)dnl
+
+STATIC=
+
+AS_IF([test "$with_dln_a_out" != yes], [
+  rb_cv_dlopen=unknown
+  AC_MSG_CHECKING(whether OS depend dynamic link works)
+  AS_IF([test "$GCC" = yes], [
+    AS_CASE(["$target_os"],
+    [darwin*], [
+      # The -fno-common is needed if we wish to embed the Ruby interpreter
+      # into a plugin module of some project (as opposed to embedding it
+      # within the project's application).  The -I/usr/local/include is
+      # needed because CPP as discovered by configure (cc -E -traditional)
+      # fails to consult /usr/local/include by default.  This causes
+      # mkmf.rb's have_header() to fail if the desired resource happens to be
+      # installed in the /usr/local tree.
+      RUBY_APPEND_OPTION(CCDLFLAGS, -fno-common)],
+    [bsdi*|cygwin*|mingw*|aix*|interix*], [ ],
+    [
+      RUBY_APPEND_OPTION(CCDLFLAGS, -fPIC)])
+  ], [
+    AS_CASE(["$target_os"],
+	[hpux*],          [CCDLFLAGS="$CCDLFLAGS +Z"],
+	[solaris*|irix*], [CCDLFLAGS="$CCDLFLAGS -KPIC"],
+	[sunos*],         [CCDLFLAGS="$CCDLFLAGS -PIC"],
+	[esix*|uxpds*],   [CCDLFLAGS="$CCDLFLAGS -KPIC"],
+	                  [: ${CCDLFLAGS=""}])
+  ])
+
+
+  AC_ARG_ENABLE(rpath,
+       AS_HELP_STRING([--enable-rpath], [embed run path into extension libraries.
+       enabled by default on ELF platforms]),
+       [enable_rpath=$enableval], [enable_rpath="$rb_cv_binary_elf"])
+
+  AS_CASE(["$target_os"],
+	[hpux*], [	DLDFLAGS="$DLDFLAGS -E"
+			: ${LDSHARED='$(LD) -b'}
+			XLDFLAGS="$XLDFLAGS -Wl,-E"
+			: ${LIBPATHENV=SHLIB_PATH}
+			rb_cv_dlopen=yes],
+	[solaris*], [	AS_IF([test "$GCC" = yes], [
+			    : ${LDSHARED='$(CC) -shared'}
+			    AS_IF([test "$rb_cv_prog_gnu_ld" = yes], [
+				LDFLAGS="$LDFLAGS -Wl,-E"
+			    ])
+			], [
+			    : ${LDSHARED='$(CC) -G'}
+			])
+			AS_IF([test "$ac_cv_sizeof_voidp" = 8], [
+			    : ${LIBPATHENV=LD_LIBRARY_PATH_64}
+			    : ${PRELOADENV=LD_PRELOAD_64}
+			], [
+			    : ${LIBPATHENV=LD_LIBRARY_PATH_32}
+			    : ${PRELOADENV=LD_PRELOAD_32}
+			])
+			rb_cv_dlopen=yes],
+	[sunos*], [	: ${LDSHARED='$(LD) -assert nodefinitions'}
+			rb_cv_dlopen=yes],
+	[irix*], [	: ${LDSHARED='$(LD) -shared'}
+			rb_cv_dlopen=yes],
+	[sysv4*], [	: ${LDSHARED='$(LD) -G'}
+			rb_cv_dlopen=yes],
+	[nto-qnx*], [	: ${LDSHARED='$(CC) -shared'}
+			rb_cv_dlopen=yes],
+	[esix*|uxpds*], [ : ${LDSHARED='$(LD) -G'}
+			rb_cv_dlopen=yes],
+	[osf*], [	: ${LDSHARED='$(LD) -shared -expect_unresolved "*"'}
+			rb_cv_dlopen=yes],
+	[bsdi3*], [	AS_CASE(["$CC"],
+			[*shlicc*], [	: ${LDSHARED='$(CC) -r'}
+					rb_cv_dlopen=yes])],
+	[linux* | gnu* | k*bsd*-gnu | netbsd* | bsdi* | kopensolaris*-gnu | haiku*], [
+			: ${LDSHARED='$(CC) -shared'}
+			AS_IF([test "$rb_cv_binary_elf" = yes], [
+			    LDFLAGS="$LDFLAGS -Wl,-export-dynamic"
+			])
+			rb_cv_dlopen=yes],
+	[interix*], [	: ${LDSHARED='$(CC) -shared'}
+			XLDFLAGS="$XLDFLAGS -Wl,-E"
+			LIBPATHFLAG=" -L%1\$-s"
+			rb_cv_dlopen=yes],
+	[freebsd*|dragonfly*], [
+			: ${LDSHARED='$(CC) -shared'}
+			AS_IF([test "$rb_cv_binary_elf" = yes], [
+			    LDFLAGS="$LDFLAGS -rdynamic"
+			    DLDFLAGS="$DLDFLAGS "'-Wl,-soname,$@'
+			], [
+			  test "$GCC" = yes && test "$rb_cv_prog_gnu_ld" = yes || LDSHARED='$(LD) -Bshareable'
+			])
+			rb_cv_dlopen=yes],
+	[openbsd*|mirbsd*], [	: ${LDSHARED='$(CC) -shared ${CCDLFLAGS}'}
+			AS_IF([test "$rb_cv_binary_elf" = yes], [
+			    LDFLAGS="$LDFLAGS -Wl,-E"
+			])
+			rb_cv_dlopen=yes],
+	[darwin*], [	: ${LDSHARED='$(CC) -dynamic -bundle'}
+			: ${DLDSHARED='$(CC) -dynamiclib'}
+			: ${LDFLAGS=""}
+			: ${LIBPATHENV=DYLD_FALLBACK_LIBRARY_PATH}
+			: ${PRELOADENV=DYLD_INSERT_LIBRARIES}
+                        AS_IF([test x"$enable_shared" = xyes], [
+                            # Resolve symbols from libruby.dylib when --enable-shared
+                            EXTDLDFLAGS='$(LIBRUBYARG_SHARED)'
+                        ], [test "x$EXTSTATIC" = x], [
+                            # When building exts as bundles, a mach-o bundle needs to know its loader
+                            # program to bind symbols from the ruby executable
+                            EXTDLDFLAGS="-bundle_loader '\$(BUILTRUBY)'"
+			])
+			rb_cv_dlopen=yes],
+        [aix*], [	: ${LDSHARED='$(CC)'}
+			AS_IF([test "$GCC" = yes], [
+			    LDSHARED="$LDSHARED ${linker_flag}-G -shared"
+			], [
+			    LDSHARED="$LDSHARED ${linker_flag}-G"
+			])
+			EXTDLDFLAGS='-e$(TARGET_ENTRY)'
+			XLDFLAGS="${linker_flag}"'-bE:$(ARCHFILE)'" ${linker_flag}-brtl"
+			XLDFLAGS="$XLDFLAGS ${linker_flag}-blibpath:${prefix}/lib:${LIBPATH:-/usr/lib:/lib}"
+			: ${ARCHFILE="ruby.imp"}
+                        TRY_LINK='$(CC) -oconftest $(INCFLAGS) -I$(hdrdir) $(CPPFLAGS)'
+                        TRY_LINK="$TRY_LINK"' $(CFLAGS) $(src) $(LIBPATH) $(LDFLAGS) $(LOCAL_LIBS) $(LIBS)'
+			: ${LIBPATHENV=LIBPATH}
+			: ${PRELOADENV=LDR_PRELOAD}
+			rb_cv_dlopen=yes],
+	[nto-qnx*], [	DLDFLAGS="$DLDFLAGS -L/lib -L/usr/lib -L/usr/local/lib"
+			: ${LDSHARED='$(LD) -Bshareable -x'}
+			LDFLAGS="$LDFLAGS -L/lib -L/usr/lib -L/usr/local/lib"
+			rb_cv_dlopen=yes],
+	[cygwin*|mingw*], [
+			: ${LDSHARED='$(CC) -shared'}
+			XLDFLAGS="$XLDFLAGS -Wl,--stack,0x00200000,--enable-auto-import"
+			DLDFLAGS="${DLDFLAGS} -Wl,--enable-auto-image-base,--enable-auto-import"
+			: ${LIBPATHENV=PATH}
+			: ${PRELOADENV=""}
+			rb_cv_dlopen=yes],
+	[hiuxmpp], [	: ${LDSHARED='$(LD) -r'}],
+	[atheos*], [	: ${LDSHARED='$(CC) -shared'}
+			rb_cv_dlopen=yes],
+	[	: ${LDSHARED='$(LD)'}])
+  AC_MSG_RESULT($rb_cv_dlopen)
+
+  AS_IF([test "$rb_cv_dlopen" = yes], [
+    AS_CASE(["$target_os"],
+      [darwin*], [
+        AC_SUBST(ADDITIONAL_DLDFLAGS, "")
+	for flag in \
+	  "-multiply_defined suppress" \
+	  "-undefined dynamic_lookup" \
+	  ; do
+      test "x${linker_flag}" = x || flag="${linker_flag}`echo ${flag} | tr ' ' ,`"
+      RUBY_TRY_LDFLAGS([$flag], [], [$flag=])
+      AS_IF([test x"$flag" = x], [continue])
+
+      AC_MSG_CHECKING([whether $flag is accepted for bundle])
+      : > conftest.c
+      AS_IF([${LDSHARED/'$(CC)'/$CC} -o conftest.bundle $flag conftest.c >/dev/null 2>conftest.err &&
+          test ! -s conftest.err], [
+          AC_MSG_RESULT([yes])
+          RUBY_APPEND_OPTIONS(DLDFLAGS, [$flag])
+      ], [
+          AC_MSG_RESULT([no])
+          RUBY_APPEND_OPTIONS(ADDITIONAL_DLDFLAGS, [$flag])
+      ])
+      rm -fr conftest.*
+	done
+      ])
+  ])
+
+  AS_IF([test "$enable_rpath:${RPATHFLAG}" = yes:], [
+      AS_IF([test "x$rpathflag" != x], [
+	  RPATHFLAG=" ${rpathflag}%1\$-s"
+      ])
+  ])
+])
+AS_IF([test "${LDSHAREDXX}" = ""], [
+    AS_CASE(["${LDSHARED}"],
+	[*'$(CC)'*], [
+	    LDSHAREDXX=`echo "${LDSHARED}" | sed 's/\$(CC)/$(CXX)/'`
+	    ],
+	[*'${CC}'*], [
+	    LDSHAREDXX=`echo "${LDSHARED}" | sed 's/\${CC}/${CXX}/'`
+	    ],
+	[*$CC*], [
+	    LDSHAREDXX=`echo "${LDSHARED}" | sed "s|$CC|$CXX|"`
+	    ],
+	[ld" "*], [
+	    ])
+])
+AS_CASE([${RPATHFLAG}],[*'%1$'*],[: ${LIBPATHFLAG=' -L%1$-s'}],[: ${LIBPATHFLAG=' -L%s'}])
+
+AC_SUBST(LINK_SO)
+AC_SUBST(LIBPATHFLAG)
+AC_SUBST(RPATHFLAG)
+AC_SUBST(LIBPATHENV, "${LIBPATHENV-LD_LIBRARY_PATH}")
+AC_SUBST(PRELOADENV, "${PRELOADENV-LD_PRELOAD}")
+AC_SUBST(TRY_LINK)
+
+AS_IF([test "x$OPT_DIR" != x], [
+    pat=`echo "${LDFLAGS_OPTDIR}" | sed ['s/[][\\.*|]/\\\\&/']`
+    LDFLAGS=`echo "${LDFLAGS}" | sed "s| ${pat}||"`
+    val=`IFS="$PATH_SEPARATOR"
+        for dir in $OPT_DIR; do
+            echo x ${LIBPATHFLAG} ${RPATHFLAG} |
+            sed "s/^x *//;s${IFS}"'%1\\$-s'"${IFS}${dir}/lib${IFS}g;s${IFS}%s${IFS}${dir}/lib${IFS}g"
+        done | tr '\012' ' ' | sed 's/ *$//'`
+    AS_IF([test x"$val" != x], [
+	test x"${LDFLAGS}" = x || LDFLAGS="$LDFLAGS "
+	LDFLAGS="$LDFLAGS$val"
+	test x"${DLDFLAGS}" = x || DLDFLAGS="$DLDFLAGS "
+	DLDFLAGS="$DLDFLAGS$val"
+    ])
+    LDFLAGS_OPTDIR="$val"
+])
+
+AS_CASE(["$target_os"],
+[freebsd*], [
+    AC_CHECK_LIB([procstat], [procstat_open_sysctl])
+    AS_IF([test "x$ac_cv_lib_procstat_procstat_open_sysctl" = xyes], [
+	AC_CHECK_FUNCS(procstat_getvmmap)
+    ])
+    ])
+AS_CASE(["$target_cpu-$target_os"],
+[*-darwin*], [
+    AC_CHECK_HEADERS([libproc.h])
+    AC_CHECK_HEADERS([execinfo.h])
+    AS_IF([test "x$ac_cv_header_execinfo_h" = xyes], [
+	AC_CHECK_LIB([execinfo], [backtrace])
+	AC_CHECK_HEADERS([libunwind.h])
+    ])],
+[*-freebsd*|x86_64-netbsd*], [
+    AC_CHECK_HEADERS([execinfo.h])
+    AS_IF([test "x$ac_cv_header_execinfo_h" = xyes], [
+	AC_CHECK_LIB([execinfo], [backtrace])
+	AC_CHECK_LIB([unwind], [unw_backtrace])
+    ])])
+AC_CHECK_FUNCS(backtrace)
+
+AS_IF([test "x$ac_cv_func_backtrace" = xyes], [
+  AC_CACHE_CHECK(for broken backtrace, rb_cv_broken_backtrace,
+    [AC_RUN_IFELSE([AC_LANG_SOURCE([[
+#include <unistd.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <stdint.h>
+#include <string.h>
+#include <signal.h>
+#include <execinfo.h>
+
+]`grep '^@%:@ *define  *RUBY_SIGALTSTACK_SIZE' ${srcdir}/signal.c`[
+#define TRACE_SIZE 256
+
+void sigsegv(int signum, siginfo_t *info, void *ctx){
+    void *trace[TRACE_SIZE];
+    int n = backtrace(trace, TRACE_SIZE);
+    if (n > 0) {
+	/*fprintf(stdout, "backtrace:%d\n",n);*/
+    } else {
+	_exit(EXIT_FAILURE);
+    }
+    _exit(EXIT_SUCCESS);
+}
+int
+main(void)
+{
+    volatile int *a = NULL;
+    stack_t ss;
+    struct sigaction sa;
+
+    ss.ss_sp = malloc(RUBY_SIGALTSTACK_SIZE);
+    if (ss.ss_sp == NULL) {
+	fprintf(stderr, "cannot allocate memory for sigaltstack\n");
+	return EXIT_FAILURE;
+    }
+    ss.ss_size = RUBY_SIGALTSTACK_SIZE;
+    ss.ss_flags = 0;
+    if (sigaltstack(&ss, NULL) == -1) {
+	fprintf(stderr, "sigaltstack failed\n");
+	return EXIT_FAILURE;
+    }
+    memset(&sa, 0, sizeof(struct sigaction));
+    sigemptyset(&sa.sa_mask);
+    sa.sa_sigaction = sigsegv;
+    sa.sa_flags |= SA_SIGINFO;
+    sa.sa_flags |= SA_ONSTACK;
+    sigaction(SIGSEGV, &sa, NULL);
+    a[0] = 1;
+    return EXIT_SUCCESS;
+}
+]])],
+	rb_cv_broken_backtrace=no,
+	rb_cv_broken_backtrace=yes,
+	rb_cv_broken_backtrace=no)])
+  AS_IF([test "$rb_cv_broken_backtrace" = yes], [
+    AC_DEFINE(BROKEN_BACKTRACE, 1)
+  ])
+])
+
+AC_ARG_WITH(valgrind,
+        AS_HELP_STRING([--without-valgrind],[disable valgrind memcheck support]),
+        [], with_valgrind=yes)
+AS_IF([test x$with_valgrind != xno],
+        [AC_CHECK_HEADERS(valgrind/memcheck.h)])
+
+dln_a_out_works=no
+AS_IF([test "$ac_cv_header_a_out_h" = yes], [
+  AS_IF([test "$with_dln_a_out" = yes || test "$rb_cv_dlopen" = unknown], [
+    cat confdefs.h > config.h
+    AC_CACHE_CHECK(whether matz's dln works, rb_cv_dln_a_out,
+    [AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[
+#define USE_DLN_A_OUT
+#include "dln.c"
+]], [[]])],
+	rb_cv_dln_a_out=yes,
+	rb_cv_dln_a_out=no)])
+    AS_IF([test "$rb_cv_dln_a_out" = yes], [
+      dln_a_out_works=yes
+      AC_DEFINE(USE_DLN_A_OUT)
+    ])
+  ])
+])
+
+AS_IF([test "$dln_a_out_works" = yes], [
+  AS_IF([test "$GCC" = yes], [
+    STATIC=-static
+  ], [
+    STATIC=-Bstatic
+  ])
+  DLEXT=so
+  CCDLFLAGS=
+], [
+  AS_CASE(["$target_os"],
+    [hpux*], [
+	DLEXT=sl],
+    [darwin*], [
+	SOEXT=dylib
+	DLEXT=bundle],
+    [cygwin*|mingw*|*djgpp*], [
+	LOAD_RELATIVE=1
+	SOEXT=dll
+	DLEXT=so],
+    [
+	DLEXT=so])
+])
+: ${SOEXT="${DLEXT}"}
+AC_SUBST(SOEXT)
+AS_IF([test "$rb_cv_dlopen:$load_relative" = yes:yes], [
+    AS_IF([test "$ac_cv_func_dladdr" = yes], [
+	LOAD_RELATIVE=1
+    ])
+])
+AS_IF([test x"$LOAD_RELATIVE" = x1], [
+    load_relative=yes
+], [
+    unset load_relative
+])
+
+len=2 # .rb
+n=`expr "$DLEXT"  : '.*'`; test "$n" -gt "$len" && len=$n
+n=`expr "$DLEXT2" : '.*'`; test "$n" -gt "$len" && len=$n
+AC_DEFINE_UNQUOTED(DLEXT_MAXLEN, `expr $len + 1`)
+test ".$DLEXT"  = "." || AC_DEFINE_UNQUOTED(DLEXT,  ".$DLEXT")
+test ".$DLEXT2" = "." || AC_DEFINE_UNQUOTED(DLEXT2, ".$DLEXT2")
+AC_SUBST(DLEXT)
+
+AS_IF([test "$with_dln_a_out" = yes], [
+  STRIP=true
+], [
+    AC_MSG_CHECKING([for $STRIP flags])
+    AC_LINK_IFELSE([AC_LANG_PROGRAM], [AS_IF(
+        ["${STRIP}" -A -n conftest$ac_exeext 2>/dev/null], [
+            AC_MSG_RESULT([-A -n])
+            STRIP="${STRIP} -A -n"
+        ],
+        ["${STRIP}" -S -x conftest$ac_exeext 2>/dev/null], [
+            AC_MSG_RESULT([-S -x])
+            STRIP="${STRIP} -S -x"
+        ], [
+            AC_MSG_RESULT([none needed])
+        ])
+    ])
+])
+
+
+AC_ARG_WITH(ext,
+            AS_HELP_STRING([--with-ext=EXTS],
+                           [pass to --with-ext option of extmk.rb]))
+AC_ARG_WITH(out-ext,
+            AS_HELP_STRING([--with-out-ext=EXTS],
+                           [pass to --without-ext option of extmk.rb]))
+EXTSTATIC=
+AC_SUBST(EXTSTATIC)dnl
+AC_ARG_WITH(static-linked-ext,
+	    AS_HELP_STRING([--with-static-linked-ext], [link external modules statically]),
+            [AS_CASE([$withval],[yes],[STATIC=;EXTSTATIC=static],[no],[],[EXTSTATIC="$withval"])])
+AS_CASE([",$EXTSTATIC,"], [,static,|*,enc,*], [
+  ENCOBJS='enc/encinit.$(OBJEXT) enc/libenc.$(LIBEXT) enc/libtrans.$(LIBEXT)'
+  EXTOBJS='ext/extinit.$(OBJEXT)'
+  AC_DEFINE_UNQUOTED(EXTSTATIC, 1)
+  AC_SUBST(ENCSTATIC, static)
+], [
+  ENCOBJS='dmyenc.$(OBJEXT)'
+  EXTOBJS='dmyext.$(OBJEXT)'
+])
+AC_SUBST(ENCOBJS)
+AC_SUBST(EXTOBJS)
+
+AC_ARG_WITH(setup,
+	    AS_HELP_STRING([--with-setup=SETUP], [use extension libraries setup]),
+	    [setup=$withval])
+AS_IF([test -n "$setup"], [
+    AS_IF([! test -f "ext/$setup" -o -f "$srcdir/ext/$setup"], [
+	AC_MSG_ERROR(Setup file $setup not found under ext or $srcdir/ext)
+    ])
+], [test -f "$srcdir/ext/Setup.$target_os"], [
+    setup="Setup.$target_os"
+], [
+    setup=
+    for file in "$srcdir"/ext/Setup.*; do
+	AS_CASE(["$file"], [*~|*.bak|*.orig|*.rej|*.tmp], [continue])
+	setup=`basename "$file"`
+	AS_CASE(["$target_os"], [`expr "$setup" : 'Setup.\(.*\)'`*], [break])
+	platform=`sed '/^option  *platform  */!d;s///;s/|/*|/g;q' "$file"`
+	AS_IF([test "x$platform" != x], [
+	    eval "AS_CASE([\"\$target_os\"], [$platform*], [break])"
+	])
+	setup=
+    done
+    : ${setup:=Setup}
+])
+AC_SUBST(setup)
+
+rubylibprefix='${libdir}/${RUBY_BASE_NAME}'
+AC_ARG_WITH(rubylibprefix,
+	    AS_HELP_STRING([--with-rubylibprefix=DIR], [prefix for ruby libraries [[LIBDIR/RUBY_BASE_NAME]]]),
+	    [AS_IF([test "x$withval" = xno], [
+		AC_MSG_ERROR([No ruby, No libprefix])
+	    ])
+	    rubylibprefix="$withval"])
+AC_SUBST(rubylibprefix)
+
+AS_IF([test x"${exec_prefix}" != xNONE], [
+    RUBY_EXEC_PREFIX="$exec_prefix"
+], [test x"$prefix" != xNONE], [
+    RUBY_EXEC_PREFIX="$prefix"
+], [
+    RUBY_EXEC_PREFIX=$ac_default_prefix
+])
+pat=`echo "${RUBY_EXEC_PREFIX}" | tr -c '\012' .`'\(.*\)'
+for var in bindir includedir libdir rubylibprefix; do
+    eval val='"$'$var'"'
+    AS_CASE(["$val"], ["${RUBY_EXEC_PREFIX}"*], [val='${exec_prefix}'"`expr \"$val\" : \"$pat\"`"])
+    eval $var='"$val"'
+done
+
+BTESTRUBY='$(MINIRUBY)'
+BOOTSTRAPRUBY='$(BASERUBY)'
+AS_IF([test x"$cross_compiling" = xyes], [
+  test x"$MINIRUBY" = x && MINIRUBY="${RUBY-$BASERUBY} -I`$CHDIR .; pwd` "-r'$(arch)-fake'
+  XRUBY_LIBDIR=`${RUBY-$BASERUBY} -rrbconfig -e ['puts RbConfig::CONFIG["libdir"]']`
+  XRUBY_RUBYLIBDIR=`${RUBY-$BASERUBY} -rrbconfig -e ['puts RbConfig::CONFIG["rubylibdir"]']`
+  XRUBY_RUBYHDRDIR=`${RUBY-$BASERUBY} -rrbconfig -e ['puts RbConfig::CONFIG["rubyhdrdir"]']`
+  AC_SUBST(XRUBY_LIBDIR)
+  AC_SUBST(XRUBY_RUBYLIBDIR)
+  AC_SUBST(XRUBY_RUBYHDRDIR)
+  PREP='$(arch)-fake.rb'
+  RUNRUBY_COMMAND='$(MINIRUBY) -I`cd $(srcdir)/lib; pwd`'
+  RUNRUBY='$(RUNRUBY_COMMAND)'
+  XRUBY='$(MINIRUBY)'
+  TEST_RUNNABLE=no
+  CROSS_COMPILING=yes
+  AC_DEFINE(CROSS_COMPILING, 1)
+], [
+  MINIRUBY='./miniruby$(EXEEXT) -I$(srcdir)/lib -I.'
+  MINIRUBY="$MINIRUBY"' -I$(EXTOUT)/common'
+  PREP='miniruby$(EXEEXT)'
+  RUNRUBY_COMMAND='$(MINIRUBY) $(tooldir)/runruby.rb --extout=$(EXTOUT) $(RUNRUBYOPT)'
+  RUNRUBY='$(RUNRUBY_COMMAND) --'
+  XRUBY='$(RUNRUBY)'
+  AS_CASE(["$HAVE_BASERUBY:$build_os"], [no:*|*:mingw*], [BOOTSTRAPRUBY='$(MINIRUBY)'])
+  TEST_RUNNABLE=yes
+  CROSS_COMPILING=no
+])
+AC_SUBST(TEST_RUNNABLE)
+AC_SUBST(CROSS_COMPILING)
+AC_SUBST(MINIRUBY)
+AC_SUBST(BTESTRUBY)
+AC_SUBST(PREP)
+AC_SUBST(RUNRUBY_COMMAND)
+AC_SUBST(RUNRUBY)
+AC_SUBST(XRUBY)
+AC_SUBST(BOOTSTRAPRUBY)
+AC_SUBST(EXTOUT, [${EXTOUT=.ext}])
+
+FIRSTMAKEFILE=""
+LIBRUBY_A='lib$(RUBY_SO_NAME)-static.a'
+LIBRUBY='$(LIBRUBY_A)'
+LIBRUBYARG_STATIC='-l$(RUBY_SO_NAME)-static'
+LIBRUBYARG='$(LIBRUBYARG_STATIC)'
+SOLIBS='$(MAINLIBS)'
+
+AS_CASE(["$target_os"],
+  [cygwin*|mingw*|haiku*|darwin*], [
+    : ${DLDLIBS=""}
+    ],
+  [
+    DLDLIBS="$DLDLIBS -lc"
+    ])
+
+AC_ARG_ENABLE(multiarch,
+	      AS_HELP_STRING([--enable-multiarch], [enable multiarch compatible directories]),
+	      [multiarch=], [unset multiarch])
+AS_IF([test ${multiarch+set}], [
+   AC_DEFINE(ENABLE_MULTIARCH)
+   MJIT_HEADER_INSTALL_DIR=include/'${arch}/${RUBY_VERSION_NAME}'
+], [
+   MJIT_HEADER_INSTALL_DIR=include/'${RUBY_VERSION_NAME}/${arch}'
+])
+
+archlibdir='${libdir}/${arch}'
+AC_ARG_WITH(archlibdir,
+	    AS_HELP_STRING([--with-archlibdir=DIR],
+			   [prefix for libruby [[LIBDIR/ARCH]]]),
+	    [archlibdir="$withval"])
+
+sitearchlibdir='${libdir}/${sitearch}'
+archincludedir='${includedir}/${arch}'
+sitearchincludedir='${includedir}/${sitearch}'
+
+AC_ARG_WITH(soname,
+	AS_HELP_STRING([--with-soname=SONAME], [base name of shared library]),
+	[RUBY_SO_NAME=$withval],
+	[
+	    AS_CASE(["$target_os"],
+	    [darwin*], [
+	        RUBY_SO_NAME='$(RUBY_BASE_NAME).$(RUBY_API_VERSION)'
+	    ],
+	    [cygwin*], [
+	        RUBY_SO_NAME='$(RUBY_BASE_NAME)$(MAJOR)$(MINOR)0'
+	    ],
+	    [mingw*], [
+		RUBY_SO_NAME="${rb_cv_msvcrt}"'-$(RUBY_BASE_NAME)$(MAJOR)$(MINOR)0'
+		AS_IF([test x"${target_cpu}" != xi386], [
+		    RUBY_SO_NAME="${target_cpu}-${RUBY_SO_NAME}"
+		])
+	    ],
+	    [RUBY_SO_NAME='$(RUBY_BASE_NAME)'])
+	])
+
+LIBRUBY_LDSHARED=${DLDSHARED=${LDSHARED}}
+LIBRUBY_DLDFLAGS=$DLDFLAGS
+LIBRUBY_SO='lib$(RUBY_SO_NAME).$(SOEXT).$(RUBY_PROGRAM_VERSION)'
+LIBRUBY_SONAME='lib$(RUBY_SO_NAME).$(SOEXT).$(RUBY_API_VERSION)'
+LIBRUBY_ALIASES='lib$(RUBY_SO_NAME).$(SOEXT)'
+ENABLE_SHARED=no
+
+AC_ARG_ENABLE(shared,
+       AS_HELP_STRING([--enable-shared], [build a shared library for Ruby]),
+       [enable_shared=$enableval])
+libprefix=${multiarch+'$(archlibdir)'}${multiarch-'$(libdir)'}
+LIBRUBY_RELATIVE=${load_relative-no}
+AS_CASE("$enable_shared", [yes], [
+  LIBRUBY='$(LIBRUBY_SO)'
+  LIBRUBYARG_SHARED='-l$(RUBY_SO_NAME)'
+  LIBRUBYARG='$(LIBRUBYARG_SHARED)'
+  LIBRUBY_RELATIVE=no
+  test -z "$CCDLFLAGS" || CFLAGS="$CFLAGS $CCDLFLAGS"
+  ENABLE_SHARED=yes
+
+  # libdir can be overridden in config.site file (on OpenSUSE at least).
+  libdir_basename=lib
+  AS_IF([test "$bindir" = '${exec_prefix}/bin'], [
+    AS_CASE(["$libdir"], ['${exec_prefix}/'*], [libdir_basename=`basename "$libdir"`])
+  ])
+  AC_DEFINE_UNQUOTED(LIBDIR_BASENAME, ["${libdir_basename}"])
+  libdir_basename="${libdir_basename}"${multiarch+'/${arch}'}
+
+  RUBY_TRY_LDFLAGS([${linker_flag}--no-as-needed], [no_as_needed=yes], [no_as_needed=no])
+  AS_IF([test "$no_as_needed" = yes], [
+      RUBY_APPEND_OPTIONS(LDFLAGS, [${linker_flag}--no-as-needed])
+  ])
+
+  AS_CASE(["$target_os"],
+    [freebsd*|dragonfly*], [],
+    [
+     AS_IF([test "$GCC" = yes], [
+       RUBY_TRY_LDFLAGS([${linker_flag}--no-undefined], [no_undefined=yes], [no_undefined=no])
+       AS_IF([test "no_undefined" = yes], [
+	  RUBY_APPEND_OPTION(EXTLDFLAGS, [${linker_flag}--no-undefined])
+       ])
+     ])
+    ])
+
+  AS_CASE(["$target_os"],
+    [sunos4*], [
+	LIBRUBY_ALIASES='$(LIBRUBY_SONAME) lib$(RUBY_SO_NAME).$(SOEXT)'
+	],
+    [linux* | gnu* | k*bsd*-gnu | atheos* | kopensolaris*-gnu | haiku*], [
+	RUBY_APPEND_OPTIONS(LIBRUBY_DLDFLAGS, ['-Wl,-soname,$(LIBRUBY_SONAME)' "$LDFLAGS_OPTDIR"])
+	LIBRUBY_ALIASES='$(LIBRUBY_SONAME) lib$(RUBY_SO_NAME).$(SOEXT)'
+	AS_IF([test "$load_relative" = yes], [
+	    libprefix="'\$\${ORIGIN}/../${libdir_basename}'"
+	    LIBRUBY_RPATHFLAGS="-Wl,-rpath,${libprefix}"
+	    LIBRUBY_RELATIVE=yes
+	])
+	],
+    [freebsd*|dragonfly*], [
+	LIBRUBY_SO='lib$(RUBY_SO_NAME).$(SOEXT).$(MAJOR)$(MINOR)'
+	LIBRUBY_SONAME='$(LIBRUBY_SO)'
+	AS_IF([test "$rb_cv_binary_elf" != "yes" ], [
+	    LIBRUBY_SO="$LIBRUBY_SO.\$(TEENY)"
+	    LIBRUBY_ALIASES=''
+	])
+	],
+    [netbsd*], [
+	LIBRUBY_SONAME='lib$(RUBY_SO_NAME).$(SOEXT).$(MAJOR)$(MINOR)'
+	LIBRUBY_SO="${LIBRUBY_SONAME}"'.$(TEENY)'
+	RUBY_APPEND_OPTIONS(LIBRUBY_DLDFLAGS, ['-Wl,-soname,$(LIBRUBY_SONAME)' "$LDFLAGS_OPTDIR"])
+	AS_IF([test "$rb_cv_binary_elf" = yes], [ # ELF platforms
+	   LIBRUBY_ALIASES='$(LIBRUBY_SONAME) lib$(RUBY_SO_NAME).$(SOEXT)'
+	], [	# a.out platforms
+	   LIBRUBY_ALIASES=""
+	])
+	],
+    [openbsd*|mirbsd*], [
+	LIBRUBY_SO='lib$(RUBY_SO_NAME).$(SOEXT).$(MAJOR).'`expr ${MINOR} \* 10 + ${TEENY}`
+	],
+    [solaris*], [
+	LIBRUBY_SO='lib$(RUBY_SO_NAME).$(SOEXT).$(MAJOR)'
+	LIBRUBY_SONAME='lib$(RUBY_SO_NAME).$(SOEXT).$(RUBY_PROGRAM_VERSION)'
+	LIBRUBY_ALIASES='$(LIBRUBY_SONAME) lib$(RUBY_SO_NAME).$(SOEXT)'
+	RUBY_APPEND_OPTIONS(LIBRUBY_DLDFLAGS, ["${linker_flag}-h${linker_flag:+,}"'$(@F)'])
+	XLDFLAGS="$XLDFLAGS "'-R${libdir}'
+	],
+    [hpux*], [
+	XLDFLAGS="$XLDFLAGS "'-Wl,+s,+b,$(libdir)'
+	LIBRUBY_ALIASES='$(LIBRUBY_SONAME) lib$(RUBY_SO_NAME).$(SOEXT)'
+	],
+    [aix*], [
+	RUBY_APPEND_OPTIONS(LIBRUBY_DLDFLAGS, ["${linker_flag}-bnoentry" "$XLDFLAGS" "$LDFLAGS_OPTDIR"])
+	LIBRUBYARG_SHARED='-L${libdir} -l${RUBY_SO_NAME}'
+	LIBS="$LIBS -lm -lc"
+	],
+    [darwin*], [
+	LIBRUBY_SO='lib$(RUBY_SO_NAME).$(SOEXT)'
+	LIBRUBY_SONAME='$(LIBRUBY_SO)'
+	LIBRUBY_ALIASES='lib$(RUBY_INSTALL_NAME).$(SOEXT)'
+	AS_IF([test "$load_relative" = yes], [
+	    libprefix="@executable_path/../${libdir_basename}"
+	    LIBRUBY_RELATIVE=yes
+	])
+	LIBRUBY_DLDFLAGS="$LIBRUBY_DLDFLAGS -install_name ${libprefix}"'/$(LIBRUBY_SONAME)'
+	LIBRUBY_DLDFLAGS="$LIBRUBY_DLDFLAGS "'-compatibility_version $(RUBY_API_VERSION)'
+	LIBRUBY_DLDFLAGS="$LIBRUBY_DLDFLAGS "'-current_version $(RUBY_PROGRAM_VERSION)'
+	AS_IF([test "$visibility_option" = ld], [
+	    LIBRUBY_DLDFLAGS="$LIBRUBY_DLDFLAGS "'-Wl,-unexported_symbol,_Init_*'
+	    LIBRUBY_DLDFLAGS="$LIBRUBY_DLDFLAGS "'-Wl,-unexported_symbol,_ruby_static_id_*'
+	    LIBRUBY_DLDFLAGS="$LIBRUBY_DLDFLAGS "'-Wl,-unexported_symbol,*_threadptr_*'
+	])
+	LIBRUBY_DLDFLAGS="$LIBRUBY_DLDFLAGS "' $(XLDFLAGS)'
+	],
+    [interix*], [
+	LIBRUBYARG_SHARED='-L. -L${libdir} -l$(RUBY_SO_NAME)'
+	],
+    [mingw*|cygwin*|mswin*], [
+	LIBRUBY_RELATIVE=yes
+	])
+], [
+  LIBRUBYARG_SHARED=
+
+  # enable PIE if possible
+  AC_ARG_ENABLE(pie,
+          AS_HELP_STRING([--disable-pie], [disable PIE feature]),
+          [pie=$enableval], [pie=])
+  AS_IF([test "$GCC" = yes -a -z "$EXTSTATIC" -a "x$pie" != xno], [
+    RUBY_TRY_CFLAGS(-fPIE, [pie=yes], [pie=no])
+    AS_IF([test "$pie" = yes], [
+      # Use -fPIE when testing -pie.  RUBY_TRY_LDFLAGS sets
+      # $save_CFLAGS internally, so set other name here.
+      save_CFLAGS_before_pie="$CFLAGS"
+      CFLAGS="$CFLAGS -fPIE"
+
+      # gcc need -pie but clang need -Wl,-pie.
+      for pie in -pie -Wl,-pie; do
+	RUBY_TRY_LDFLAGS([$pie], [], [pie=])
+	AS_IF([test "x$pie" != x], [
+	  RUBY_APPEND_OPTION(XCFLAGS, -fPIE)
+	  RUBY_APPEND_OPTION(XLDFLAGS, $pie)
+	  break
+	])
+      done
+      CFLAGS="$save_CFLAGS_before_pie"
+    ])
+  ])
+])
+AS_IF([test "$enable_rpath" = yes], [
+    test -z "$LIBRUBY_RPATHFLAGS" || LIBRUBY_RPATHFLAGS="$LIBRUBY_RPATHFLAGS "
+    rpathflag="${RPATHFLAG}"
+    AS_CASE(["${cross_compiling}${load_relative}"], [*yes*], [], [rpathflag="$RPATHFLAG$LIBPATHFLAG"])
+    rpathflag=`IFS="$PATH_SEPARATOR"
+        echo x "$rpathflag" |
+        sed "s/^x *//;s${IFS}"'%1\\$-s'"${IFS}${libprefix}${IFS}g;s${IFS}%s${IFS}${libprefix}${IFS}g"
+    `
+    LIBRUBY_RPATHFLAGS="$LIBRUBY_RPATHFLAGS${rpathflag}"
+    LIBRUBYARG_SHARED="$LIBRUBY_RPATHFLAGS $LIBRUBYARG_SHARED"
+    LIBRUBYARG_STATIC="$LIBRUBY_RPATHFLAGS $LIBRUBYARG_STATIC"
+])
+AC_SUBST(LIBRUBY_RELATIVE)
+
+LDFLAGS="-L. $LDFLAGS"
+AC_SUBST(ARCHFILE)
+
+AS_IF([test "$EXEEXT" = .exe], [
+    EXECUTABLE_EXTS='".exe",".com",".cmd",".bat"'
+    AC_DEFINE_UNQUOTED(EXECUTABLE_EXTS, $EXECUTABLE_EXTS)
+    EXECUTABLE_EXTS=`echo $EXECUTABLE_EXTS | tr -d '"' | tr , ' '`
+    AC_SUBST(EXECUTABLE_EXTS)
+])
+
+AS_CASE("$cross_compiling:${LIBPATHENV}", [yes:* | no:], [], [
+    AC_MSG_CHECKING(whether wrapper for $LIBPATHENV is needed)
+    AS_IF([env ${LIBPATHENV}=/lib /bin/sh -c ': ${'${LIBPATHENV}'?}' 2>/dev/null],
+	[AC_MSG_RESULT(no)],
+	[PREP="$PREP"' exe/$(PROGRAM)'
+	AC_MSG_RESULT(yes)]
+    )
+])
+
+AC_ARG_ENABLE(dtrace,
+        AS_HELP_STRING([--enable-dtrace],
+        [enable DTrace for tracing inside ruby. enabled by default on systems having dtrace]),
+        [enable_dtrace=$enableval], [enable_dtrace=auto])
+
+LIBRUBY_A_OBJS='$(OBJS)'
+DTRACE_REBUILD=
+AS_CASE(["${enable_dtrace}"],
+[yes|auto], [
+    RUBY_DTRACE_AVAILABLE()
+], [
+    rb_cv_dtrace_available=no
+])
+AS_CASE(["$target_os"],[freebsd*],[
+         rb_cv_dtrace_available=no
+	 ])
+AS_IF([test "${enable_dtrace}" = yes], [dnl
+    AS_IF([test -z "$DTRACE"], [dnl
+	AC_MSG_ERROR([dtrace(1) is missing])
+    ], [test "$cross_compiling" = yes], [dnl
+	AC_MSG_ERROR([--enable-dtrace, however, cross compiling])
+    ], [test "${rb_cv_dtrace_available}" = "no"], [dnl
+       AC_MSG_ERROR([--enable-dtrace, however, USDT is not available])
+    ])
+])
+AS_CASE([$rb_cv_dtrace_available],
+[yes*], [dnl
+    RUBY_DTRACE_POSTPROCESS()
+    AS_IF([test "$rb_cv_prog_dtrace_g" != no], [dnl
+	DTRACE_OBJ='probes.$(OBJEXT)'
+    ])
+    AS_IF([test "$rb_cv_prog_dtrace_g" = rebuild], [dnl
+	DTRACE_REBUILD=yes
+	LIBRUBY_A_OBJS='$(DTRACE_GLOMMED_OBJ)'
+    ])
+    AS_CASE("${target_os}", [freebsd*], [dnl
+        # FreeBSD's dtrace requires libelf
+        LIBS="-lelf $LIBS"
+    ])
+    DTRACE_EXT=d
+], [dnl
+    enable_dtrace=no
+    DTRACE_EXT=dmyh
+])
+AC_SUBST(DTRACE_EXT)
+AC_SUBST(DTRACE_OBJ)
+AC_SUBST(DTRACE_REBUILD)
+AC_SUBST(DTRACE_OPT)
+AC_SUBST(LIBRUBY_A_OBJS)
+
+AC_ARG_ENABLE(gcov,
+       AS_HELP_STRING([--enable-gcov], [enable coverage measurement by gcov]),
+       [gcov=yes])
+AS_IF([test x"$gcov" = xyes], [
+    CFLAGS="$CFLAGS -coverage"
+    LDFLAGS="$LDFLAGS -coverage"
+])
+
+RUBY_SETJMP_TYPE
+}
+
+: "build section" && {
+dnl build rdoc index if requested
+RDOCTARGET=""
+CAPITARGET=""
+AC_ARG_ENABLE(install-doc,
+       AS_HELP_STRING([--disable-install-doc], [do not install either rdoc indexes or C API documents during install]),
+       [install_doc=$enableval], [install_doc=yes])
+AC_ARG_WITH(rdoc,
+      AS_HELP_STRING([--with-rdoc=ri,html], [comma/space separated list of RDoc formats to install]),
+      [install_rdoc=`echo ,$withval, | sed 'y/,/ /;s/ ri / rdoc /;s/^ *//;s/ *$//'`], [
+AC_ARG_ENABLE(install-rdoc,
+      AS_HELP_STRING([--disable-install-rdoc], [do not install rdoc indexes during install]),
+      [install_rdoc=$enableval], [install_rdoc=yes])
+])
+AC_ARG_ENABLE(install-capi,
+      AS_HELP_STRING([--disable-install-capi], [do not install C API documents during install]),
+      [install_capi=$enableval], [install_capi=no])
+
+AS_IF([test "$install_doc" != no], [
+    AS_CASE(["$install_rdoc"],
+    [yes], [
+	RDOCTARGET="rdoc"
+    ],
+    [all], [
+	RDOCTARGET="rdoc html"
+    ],
+    [no|''], [
+	RDOCTARGET="nodoc"
+    ],
+    [
+	RDOCTARGET="$install_rdoc"
+    ])
+    AS_IF([test "$install_capi" != no -a -n "$DOXYGEN"], [
+	CAPITARGET="capi"
+    ], [
+	CAPITARGET="nodoc"
+    ])
+], [
+    RDOCTARGET="nodoc"
+    CAPITARGET="nodoc"
+])
+
+AC_SUBST(RDOCTARGET)
+AC_SUBST(CAPITARGET)
+
+AS_CASE(["$RDOCTARGET:$CAPITARGET"],[nodoc:nodoc],[INSTALLDOC=nodoc],[INSTALLDOC=all])
+AC_SUBST(INSTALLDOC)
+
+AC_ARG_ENABLE(jit-support,
+        AS_HELP_STRING([--disable-jit-support], [disable JIT features]),
+        [MJIT_SUPPORT=$enableval
+         AS_IF([test x"$enable_jit_support" = "xyes"],
+                 [AC_DEFINE(USE_MJIT, 1)],
+                 [AC_DEFINE(USE_MJIT, 0)])],
+        [MJIT_SUPPORT=yes
+         AC_DEFINE(USE_MJIT, 1)])
+
+AC_SUBST(MJIT_SUPPORT)
+
+AC_ARG_ENABLE(install-static-library,
+	AS_HELP_STRING([--disable-install-static-library], [do not install static ruby library]),
+	[INSTALL_STATIC_LIBRARY=$enableval],
+	AS_IF([test x"$enable_shared" = xyes],
+	    [INSTALL_STATIC_LIBRARY=no],
+	    [INSTALL_STATIC_LIBRARY=yes]))
+AC_SUBST(INSTALL_STATIC_LIBRARY)
+
+AS_IF([test "$rb_with_pthread" = "yes"], [
+    THREAD_MODEL=pthread
+])
+AC_CACHE_CHECK([for prefix of external symbols], rb_cv_symbol_prefix, [
+    AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[extern void conftest_external(void) {}]], [[]])],[
+	rb_cv_symbol_prefix=`$NM conftest.$ac_objext |
+			     sed -n ['/.*T[ 	]\([^ 	]*\)conftest_external.*/!d;s//\1/p;q']`
+	],
+	[rb_cv_symbol_prefix=''])
+    test -n "$rb_cv_symbol_prefix" || rb_cv_symbol_prefix=NONE
+])
+SYMBOL_PREFIX="$rb_cv_symbol_prefix"
+test "x$SYMBOL_PREFIX" = xNONE && SYMBOL_PREFIX=''
+DLNOBJ=dln.o
+AC_ARG_ENABLE(dln,
+	      AS_HELP_STRING([--disable-dln], [disable dynamic link feature]),
+	      [test "$enableval" = yes || DLNOBJ=dmydln.o])
+AC_SUBST(DLNOBJ)
+MINIDLNOBJ=dmydln.o
+
+AS_CASE(["$target_os"],
+    [linux*], [
+	],
+    [netbsd*], [
+	RUBY_APPEND_OPTION(CFLAGS, -pipe)
+	],
+    [darwin*], [
+	RUBY_APPEND_OPTION(CFLAGS, -pipe)
+	AC_COMPILE_IFELSE([
+	    AC_LANG_BOOL_COMPILE_TRY([@%:@include <AvailabilityMacros.h>],
+		[MAC_OS_X_VERSION_MIN_REQUIRED >= MAC_OS_X_VERSION_10_7])],
+	    [dnl
+		RUBY_APPEND_OPTION(XLDFLAGS, [-framework Security])
+		RUBY_APPEND_OPTION(LIBRUBYARG_STATIC, [-framework Security])
+	    ]dnl
+	)
+	RUBY_APPEND_OPTION(XLDFLAGS, [-framework Foundation])
+	RUBY_APPEND_OPTION(LIBRUBYARG_STATIC, [-framework Foundation])
+	],
+    [osf*], [
+	AS_IF([test "$GCC" != "yes" ], [
+	  # compile something small: taint.c is fine for this.
+	  # the main point is the '-v' flag of 'cc'.
+	  AS_CASE(["`cc -v -I. -c main.c -o /tmp/main.o 2>&1`"],
+	  [*/gemc_cc*], [   # we have the new DEC GEM CC
+                        CFLAGS="$CFLAGS -oldc"
+                        ],
+          [            # we have the old MIPS CC
+                        ])
+	  # cleanup
+	  rm -f /tmp/main.o
+	  CFLAGS="$CFLAGS -std"
+	])
+	],
+    [cygwin*|mingw*], [
+	LIBRUBY_DLDFLAGS="${LIBRUBY_DLDFLAGS}"' -Wl,--out-implib=$(LIBRUBY)'
+	AS_CASE(["$target_os"],
+	[cygwin*], [
+	    AS_IF([test x"$enable_shared" = xyes], [
+		LIBRUBY_SO='cyg$(RUBY_SO_NAME)'.dll
+		LIBRUBY_DLDFLAGS="${LIBRUBY_DLDFLAGS}"' $(RUBYDEF)'
+	    ])
+	    ],
+	[mingw*], [
+	    AS_IF([test x"$enable_shared" = xyes], [
+		LIBRUBY_SO='$(RUBY_SO_NAME)'.dll
+		LIBRUBY_DLDFLAGS="${LIBRUBY_DLDFLAGS}"' $(RUBYDEF)'
+	    ])
+	    EXPORT_PREFIX=' '
+	    DLDFLAGS="${DLDFLAGS}"' $(DEFFILE)'
+	    AC_LIBOBJ([win32/win32])
+	    AC_LIBOBJ([win32/file])
+	    COMMON_LIBS=m
+#	    COMMON_MACROS="WIN32_LEAN_AND_MEAN="
+	    COMMON_HEADERS="winsock2.h windows.h"
+	    THREAD_MODEL=win32
+	    PLATFORM_DIR=win32
+	    ])
+	LIBRUBY_ALIASES=''
+	FIRSTMAKEFILE=GNUmakefile:cygwin/GNUmakefile.in
+	AS_IF([test x"$enable_shared" = xyes], [
+	    LIBRUBY='lib$(RUBY_SO_NAME).dll.a'
+	], [
+	    LIBRUBY_SO=dummy
+	    LIBRUBY='lib$(RUBY_SO_NAME).a'
+	    LIBRUBYARG='-l$(RUBY_SO_NAME)'
+	])
+	],
+    [hpux*], [
+	AS_CASE(["$YACC"],[*yacc*], [
+	    XCFLAGS="$XCFLAGS -DYYMAXDEPTH=300"
+	    YACC="$YACC -Nl40000 -Nm40000"
+	])
+])
+
+MINIOBJS="$MINIDLNOBJ"
+
+AS_CASE(["$THREAD_MODEL"],
+[pthread], [AC_CHECK_HEADERS(pthread.h)],
+[win32],   [],
+[""],      [AC_MSG_ERROR(thread model is missing)],
+           [AC_MSG_ERROR(unknown thread model $THREAD_MODEL)])
+
+AC_ARG_ENABLE(debug-env,
+       AS_HELP_STRING([--enable-debug-env], [enable RUBY_DEBUG environment variable]),
+       [AC_SUBST(ENABLE_DEBUG_ENV, yes)])
+
+AS_CASE(["$FIRSTMAKEFILE"], [*GNUmakefile:*], [gnumake=yes], [
+    AC_MSG_CHECKING([if ${MAKE-make} is GNU make])
+    mkdir conftest.dir
+    echo "all:; @echo yes" > conftest.dir/GNUmakefile
+    echo "all:; @echo no" > conftest.dir/Makefile
+    gnumake=`(cd conftest.dir; ${MAKE-make})`
+    rm -fr conftest.dir
+    AS_CASE(["$gnumake"],
+    [*yes*], [
+	FIRSTMAKEFILE=GNUmakefile:template/GNUmakefile.in
+	gnumake=yes],
+    [
+	gnumake=no])
+    AC_MSG_RESULT($gnumake)
+])
+AS_IF([test "$gnumake" = yes], [ NULLCMD=: ], [
+    AC_MSG_CHECKING([for safe null command for ${MAKE-make}])
+    mkdir conftest.dir
+    NULLCMD=
+    for cmd in : true; do
+	echo 'A=1' > conftest.dir/Makefile
+	echo 'B=$(A:1=@'$cmd')' >> conftest.dir/Makefile
+	echo 'all:; $B 1 2 3 4 5 6 7 8 9' >> conftest.dir/Makefile
+	AS_IF([(cd conftest.dir; ${MAKE-make} >/dev/null 2>/dev/null)], [
+	    NULLCMD=$cmd
+	    break
+	])
+    done
+    rm -fr conftest.dir
+    AS_IF([test -z "$NULLCMD"], [
+	AC_MSG_ERROR(no candidate for safe null command)
+    ])
+    AC_MSG_RESULT($NULLCMD)
+])
+AC_SUBST(NULLCMD)
+
+AS_IF([test "${universal_binary-no}" = yes ], [
+    AC_CACHE_CHECK([for architecture macros], rb_cv_architecture_macros, [
+    mv confdefs.h confdefs1.h
+    : > confdefs.h
+    AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[@%:@if defined __`echo ${universal_archnames} |
+    sed 's/=[^ ]*//g;s/ /__ || defined __/g'`__
+@%:@else
+@%:@error
+>>>>>><<<<<<
+@%:@endif]], [[]])],[
+    rb_cv_architecture_macros=yes
+    mv -f confdefs1.h confdefs.h
+], [
+    rb_cv_architecture_macros=no
+    archflagpat=`eval echo '"'"${ARCH_FLAG}"'"' | sed 's/[[][|.*]]/\\&/g'`
+    new_cflags=`echo "$CFLAGS" | sed "s|$archflagpat"'||'`
+    for archs in ${universal_archnames}; do
+	cpu=${archs@%:@*=}
+	archs=${archs%=*}
+	CFLAGS="$new_cflags -arch $archs"
+	archs="__${archs}__"
+	AC_MSG_CHECKING([for macro ${archs} on ${cpu}])
+	AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[@%:@ifndef ${archs}
+@%:@error
+@%:@endif]], [[]])],
+	[AC_MSG_RESULT([yes])], [AC_MSG_RESULT([no])])
+    done
+    mv -f confdefs1.h confdefs.h
+    AC_MSG_ERROR([failed])
+    ])])
+    AC_CACHE_CHECK(whether __ARCHITECTURE__ is available, rb_cv_architecture_available,
+	AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[@%:@include <stdio.h>
+		const char arch[[]] = __ARCHITECTURE__;]], [[puts(arch);]])],
+		[rb_cv_architecture_available=yes], [rb_cv_architecture_available=no]))
+])
+
+: ${MJIT_LDSHARED=`echo "$LDSHARED" | sed ['s|\$(LD)|'"${LD}"'|g;s|\$(CC)|$(MJIT_CC)|g']`}
+
+MAINLIBS="$LIBS"
+LIBS=$ORIG_LIBS
+AS_IF([test -n "${LIBS}"], [
+    libspat=`echo "${LIBS}" | sed 's/[[][|.*$^]]/\\&/g;s/^  */ /;s/^  *$/ /'`
+    MAINFLAGS=`echo " $MAINLIBS " | sed "s|$libspat"'||;s/^ *//;s/ *$//'`
+])
+LIBRUBYARG_STATIC="${LIBRUBYARG_STATIC} \$(MAINLIBS)"
+CPPFLAGS="$CPPFLAGS "'$(DEFS)'
+test -z "$CPPFLAGS" || CPPFLAGS="$CPPFLAGS "; CPPFLAGS="$CPPFLAGS"'${cppflags}'
+AS_IF([test -n "${cflags+set}"], [
+    cflagspat=`eval echo '"'"${cflags}"'"' | sed 's/[[][|.*]]/\\&/g;s/^  */ /;s/^  *$/ /'`
+    CFLAGS=`echo " $CFLAGS " | sed "s|$cflagspat"'|${cflags}|;s/^ *//;s/ *$//'`
+])
+AS_IF([test -n "${cxxflags+set}"], [
+    cxxflagspat=`eval echo '"'"${cxxflags}"'"' | sed 's/[[][|.*]]/\\&/g;s/^  */ /;s/^  *$/ /'`
+    CXXFLAGS=`echo " $CXXFLAGS " | sed "s|$cxxflagspat"'|${cxxflags}|;s/^ *//;s/ *$//'`
+])
+AS_IF([test "${ARCH_FLAG}"], [
+    archflagpat=`eval echo '"'"${ARCH_FLAG}"'"' | sed 's/[[][|.*]]/\\&/g'`
+    CFLAGS=`echo "$CFLAGS" | sed "s| *$archflagpat"'||'`
+    CXXFLAGS=`echo "$CXXFLAGS" | sed "s| *$archflagpat"'||'`
+    LDFLAGS=`echo "$LDFLAGS" | sed "s| *$archflagpat"'||'`
+])
+rb_cv_warnflags=`echo "$rb_cv_warnflags" | sed 's/^ *//;s/ *$//'`
+warnflags="$rb_cv_warnflags"
+AC_SUBST(cppflags)dnl
+AC_SUBST(cflags, ["${orig_cflags:+$orig_cflags }"'${optflags} ${debugflags} ${warnflags}'])dnl
+AC_SUBST(cxxflags)dnl
+AC_SUBST(optflags)dnl
+AC_SUBST(debugflags)dnl
+AC_SUBST(warnflags)dnl
+AC_SUBST(strict_warnflags)dnl
+AC_SUBST(XCFLAGS)dnl
+AC_SUBST(XLDFLAGS)dnl
+AC_SUBST(EXTLDFLAGS)dnl
+AC_SUBST(EXTDLDFLAGS)dnl
+AC_SUBST(LIBRUBY_LDSHARED)
+AC_SUBST(LIBRUBY_DLDFLAGS)
+AC_SUBST(RUBY_INSTALL_NAME)
+AC_SUBST(rubyw_install_name)
+AC_SUBST(RUBYW_INSTALL_NAME)
+AC_SUBST(RUBY_SO_NAME)
+AC_SUBST(LIBRUBY_A)
+AC_SUBST(LIBRUBY_SO)
+AC_SUBST(LIBRUBY_SONAME)
+AC_SUBST(LIBRUBY_ALIASES)
+AC_SUBST(LIBRUBY)
+AC_SUBST(LIBRUBYARG)
+AC_SUBST(LIBRUBYARG_STATIC)
+AC_SUBST(LIBRUBYARG_SHARED)
+AC_SUBST(SOLIBS)
+AC_SUBST(DLDLIBS)
+AC_SUBST(DLDSHARED)
+AC_SUBST(ENABLE_SHARED)
+AC_SUBST(MAINLIBS)
+AC_SUBST(COMMON_LIBS)
+AC_SUBST(COMMON_MACROS)
+AC_SUBST(COMMON_HEADERS)
+AC_SUBST(EXPORT_PREFIX)
+AC_SUBST(SYMBOL_PREFIX)
+AC_SUBST(MINIOBJS)
+AC_SUBST(THREAD_MODEL)
+AC_SUBST(PLATFORM_DIR)
+
+firstmf=`echo $FIRSTMAKEFILE | sed 's/:.*//'`
+firsttmpl=`echo $FIRSTMAKEFILE | sed 's/.*://'`
+MAKEFILES="Makefile $firstmf"
+MAKEFILES="`echo $MAKEFILES`"
+AC_SUBST(MAKEFILES)
+
+ri_prefix=
+test "$program_prefix" != NONE &&
+  ri_prefix=$program_prefix
+
+ri_suffix=
+test "$program_suffix" != NONE &&
+  ri_suffix=$program_suffix
+
+RUBY_INSTALL_NAME="${ri_prefix}"'$(RUBY_BASE_NAME)'"${ri_suffix}"
+AS_CASE(["$target_os"],
+  [cygwin*|mingw*], [
+    RUBYW_INSTALL_NAME="${ri_prefix}"'$(RUBYW_BASE_NAME)'"${ri_suffix}"
+    rubyw_install_name='$(RUBYW_INSTALL_NAME)'
+    ])
+
+rubyarchprefix=${multiarch+'${archlibdir}/${RUBY_BASE_NAME}'}${multiarch-'${rubylibprefix}/${arch}'}
+AC_ARG_WITH(rubyarchprefix,
+	    AS_HELP_STRING([--with-rubyarchprefix=DIR],
+			   [prefix for architecture dependent ruby libraries [[RUBYLIBPREFIX/ARCH]]]),
+	    [rubyarchprefix="$withval"])
+AC_SUBST(rubyarchprefix)
+
+rubysitearchprefix=${multiarch+'${sitearchlibdir}/${RUBY_BASE_NAME}'}${multiarch-'${rubylibprefix}/${sitearch}'}
+AC_ARG_WITH(rubysitearchprefix,
+	    AS_HELP_STRING([--with-rubysitearchprefix=DIR],
+			   [prefix for architecture dependent site libraries [[RUBYLIBPREFIX/SITEARCH]]]),
+	    [rubysitearchprefix="$withval"])
+AC_SUBST(rubysitearchprefix)
+
+RI_BASE_NAME=`echo ${RUBY_BASE_NAME} | sed 's/ruby/ri/'`
+ridir='${datarootdir}/${RI_BASE_NAME}'
+AC_ARG_WITH(ridir,
+	    AS_HELP_STRING([--with-ridir=DIR], [ri documentation [[DATAROOTDIR/ri]]]),
+	    [ridir=$withval])
+AC_SUBST(ridir)
+AC_SUBST(RI_BASE_NAME)
+
+unset RUBY_LIB_VERSION
+RUBY_LIB_VERSION_STYLE='3	/* full */'
+{
+echo "#define RUBY_LIB_VERSION_STYLE $RUBY_LIB_VERSION_STYLE"
+echo '#define STRINGIZE(x) x'
+test -f revision.h -o -f "${srcdir}/revision.h" || echo '#define RUBY_REVISION 0'
+echo '#include "version.h"'
+echo 'ruby_version=RUBY_LIB_VERSION'
+} > conftest.c
+ruby_version="`$CPP -I. -I"${srcdir}" -I"${srcdir}/include" conftest.c | sed '/^ruby_version=/!d;s/ //g'`"
+eval $ruby_version
+
+RUBY_LIB_VERSION="${ruby_version}"
+
+AC_SUBST(RUBY_LIB_VERSION_STYLE)
+AC_SUBST(RUBY_LIB_VERSION)
+
+AC_ARG_WITH(ruby-version,
+	    AS_HELP_STRING([--with-ruby-version=STR], [ruby version string for version specific directories [[full]] (full|STR)]),
+            [ruby_version_dir_name=$withval],
+            [ruby_version_dir_name=full])
+AS_CASE(["$ruby_version_dir_name"],
+  [full], [ruby_version_dir_name='${ruby_version}'])
+
+ruby_version_dir=/'${ruby_version_dir_name}'
+
+if test -z "${ruby_version_dir_name}"; then
+    unset ruby_version_dir
+    AC_DEFINE(RUBY_LIB_VERSION_BLANK, 1)
+fi
+
+rubylibdir='${rubylibprefix}'${ruby_version_dir}
+rubyarchdir=${multiarch+'${rubyarchprefix}'${ruby_version_dir}}${multiarch-'${rubylibdir}/${arch}'}
+
+AC_ARG_WITH(sitedir,
+	    AS_HELP_STRING([--with-sitedir=DIR], [site libraries in DIR [[RUBY_LIB_PREFIX/site_ruby]], "no" to disable site directory]),
+            [sitedir=$withval],
+            [sitedir='${rubylibprefix}/site_ruby'])
+sitelibdir='${sitedir}'${ruby_version_dir}
+
+AC_ARG_WITH(sitearchdir,
+	    AS_HELP_STRING([--with-sitearchdir=DIR],
+			   [architecture dependent site libraries in DIR [[SITEDIR/SITEARCH]], "no" to disable site directory]),
+            [sitearchdir=$withval],
+            [sitearchdir=${multiarch+'${rubysitearchprefix}/site_ruby'${ruby_version_dir}}${multiarch-'${sitelibdir}/${sitearch}'}])
+
+AC_ARG_WITH(vendordir,
+	    AS_HELP_STRING([--with-vendordir=DIR], [vendor libraries in DIR [[RUBY_LIB_PREFIX/vendor_ruby]], "no" to disable vendor directory]),
+            [vendordir=$withval],
+            [vendordir='${rubylibprefix}/vendor_ruby'])
+vendorlibdir='${vendordir}'${ruby_version_dir}
+
+AC_ARG_WITH(vendorarchdir,
+	    AS_HELP_STRING([--with-vendorarchdir=DIR],
+			   [architecture dependent vendor libraries in DIR [[VENDORDIR/SITEARCH]], "no" to disable vendor directory]),
+            [vendorarchdir=$withval],
+            [vendorarchdir=${multiarch+'${rubysitearchprefix}/vendor_ruby'${ruby_version_dir}}${multiarch-'${vendorlibdir}/${sitearch}'}])
+
+AS_IF([test "${LOAD_RELATIVE+set}"], [
+    AC_DEFINE_UNQUOTED(LOAD_RELATIVE, $LOAD_RELATIVE)
+    RUBY_EXEC_PREFIX=''
+])
+
+AC_SUBST(RUBY_EXEC_PREFIX)
+
+AC_SUBST(libdirname, ${multiarch+arch}libdir)
+AC_SUBST(archlibdir)dnl
+AC_SUBST(sitearchlibdir)dnl
+AC_SUBST(archincludedir)dnl
+AC_SUBST(sitearchincludedir)dnl
+AC_SUBST(arch)dnl
+AC_SUBST(sitearch)dnl
+AC_SUBST(ruby_version)dnl
+AC_SUBST(ruby_version_dir_name)dnl
+AC_SUBST(rubylibdir)dnl
+AC_SUBST(rubyarchdir)dnl
+AC_SUBST(sitedir)dnl
+AC_SUBST(sitelibdir)dnl
+AC_SUBST(sitearchdir)dnl
+AC_SUBST(vendordir)dnl
+AC_SUBST(vendorlibdir)dnl
+AC_SUBST(vendorarchdir)dnl
+
+AC_SUBST(CONFIGURE, "`echo $0 | sed 's|.*/||'`")dnl
+AC_SUBST(configure_args, "`echo "${ac_configure_args}" | sed 's/\\$/$$/g'`")dnl
+
+target_cpu=`echo $target_cpu | sed s/i.86/i386/`
+
+AS_IF([test "${universal_binary-no}" = yes ], [
+    arch="universal-${target_os}"
+    AS_IF([test "${rb_cv_architecture_available}" = yes], [
+	AC_DEFINE_UNQUOTED(RUBY_PLATFORM_CPU, __ARCHITECTURE__)
+    ], [
+	for archs in ${universal_archnames}; do
+	    cpu=`echo $archs | sed 's/.*=//'`
+	    archs=`echo $archs | sed 's/=.*//'`
+	    RUBY_DEFINE_IF([defined __${archs}__ &&! defined RUBY_PLATFORM_CPU], RUBY_PLATFORM_CPU, ["${cpu}"])
+	done
+    ])
+    ints='long int short'
+    test "$ac_cv_type_long_long" = yes && ints="'long long' $ints"
+    AC_SUBST(UNIVERSAL_ARCHNAMES, "${universal_archnames}")
+    AC_SUBST(UNIVERSAL_INTS, "${ints}")
+    AC_DEFINE_UNQUOTED(RUBY_PLATFORM_OS, "${target_os}")
+    AC_DEFINE_UNQUOTED(RUBY_ARCH, "universal-" RUBY_PLATFORM_OS)
+    AC_DEFINE_UNQUOTED(RUBY_PLATFORM, "universal." RUBY_PLATFORM_CPU "-" RUBY_PLATFORM_OS)
+], [
+    arch="${target_cpu}-${target_os}"
+    AC_DEFINE_UNQUOTED(RUBY_PLATFORM, "$arch")
+])
+
+unset sitearch
+AS_CASE(["$target_os"],[mingw*],[sitearch="$target_cpu-$rb_cv_msvcrt"])
+: ${sitearch='${arch}'}
+
+AC_ARG_WITH(search-path,
+		AS_HELP_STRING([--with-search-path=DIR], [specify the additional search path]),
+		[search_path=$withval])
+AS_IF([test "$search_path" != ""], [
+    AC_SUBST(RUBY_SEARCH_PATH, $search_path)
+])
+
+AC_ARG_WITH(rubyhdrdir,
+	    AS_HELP_STRING([--with-rubyhdrdir=DIR], [core headers in DIR [[INCLUDEDIR/RUBY_BASE_NAME-RUBY_VERSION]]]),
+	    [rubyhdrdir=$withval],
+	    [rubyhdrdir='${includedir}/${RUBY_VERSION_NAME}'])
+
+AC_ARG_WITH(rubyarchhdrdir,
+	    AS_HELP_STRING([--with-rubyarchhdrdir=DIR],
+			   [architecture dependent core headers in DIR [[$(rubyhdrdir)/$(arch)]]]),
+	    [rubyarchhdrdir=$withval],
+	    [rubyarchhdrdir=${multiarch+'${archincludedir}/${RUBY_VERSION_NAME}'}${multiarch-'${rubyhdrdir}/${arch}'}])
+
+AC_ARG_WITH(sitehdrdir,
+	    AS_HELP_STRING([--with-sitehdrdir=DIR], [core site headers in DIR [[RUBYHDRDIR/site_ruby]]]),
+	    [sitehdrdir=$withval],
+	    [sitehdrdir='${rubyhdrdir}/site_ruby'])
+
+AC_ARG_WITH(sitearchhdrdir,
+	    AS_HELP_STRING([--with-sitearchhdrdir=DIR],
+			   [architecture dependent core site headers in DIR [[RUBYHDRDIR/site_ruby]]]),
+	    [sitearchhdrdir=$withval],
+	    [sitearchhdrdir=${multiarch+'${sitearchincludedir}/${RUBY_VERSION_NAME}/site_ruby'}${multiarch-'${sitehdrdir}/${sitearch}'}])
+
+AC_ARG_WITH(vendorhdrdir,
+	    AS_HELP_STRING([--with-vendorhdrdir=DIR], [core vendor headers in DIR [[RUBYHDRDIR/vendor_ruby]]]),
+	    [vendorhdrdir=$withval],
+	    [vendorhdrdir='${rubyhdrdir}/vendor_ruby'])
+
+AC_ARG_WITH(vendorarchhdrdir,
+	    AS_HELP_STRING([--with-vendorarchhdrdir=DIR],
+			   [architecture dependent core vendor headers in DIR [[RUBYHDRDIR/vendor_ruby]]]),
+	    [vendorarchhdrdir=$withval],
+	    [vendorarchhdrdir=${multiarch+'${sitearchincludedir}/${RUBY_VERSION_NAME}/vendor_ruby'}${multiarch-'${vendorhdrdir}/${sitearch}'}])
+
+AC_SUBST(rubyhdrdir)dnl
+AC_SUBST(sitehdrdir)dnl
+AC_SUBST(vendorhdrdir)dnl
+AC_SUBST(rubyarchhdrdir)dnl
+AC_SUBST(sitearchhdrdir)dnl
+AC_SUBST(vendorarchhdrdir)dnl
+
+AC_ARG_WITH(mantype,
+	AS_HELP_STRING([--with-mantype=TYPE], [specify man page type; TYPE is one of man and doc]),
+		[
+			AS_CASE(["$withval"],
+			[man|man.gz|man.bz2|doc|doc.gz|doc.bz2], [MANTYPE=$withval],
+			[AC_MSG_ERROR(invalid man type: $withval)])
+		])
+AS_IF([test -z "$MANTYPE"], [
+	dnl Looks for nroff with -mdoc support.
+	AC_CACHE_VAL([ac_cv_path_NROFF], [
+		AC_PATH_PROGS_FEATURE_CHECK([NROFF],
+			[nroff awf mandoc],
+			[$ac_path_NROFF -mdoc ${srcdir}/man/ruby.1 \
+				>/dev/null 2>&1 &&
+				ac_cv_path_NROFF=$ac_path_NROFF \
+				ac_path_NROFF_found=:],
+			[], ["/usr/bin:/usr/ucb"]
+		)
+	])
+	AS_IF([test -n "$ac_cv_path_NROFF"], [
+		MANTYPE=doc
+	], [
+		MANTYPE=man
+	])
+])
+AC_SUBST(MANTYPE)
+
+AC_ARG_ENABLE(rubygems,
+	AS_HELP_STRING([--disable-rubygems], [disable rubygems by default]),
+	[enable_rubygems="$enableval"], [enable_rubygems=yes])
+AS_IF([test x"$enable_rubygems" = xno], [
+    USE_RUBYGEMS=no
+], [
+    USE_RUBYGEMS=yes
+])
+AC_SUBST(USE_RUBYGEMS)
+
+arch_hdrdir="${EXTOUT}/include/${arch}/ruby"
+AS_MKDIR_P("${arch_hdrdir}")
+config_h="${arch_hdrdir}/config.h"
+guard=INCLUDE_RUBY_CONFIG_H
+{
+  echo "#ifndef $guard"
+  echo "#define $guard 1"
+  grep -v "^#define PACKAGE_" confdefs.h
+  echo "#endif /* $guard */"
+} | tr -d '\015' |
+(
+  AS_IF([test "x$CONFIGURE_TTY" = xyes], [color=--color], [color=])
+  exec ${tooldir}/ifchange $color "${config_h}" -
+) >&AS_MESSAGE_FD || AC_MSG_ERROR([failed to create ${config_h}])
+tr -d '\015' < largefile.h > confdefs.h
+rm largefile.h
+
+BUILTIN_ENCS=["`sed -n -e '/^BUILTIN_ENCS[ 	]*=/{' \
+	-e s/// -e :l -e '/\\\\$/N' -e 's/\\\\\\n/ /' -e 't l' -e p \
+	-e '}' "${srcdir}/enc/Makefile.in"`"]
+BUILTIN_ENCOBJS=
+for e in $BUILTIN_ENCS; do BUILTIN_ENCOBJS="$BUILTIN_ENCOBJS "`echo $e | sed 's/\.c$/.$(OBJEXT)/'`; done
+AC_SUBST(BUILTIN_ENCOBJS)
+
+BUILTIN_TRANSES=["`sed -n -e '/^BUILTIN_TRANSES[ 	]*=/{' \
+	-e s/// -e :l -e '/\\\\$/N' -e 's/\\\\\\n/ /' -e 't l' -e p \
+	-e '}' "${srcdir}/enc/Makefile.in"`"]
+BUILTIN_TRANSSRCS=
+BUILTIN_TRANSOBJS=
+for e in $BUILTIN_TRANSES; do
+  BUILTIN_TRANSSRCS="$BUILTIN_TRANSSRCS "`echo $e | sed 's/\.trans$/.c/'`
+  BUILTIN_TRANSOBJS="$BUILTIN_TRANSOBJS "`echo $e | sed 's/\.trans$/.$(OBJEXT)/'`
+done
+AC_SUBST(BUILTIN_TRANSSRCS)
+AC_SUBST(BUILTIN_TRANSOBJS)
+
+PACKAGE=$RUBY_BASE_NAME
+AC_SUBST(PACKAGE)
+AS_MESSAGE([$PACKAGE library version = $ruby_version])
+
+AS_IF([test x"$CC_WRAPPER" != x], [
+    CC='$(CC_WRAPPER) '"${CC@%:@$CC_WRAPPER }"
+    CPP='$(CC_WRAPPER) '"${CPP@%:@$CC_WRAPPER }"
+    CC_WRAPPER='$(rubyarchdir)/darwin-cc'
+    XCC_WRAPPER='$(top_srcdir)/tool/darwin-cc'
+])
+AC_SUBST(CC_WRAPPER, '')
+AC_SUBST(XCC_WRAPPER)
+
+AS_CASE([" $CPP "], [*" $CC "*], [CPP=`echo " $CPP " | sed "s| $CC |"' $(CC) |;s/^ *//;s/  *$//'`])
+
+AS_IF([test x"$firstmf" != x], [
+    AC_CONFIG_FILES($firstmf:$firsttmpl, [], [firstmf="$firstmf" firsttmpl="$firsttmpl"])
+])
+AC_CONFIG_FILES(Makefile:template/Makefile.in, [
+    tmpmk=confmk$$.tmp
+    {
+	AS_IF([test ${VCS+set}], [
+	    :
+	], [git_dir=`$GIT --work-tree="$srcdir" --git-dir="$srcdir/.git" rev-parse --git-dir 2>/dev/null`], [
+	    VCS='$(GIT)'
+	], [
+	    VCS='echo cannot'
+	])
+	AS_CASE("$VCS",
+		['$(GIT)'|git], [VCSUP='$(VCS) pull --rebase $(GITPULLOPTIONS)'],
+		[VCSUP='$(VCS)'])
+	sed -n \
+	    -e '[/^@%:@define \(RUBY_RELEASE_[A-Z]*\) \([0-9][0-9]*\)/]{' \
+	    -e   's//\1 = \2/' \
+	    -e   '[s/ \([0-9]\)$/ 0\1/]' \
+	    -e   p \
+	    -e '}' "$srcdir/version.h"
+	sed '/^MISSING/s/\$U\././g;/^VCS *=/s#@VCS@#'"$VCS"'#;/^VCSUP *=/s#@VCSUP@#'"$VCSUP"'#' Makefile
+	echo; test x"$EXEEXT" = x || echo 'miniruby: miniruby$(EXEEXT)'
+	AS_IF([test "$gnumake" != yes], [
+	    echo ['$(MKFILES): $(srcdir)/common.mk']
+	    sed ['s/{\$([^(){}]*)[^{}]*}//g'] ${srcdir}/common.mk
+	], [
+	    echo 'distclean-local::; @$(RM) GNUmakefile uncommon.mk'
+	])
+    } > $tmpmk && AS_IF([! grep '^ruby:' $tmpmk > /dev/null], [
+	AS_IF([test "${gnumake}" = yes], [
+	    tmpgmk=confgmk$$.tmp
+	    {
+		echo "include $tmpmk"
+		echo "-include uncommon.mk"
+	    } > $tmpgmk
+	], [
+	    tmpgmk=$tmpmk
+	]) &&
+	test -z "`${MAKE-make} -f $tmpgmk info-program | grep '^PROGRAM=ruby$'`" &&
+	echo 'ruby: $(PROGRAM);' >> $tmpmk
+	test "$tmpmk" = "$tmpgmk" || rm -f "$tmpgmk"
+    ]) && mv -f $tmpmk Makefile],
+[EXEEXT='$EXEEXT' MAKE='${MAKE-make}' gnumake='$gnumake' GIT='$GIT'])
+
+AC_ARG_WITH([ruby-pc],
+	    AS_HELP_STRING([--with-ruby-pc=FILENAME], [pc file basename]),
+	    [ruby_pc="$withval"],
+	    [ruby_pc="${RUBY_BASE_NAME}-${MAJOR}.${MINOR}.pc"])
+AC_SUBST(ruby_pc)
+AC_SUBST(exec, [exec])
+
+AC_ARG_WITH(destdir,
+	    AS_HELP_STRING([--with-destdir=DESTDIR], [specify default directory to install]),
+	    [DESTDIR="$withval"])
+AC_SUBST(DESTDIR)
+
+AC_CONFIG_FILES($ruby_pc:template/ruby.pc.in,
+    [
+    AS_IF([sed ['s/\$(\([A-Za-z_][A-Za-z0-9_]*\))/${\1}/g;s/@[A-Za-z_][A-Za-z0-9_]*@//'] $ruby_pc > ruby.tmp.pc &&
+	{
+	    test -z "$PKG_CONFIG" ||
+	    PKG_CONFIG_PATH=. $PKG_CONFIG --print-errors ruby.tmp
+	}],
+    [
+	mv -f ruby.tmp.pc $ruby_pc
+    ], [
+	exit 1
+    ])
+    ],
+    [ruby_pc='$ruby_pc' PKG_CONFIG='$PKG_CONFIG'])
+
+AC_OUTPUT
+}
+}
+
+AS_IF([test "$silent" = yes], [], [
+AS_IF([${FOLD+:} false], [], [
+AS_IF([test "`echo abcdefg hijklmno | fold -s -w10 | sed 1d`" = hijklmno], [FOLD="fold"], [FOLD=])
+])
+fold_width=`expr $COLUMNS - 30 2>/dev/null` || fold_width=50
+AS_REQUIRE_SHELL_FN([config_summary],
+    [AS_FUNCTION_DESCRIBE([config_summary], [NAME, VAL], [configuration summary])],
+    [AS_IF([test -z "$2"], [], [
+	AS_ECHO_N(["   * $1:                     "]) | dd bs=1 count=26 2>/dev/null
+	AS_IF([test "$FOLD"], [
+	    echo "$2" | fold -s -w$fold_width |
+	    sed '1!s/^/                          /;$!s/$/\\/'
+	], [echo "$2"])
+    ])]
+)
+
+AS_IF([test $install_doc = yes],
+    [DOCTARGETS=`echo " $RDOCTARGET $CAPITARGET " | sed 's/ nodoc //g;s/^ *//;s/ *$//'`],
+    [DOCTARGETS=no])
+echo "---"
+echo "Configuration summary for $RUBY_BASE_NAME version $MAJOR.$MINOR.$TEENY"
+echo ""
+config_summary "Installation prefix" "$prefix"
+config_summary "exec prefix"         "$exec_prefix"
+config_summary "arch"                "$arch"
+config_summary "site arch"           "$sitearch"
+config_summary "RUBY_BASE_NAME"      "$RUBY_BASE_NAME"
+config_summary "enable shared"       "$enable_shared"
+config_summary "ruby lib prefix"     "$rubylibprefix"
+config_summary "site libraries path" "$rubysitearchprefix"
+config_summary "vendor path"         "$vendordir"
+config_summary "target OS"           "$target_os"
+config_summary "compiler"            "$CC"
+config_summary "with pthread"        "$enable_pthread"
+config_summary "with coroutine"      "$rb_cv_coroutine"
+config_summary "enable shared libs"  "$ENABLE_SHARED"
+config_summary "dynamic library ext" "$DLEXT"
+config_summary "CFLAGS"              "$cflags"
+config_summary "CPPFLAGS"            "$cppflags"
+config_summary "LDFLAGS"             "$LDFLAGS"
+config_summary "DLDFLAGS"            "$DLDFLAGS"
+config_summary "optflags"            "$optflags"
+config_summary "debugflags"          "$debugflags"
+config_summary "warnflags"           "$warnflags"
+config_summary "strip command"       "$STRIP"
+config_summary "install doc"         "$DOCTARGETS"
+config_summary "JIT support"         "$MJIT_SUPPORT"
+config_summary "man page type"       "$MANTYPE"
+config_summary "search path"         "$search_path"
+config_summary "static-linked-ext"   ${EXTSTATIC:+"yes"}
+config_summary "BASERUBY -v"         "$BASERUBY_VERSION"
+echo ""
+echo "---"
+])
diff -Nuarp ruby-3.0.5.a/gc.c ruby-3.0.5.b/gc.c
--- ruby-3.0.5.a/gc.c	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/gc.c	2023-02-02 23:12:42.033521541 -0500
@@ -32,6 +32,7 @@
 #include <stdarg.h>
 #include <stdio.h>
 
+/* MALLOC_HEADERS_BEGIN */
 #ifndef HAVE_MALLOC_USABLE_SIZE
 # ifdef _WIN32
 #  define HAVE_MALLOC_USABLE_SIZE
@@ -54,6 +55,12 @@
 # endif
 #endif
 
+#if !defined(PAGE_SIZE) && defined(HAVE_SYS_USER_H)
+/* LIST_HEAD conflicts with sys/queue.h on macOS */
+# include <sys/user.h>
+#endif
+/* MALLOC_HEADERS_END */
+
 #ifdef HAVE_SYS_TIME_H
 # include <sys/time.h>
 #endif
@@ -286,6 +293,9 @@ rb_gc_guarded_ptr_val(volatile VALUE *pt
 #ifndef GC_MALLOC_LIMIT_GROWTH_FACTOR
 #define GC_MALLOC_LIMIT_GROWTH_FACTOR 1.4
 #endif
+#ifndef GC_MALLOC_TRIM_FREQUENCY
+#define GC_MALLOC_TRIM_FREQUENCY 0
+#endif
 
 #ifndef GC_OLDMALLOC_LIMIT_MIN
 #define GC_OLDMALLOC_LIMIT_MIN (16 * 1024 * 1024 /* 16MB */)
@@ -324,6 +334,7 @@ typedef struct {
     size_t malloc_limit_min;
     size_t malloc_limit_max;
     double malloc_limit_growth_factor;
+    size_t malloc_trim_frequency;
 
     size_t oldmalloc_limit_min;
     size_t oldmalloc_limit_max;
@@ -346,6 +357,7 @@ static ruby_gc_params_t gc_params = {
     GC_MALLOC_LIMIT_MIN,
     GC_MALLOC_LIMIT_MAX,
     GC_MALLOC_LIMIT_GROWTH_FACTOR,
+    GC_MALLOC_TRIM_FREQUENCY,
 
     GC_OLDMALLOC_LIMIT_MIN,
     GC_OLDMALLOC_LIMIT_MAX,
@@ -686,6 +698,8 @@ typedef struct rb_objspace {
 #if GC_ENABLE_INCREMENTAL_MARK
 	unsigned int during_incremental_marking : 1;
 #endif
+        int collect_gc_stats;
+        int verbose_gc_stats;
     } flags;
 
     rb_event_flag_t hook_events;
@@ -754,14 +768,21 @@ typedef struct rb_objspace {
 
 	/* temporary profiling space */
 	double gc_sweep_start_time;
+        double gc_mark_start_time;
+
 	size_t total_allocated_objects_at_gc_start;
 	size_t heap_used_at_gc_start;
 
 	/* basic statistics */
 	size_t count;
+        double time;
 	size_t total_freed_objects;
 	size_t total_allocated_pages;
 	size_t total_freed_pages;
+        size_t total_mallocs;
+        size_t total_malloced_bytes;
+        size_t live_after_last_sweep;
+
     } profile;
     struct gc_list *global_list;
 
@@ -821,6 +842,25 @@ enum {
     HEAP_PAGE_BITMAP_SIZE = (BITS_SIZE * HEAP_PAGE_BITMAP_LIMIT),
     HEAP_PAGE_BITMAP_PLANES = 4 /* RGENGC: mark, unprotected, uncollectible, marking */
 };
+#define HEAP_PAGE_ALIGN (1 << HEAP_PAGE_ALIGN_LOG)
+#define HEAP_PAGE_SIZE HEAP_PAGE_ALIGN
+
+#ifdef HAVE_MMAP
+# if HAVE_CONST_PAGE_SIZE
+/* If we have the HEAP_PAGE and it is a constant, then we can directly use it. */
+static const bool USE_MMAP_ALIGNED_ALLOC = (PAGE_SIZE <= HEAP_PAGE_SIZE);
+# elif defined(PAGE_MAX_SIZE) && (PAGE_MAX_SIZE <= HEAP_PAGE_SIZE)
+/* PAGE_SIZE <= HEAP_PAGE_SIZE */
+static const bool USE_MMAP_ALIGNED_ALLOC = true;
+# else
+/* Otherwise, fall back to determining if we can use mmap during runtime. */
+#  define USE_MMAP_ALIGNED_ALLOC (use_mmap_aligned_alloc != false)
+
+static bool use_mmap_aligned_alloc;
+# endif
+#elif !defined(__MINGW32__) && !defined(_WIN32)
+static const bool USE_MMAP_ALIGNED_ALLOC = false;
+#endif
 
 struct heap_page {
     short total_slots;
@@ -893,6 +933,7 @@ VALUE *ruby_initial_gc_stress_ptr = &rub
 #define heap_eden               (&objspace->eden_heap)
 #define heap_tomb               (&objspace->tomb_heap)
 #define during_gc		objspace->flags.during_gc
+#define collect_gc_stats        objspace->flags.collect_gc_stats
 #define finalizing		objspace->atomic_flags.finalizing
 #define finalizer_table 	objspace->finalizer_table
 #define global_list		objspace->global_list
@@ -1760,14 +1801,14 @@ heap_unlink_page(rb_objspace_t *objspace
     heap->total_slots -= page->total_slots;
 }
 
-static void rb_aligned_free(void *ptr);
+static void rb_aligned_free(void *ptr, size_t size);
 
 static void
 heap_page_free(rb_objspace_t *objspace, struct heap_page *page)
 {
     heap_allocated_pages--;
     objspace->profile.total_freed_pages++;
-    rb_aligned_free(GET_PAGE_BODY(page->start));
+    rb_aligned_free(GET_PAGE_BODY(page->start), HEAP_PAGE_SIZE);
     free(page);
 }
 
@@ -1819,7 +1860,7 @@ heap_page_allocate(rb_objspace_t *objspa
     /* assign heap_page entry */
     page = calloc1(sizeof(struct heap_page));
     if (page == 0) {
-        rb_aligned_free(page_body);
+        rb_aligned_free(page_body, HEAP_PAGE_SIZE);
 	rb_memerror();
     }
 
@@ -3159,15 +3200,18 @@ Init_heap(void)
 {
     rb_objspace_t *objspace = &rb_objspace;
 
-#if defined(HAVE_SYSCONF) && defined(_SC_PAGE_SIZE)
-    /* If Ruby's heap pages are not a multiple of the system page size, we
-     * cannot use mprotect for the read barrier, so we must disable automatic
-     * compaction. */
-    int pagesize;
-    pagesize = (int)sysconf(_SC_PAGE_SIZE);
-    if ((HEAP_PAGE_SIZE % pagesize) != 0) {
-        ruby_enable_autocompact = 0;
-    }
+#if defined(HAVE_MMAP) && !HAVE_CONST_PAGE_SIZE && !defined(PAGE_MAX_SIZE)
+    /* Need to determine if we can use mmap at runtime. */
+# ifdef PAGE_SIZE
+    /* If the PAGE_SIZE macro can be used. */
+    use_mmap_aligned_alloc = PAGE_SIZE <= HEAP_PAGE_SIZE;
+# elif defined(HAVE_SYSCONF) && defined(_SC_PAGE_SIZE)
+    /* If we can use sysconf to determine the page size. */
+    use_mmap_aligned_alloc = sysconf(_SC_PAGE_SIZE) <= HEAP_PAGE_SIZE;
+# else
+    /* Otherwise we can't determine the system page size, so don't use mmap. */
+    use_mmap_aligned_alloc = FALSE;
+# endif
 #endif
 
     objspace->next_object_id = INT2FIX(OBJ_ID_INITIAL);
@@ -7831,6 +7875,107 @@ rb_gc_writebarrier_remember(VALUE obj)
 
 static st_table *rgengc_unprotect_logging_table;
 
+VALUE
+rb_gc_enable_stats()
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    int old = collect_gc_stats;
+    collect_gc_stats = 1;
+    return old ? Qtrue : Qfalse;
+}
+
+static VALUE
+gc_enable_stats(rb_execution_context_t *ec, VALUE _)
+{
+    return rb_gc_enable_stats();
+}
+
+VALUE
+rb_gc_disable_stats()
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    int old = collect_gc_stats;
+    collect_gc_stats = 0;
+    return old ? Qtrue : Qfalse;
+}
+
+static VALUE
+gc_disable_stats(rb_execution_context_t *ec, VALUE _)
+{
+    return rb_gc_disable_stats();
+}
+
+
+VALUE
+rb_gc_stats_enabled()
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return collect_gc_stats ? Qtrue : Qfalse;
+}
+
+static VALUE
+gc_stats_enabled(rb_execution_context_t *ec, VALUE _)
+{
+    return rb_gc_stats_enabled();
+}
+
+double rb_gc_total_time()
+{
+    return rb_objspace.profile.time;
+}
+
+static VALUE
+gc_time(rb_execution_context_t *ec, VALUE _)
+{
+    return DBL2NUM(1000000*rb_objspace.profile.time);
+}
+
+VALUE
+rb_gc_heap_slots()
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return SIZET2NUM(heap_allocated_pages * HEAP_PAGE_OBJ_LIMIT);
+}
+
+static
+VALUE gc_heap_slots(rb_execution_context_t *ec, VALUE _)
+{
+    return rb_gc_heap_slots();
+}
+
+VALUE
+rb_gc_heap_slots_live_after_last_gc()
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return SIZET2NUM(objspace->profile.live_after_last_sweep);
+}
+
+static
+VALUE gc_heap_slots_live_after_last_gc(rb_execution_context_t *ec, VALUE _)
+{
+    return rb_gc_heap_slots_live_after_last_gc();
+}
+
+size_t rb_gc_total_mallocs() {
+    return rb_objspace.profile.total_mallocs;
+}
+
+static VALUE
+gc_total_mallocs(rb_execution_context_t *ec, VALUE _)
+{
+    return SIZET2NUM(rb_objspace.profile.total_mallocs);
+}
+
+size_t rb_gc_total_malloced_bytes(void) {
+    return rb_objspace.profile.total_malloced_bytes;
+}
+
+static VALUE
+gc_total_malloced_bytes(rb_execution_context_t *ec, VALUE _)
+{
+    return SIZET2NUM(rb_objspace.profile.total_malloced_bytes);
+}
+
 static int
 rgengc_unprotect_logging_exit_func_i(st_data_t key, st_data_t val, st_data_t arg)
 {
@@ -8310,6 +8455,20 @@ gc_start(rb_objspace_t *objspace, int re
     gc_prof_timer_start(objspace);
     {
 	gc_marks(objspace, do_full_mark);
+#ifdef HAVE_MALLOC_TRIM
+        /* [Experimental] Explicitly free all eligible pages to the kernel.  See:
+         *
+         * - https://www.joyfulbikeshedding.com/blog/2019-03-14-what-causes-ruby-memory-bloat.html
+         * - https://bugs.ruby-lang.org/issues/15667
+         */
+#if USE_RGENGC
+        size_t gc_count = rb_objspace.profile.major_gc_count;
+#else
+        size_t gc_count = rb_objspace.profile.count;
+#endif
+        if (do_full_mark && gc_params.malloc_trim_frequency && gc_count % gc_params.malloc_trim_frequency == 0)
+            malloc_trim(0);
+#endif
     }
     gc_prof_timer_stop(objspace);
 
@@ -8533,6 +8692,14 @@ gc_start_internal(rb_execution_context_t
 
     /* For now, compact implies full mark / sweep, so ignore other flags */
     if (RTEST(compact)) {
+        /* If not MinGW, Windows, or does not have mmap, we cannot use mprotect for
+         * the read barrier, so we must disable compaction. */
+#if !defined(__MINGW32__) && !defined(_WIN32)
+        if (!USE_MMAP_ALIGNED_ALLOC) {
+            rb_raise(rb_eNotImpError, "Compaction isn't available on this platform");
+        }
+#endif
+
         reason |= GPR_FLAG_COMPACT;
     } else {
         if (!RTEST(full_mark))       reason &= ~GPR_FLAG_FULL_MARK;
@@ -9944,16 +10111,14 @@ gc_disable(rb_execution_context_t *ec, V
 static VALUE
 gc_set_auto_compact(rb_execution_context_t *ec, VALUE _, VALUE v)
 {
-#if defined(HAVE_SYSCONF) && defined(_SC_PAGE_SIZE)
-    /* If Ruby's heap pages are not a multiple of the system page size, we
-     * cannot use mprotect for the read barrier, so we must disable automatic
-     * compaction. */
-    int pagesize;
-    pagesize = (int)sysconf(_SC_PAGE_SIZE);
-    if ((HEAP_PAGE_SIZE % pagesize) != 0) {
+    /* If not MinGW, Windows, or does not have mmap, we cannot use mprotect for
+     * the read barrier, so we must disable automatic compaction. */
+#if !defined(__MINGW32__) && !defined(_WIN32)
+    if (!USE_MMAP_ALIGNED_ALLOC) {
         rb_raise(rb_eNotImpError, "Automatic compaction isn't available on this platform");
     }
 #endif
+
     ruby_enable_autocompact = RTEST(v);
     return v;
 }
@@ -10156,6 +10321,7 @@ ruby_gc_set_params(void)
     get_envparam_size  ("RUBY_GC_OLDMALLOC_LIMIT_MAX", &gc_params.oldmalloc_limit_max, 0);
     get_envparam_double("RUBY_GC_OLDMALLOC_LIMIT_GROWTH_FACTOR", &gc_params.oldmalloc_limit_growth_factor, 1.0, 0.0, FALSE);
 #endif
+    get_envparam_size  ("RUBY_GC_MALLOC_TRIM_FREQUENCY", &gc_params.malloc_trim_frequency, 0);
 }
 
 static void
@@ -10350,22 +10516,54 @@ rb_aligned_malloc(size_t alignment, size
 #elif defined _WIN32
     void *_aligned_malloc(size_t, size_t);
     res = _aligned_malloc(size, alignment);
-#elif defined(HAVE_POSIX_MEMALIGN)
-    if (posix_memalign(&res, alignment, size) == 0) {
-        return res;
+#else
+    if (USE_MMAP_ALIGNED_ALLOC) {
+        GC_ASSERT(alignment % sysconf(_SC_PAGE_SIZE) == 0);
+
+        char *ptr = mmap(NULL, alignment + size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
+        if (ptr == MAP_FAILED) {
+            return NULL;
+        }
+
+        char *aligned = ptr + alignment;
+        aligned -= ((VALUE)aligned & (alignment - 1));
+        GC_ASSERT(aligned > ptr);
+        GC_ASSERT(aligned <= ptr + alignment);
+
+        size_t start_out_of_range_size = aligned - ptr;
+        GC_ASSERT(start_out_of_range_size % sysconf(_SC_PAGE_SIZE) == 0);
+        if (start_out_of_range_size > 0) {
+            if (munmap(ptr, start_out_of_range_size)) {
+                rb_bug("rb_aligned_malloc: munmap failed for start");
+            }
+        }
+
+        size_t end_out_of_range_size = alignment - start_out_of_range_size;
+        GC_ASSERT(end_out_of_range_size % sysconf(_SC_PAGE_SIZE) == 0);
+        if (end_out_of_range_size > 0) {
+            if (munmap(aligned + size, end_out_of_range_size)) {
+                rb_bug("rb_aligned_malloc: munmap failed for end");
+            }
+        }
+
+        res = (void *)aligned;
     }
     else {
-        return NULL;
+# if defined(HAVE_POSIX_MEMALIGN)
+        if (posix_memalign(&res, alignment, size) != 0) {
+            return NULL;
+        }
+# elif defined(HAVE_MEMALIGN)
+        res = memalign(alignment, size);
+# else
+        char* aligned;
+        res = malloc(alignment + size + sizeof(void*));
+        aligned = (char*)res + alignment + sizeof(void*);
+        aligned -= ((VALUE)aligned & (alignment - 1));
+        ((void**)aligned)[-1] = res;
+        res = (void*)aligned;
+# endif
     }
-#elif defined(HAVE_MEMALIGN)
-    res = memalign(alignment, size);
-#else
-    char* aligned;
-    res = malloc(alignment + size + sizeof(void*));
-    aligned = (char*)res + alignment + sizeof(void*);
-    aligned -= ((VALUE)aligned & (alignment - 1));
-    ((void**)aligned)[-1] = res;
-    res = (void*)aligned;
 #endif
 
     /* alignment must be a power of 2 */
@@ -10375,16 +10573,26 @@ rb_aligned_malloc(size_t alignment, size
 }
 
 static void
-rb_aligned_free(void *ptr)
+rb_aligned_free(void *ptr, size_t size)
 {
 #if defined __MINGW32__
     __mingw_aligned_free(ptr);
 #elif defined _WIN32
     _aligned_free(ptr);
-#elif defined(HAVE_MEMALIGN) || defined(HAVE_POSIX_MEMALIGN)
-    free(ptr);
 #else
-    free(((void**)ptr)[-1]);
+    if (USE_MMAP_ALIGNED_ALLOC) {
+        GC_ASSERT(size % sysconf(_SC_PAGE_SIZE) == 0);
+        if (munmap(ptr, size)) {
+            rb_bug("rb_aligned_free: munmap failed");
+        }
+    }
+    else {
+# if defined(HAVE_POSIX_MEMALIGN) || defined(HAVE_MEMALIGN)
+        free(ptr);
+# else
+        free(((void**)ptr)[-1]);
+# endif
+    }
 #endif
 }
 
@@ -10435,6 +10643,10 @@ objspace_malloc_increase(rb_objspace_t *
 {
     if (new_size > old_size) {
 	ATOMIC_SIZE_ADD(malloc_increase, new_size - old_size);
+        if (collect_gc_stats) {
+            ATOMIC_SIZE_ADD(objspace->profile.total_mallocs, 1);
+            ATOMIC_SIZE_ADD(objspace->profile.total_malloced_bytes, new_size - old_size);
+        }
 #if RGENGC_ESTIMATE_OLDMALLOC
 	ATOMIC_SIZE_ADD(objspace->rgengc.oldmalloc_increase, new_size - old_size);
 #endif
@@ -11042,6 +11254,12 @@ gc_malloc_allocated_size(VALUE self)
     return UINT2NUM(rb_objspace.malloc_params.allocated_size);
 }
 
+size_t
+rb_gc_malloc_allocated_size(void)
+{
+    return rb_objspace.malloc_params.allocated_size;
+}
+
 /*
  *  call-seq:
  *     GC.malloc_allocations -> Integer
@@ -11056,6 +11274,12 @@ gc_malloc_allocations(VALUE self)
 {
     return UINT2NUM(rb_objspace.malloc_params.allocations);
 }
+
+size_t
+rb_gc_malloc_allocations(void)
+{
+    return rb_objspace.malloc_params.allocations;
+}
 #endif
 
 void
@@ -11673,6 +11897,14 @@ gc_prof_mark_timer_start(rb_objspace_t *
 #if GC_PROFILE_MORE_DETAIL
     if (gc_prof_enabled(objspace)) {
 	gc_prof_record(objspace)->gc_mark_time = getrusage_time();
+    } else {
+        if (collect_gc_stats) {
+          objspace->profile.gc_mark_start_time = getrusage_time();
+        }
+    }
+#else
+    if (collect_gc_stats) {
+        objspace->profile.gc_mark_start_time = getrusage_time();
     }
 #endif
 }
@@ -11685,6 +11917,17 @@ gc_prof_mark_timer_stop(rb_objspace_t *o
     if (gc_prof_enabled(objspace)) {
         gc_profile_record *record = gc_prof_record(objspace);
 	record->gc_mark_time = elapsed_time_from(record->gc_mark_time);
+        if (collect_gc_stats) {
+            objspace->profile.time += record->gc_mark_time;
+        }
+    } else {
+        if (collect_gc_stats) {
+            objspace->profile.time += elapsed_time_from(objspace->profile.gc_mark_start_time);
+        }
+    }
+#else
+    if (collect_gc_stats) {
+        objspace->profile.time += elapsed_time_from(objspace->profile.gc_mark_start_time);
     }
 #endif
 }
@@ -11696,9 +11939,13 @@ gc_prof_sweep_timer_start(rb_objspace_t
     if (gc_prof_enabled(objspace)) {
 	gc_profile_record *record = gc_prof_record(objspace);
 
-	if (record->gc_time > 0 || GC_PROFILE_MORE_DETAIL) {
+	if (record->gc_time > 0 || GC_PROFILE_MORE_DETAIL || collect_gc_stats) {
 	    objspace->profile.gc_sweep_start_time = getrusage_time();
-	}
+        }
+    } else {
+        if (collect_gc_stats) {
+            objspace->profile.gc_sweep_start_time = getrusage_time();
+        }
     }
 }
 
@@ -11715,16 +11962,30 @@ gc_prof_sweep_timer_stop(rb_objspace_t *
 	    sweep_time = elapsed_time_from(objspace->profile.gc_sweep_start_time);
 	    /* need to accumulate GC time for lazy sweep after gc() */
 	    record->gc_time += sweep_time;
+            if (collect_gc_stats) {
+                objspace->profile.time += sweep_time;
+            }
 	}
 	else if (GC_PROFILE_MORE_DETAIL) {
 	    sweep_time = elapsed_time_from(objspace->profile.gc_sweep_start_time);
-	}
+            if (collect_gc_stats) {
+                objspace->profile.time += sweep_time;
+            }
+	} else {
+            if (collect_gc_stats) {
+                objspace->profile.time += elapsed_time_from(objspace->profile.gc_sweep_start_time);
+            }
+        }
 
 #if GC_PROFILE_MORE_DETAIL
 	record->gc_sweep_time += sweep_time;
 	if (heap_pages_deferred_final) record->flags |= GPR_FLAG_HAVE_FINALIZE;
 #endif
 	if (heap_pages_deferred_final) objspace->profile.latest_gc_info |= GPR_FLAG_HAVE_FINALIZE;
+    } else {
+        if (collect_gc_stats) {
+            objspace->profile.time += elapsed_time_from(objspace->profile.gc_sweep_start_time);
+        }
     }
 }
 
@@ -11743,9 +12004,13 @@ gc_prof_set_malloc_info(rb_objspace_t *o
 static inline void
 gc_prof_set_heap_info(rb_objspace_t *objspace)
 {
+    if (objspace->profile.total_allocated_objects_at_gc_start > objspace->profile.total_freed_objects)
+        objspace->profile.live_after_last_sweep =
+            objspace->profile.total_allocated_objects_at_gc_start - objspace->profile.total_freed_objects;
+
     if (gc_prof_enabled(objspace)) {
 	gc_profile_record *record = gc_prof_record(objspace);
-	size_t live = objspace->profile.total_allocated_objects_at_gc_start - objspace->profile.total_freed_objects;
+        size_t live = objspace->profile.live_after_last_sweep;
 	size_t total = objspace->profile.heap_used_at_gc_start * HEAP_PAGE_OBJ_LIMIT;
 
 #if GC_PROFILE_MORE_DETAIL
diff -Nuarp ruby-3.0.5.a/gc.c.orig ruby-3.0.5.b/gc.c.orig
--- ruby-3.0.5.a/gc.c.orig	1969-12-31 19:00:00.000000000 -0500
+++ ruby-3.0.5.b/gc.c.orig	2023-02-02 23:12:34.596462504 -0500
@@ -0,0 +1,13087 @@
+/**********************************************************************
+
+  gc.c -
+
+  $Author$
+  created at: Tue Oct  5 09:44:46 JST 1993
+
+  Copyright (C) 1993-2007 Yukihiro Matsumoto
+  Copyright (C) 2000  Network Applied Communication Laboratory, Inc.
+  Copyright (C) 2000  Information-technology Promotion Agency, Japan
+
+**********************************************************************/
+
+#define rb_data_object_alloc rb_data_object_alloc
+#define rb_data_typed_object_alloc rb_data_typed_object_alloc
+
+#include "ruby/internal/config.h"
+#ifdef _WIN32
+# include "ruby/ruby.h"
+#endif
+
+#include <signal.h>
+
+#define sighandler_t ruby_sighandler_t
+
+#ifndef _WIN32
+#include <unistd.h>
+#include <sys/mman.h>
+#endif
+
+#include <setjmp.h>
+#include <stdarg.h>
+#include <stdio.h>
+
+/* MALLOC_HEADERS_BEGIN */
+#ifndef HAVE_MALLOC_USABLE_SIZE
+# ifdef _WIN32
+#  define HAVE_MALLOC_USABLE_SIZE
+#  define malloc_usable_size(a) _msize(a)
+# elif defined HAVE_MALLOC_SIZE
+#  define HAVE_MALLOC_USABLE_SIZE
+#  define malloc_usable_size(a) malloc_size(a)
+# endif
+#endif
+
+#ifdef HAVE_MALLOC_USABLE_SIZE
+# ifdef RUBY_ALTERNATIVE_MALLOC_HEADER
+#  include RUBY_ALTERNATIVE_MALLOC_HEADER
+# elif HAVE_MALLOC_H
+#  include <malloc.h>
+# elif defined(HAVE_MALLOC_NP_H)
+#  include <malloc_np.h>
+# elif defined(HAVE_MALLOC_MALLOC_H)
+#  include <malloc/malloc.h>
+# endif
+#endif
+
+#if !defined(PAGE_SIZE) && defined(HAVE_SYS_USER_H)
+/* LIST_HEAD conflicts with sys/queue.h on macOS */
+# include <sys/user.h>
+#endif
+/* MALLOC_HEADERS_END */
+
+#ifdef HAVE_SYS_TIME_H
+# include <sys/time.h>
+#endif
+
+#ifdef HAVE_SYS_RESOURCE_H
+# include <sys/resource.h>
+#endif
+
+#if defined _WIN32 || defined __CYGWIN__
+# include <windows.h>
+#elif defined(HAVE_POSIX_MEMALIGN)
+#elif defined(HAVE_MEMALIGN)
+# include <malloc.h>
+#endif
+
+#include <sys/types.h>
+
+#include "constant.h"
+#include "debug_counter.h"
+#include "eval_intern.h"
+#include "gc.h"
+#include "id_table.h"
+#include "internal.h"
+#include "internal/class.h"
+#include "internal/complex.h"
+#include "internal/cont.h"
+#include "internal/error.h"
+#include "internal/eval.h"
+#include "internal/gc.h"
+#include "internal/hash.h"
+#include "internal/imemo.h"
+#include "internal/io.h"
+#include "internal/numeric.h"
+#include "internal/object.h"
+#include "internal/proc.h"
+#include "internal/rational.h"
+#include "internal/sanitizers.h"
+#include "internal/struct.h"
+#include "internal/symbol.h"
+#include "internal/thread.h"
+#include "internal/variable.h"
+#include "internal/warnings.h"
+#include "mjit.h"
+#include "probes.h"
+#include "regint.h"
+#include "ruby/debug.h"
+#include "ruby/io.h"
+#include "ruby/re.h"
+#include "ruby/st.h"
+#include "ruby/thread.h"
+#include "ruby/util.h"
+#include "ruby_assert.h"
+#include "ruby_atomic.h"
+#include "symbol.h"
+#include "transient_heap.h"
+#include "vm_core.h"
+#include "vm_sync.h"
+#include "vm_callinfo.h"
+#include "ractor_core.h"
+
+#include "builtin.h"
+
+#define rb_setjmp(env) RUBY_SETJMP(env)
+#define rb_jmp_buf rb_jmpbuf_t
+#undef rb_data_object_wrap
+
+static inline struct rbimpl_size_mul_overflow_tag
+size_add_overflow(size_t x, size_t y)
+{
+    size_t z;
+    bool p;
+#if 0
+
+#elif __has_builtin(__builtin_add_overflow)
+    p = __builtin_add_overflow(x, y, &z);
+
+#elif defined(DSIZE_T)
+    RB_GNUC_EXTENSION DSIZE_T dx = x;
+    RB_GNUC_EXTENSION DSIZE_T dy = y;
+    RB_GNUC_EXTENSION DSIZE_T dz = dx + dy;
+    p = dz > SIZE_MAX;
+    z = (size_t)dz;
+
+#else
+    z = x + y;
+    p = z < y;
+
+#endif
+    return (struct rbimpl_size_mul_overflow_tag) { p, z, };
+}
+
+static inline struct rbimpl_size_mul_overflow_tag
+size_mul_add_overflow(size_t x, size_t y, size_t z) /* x * y + z */
+{
+    struct rbimpl_size_mul_overflow_tag t = rbimpl_size_mul_overflow(x, y);
+    struct rbimpl_size_mul_overflow_tag u = size_add_overflow(t.right, z);
+    return (struct rbimpl_size_mul_overflow_tag) { t.left || u.left, u.right };
+}
+
+static inline struct rbimpl_size_mul_overflow_tag
+size_mul_add_mul_overflow(size_t x, size_t y, size_t z, size_t w) /* x * y + z * w */
+{
+    struct rbimpl_size_mul_overflow_tag t = rbimpl_size_mul_overflow(x, y);
+    struct rbimpl_size_mul_overflow_tag u = rbimpl_size_mul_overflow(z, w);
+    struct rbimpl_size_mul_overflow_tag v = size_add_overflow(t.right, u.right);
+    return (struct rbimpl_size_mul_overflow_tag) { t.left || u.left || v.left, v.right };
+}
+
+PRINTF_ARGS(NORETURN(static void gc_raise(VALUE, const char*, ...)), 2, 3);
+
+static inline size_t
+size_mul_or_raise(size_t x, size_t y, VALUE exc)
+{
+    struct rbimpl_size_mul_overflow_tag t = rbimpl_size_mul_overflow(x, y);
+    if (LIKELY(!t.left)) {
+        return t.right;
+    }
+    else if (rb_during_gc()) {
+        rb_memerror();          /* or...? */
+    }
+    else {
+        gc_raise(
+            exc,
+            "integer overflow: %"PRIuSIZE
+            " * %"PRIuSIZE
+            " > %"PRIuSIZE,
+            x, y, SIZE_MAX);
+    }
+}
+
+size_t
+rb_size_mul_or_raise(size_t x, size_t y, VALUE exc)
+{
+    return size_mul_or_raise(x, y, exc);
+}
+
+static inline size_t
+size_mul_add_or_raise(size_t x, size_t y, size_t z, VALUE exc)
+{
+    struct rbimpl_size_mul_overflow_tag t = size_mul_add_overflow(x, y, z);
+    if (LIKELY(!t.left)) {
+        return t.right;
+    }
+    else if (rb_during_gc()) {
+        rb_memerror();          /* or...? */
+    }
+    else {
+        gc_raise(
+            exc,
+            "integer overflow: %"PRIuSIZE
+            " * %"PRIuSIZE
+            " + %"PRIuSIZE
+            " > %"PRIuSIZE,
+            x, y, z, SIZE_MAX);
+    }
+}
+
+size_t
+rb_size_mul_add_or_raise(size_t x, size_t y, size_t z, VALUE exc)
+{
+    return size_mul_add_or_raise(x, y, z, exc);
+}
+
+static inline size_t
+size_mul_add_mul_or_raise(size_t x, size_t y, size_t z, size_t w, VALUE exc)
+{
+    struct rbimpl_size_mul_overflow_tag t = size_mul_add_mul_overflow(x, y, z, w);
+    if (LIKELY(!t.left)) {
+        return t.right;
+    }
+    else if (rb_during_gc()) {
+        rb_memerror();          /* or...? */
+    }
+    else {
+        gc_raise(
+            exc,
+            "integer overflow: %"PRIdSIZE
+            " * %"PRIdSIZE
+            " + %"PRIdSIZE
+            " * %"PRIdSIZE
+            " > %"PRIdSIZE,
+            x, y, z, w, SIZE_MAX);
+    }
+}
+
+#if defined(HAVE_RB_GC_GUARDED_PTR_VAL) && HAVE_RB_GC_GUARDED_PTR_VAL
+/* trick the compiler into thinking a external signal handler uses this */
+volatile VALUE rb_gc_guarded_val;
+volatile VALUE *
+rb_gc_guarded_ptr_val(volatile VALUE *ptr, VALUE val)
+{
+    rb_gc_guarded_val = val;
+
+    return ptr;
+}
+#endif
+
+#ifndef GC_HEAP_INIT_SLOTS
+#define GC_HEAP_INIT_SLOTS 10000
+#endif
+#ifndef GC_HEAP_FREE_SLOTS
+#define GC_HEAP_FREE_SLOTS  4096
+#endif
+#ifndef GC_HEAP_GROWTH_FACTOR
+#define GC_HEAP_GROWTH_FACTOR 1.8
+#endif
+#ifndef GC_HEAP_GROWTH_MAX_SLOTS
+#define GC_HEAP_GROWTH_MAX_SLOTS 0 /* 0 is disable */
+#endif
+#ifndef GC_HEAP_OLDOBJECT_LIMIT_FACTOR
+#define GC_HEAP_OLDOBJECT_LIMIT_FACTOR 2.0
+#endif
+
+#ifndef GC_HEAP_FREE_SLOTS_MIN_RATIO
+#define GC_HEAP_FREE_SLOTS_MIN_RATIO  0.20
+#endif
+#ifndef GC_HEAP_FREE_SLOTS_GOAL_RATIO
+#define GC_HEAP_FREE_SLOTS_GOAL_RATIO 0.40
+#endif
+#ifndef GC_HEAP_FREE_SLOTS_MAX_RATIO
+#define GC_HEAP_FREE_SLOTS_MAX_RATIO  0.65
+#endif
+
+#ifndef GC_MALLOC_LIMIT_MIN
+#define GC_MALLOC_LIMIT_MIN (16 * 1024 * 1024 /* 16MB */)
+#endif
+#ifndef GC_MALLOC_LIMIT_MAX
+#define GC_MALLOC_LIMIT_MAX (32 * 1024 * 1024 /* 32MB */)
+#endif
+#ifndef GC_MALLOC_LIMIT_GROWTH_FACTOR
+#define GC_MALLOC_LIMIT_GROWTH_FACTOR 1.4
+#endif
+
+#ifndef GC_OLDMALLOC_LIMIT_MIN
+#define GC_OLDMALLOC_LIMIT_MIN (16 * 1024 * 1024 /* 16MB */)
+#endif
+#ifndef GC_OLDMALLOC_LIMIT_GROWTH_FACTOR
+#define GC_OLDMALLOC_LIMIT_GROWTH_FACTOR 1.2
+#endif
+#ifndef GC_OLDMALLOC_LIMIT_MAX
+#define GC_OLDMALLOC_LIMIT_MAX (128 * 1024 * 1024 /* 128MB */)
+#endif
+
+#ifndef PRINT_MEASURE_LINE
+#define PRINT_MEASURE_LINE 0
+#endif
+#ifndef PRINT_ENTER_EXIT_TICK
+#define PRINT_ENTER_EXIT_TICK 0
+#endif
+#ifndef PRINT_ROOT_TICKS
+#define PRINT_ROOT_TICKS 0
+#endif
+
+#define USE_TICK_T                 (PRINT_ENTER_EXIT_TICK || PRINT_MEASURE_LINE || PRINT_ROOT_TICKS)
+#define TICK_TYPE 1
+
+typedef struct {
+    size_t heap_init_slots;
+    size_t heap_free_slots;
+    double growth_factor;
+    size_t growth_max_slots;
+
+    double heap_free_slots_min_ratio;
+    double heap_free_slots_goal_ratio;
+    double heap_free_slots_max_ratio;
+    double oldobject_limit_factor;
+
+    size_t malloc_limit_min;
+    size_t malloc_limit_max;
+    double malloc_limit_growth_factor;
+
+    size_t oldmalloc_limit_min;
+    size_t oldmalloc_limit_max;
+    double oldmalloc_limit_growth_factor;
+
+    VALUE gc_stress;
+} ruby_gc_params_t;
+
+static ruby_gc_params_t gc_params = {
+    GC_HEAP_INIT_SLOTS,
+    GC_HEAP_FREE_SLOTS,
+    GC_HEAP_GROWTH_FACTOR,
+    GC_HEAP_GROWTH_MAX_SLOTS,
+
+    GC_HEAP_FREE_SLOTS_MIN_RATIO,
+    GC_HEAP_FREE_SLOTS_GOAL_RATIO,
+    GC_HEAP_FREE_SLOTS_MAX_RATIO,
+    GC_HEAP_OLDOBJECT_LIMIT_FACTOR,
+
+    GC_MALLOC_LIMIT_MIN,
+    GC_MALLOC_LIMIT_MAX,
+    GC_MALLOC_LIMIT_GROWTH_FACTOR,
+
+    GC_OLDMALLOC_LIMIT_MIN,
+    GC_OLDMALLOC_LIMIT_MAX,
+    GC_OLDMALLOC_LIMIT_GROWTH_FACTOR,
+
+    FALSE,
+};
+
+/* GC_DEBUG:
+ *  enable to embed GC debugging information.
+ */
+#ifndef GC_DEBUG
+#define GC_DEBUG 0
+#endif
+
+/* RGENGC_DEBUG:
+ * 1: basic information
+ * 2: remember set operation
+ * 3: mark
+ * 4:
+ * 5: sweep
+ */
+#ifndef RGENGC_DEBUG
+#ifdef RUBY_DEVEL
+#define RGENGC_DEBUG       -1
+#else
+#define RGENGC_DEBUG       0
+#endif
+#endif
+#if RGENGC_DEBUG < 0 && !defined(_MSC_VER)
+# define RGENGC_DEBUG_ENABLED(level) (-(RGENGC_DEBUG) >= (level) && ruby_rgengc_debug >= (level))
+#else
+# define RGENGC_DEBUG_ENABLED(level) 0
+#endif
+int ruby_rgengc_debug;
+
+/* RGENGC_CHECK_MODE
+ * 0: disable all assertions
+ * 1: enable assertions (to debug RGenGC)
+ * 2: enable internal consistency check at each GC (for debugging)
+ * 3: enable internal consistency check at each GC steps (for debugging)
+ * 4: enable liveness check
+ * 5: show all references
+ */
+#ifndef RGENGC_CHECK_MODE
+#define RGENGC_CHECK_MODE  0
+#endif
+
+// Note: using RUBY_ASSERT_WHEN() extend a macro in expr (info by nobu).
+#define GC_ASSERT(expr) RUBY_ASSERT_MESG_WHEN(RGENGC_CHECK_MODE > 0, expr, #expr)
+
+/* RGENGC_OLD_NEWOBJ_CHECK
+ * 0:  disable all assertions
+ * >0: make a OLD object when new object creation.
+ *
+ * Make one OLD object per RGENGC_OLD_NEWOBJ_CHECK WB protected objects creation.
+ */
+#ifndef RGENGC_OLD_NEWOBJ_CHECK
+#define RGENGC_OLD_NEWOBJ_CHECK 0
+#endif
+
+/* RGENGC_PROFILE
+ * 0: disable RGenGC profiling
+ * 1: enable profiling for basic information
+ * 2: enable profiling for each types
+ */
+#ifndef RGENGC_PROFILE
+#define RGENGC_PROFILE     0
+#endif
+
+/* RGENGC_ESTIMATE_OLDMALLOC
+ * Enable/disable to estimate increase size of malloc'ed size by old objects.
+ * If estimation exceeds threshold, then will invoke full GC.
+ * 0: disable estimation.
+ * 1: enable estimation.
+ */
+#ifndef RGENGC_ESTIMATE_OLDMALLOC
+#define RGENGC_ESTIMATE_OLDMALLOC 1
+#endif
+
+/* RGENGC_FORCE_MAJOR_GC
+ * Force major/full GC if this macro is not 0.
+ */
+#ifndef RGENGC_FORCE_MAJOR_GC
+#define RGENGC_FORCE_MAJOR_GC 0
+#endif
+
+#ifndef GC_PROFILE_MORE_DETAIL
+#define GC_PROFILE_MORE_DETAIL 0
+#endif
+#ifndef GC_PROFILE_DETAIL_MEMORY
+#define GC_PROFILE_DETAIL_MEMORY 0
+#endif
+#ifndef GC_ENABLE_INCREMENTAL_MARK
+#define GC_ENABLE_INCREMENTAL_MARK USE_RINCGC
+#endif
+#ifndef GC_ENABLE_LAZY_SWEEP
+#define GC_ENABLE_LAZY_SWEEP   1
+#endif
+#ifndef CALC_EXACT_MALLOC_SIZE
+#define CALC_EXACT_MALLOC_SIZE USE_GC_MALLOC_OBJ_INFO_DETAILS
+#endif
+#if defined(HAVE_MALLOC_USABLE_SIZE) || CALC_EXACT_MALLOC_SIZE > 0
+#ifndef MALLOC_ALLOCATED_SIZE
+#define MALLOC_ALLOCATED_SIZE 0
+#endif
+#else
+#define MALLOC_ALLOCATED_SIZE 0
+#endif
+#ifndef MALLOC_ALLOCATED_SIZE_CHECK
+#define MALLOC_ALLOCATED_SIZE_CHECK 0
+#endif
+
+#ifndef GC_DEBUG_STRESS_TO_CLASS
+#define GC_DEBUG_STRESS_TO_CLASS 0
+#endif
+
+#ifndef RGENGC_OBJ_INFO
+#define RGENGC_OBJ_INFO (RGENGC_DEBUG | RGENGC_CHECK_MODE)
+#endif
+
+typedef enum {
+    GPR_FLAG_NONE               = 0x000,
+    /* major reason */
+    GPR_FLAG_MAJOR_BY_NOFREE    = 0x001,
+    GPR_FLAG_MAJOR_BY_OLDGEN    = 0x002,
+    GPR_FLAG_MAJOR_BY_SHADY     = 0x004,
+    GPR_FLAG_MAJOR_BY_FORCE     = 0x008,
+#if RGENGC_ESTIMATE_OLDMALLOC
+    GPR_FLAG_MAJOR_BY_OLDMALLOC = 0x020,
+#endif
+    GPR_FLAG_MAJOR_MASK         = 0x0ff,
+
+    /* gc reason */
+    GPR_FLAG_NEWOBJ             = 0x100,
+    GPR_FLAG_MALLOC             = 0x200,
+    GPR_FLAG_METHOD             = 0x400,
+    GPR_FLAG_CAPI               = 0x800,
+    GPR_FLAG_STRESS            = 0x1000,
+
+    /* others */
+    GPR_FLAG_IMMEDIATE_SWEEP   = 0x2000,
+    GPR_FLAG_HAVE_FINALIZE     = 0x4000,
+    GPR_FLAG_IMMEDIATE_MARK    = 0x8000,
+    GPR_FLAG_FULL_MARK        = 0x10000,
+    GPR_FLAG_COMPACT          = 0x20000,
+
+    GPR_DEFAULT_REASON =
+        (GPR_FLAG_FULL_MARK | GPR_FLAG_IMMEDIATE_MARK |
+         GPR_FLAG_IMMEDIATE_SWEEP | GPR_FLAG_CAPI),
+} gc_profile_record_flag;
+
+typedef struct gc_profile_record {
+    int flags;
+
+    double gc_time;
+    double gc_invoke_time;
+
+    size_t heap_total_objects;
+    size_t heap_use_size;
+    size_t heap_total_size;
+    size_t moved_objects;
+
+#if GC_PROFILE_MORE_DETAIL
+    double gc_mark_time;
+    double gc_sweep_time;
+
+    size_t heap_use_pages;
+    size_t heap_live_objects;
+    size_t heap_free_objects;
+
+    size_t allocate_increase;
+    size_t allocate_limit;
+
+    double prepare_time;
+    size_t removing_objects;
+    size_t empty_objects;
+#if GC_PROFILE_DETAIL_MEMORY
+    long maxrss;
+    long minflt;
+    long majflt;
+#endif
+#endif
+#if MALLOC_ALLOCATED_SIZE
+    size_t allocated_size;
+#endif
+
+#if RGENGC_PROFILE > 0
+    size_t old_objects;
+    size_t remembered_normal_objects;
+    size_t remembered_shady_objects;
+#endif
+} gc_profile_record;
+
+#define FL_FROM_FREELIST FL_USER0
+
+struct RMoved {
+    VALUE flags;
+    VALUE dummy;
+    VALUE destination;
+};
+
+#define RMOVED(obj) ((struct RMoved *)(obj))
+
+#if defined(_MSC_VER) || defined(__CYGWIN__)
+#pragma pack(push, 1) /* magic for reducing sizeof(RVALUE): 24 -> 20 */
+#endif
+
+typedef struct RVALUE {
+    union {
+	struct {
+	    VALUE flags;		/* always 0 for freed obj */
+	    struct RVALUE *next;
+	} free;
+        struct RMoved  moved;
+	struct RBasic  basic;
+	struct RObject object;
+	struct RClass  klass;
+	struct RFloat  flonum;
+	struct RString string;
+	struct RArray  array;
+	struct RRegexp regexp;
+	struct RHash   hash;
+	struct RData   data;
+	struct RTypedData   typeddata;
+	struct RStruct rstruct;
+	struct RBignum bignum;
+	struct RFile   file;
+	struct RMatch  match;
+	struct RRational rational;
+	struct RComplex complex;
+	union {
+	    rb_cref_t cref;
+	    struct vm_svar svar;
+	    struct vm_throw_data throw_data;
+	    struct vm_ifunc ifunc;
+	    struct MEMO memo;
+	    struct rb_method_entry_struct ment;
+	    const rb_iseq_t iseq;
+	    rb_env_t env;
+	    struct rb_imemo_tmpbuf_struct alloc;
+	    rb_ast_t ast;
+	} imemo;
+	struct {
+	    struct RBasic basic;
+	    VALUE v1;
+	    VALUE v2;
+	    VALUE v3;
+	} values;
+    } as;
+#if GC_DEBUG
+    const char *file;
+    int line;
+#endif
+} RVALUE;
+
+#if defined(_MSC_VER) || defined(__CYGWIN__)
+#pragma pack(pop)
+#endif
+
+typedef uintptr_t bits_t;
+enum {
+    BITS_SIZE = sizeof(bits_t),
+    BITS_BITLENGTH = ( BITS_SIZE * CHAR_BIT )
+};
+#define popcount_bits rb_popcount_intptr
+
+struct heap_page_header {
+    struct heap_page *page;
+};
+
+struct heap_page_body {
+    struct heap_page_header header;
+    /* char gap[];      */
+    /* RVALUE values[]; */
+};
+
+struct gc_list {
+    VALUE *varptr;
+    struct gc_list *next;
+};
+
+#define STACK_CHUNK_SIZE 500
+
+typedef struct stack_chunk {
+    VALUE data[STACK_CHUNK_SIZE];
+    struct stack_chunk *next;
+} stack_chunk_t;
+
+typedef struct mark_stack {
+    stack_chunk_t *chunk;
+    stack_chunk_t *cache;
+    int index;
+    int limit;
+    size_t cache_size;
+    size_t unused_cache_size;
+} mark_stack_t;
+
+typedef struct rb_heap_struct {
+    struct heap_page *free_pages;
+    struct list_head pages;
+    struct heap_page *sweeping_page; /* iterator for .pages */
+    struct heap_page *compact_cursor;
+    size_t compact_cursor_index;
+#if GC_ENABLE_INCREMENTAL_MARK
+    struct heap_page *pooled_pages;
+#endif
+    size_t total_pages;      /* total page count in a heap */
+    size_t total_slots;      /* total slot count (about total_pages * HEAP_PAGE_OBJ_LIMIT) */
+} rb_heap_t;
+
+enum gc_mode {
+    gc_mode_none,
+    gc_mode_marking,
+    gc_mode_sweeping
+};
+
+typedef struct rb_objspace {
+    struct {
+	size_t limit;
+	size_t increase;
+#if MALLOC_ALLOCATED_SIZE
+	size_t allocated_size;
+	size_t allocations;
+#endif
+    } malloc_params;
+
+    struct {
+	unsigned int mode : 2;
+	unsigned int immediate_sweep : 1;
+	unsigned int dont_gc : 1;
+	unsigned int dont_incremental : 1;
+	unsigned int during_gc : 1;
+        unsigned int during_compacting : 1;
+	unsigned int gc_stressful: 1;
+	unsigned int has_hook: 1;
+	unsigned int during_minor_gc : 1;
+#if GC_ENABLE_INCREMENTAL_MARK
+	unsigned int during_incremental_marking : 1;
+#endif
+        int collect_gc_stats;
+        int verbose_gc_stats;
+    } flags;
+
+    rb_event_flag_t hook_events;
+    size_t total_allocated_objects;
+    VALUE next_object_id;
+
+    rb_heap_t eden_heap;
+    rb_heap_t tomb_heap; /* heap for zombies and ghosts */
+
+    struct {
+	rb_atomic_t finalizing;
+    } atomic_flags;
+
+    mark_stack_t mark_stack;
+    size_t marked_slots;
+
+    struct {
+	struct heap_page **sorted;
+	size_t allocated_pages;
+	size_t allocatable_pages;
+	size_t sorted_length;
+	RVALUE *range[2];
+	size_t freeable_pages;
+
+	/* final */
+	size_t final_slots;
+	VALUE deferred_final;
+    } heap_pages;
+
+    st_table *finalizer_table;
+
+    struct {
+	int run;
+	int latest_gc_info;
+	gc_profile_record *records;
+	gc_profile_record *current_record;
+	size_t next_index;
+	size_t size;
+
+#if GC_PROFILE_MORE_DETAIL
+	double prepare_time;
+#endif
+	double invoke_time;
+
+	size_t minor_gc_count;
+	size_t major_gc_count;
+	size_t compact_count;
+	size_t read_barrier_faults;
+#if RGENGC_PROFILE > 0
+	size_t total_generated_normal_object_count;
+	size_t total_generated_shady_object_count;
+	size_t total_shade_operation_count;
+	size_t total_promoted_count;
+	size_t total_remembered_normal_object_count;
+	size_t total_remembered_shady_object_count;
+
+#if RGENGC_PROFILE >= 2
+	size_t generated_normal_object_count_types[RUBY_T_MASK];
+	size_t generated_shady_object_count_types[RUBY_T_MASK];
+	size_t shade_operation_count_types[RUBY_T_MASK];
+	size_t promoted_types[RUBY_T_MASK];
+	size_t remembered_normal_object_count_types[RUBY_T_MASK];
+	size_t remembered_shady_object_count_types[RUBY_T_MASK];
+#endif
+#endif /* RGENGC_PROFILE */
+
+	/* temporary profiling space */
+	double gc_sweep_start_time;
+        double gc_mark_start_time;
+
+	size_t total_allocated_objects_at_gc_start;
+	size_t heap_used_at_gc_start;
+
+	/* basic statistics */
+	size_t count;
+        double time;
+	size_t total_freed_objects;
+	size_t total_allocated_pages;
+	size_t total_freed_pages;
+        size_t total_mallocs;
+        size_t total_malloced_bytes;
+        size_t live_after_last_sweep;
+
+    } profile;
+    struct gc_list *global_list;
+
+    VALUE gc_stress_mode;
+
+    struct {
+	VALUE parent_object;
+	int need_major_gc;
+	size_t last_major_gc;
+	size_t uncollectible_wb_unprotected_objects;
+	size_t uncollectible_wb_unprotected_objects_limit;
+	size_t old_objects;
+	size_t old_objects_limit;
+
+#if RGENGC_ESTIMATE_OLDMALLOC
+	size_t oldmalloc_increase;
+	size_t oldmalloc_increase_limit;
+#endif
+
+#if RGENGC_CHECK_MODE >= 2
+	struct st_table *allrefs_table;
+	size_t error_count;
+#endif
+    } rgengc;
+
+    struct {
+        size_t considered_count_table[T_MASK];
+        size_t moved_count_table[T_MASK];
+        size_t total_moved;
+    } rcompactor;
+
+#if GC_ENABLE_INCREMENTAL_MARK
+    struct {
+	size_t pooled_slots;
+	size_t step_slots;
+    } rincgc;
+#endif
+
+    st_table *id_to_obj_tbl;
+    st_table *obj_to_id_tbl;
+
+#if GC_DEBUG_STRESS_TO_CLASS
+    VALUE stress_to_class;
+#endif
+} rb_objspace_t;
+
+
+/* default tiny heap size: 16KB */
+#define HEAP_PAGE_ALIGN_LOG 14
+#define CEILDIV(i, mod) (((i) + (mod) - 1)/(mod))
+enum {
+    HEAP_PAGE_ALIGN = (1UL << HEAP_PAGE_ALIGN_LOG),
+    HEAP_PAGE_ALIGN_MASK = (~(~0UL << HEAP_PAGE_ALIGN_LOG)),
+    HEAP_PAGE_SIZE = HEAP_PAGE_ALIGN,
+    HEAP_PAGE_OBJ_LIMIT = (unsigned int)((HEAP_PAGE_SIZE - sizeof(struct heap_page_header))/sizeof(struct RVALUE)),
+    HEAP_PAGE_BITMAP_LIMIT = CEILDIV(CEILDIV(HEAP_PAGE_SIZE, sizeof(struct RVALUE)), BITS_BITLENGTH),
+    HEAP_PAGE_BITMAP_SIZE = (BITS_SIZE * HEAP_PAGE_BITMAP_LIMIT),
+    HEAP_PAGE_BITMAP_PLANES = 4 /* RGENGC: mark, unprotected, uncollectible, marking */
+};
+#define HEAP_PAGE_ALIGN (1 << HEAP_PAGE_ALIGN_LOG)
+#define HEAP_PAGE_SIZE HEAP_PAGE_ALIGN
+
+#ifdef HAVE_MMAP
+# if HAVE_CONST_PAGE_SIZE
+/* If we have the HEAP_PAGE and it is a constant, then we can directly use it. */
+static const bool USE_MMAP_ALIGNED_ALLOC = (PAGE_SIZE <= HEAP_PAGE_SIZE);
+# elif defined(PAGE_MAX_SIZE) && (PAGE_MAX_SIZE <= HEAP_PAGE_SIZE)
+/* PAGE_SIZE <= HEAP_PAGE_SIZE */
+static const bool USE_MMAP_ALIGNED_ALLOC = true;
+# else
+/* Otherwise, fall back to determining if we can use mmap during runtime. */
+#  define USE_MMAP_ALIGNED_ALLOC (use_mmap_aligned_alloc != false)
+
+static bool use_mmap_aligned_alloc;
+# endif
+#elif !defined(__MINGW32__) && !defined(_WIN32)
+static const bool USE_MMAP_ALIGNED_ALLOC = false;
+#endif
+
+struct heap_page {
+    short total_slots;
+    short free_slots;
+    short pinned_slots;
+    short final_slots;
+    struct {
+	unsigned int before_sweep : 1;
+	unsigned int has_remembered_objects : 1;
+	unsigned int has_uncollectible_shady_objects : 1;
+	unsigned int in_tomb : 1;
+    } flags;
+
+    struct heap_page *free_next;
+    RVALUE *start;
+    RVALUE *freelist;
+    struct list_node page_node;
+
+    bits_t wb_unprotected_bits[HEAP_PAGE_BITMAP_LIMIT];
+    /* the following three bitmaps are cleared at the beginning of full GC */
+    bits_t mark_bits[HEAP_PAGE_BITMAP_LIMIT];
+    bits_t uncollectible_bits[HEAP_PAGE_BITMAP_LIMIT];
+    bits_t marking_bits[HEAP_PAGE_BITMAP_LIMIT];
+
+    /* If set, the object is not movable */
+    bits_t pinned_bits[HEAP_PAGE_BITMAP_LIMIT];
+};
+
+#define GET_PAGE_BODY(x)   ((struct heap_page_body *)((bits_t)(x) & ~(HEAP_PAGE_ALIGN_MASK)))
+#define GET_PAGE_HEADER(x) (&GET_PAGE_BODY(x)->header)
+#define GET_HEAP_PAGE(x)   (GET_PAGE_HEADER(x)->page)
+
+#define NUM_IN_PAGE(p)   (((bits_t)(p) & HEAP_PAGE_ALIGN_MASK)/sizeof(RVALUE))
+#define BITMAP_INDEX(p)  (NUM_IN_PAGE(p) / BITS_BITLENGTH )
+#define BITMAP_OFFSET(p) (NUM_IN_PAGE(p) & (BITS_BITLENGTH-1))
+#define BITMAP_BIT(p)    ((bits_t)1 << BITMAP_OFFSET(p))
+
+/* Bitmap Operations */
+#define MARKED_IN_BITMAP(bits, p)    ((bits)[BITMAP_INDEX(p)] & BITMAP_BIT(p))
+#define MARK_IN_BITMAP(bits, p)      ((bits)[BITMAP_INDEX(p)] = (bits)[BITMAP_INDEX(p)] | BITMAP_BIT(p))
+#define CLEAR_IN_BITMAP(bits, p)     ((bits)[BITMAP_INDEX(p)] = (bits)[BITMAP_INDEX(p)] & ~BITMAP_BIT(p))
+
+/* getting bitmap */
+#define GET_HEAP_MARK_BITS(x)           (&GET_HEAP_PAGE(x)->mark_bits[0])
+#define GET_HEAP_PINNED_BITS(x)         (&GET_HEAP_PAGE(x)->pinned_bits[0])
+#define GET_HEAP_UNCOLLECTIBLE_BITS(x)  (&GET_HEAP_PAGE(x)->uncollectible_bits[0])
+#define GET_HEAP_WB_UNPROTECTED_BITS(x) (&GET_HEAP_PAGE(x)->wb_unprotected_bits[0])
+#define GET_HEAP_MARKING_BITS(x)        (&GET_HEAP_PAGE(x)->marking_bits[0])
+
+/* Aliases */
+#define rb_objspace (*rb_objspace_of(GET_VM()))
+#define rb_objspace_of(vm) ((vm)->objspace)
+
+#define ruby_initial_gc_stress	gc_params.gc_stress
+
+VALUE *ruby_initial_gc_stress_ptr = &ruby_initial_gc_stress;
+
+#define malloc_limit		objspace->malloc_params.limit
+#define malloc_increase 	objspace->malloc_params.increase
+#define malloc_allocated_size 	objspace->malloc_params.allocated_size
+#define heap_pages_sorted       objspace->heap_pages.sorted
+#define heap_allocated_pages    objspace->heap_pages.allocated_pages
+#define heap_pages_sorted_length objspace->heap_pages.sorted_length
+#define heap_pages_lomem	objspace->heap_pages.range[0]
+#define heap_pages_himem	objspace->heap_pages.range[1]
+#define heap_allocatable_pages	objspace->heap_pages.allocatable_pages
+#define heap_pages_freeable_pages	objspace->heap_pages.freeable_pages
+#define heap_pages_final_slots		objspace->heap_pages.final_slots
+#define heap_pages_deferred_final	objspace->heap_pages.deferred_final
+#define heap_eden               (&objspace->eden_heap)
+#define heap_tomb               (&objspace->tomb_heap)
+#define during_gc		objspace->flags.during_gc
+#define collect_gc_stats        objspace->flags.collect_gc_stats
+#define finalizing		objspace->atomic_flags.finalizing
+#define finalizer_table 	objspace->finalizer_table
+#define global_list		objspace->global_list
+#define ruby_gc_stressful	objspace->flags.gc_stressful
+#define ruby_gc_stress_mode     objspace->gc_stress_mode
+#if GC_DEBUG_STRESS_TO_CLASS
+#define stress_to_class         objspace->stress_to_class
+#else
+#define stress_to_class         0
+#endif
+
+#if 0
+#define dont_gc_on()          (fprintf(stderr, "dont_gc_on@%s:%d\n",      __FILE__, __LINE__), objspace->flags.dont_gc = 1)
+#define dont_gc_off()         (fprintf(stderr, "dont_gc_off@%s:%d\n",     __FILE__, __LINE__), objspace->flags.dont_gc = 0)
+#define dont_gc_set(b)        (fprintf(stderr, "dont_gc_set(%d)@%s:%d\n", __FILE__, __LINE__), (int)b), objspace->flags.dont_gc = (b))
+#define dont_gc_val()         (objspace->flags.dont_gc)
+#else
+#define dont_gc_on()          (objspace->flags.dont_gc = 1)
+#define dont_gc_off()         (objspace->flags.dont_gc = 0)
+#define dont_gc_set(b)        (((int)b), objspace->flags.dont_gc = (b))
+#define dont_gc_val()         (objspace->flags.dont_gc)
+#endif
+
+static inline enum gc_mode
+gc_mode_verify(enum gc_mode mode)
+{
+#if RGENGC_CHECK_MODE > 0
+    switch (mode) {
+      case gc_mode_none:
+      case gc_mode_marking:
+      case gc_mode_sweeping:
+	break;
+      default:
+	rb_bug("gc_mode_verify: unreachable (%d)", (int)mode);
+    }
+#endif
+    return mode;
+}
+
+#define gc_mode(objspace)                gc_mode_verify((enum gc_mode)(objspace)->flags.mode)
+#define gc_mode_set(objspace, mode)      ((objspace)->flags.mode = (unsigned int)gc_mode_verify(mode))
+
+#define is_marking(objspace)             (gc_mode(objspace) == gc_mode_marking)
+#define is_sweeping(objspace)            (gc_mode(objspace) == gc_mode_sweeping)
+#define is_full_marking(objspace)        ((objspace)->flags.during_minor_gc == FALSE)
+#if GC_ENABLE_INCREMENTAL_MARK
+#define is_incremental_marking(objspace) ((objspace)->flags.during_incremental_marking != FALSE)
+#else
+#define is_incremental_marking(objspace) FALSE
+#endif
+#if GC_ENABLE_INCREMENTAL_MARK
+#define will_be_incremental_marking(objspace) ((objspace)->rgengc.need_major_gc != GPR_FLAG_NONE)
+#else
+#define will_be_incremental_marking(objspace) FALSE
+#endif
+#define has_sweeping_pages(heap)         ((heap)->sweeping_page != 0)
+#define is_lazy_sweeping(heap)           (GC_ENABLE_LAZY_SWEEP && has_sweeping_pages(heap))
+
+#if SIZEOF_LONG == SIZEOF_VOIDP
+# define nonspecial_obj_id(obj) (VALUE)((SIGNED_VALUE)(obj)|FIXNUM_FLAG)
+# define obj_id_to_ref(objid) ((objid) ^ FIXNUM_FLAG) /* unset FIXNUM_FLAG */
+#elif SIZEOF_LONG_LONG == SIZEOF_VOIDP
+# define nonspecial_obj_id(obj) LL2NUM((SIGNED_VALUE)(obj) / 2)
+# define obj_id_to_ref(objid) (FIXNUM_P(objid) ? \
+   ((objid) ^ FIXNUM_FLAG) : (NUM2PTR(objid) << 1))
+#else
+# error not supported
+#endif
+
+#define RANY(o) ((RVALUE*)(o))
+
+struct RZombie {
+    struct RBasic basic;
+    VALUE next;
+    void (*dfree)(void *);
+    void *data;
+};
+
+#define RZOMBIE(o) ((struct RZombie *)(o))
+
+#define nomem_error GET_VM()->special_exceptions[ruby_error_nomemory]
+
+#if RUBY_MARK_FREE_DEBUG
+int ruby_gc_debug_indent = 0;
+#endif
+VALUE rb_mGC;
+int ruby_disable_gc = 0;
+int ruby_enable_autocompact = 0;
+
+void rb_iseq_mark(const rb_iseq_t *iseq);
+void rb_iseq_update_references(rb_iseq_t *iseq);
+void rb_iseq_free(const rb_iseq_t *iseq);
+size_t rb_iseq_memsize(const rb_iseq_t *iseq);
+void rb_vm_update_references(void *ptr);
+
+void rb_gcdebug_print_obj_condition(VALUE obj);
+
+static VALUE define_final0(VALUE obj, VALUE block);
+
+NORETURN(static void *gc_vraise(void *ptr));
+NORETURN(static void gc_raise(VALUE exc, const char *fmt, ...));
+NORETURN(static void negative_size_allocation_error(const char *));
+
+static void init_mark_stack(mark_stack_t *stack);
+
+static int ready_to_gc(rb_objspace_t *objspace);
+
+static int garbage_collect(rb_objspace_t *, int reason);
+
+static int  gc_start(rb_objspace_t *objspace, int reason);
+static void gc_rest(rb_objspace_t *objspace);
+
+enum gc_enter_event {
+    gc_enter_event_start,
+    gc_enter_event_mark_continue,
+    gc_enter_event_sweep_continue,
+    gc_enter_event_rest,
+    gc_enter_event_finalizer,
+    gc_enter_event_rb_memerror,
+};
+
+static inline void gc_enter(rb_objspace_t *objspace, enum gc_enter_event event, unsigned int *lock_lev);
+static inline void gc_exit(rb_objspace_t *objspace, enum gc_enter_event event, unsigned int *lock_lev);
+
+static void gc_marks(rb_objspace_t *objspace, int full_mark);
+static void gc_marks_start(rb_objspace_t *objspace, int full);
+static int  gc_marks_finish(rb_objspace_t *objspace);
+static void gc_marks_rest(rb_objspace_t *objspace);
+static void gc_marks_step(rb_objspace_t *objspace, size_t slots);
+static void gc_marks_continue(rb_objspace_t *objspace, rb_heap_t *heap);
+
+static void gc_sweep(rb_objspace_t *objspace);
+static void gc_sweep_start(rb_objspace_t *objspace);
+static void gc_sweep_finish(rb_objspace_t *objspace);
+static int  gc_sweep_step(rb_objspace_t *objspace, rb_heap_t *heap);
+static void gc_sweep_rest(rb_objspace_t *objspace);
+static void gc_sweep_continue(rb_objspace_t *objspace, rb_heap_t *heap);
+
+static inline void gc_mark(rb_objspace_t *objspace, VALUE ptr);
+static inline void gc_pin(rb_objspace_t *objspace, VALUE ptr);
+static inline void gc_mark_and_pin(rb_objspace_t *objspace, VALUE ptr);
+static void gc_mark_ptr(rb_objspace_t *objspace, VALUE ptr);
+NO_SANITIZE("memory", static void gc_mark_maybe(rb_objspace_t *objspace, VALUE ptr));
+static void gc_mark_children(rb_objspace_t *objspace, VALUE ptr);
+
+static int gc_mark_stacked_objects_incremental(rb_objspace_t *, size_t count);
+static int gc_mark_stacked_objects_all(rb_objspace_t *);
+static void gc_grey(rb_objspace_t *objspace, VALUE ptr);
+
+static inline int gc_mark_set(rb_objspace_t *objspace, VALUE obj);
+NO_SANITIZE("memory", static inline int is_pointer_to_heap(rb_objspace_t *objspace, void *ptr));
+
+static void   push_mark_stack(mark_stack_t *, VALUE);
+static int    pop_mark_stack(mark_stack_t *, VALUE *);
+static size_t mark_stack_size(mark_stack_t *stack);
+static void   shrink_stack_chunk_cache(mark_stack_t *stack);
+
+static size_t obj_memsize_of(VALUE obj, int use_all_types);
+static void gc_verify_internal_consistency(rb_objspace_t *objspace);
+static int gc_verify_heap_page(rb_objspace_t *objspace, struct heap_page *page, VALUE obj);
+static int gc_verify_heap_pages(rb_objspace_t *objspace);
+
+static void gc_stress_set(rb_objspace_t *objspace, VALUE flag);
+static VALUE gc_disable_no_rest(rb_objspace_t *);
+
+static double getrusage_time(void);
+static inline void gc_prof_setup_new_record(rb_objspace_t *objspace, int reason);
+static inline void gc_prof_timer_start(rb_objspace_t *);
+static inline void gc_prof_timer_stop(rb_objspace_t *);
+static inline void gc_prof_mark_timer_start(rb_objspace_t *);
+static inline void gc_prof_mark_timer_stop(rb_objspace_t *);
+static inline void gc_prof_sweep_timer_start(rb_objspace_t *);
+static inline void gc_prof_sweep_timer_stop(rb_objspace_t *);
+static inline void gc_prof_set_malloc_info(rb_objspace_t *);
+static inline void gc_prof_set_heap_info(rb_objspace_t *);
+
+#define TYPED_UPDATE_IF_MOVED(_objspace, _type, _thing) do { \
+    if (gc_object_moved_p(_objspace, (VALUE)_thing)) { \
+       *((_type *)(&_thing)) = (_type)RMOVED((_thing))->destination; \
+    } \
+} while (0)
+
+#define UPDATE_IF_MOVED(_objspace, _thing) TYPED_UPDATE_IF_MOVED(_objspace, VALUE, _thing)
+
+#define gc_prof_record(objspace) (objspace)->profile.current_record
+#define gc_prof_enabled(objspace) ((objspace)->profile.run && (objspace)->profile.current_record)
+
+#ifdef HAVE_VA_ARGS_MACRO
+# define gc_report(level, objspace, ...) \
+    if (!RGENGC_DEBUG_ENABLED(level)) {} else gc_report_body(level, objspace, __VA_ARGS__)
+#else
+# define gc_report if (!RGENGC_DEBUG_ENABLED(0)) {} else gc_report_body
+#endif
+PRINTF_ARGS(static void gc_report_body(int level, rb_objspace_t *objspace, const char *fmt, ...), 3, 4);
+static const char *obj_info(VALUE obj);
+static const char *obj_type_name(VALUE obj);
+
+/*
+ * 1 - TSC (H/W Time Stamp Counter)
+ * 2 - getrusage
+ */
+#ifndef TICK_TYPE
+#define TICK_TYPE 1
+#endif
+
+#if USE_TICK_T
+
+#if TICK_TYPE == 1
+/* the following code is only for internal tuning. */
+
+/* Source code to use RDTSC is quoted and modified from
+ * http://www.mcs.anl.gov/~kazutomo/rdtsc.html
+ * written by Kazutomo Yoshii <kazutomo@mcs.anl.gov>
+ */
+
+#if defined(__GNUC__) && defined(__i386__)
+typedef unsigned long long tick_t;
+#define PRItick "llu"
+static inline tick_t
+tick(void)
+{
+    unsigned long long int x;
+    __asm__ __volatile__ ("rdtsc" : "=A" (x));
+    return x;
+}
+
+#elif defined(__GNUC__) && defined(__x86_64__)
+typedef unsigned long long tick_t;
+#define PRItick "llu"
+
+static __inline__ tick_t
+tick(void)
+{
+    unsigned long hi, lo;
+    __asm__ __volatile__ ("rdtsc" : "=a"(lo), "=d"(hi));
+    return ((unsigned long long)lo)|( ((unsigned long long)hi)<<32);
+}
+
+#elif defined(__powerpc64__) && GCC_VERSION_SINCE(4,8,0)
+typedef unsigned long long tick_t;
+#define PRItick "llu"
+
+static __inline__ tick_t
+tick(void)
+{
+    unsigned long long val = __builtin_ppc_get_timebase();
+    return val;
+}
+
+#elif defined(__aarch64__) &&  defined(__GNUC__)
+typedef unsigned long tick_t;
+#define PRItick "lu"
+
+static __inline__ tick_t
+tick(void)
+{
+    unsigned long val;
+    __asm__ __volatile__ ("mrs %0, cntvct_el0", : "=r" (val));
+    return val;
+}
+
+
+#elif defined(_WIN32) && defined(_MSC_VER)
+#include <intrin.h>
+typedef unsigned __int64 tick_t;
+#define PRItick "llu"
+
+static inline tick_t
+tick(void)
+{
+    return __rdtsc();
+}
+
+#else /* use clock */
+typedef clock_t tick_t;
+#define PRItick "llu"
+
+static inline tick_t
+tick(void)
+{
+    return clock();
+}
+#endif /* TSC */
+
+#elif TICK_TYPE == 2
+typedef double tick_t;
+#define PRItick "4.9f"
+
+static inline tick_t
+tick(void)
+{
+    return getrusage_time();
+}
+#else /* TICK_TYPE */
+#error "choose tick type"
+#endif /* TICK_TYPE */
+
+#define MEASURE_LINE(expr) do { \
+    volatile tick_t start_time = tick(); \
+    volatile tick_t end_time; \
+    expr; \
+    end_time = tick(); \
+    fprintf(stderr, "0\t%"PRItick"\t%s\n", end_time - start_time, #expr); \
+} while (0)
+
+#else /* USE_TICK_T */
+#define MEASURE_LINE(expr) expr
+#endif /* USE_TICK_T */
+
+static inline void *
+asan_unpoison_object_temporary(VALUE obj)
+{
+    void *ptr = asan_poisoned_object_p(obj);
+    asan_unpoison_object(obj, false);
+    return ptr;
+}
+
+#define FL_CHECK2(name, x, pred) \
+    ((RGENGC_CHECK_MODE && SPECIAL_CONST_P(x)) ? \
+     (rb_bug(name": SPECIAL_CONST (%p)", (void *)(x)), 0) : (pred))
+#define FL_TEST2(x,f)  FL_CHECK2("FL_TEST2",  x, FL_TEST_RAW((x),(f)) != 0)
+#define FL_SET2(x,f)   FL_CHECK2("FL_SET2",   x, RBASIC(x)->flags |= (f))
+#define FL_UNSET2(x,f) FL_CHECK2("FL_UNSET2", x, RBASIC(x)->flags &= ~(f))
+
+#define RVALUE_MARK_BITMAP(obj)           MARKED_IN_BITMAP(GET_HEAP_MARK_BITS(obj), (obj))
+#define RVALUE_PIN_BITMAP(obj)            MARKED_IN_BITMAP(GET_HEAP_PINNED_BITS(obj), (obj))
+#define RVALUE_PAGE_MARKED(page, obj)     MARKED_IN_BITMAP((page)->mark_bits, (obj))
+
+#define RVALUE_WB_UNPROTECTED_BITMAP(obj) MARKED_IN_BITMAP(GET_HEAP_WB_UNPROTECTED_BITS(obj), (obj))
+#define RVALUE_UNCOLLECTIBLE_BITMAP(obj)  MARKED_IN_BITMAP(GET_HEAP_UNCOLLECTIBLE_BITS(obj), (obj))
+#define RVALUE_MARKING_BITMAP(obj)        MARKED_IN_BITMAP(GET_HEAP_MARKING_BITS(obj), (obj))
+
+#define RVALUE_PAGE_WB_UNPROTECTED(page, obj) MARKED_IN_BITMAP((page)->wb_unprotected_bits, (obj))
+#define RVALUE_PAGE_UNCOLLECTIBLE(page, obj)  MARKED_IN_BITMAP((page)->uncollectible_bits, (obj))
+#define RVALUE_PAGE_MARKING(page, obj)        MARKED_IN_BITMAP((page)->marking_bits, (obj))
+
+#define RVALUE_OLD_AGE   3
+#define RVALUE_AGE_SHIFT 5 /* FL_PROMOTED0 bit */
+
+static int rgengc_remembered(rb_objspace_t *objspace, VALUE obj);
+static int rgengc_remembered_sweep(rb_objspace_t *objspace, VALUE obj);
+static int rgengc_remember(rb_objspace_t *objspace, VALUE obj);
+static void rgengc_mark_and_rememberset_clear(rb_objspace_t *objspace, rb_heap_t *heap);
+static void rgengc_rememberset_mark(rb_objspace_t *objspace, rb_heap_t *heap);
+
+static inline int
+RVALUE_FLAGS_AGE(VALUE flags)
+{
+    return (int)((flags & (FL_PROMOTED0 | FL_PROMOTED1)) >> RVALUE_AGE_SHIFT);
+}
+
+static int
+check_rvalue_consistency_force(const VALUE obj, int terminate)
+{
+    int err = 0;
+    rb_objspace_t *objspace = &rb_objspace;
+
+    RB_VM_LOCK_ENTER_NO_BARRIER();
+    {
+        if (SPECIAL_CONST_P(obj)) {
+            fprintf(stderr, "check_rvalue_consistency: %p is a special const.\n", (void *)obj);
+            err++;
+        }
+        else if (!is_pointer_to_heap(objspace, (void *)obj)) {
+            /* check if it is in tomb_pages */
+            struct heap_page *page = NULL;
+            list_for_each(&heap_tomb->pages, page, page_node) {
+                if (&page->start[0] <= (RVALUE *)obj &&
+                    (RVALUE *)obj < &page->start[page->total_slots]) {
+                    fprintf(stderr, "check_rvalue_consistency: %p is in a tomb_heap (%p).\n",
+                            (void *)obj, (void *)page);
+                    err++;
+                    goto skip;
+                }
+            }
+            bp();
+            fprintf(stderr, "check_rvalue_consistency: %p is not a Ruby object.\n", (void *)obj);
+            err++;
+          skip:
+            ;
+        }
+        else {
+            const int wb_unprotected_bit = RVALUE_WB_UNPROTECTED_BITMAP(obj) != 0;
+            const int uncollectible_bit = RVALUE_UNCOLLECTIBLE_BITMAP(obj) != 0;
+            const int mark_bit = RVALUE_MARK_BITMAP(obj) != 0;
+            const int marking_bit = RVALUE_MARKING_BITMAP(obj) != 0, remembered_bit = marking_bit;
+            const int age = RVALUE_FLAGS_AGE(RBASIC(obj)->flags);
+
+            if (GET_HEAP_PAGE(obj)->flags.in_tomb) {
+                fprintf(stderr, "check_rvalue_consistency: %s is in tomb page.\n", obj_info(obj));
+                err++;
+            }
+            if (BUILTIN_TYPE(obj) == T_NONE) {
+                fprintf(stderr, "check_rvalue_consistency: %s is T_NONE.\n", obj_info(obj));
+                err++;
+            }
+            if (BUILTIN_TYPE(obj) == T_ZOMBIE) {
+                fprintf(stderr, "check_rvalue_consistency: %s is T_ZOMBIE.\n", obj_info(obj));
+                err++;
+            }
+
+            obj_memsize_of((VALUE)obj, FALSE);
+
+            /* check generation
+             *
+             * OLD == age == 3 && old-bitmap && mark-bit (except incremental marking)
+             */
+            if (age > 0 && wb_unprotected_bit) {
+                fprintf(stderr, "check_rvalue_consistency: %s is not WB protected, but age is %d > 0.\n", obj_info(obj), age);
+                err++;
+            }
+
+            if (!is_marking(objspace) && uncollectible_bit && !mark_bit) {
+                fprintf(stderr, "check_rvalue_consistency: %s is uncollectible, but is not marked while !gc.\n", obj_info(obj));
+                err++;
+            }
+
+            if (!is_full_marking(objspace)) {
+                if (uncollectible_bit && age != RVALUE_OLD_AGE && !wb_unprotected_bit) {
+                    fprintf(stderr, "check_rvalue_consistency: %s is uncollectible, but not old (age: %d) and not WB unprotected.\n",
+                            obj_info(obj), age);
+                    err++;
+                }
+                if (remembered_bit && age != RVALUE_OLD_AGE) {
+                    fprintf(stderr, "check_rvalue_consistency: %s is remembered, but not old (age: %d).\n",
+                            obj_info(obj), age);
+                    err++;
+                }
+            }
+
+            /*
+             * check coloring
+             *
+             *               marking:false marking:true
+             * marked:false  white         *invalid*
+             * marked:true   black         grey
+             */
+            if (is_incremental_marking(objspace) && marking_bit) {
+                if (!is_marking(objspace) && !mark_bit) {
+                    fprintf(stderr, "check_rvalue_consistency: %s is marking, but not marked.\n", obj_info(obj));
+                    err++;
+                }
+            }
+        }
+    }
+    RB_VM_LOCK_LEAVE_NO_BARRIER();
+
+    if (err > 0 && terminate) {
+        rb_bug("check_rvalue_consistency_force: there is %d errors.", err);
+    }
+    return err;
+}
+
+#if RGENGC_CHECK_MODE == 0
+static inline VALUE
+check_rvalue_consistency(const VALUE obj)
+{
+    return obj;
+}
+#else
+static VALUE
+check_rvalue_consistency(const VALUE obj)
+{
+    check_rvalue_consistency_force(obj, TRUE);
+    return obj;
+}
+#endif
+
+static inline int
+gc_object_moved_p(rb_objspace_t * objspace, VALUE obj)
+{
+    if (RB_SPECIAL_CONST_P(obj)) {
+        return FALSE;
+    }
+    else {
+        void *poisoned = asan_poisoned_object_p(obj);
+        asan_unpoison_object(obj, false);
+
+        int ret =  BUILTIN_TYPE(obj) == T_MOVED;
+        /* Re-poison slot if it's not the one we want */
+        if (poisoned) {
+            GC_ASSERT(BUILTIN_TYPE(obj) == T_NONE);
+            asan_poison_object(obj);
+        }
+        return ret;
+    }
+}
+
+static inline int
+RVALUE_MARKED(VALUE obj)
+{
+    check_rvalue_consistency(obj);
+    return RVALUE_MARK_BITMAP(obj) != 0;
+}
+
+static inline int
+RVALUE_PINNED(VALUE obj)
+{
+    check_rvalue_consistency(obj);
+    return RVALUE_PIN_BITMAP(obj) != 0;
+}
+
+static inline int
+RVALUE_WB_UNPROTECTED(VALUE obj)
+{
+    check_rvalue_consistency(obj);
+    return RVALUE_WB_UNPROTECTED_BITMAP(obj) != 0;
+}
+
+static inline int
+RVALUE_MARKING(VALUE obj)
+{
+    check_rvalue_consistency(obj);
+    return RVALUE_MARKING_BITMAP(obj) != 0;
+}
+
+static inline int
+RVALUE_REMEMBERED(VALUE obj)
+{
+    check_rvalue_consistency(obj);
+    return RVALUE_MARKING_BITMAP(obj) != 0;
+}
+
+static inline int
+RVALUE_UNCOLLECTIBLE(VALUE obj)
+{
+    check_rvalue_consistency(obj);
+    return RVALUE_UNCOLLECTIBLE_BITMAP(obj) != 0;
+}
+
+static inline int
+RVALUE_OLD_P_RAW(VALUE obj)
+{
+    const VALUE promoted = FL_PROMOTED0 | FL_PROMOTED1;
+    return (RBASIC(obj)->flags & promoted) == promoted;
+}
+
+static inline int
+RVALUE_OLD_P(VALUE obj)
+{
+    check_rvalue_consistency(obj);
+    return RVALUE_OLD_P_RAW(obj);
+}
+
+#if RGENGC_CHECK_MODE || GC_DEBUG
+static inline int
+RVALUE_AGE(VALUE obj)
+{
+    check_rvalue_consistency(obj);
+    return RVALUE_FLAGS_AGE(RBASIC(obj)->flags);
+}
+#endif
+
+static inline void
+RVALUE_PAGE_OLD_UNCOLLECTIBLE_SET(rb_objspace_t *objspace, struct heap_page *page, VALUE obj)
+{
+    MARK_IN_BITMAP(&page->uncollectible_bits[0], obj);
+    objspace->rgengc.old_objects++;
+    rb_transient_heap_promote(obj);
+
+#if RGENGC_PROFILE >= 2
+    objspace->profile.total_promoted_count++;
+    objspace->profile.promoted_types[BUILTIN_TYPE(obj)]++;
+#endif
+}
+
+static inline void
+RVALUE_OLD_UNCOLLECTIBLE_SET(rb_objspace_t *objspace, VALUE obj)
+{
+    RB_DEBUG_COUNTER_INC(obj_promote);
+    RVALUE_PAGE_OLD_UNCOLLECTIBLE_SET(objspace, GET_HEAP_PAGE(obj), obj);
+}
+
+static inline VALUE
+RVALUE_FLAGS_AGE_SET(VALUE flags, int age)
+{
+    flags &= ~(FL_PROMOTED0 | FL_PROMOTED1);
+    flags |= (age << RVALUE_AGE_SHIFT);
+    return flags;
+}
+
+/* set age to age+1 */
+static inline void
+RVALUE_AGE_INC(rb_objspace_t *objspace, VALUE obj)
+{
+    VALUE flags = RBASIC(obj)->flags;
+    int age = RVALUE_FLAGS_AGE(flags);
+
+    if (RGENGC_CHECK_MODE && age == RVALUE_OLD_AGE) {
+	rb_bug("RVALUE_AGE_INC: can not increment age of OLD object %s.", obj_info(obj));
+    }
+
+    age++;
+    RBASIC(obj)->flags = RVALUE_FLAGS_AGE_SET(flags, age);
+
+    if (age == RVALUE_OLD_AGE) {
+	RVALUE_OLD_UNCOLLECTIBLE_SET(objspace, obj);
+    }
+    check_rvalue_consistency(obj);
+}
+
+/* set age to RVALUE_OLD_AGE */
+static inline void
+RVALUE_AGE_SET_OLD(rb_objspace_t *objspace, VALUE obj)
+{
+    check_rvalue_consistency(obj);
+    GC_ASSERT(!RVALUE_OLD_P(obj));
+
+    RBASIC(obj)->flags = RVALUE_FLAGS_AGE_SET(RBASIC(obj)->flags, RVALUE_OLD_AGE);
+    RVALUE_OLD_UNCOLLECTIBLE_SET(objspace, obj);
+
+    check_rvalue_consistency(obj);
+}
+
+/* set age to RVALUE_OLD_AGE - 1 */
+static inline void
+RVALUE_AGE_SET_CANDIDATE(rb_objspace_t *objspace, VALUE obj)
+{
+    check_rvalue_consistency(obj);
+    GC_ASSERT(!RVALUE_OLD_P(obj));
+
+    RBASIC(obj)->flags = RVALUE_FLAGS_AGE_SET(RBASIC(obj)->flags, RVALUE_OLD_AGE - 1);
+
+    check_rvalue_consistency(obj);
+}
+
+static inline void
+RVALUE_DEMOTE_RAW(rb_objspace_t *objspace, VALUE obj)
+{
+    RBASIC(obj)->flags = RVALUE_FLAGS_AGE_SET(RBASIC(obj)->flags, 0);
+    CLEAR_IN_BITMAP(GET_HEAP_UNCOLLECTIBLE_BITS(obj), obj);
+}
+
+static inline void
+RVALUE_DEMOTE(rb_objspace_t *objspace, VALUE obj)
+{
+    check_rvalue_consistency(obj);
+    GC_ASSERT(RVALUE_OLD_P(obj));
+
+    if (!is_incremental_marking(objspace) && RVALUE_REMEMBERED(obj)) {
+	CLEAR_IN_BITMAP(GET_HEAP_MARKING_BITS(obj), obj);
+    }
+
+    RVALUE_DEMOTE_RAW(objspace, obj);
+
+    if (RVALUE_MARKED(obj)) {
+	objspace->rgengc.old_objects--;
+    }
+
+    check_rvalue_consistency(obj);
+}
+
+static inline void
+RVALUE_AGE_RESET_RAW(VALUE obj)
+{
+    RBASIC(obj)->flags = RVALUE_FLAGS_AGE_SET(RBASIC(obj)->flags, 0);
+}
+
+static inline void
+RVALUE_AGE_RESET(VALUE obj)
+{
+    check_rvalue_consistency(obj);
+    GC_ASSERT(!RVALUE_OLD_P(obj));
+
+    RVALUE_AGE_RESET_RAW(obj);
+    check_rvalue_consistency(obj);
+}
+
+static inline int
+RVALUE_BLACK_P(VALUE obj)
+{
+    return RVALUE_MARKED(obj) && !RVALUE_MARKING(obj);
+}
+
+#if 0
+static inline int
+RVALUE_GREY_P(VALUE obj)
+{
+    return RVALUE_MARKED(obj) && RVALUE_MARKING(obj);
+}
+#endif
+
+static inline int
+RVALUE_WHITE_P(VALUE obj)
+{
+    return RVALUE_MARKED(obj) == FALSE;
+}
+
+/*
+  --------------------------- ObjectSpace -----------------------------
+*/
+
+static inline void *
+calloc1(size_t n)
+{
+    return calloc(1, n);
+}
+
+rb_objspace_t *
+rb_objspace_alloc(void)
+{
+    rb_objspace_t *objspace = calloc1(sizeof(rb_objspace_t));
+    malloc_limit = gc_params.malloc_limit_min;
+    list_head_init(&objspace->eden_heap.pages);
+    list_head_init(&objspace->tomb_heap.pages);
+    dont_gc_on();
+
+    return objspace;
+}
+
+static void free_stack_chunks(mark_stack_t *);
+static void heap_page_free(rb_objspace_t *objspace, struct heap_page *page);
+
+void
+rb_objspace_free(rb_objspace_t *objspace)
+{
+    if (is_lazy_sweeping(heap_eden))
+	rb_bug("lazy sweeping underway when freeing object space");
+
+    if (objspace->profile.records) {
+	free(objspace->profile.records);
+	objspace->profile.records = 0;
+    }
+
+    if (global_list) {
+	struct gc_list *list, *next;
+	for (list = global_list; list; list = next) {
+	    next = list->next;
+	    xfree(list);
+	}
+    }
+    if (heap_pages_sorted) {
+	size_t i;
+	for (i = 0; i < heap_allocated_pages; ++i) {
+	    heap_page_free(objspace, heap_pages_sorted[i]);
+	}
+	free(heap_pages_sorted);
+	heap_allocated_pages = 0;
+	heap_pages_sorted_length = 0;
+	heap_pages_lomem = 0;
+	heap_pages_himem = 0;
+
+	objspace->eden_heap.total_pages = 0;
+	objspace->eden_heap.total_slots = 0;
+    }
+    st_free_table(objspace->id_to_obj_tbl);
+    st_free_table(objspace->obj_to_id_tbl);
+    free_stack_chunks(&objspace->mark_stack);
+    free(objspace);
+}
+
+static void
+heap_pages_expand_sorted_to(rb_objspace_t *objspace, size_t next_length)
+{
+    struct heap_page **sorted;
+    size_t size = size_mul_or_raise(next_length, sizeof(struct heap_page *), rb_eRuntimeError);
+
+    gc_report(3, objspace, "heap_pages_expand_sorted: next_length: %"PRIdSIZE", size: %"PRIdSIZE"\n",
+              next_length, size);
+
+    if (heap_pages_sorted_length > 0) {
+	sorted = (struct heap_page **)realloc(heap_pages_sorted, size);
+	if (sorted) heap_pages_sorted = sorted;
+    }
+    else {
+	sorted = heap_pages_sorted = (struct heap_page **)malloc(size);
+    }
+
+    if (sorted == 0) {
+	rb_memerror();
+    }
+
+    heap_pages_sorted_length = next_length;
+}
+
+static void
+heap_pages_expand_sorted(rb_objspace_t *objspace)
+{
+    /* usually heap_allocatable_pages + heap_eden->total_pages == heap_pages_sorted_length
+     * because heap_allocatable_pages contains heap_tomb->total_pages (recycle heap_tomb pages).
+     * however, if there are pages which do not have empty slots, then try to create new pages
+     * so that the additional allocatable_pages counts (heap_tomb->total_pages) are added.
+     */
+    size_t next_length = heap_allocatable_pages;
+    next_length += heap_eden->total_pages;
+    next_length += heap_tomb->total_pages;
+
+    if (next_length > heap_pages_sorted_length) {
+	heap_pages_expand_sorted_to(objspace, next_length);
+    }
+
+    GC_ASSERT(heap_allocatable_pages + heap_eden->total_pages <= heap_pages_sorted_length);
+    GC_ASSERT(heap_allocated_pages <= heap_pages_sorted_length);
+}
+
+static void
+heap_allocatable_pages_set(rb_objspace_t *objspace, size_t s)
+{
+    heap_allocatable_pages = s;
+    heap_pages_expand_sorted(objspace);
+}
+
+static inline void
+heap_page_add_freeobj(rb_objspace_t *objspace, struct heap_page *page, VALUE obj)
+{
+    ASSERT_vm_locking();
+
+    RVALUE *p = (RVALUE *)obj;
+
+    asan_unpoison_memory_region(&page->freelist, sizeof(RVALUE*), false);
+
+    p->as.free.flags = 0;
+    p->as.free.next = page->freelist;
+    page->freelist = p;
+    asan_poison_memory_region(&page->freelist, sizeof(RVALUE*));
+
+    if (RGENGC_CHECK_MODE &&
+        /* obj should belong to page */
+        !(&page->start[0] <= (RVALUE *)obj &&
+          (RVALUE *)obj   <  &page->start[page->total_slots] &&
+          obj % sizeof(RVALUE) == 0)) {
+        rb_bug("heap_page_add_freeobj: %p is not rvalue.", (void *)p);
+    }
+
+    asan_poison_object(obj);
+    gc_report(3, objspace, "heap_page_add_freeobj: add %p to freelist\n", (void *)obj);
+}
+
+static inline void
+heap_add_freepage(rb_heap_t *heap, struct heap_page *page)
+{
+    asan_unpoison_memory_region(&page->freelist, sizeof(RVALUE*), false);
+    GC_ASSERT(page->free_slots != 0);
+    GC_ASSERT(page->freelist != NULL);
+
+    page->free_next = heap->free_pages;
+    heap->free_pages = page;
+
+    RUBY_DEBUG_LOG("page:%p freelist:%p", page, page->freelist);
+
+    asan_poison_memory_region(&page->freelist, sizeof(RVALUE*));
+}
+
+#if GC_ENABLE_INCREMENTAL_MARK
+static inline void
+heap_add_poolpage(rb_objspace_t *objspace, rb_heap_t *heap, struct heap_page *page)
+{
+    asan_unpoison_memory_region(&page->freelist, sizeof(RVALUE*), false);
+    GC_ASSERT(page->free_slots != 0);
+    GC_ASSERT(page->freelist != NULL);
+
+    page->free_next = heap->pooled_pages;
+    heap->pooled_pages = page;
+    objspace->rincgc.pooled_slots += page->free_slots;
+
+    asan_poison_memory_region(&page->freelist, sizeof(RVALUE*));
+}
+#endif
+
+static void
+heap_unlink_page(rb_objspace_t *objspace, rb_heap_t *heap, struct heap_page *page)
+{
+    list_del(&page->page_node);
+    heap->total_pages--;
+    heap->total_slots -= page->total_slots;
+}
+
+static void rb_aligned_free(void *ptr, size_t size);
+
+static void
+heap_page_free(rb_objspace_t *objspace, struct heap_page *page)
+{
+    heap_allocated_pages--;
+    objspace->profile.total_freed_pages++;
+    rb_aligned_free(GET_PAGE_BODY(page->start), HEAP_PAGE_SIZE);
+    free(page);
+}
+
+static void
+heap_pages_free_unused_pages(rb_objspace_t *objspace)
+{
+    size_t i, j;
+
+    if (!list_empty(&heap_tomb->pages)) {
+	for (i = j = 1; j < heap_allocated_pages; i++) {
+	    struct heap_page *page = heap_pages_sorted[i];
+
+	    if (page->flags.in_tomb && page->free_slots == page->total_slots) {
+		heap_unlink_page(objspace, heap_tomb, page);
+		heap_page_free(objspace, page);
+	    }
+	    else {
+		if (i != j) {
+		    heap_pages_sorted[j] = page;
+		}
+		j++;
+	    }
+	}
+
+        struct heap_page *hipage = heap_pages_sorted[heap_allocated_pages - 1];
+        RVALUE *himem = hipage->start + hipage->total_slots;
+        GC_ASSERT(himem <= heap_pages_himem);
+        heap_pages_himem = himem;
+
+	GC_ASSERT(j == heap_allocated_pages);
+    }
+}
+
+static struct heap_page *
+heap_page_allocate(rb_objspace_t *objspace)
+{
+    RVALUE *start, *end, *p;
+    struct heap_page *page;
+    struct heap_page_body *page_body = 0;
+    size_t hi, lo, mid;
+    int limit = HEAP_PAGE_OBJ_LIMIT;
+
+    /* assign heap_page body (contains heap_page_header and RVALUEs) */
+    page_body = (struct heap_page_body *)rb_aligned_malloc(HEAP_PAGE_ALIGN, HEAP_PAGE_SIZE);
+    if (page_body == 0) {
+	rb_memerror();
+    }
+
+    /* assign heap_page entry */
+    page = calloc1(sizeof(struct heap_page));
+    if (page == 0) {
+        rb_aligned_free(page_body, HEAP_PAGE_SIZE);
+	rb_memerror();
+    }
+
+    /* adjust obj_limit (object number available in this page) */
+    start = (RVALUE*)((VALUE)page_body + sizeof(struct heap_page_header));
+    if ((VALUE)start % sizeof(RVALUE) != 0) {
+	int delta = (int)(sizeof(RVALUE) - ((VALUE)start % sizeof(RVALUE)));
+	start = (RVALUE*)((VALUE)start + delta);
+	limit = (HEAP_PAGE_SIZE - (int)((VALUE)start - (VALUE)page_body))/(int)sizeof(RVALUE);
+    }
+    end = start + limit;
+
+    /* setup heap_pages_sorted */
+    lo = 0;
+    hi = heap_allocated_pages;
+    while (lo < hi) {
+	struct heap_page *mid_page;
+
+	mid = (lo + hi) / 2;
+	mid_page = heap_pages_sorted[mid];
+	if (mid_page->start < start) {
+	    lo = mid + 1;
+	}
+	else if (mid_page->start > start) {
+	    hi = mid;
+	}
+	else {
+	    rb_bug("same heap page is allocated: %p at %"PRIuVALUE, (void *)page_body, (VALUE)mid);
+	}
+    }
+
+    if (hi < heap_allocated_pages) {
+	MEMMOVE(&heap_pages_sorted[hi+1], &heap_pages_sorted[hi], struct heap_page_header*, heap_allocated_pages - hi);
+    }
+
+    heap_pages_sorted[hi] = page;
+
+    heap_allocated_pages++;
+
+    GC_ASSERT(heap_eden->total_pages + heap_allocatable_pages <= heap_pages_sorted_length);
+    GC_ASSERT(heap_eden->total_pages + heap_tomb->total_pages == heap_allocated_pages - 1);
+    GC_ASSERT(heap_allocated_pages <= heap_pages_sorted_length);
+
+    objspace->profile.total_allocated_pages++;
+
+    if (heap_allocated_pages > heap_pages_sorted_length) {
+	rb_bug("heap_page_allocate: allocated(%"PRIdSIZE") > sorted(%"PRIdSIZE")",
+	       heap_allocated_pages, heap_pages_sorted_length);
+    }
+
+    if (heap_pages_lomem == 0 || heap_pages_lomem > start) heap_pages_lomem = start;
+    if (heap_pages_himem < end) heap_pages_himem = end;
+
+    page->start = start;
+    page->total_slots = limit;
+    page_body->header.page = page;
+
+    for (p = start; p != end; p++) {
+	gc_report(3, objspace, "assign_heap_page: %p is added to freelist\n", (void *)p);
+	heap_page_add_freeobj(objspace, page, (VALUE)p);
+    }
+    page->free_slots = limit;
+
+    asan_poison_memory_region(&page->freelist, sizeof(RVALUE*));
+    return page;
+}
+
+static struct heap_page *
+heap_page_resurrect(rb_objspace_t *objspace)
+{
+    struct heap_page *page = 0, *next;
+
+    list_for_each_safe(&heap_tomb->pages, page, next, page_node) {
+        asan_unpoison_memory_region(&page->freelist, sizeof(RVALUE*), false);
+	if (page->freelist != NULL) {
+	    heap_unlink_page(objspace, heap_tomb, page);
+            asan_poison_memory_region(&page->freelist, sizeof(RVALUE*));
+	    return page;
+	}
+    }
+
+    return NULL;
+}
+
+static struct heap_page *
+heap_page_create(rb_objspace_t *objspace)
+{
+    struct heap_page *page;
+    const char *method = "recycle";
+
+    heap_allocatable_pages--;
+
+    page = heap_page_resurrect(objspace);
+
+    if (page == NULL) {
+	page = heap_page_allocate(objspace);
+	method = "allocate";
+    }
+    if (0) fprintf(stderr, "heap_page_create: %s - %p, "
+                   "heap_allocated_pages: %"PRIdSIZE", "
+                   "heap_allocated_pages: %"PRIdSIZE", "
+                   "tomb->total_pages: %"PRIdSIZE"\n",
+                   method, (void *)page, heap_pages_sorted_length, heap_allocated_pages, heap_tomb->total_pages);
+    return page;
+}
+
+static void
+heap_add_page(rb_objspace_t *objspace, rb_heap_t *heap, struct heap_page *page)
+{
+    /* Adding to eden heap during incremental sweeping is forbidden */
+    GC_ASSERT(!(heap == heap_eden && heap->sweeping_page));
+    page->flags.in_tomb = (heap == heap_tomb);
+    list_add_tail(&heap->pages, &page->page_node);
+    heap->total_pages++;
+    heap->total_slots += page->total_slots;
+}
+
+static void
+heap_assign_page(rb_objspace_t *objspace, rb_heap_t *heap)
+{
+    struct heap_page *page = heap_page_create(objspace);
+    heap_add_page(objspace, heap, page);
+    heap_add_freepage(heap, page);
+}
+
+static void
+heap_add_pages(rb_objspace_t *objspace, rb_heap_t *heap, size_t add)
+{
+    size_t i;
+
+    heap_allocatable_pages_set(objspace, add);
+
+    for (i = 0; i < add; i++) {
+	heap_assign_page(objspace, heap);
+    }
+
+    GC_ASSERT(heap_allocatable_pages == 0);
+}
+
+static size_t
+heap_extend_pages(rb_objspace_t *objspace, size_t free_slots, size_t total_slots)
+{
+    double goal_ratio = gc_params.heap_free_slots_goal_ratio;
+    size_t used = heap_allocated_pages + heap_allocatable_pages;
+    size_t next_used;
+
+    if (goal_ratio == 0.0) {
+	next_used = (size_t)(used * gc_params.growth_factor);
+    }
+    else {
+	/* Find `f' where free_slots = f * total_slots * goal_ratio
+	 * => f = (total_slots - free_slots) / ((1 - goal_ratio) * total_slots)
+	 */
+	double f = (double)(total_slots - free_slots) / ((1 - goal_ratio) * total_slots);
+
+	if (f > gc_params.growth_factor) f = gc_params.growth_factor;
+	if (f < 1.0) f = 1.1;
+
+	next_used = (size_t)(f * used);
+
+	if (0) {
+	    fprintf(stderr,
+		    "free_slots(%8"PRIuSIZE")/total_slots(%8"PRIuSIZE")=%1.2f,"
+		    " G(%1.2f), f(%1.2f),"
+		    " used(%8"PRIuSIZE") => next_used(%8"PRIuSIZE")\n",
+		    free_slots, total_slots, free_slots/(double)total_slots,
+		    goal_ratio, f, used, next_used);
+	}
+    }
+
+    if (gc_params.growth_max_slots > 0) {
+	size_t max_used = (size_t)(used + gc_params.growth_max_slots/HEAP_PAGE_OBJ_LIMIT);
+	if (next_used > max_used) next_used = max_used;
+    }
+
+    return next_used - used;
+}
+
+static void
+heap_set_increment(rb_objspace_t *objspace, size_t additional_pages)
+{
+    size_t used = heap_eden->total_pages;
+    size_t next_used_limit = used + additional_pages;
+
+    if (next_used_limit == heap_allocated_pages) next_used_limit++;
+
+    heap_allocatable_pages_set(objspace, next_used_limit - used);
+
+    gc_report(1, objspace, "heap_set_increment: heap_allocatable_pages is %"PRIdSIZE"\n",
+              heap_allocatable_pages);
+}
+
+static int
+heap_increment(rb_objspace_t *objspace, rb_heap_t *heap)
+{
+    if (heap_allocatable_pages > 0) {
+	gc_report(1, objspace, "heap_increment: heap_pages_sorted_length: %"PRIdSIZE", "
+                  "heap_pages_inc: %"PRIdSIZE", heap->total_pages: %"PRIdSIZE"\n",
+		  heap_pages_sorted_length, heap_allocatable_pages, heap->total_pages);
+
+	GC_ASSERT(heap_allocatable_pages + heap_eden->total_pages <= heap_pages_sorted_length);
+	GC_ASSERT(heap_allocated_pages <= heap_pages_sorted_length);
+
+	heap_assign_page(objspace, heap);
+	return TRUE;
+    }
+    return FALSE;
+}
+
+static void
+heap_prepare(rb_objspace_t *objspace, rb_heap_t *heap)
+{
+    GC_ASSERT(heap->free_pages == NULL);
+
+    if (is_lazy_sweeping(heap)) {
+	gc_sweep_continue(objspace, heap);
+    }
+    else if (is_incremental_marking(objspace)) {
+	gc_marks_continue(objspace, heap);
+    }
+
+    if (heap->free_pages == NULL &&
+	(will_be_incremental_marking(objspace) || heap_increment(objspace, heap) == FALSE) &&
+	gc_start(objspace, GPR_FLAG_NEWOBJ) == FALSE) {
+	rb_memerror();
+    }
+}
+
+void
+rb_objspace_set_event_hook(const rb_event_flag_t event)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    objspace->hook_events = event & RUBY_INTERNAL_EVENT_OBJSPACE_MASK;
+    objspace->flags.has_hook = (objspace->hook_events != 0);
+}
+
+static void
+gc_event_hook_body(rb_execution_context_t *ec, rb_objspace_t *objspace, const rb_event_flag_t event, VALUE data)
+{
+    const VALUE *pc = ec->cfp->pc;
+    if (pc && VM_FRAME_RUBYFRAME_P(ec->cfp)) {
+        /* increment PC because source line is calculated with PC-1 */
+        ec->cfp->pc++;
+    }
+    EXEC_EVENT_HOOK(ec, event, ec->cfp->self, 0, 0, 0, data);
+    ec->cfp->pc = pc;
+}
+
+#define gc_event_hook_available_p(objspace) ((objspace)->flags.has_hook)
+#define gc_event_hook_needed_p(objspace, event) ((objspace)->hook_events & (event))
+
+#define gc_event_hook_prep(objspace, event, data, prep) do { \
+    if (UNLIKELY(gc_event_hook_needed_p(objspace, event))) { \
+        prep; \
+	gc_event_hook_body(GET_EC(), (objspace), (event), (data)); \
+    } \
+} while (0)
+
+#define gc_event_hook(objspace, event, data) gc_event_hook_prep(objspace, event, data, (void)0)
+
+static inline VALUE
+newobj_init(VALUE klass, VALUE flags, int wb_protected, rb_objspace_t *objspace, VALUE obj)
+{
+#if !__has_feature(memory_sanitizer)
+    GC_ASSERT(BUILTIN_TYPE(obj) == T_NONE);
+    GC_ASSERT((flags & FL_WB_PROTECTED) == 0);
+#endif
+    RVALUE *p = RANY(obj);
+    p->as.basic.flags = flags;
+    *((VALUE *)&p->as.basic.klass) = klass;
+
+#if RACTOR_CHECK_MODE
+    rb_ractor_setup_belonging(obj);
+#endif
+
+#if RGENGC_CHECK_MODE
+    p->as.values.v1 = p->as.values.v2 = p->as.values.v3 = 0;
+
+    RB_VM_LOCK_ENTER_NO_BARRIER();
+    {
+        check_rvalue_consistency(obj);
+
+        GC_ASSERT(RVALUE_MARKED(obj) == FALSE);
+        GC_ASSERT(RVALUE_MARKING(obj) == FALSE);
+        GC_ASSERT(RVALUE_OLD_P(obj) == FALSE);
+        GC_ASSERT(RVALUE_WB_UNPROTECTED(obj) == FALSE);
+
+        if (flags & FL_PROMOTED1) {
+            if (RVALUE_AGE(obj) != 2) rb_bug("newobj: %s of age (%d) != 2.", obj_info(obj), RVALUE_AGE(obj));
+        }
+        else {
+            if (RVALUE_AGE(obj) > 0) rb_bug("newobj: %s of age (%d) > 0.", obj_info(obj), RVALUE_AGE(obj));
+        }
+        if (rgengc_remembered(objspace, (VALUE)obj)) rb_bug("newobj: %s is remembered.", obj_info(obj));
+    }
+    RB_VM_LOCK_LEAVE_NO_BARRIER();
+#endif
+
+    if (UNLIKELY(wb_protected == FALSE)) {
+        ASSERT_vm_locking();
+        MARK_IN_BITMAP(GET_HEAP_WB_UNPROTECTED_BITS(obj), obj);
+    }
+
+    // TODO: make it atomic, or ractor local
+    objspace->total_allocated_objects++;
+
+#if RGENGC_PROFILE
+    if (wb_protected) {
+        objspace->profile.total_generated_normal_object_count++;
+#if RGENGC_PROFILE >= 2
+        objspace->profile.generated_normal_object_count_types[BUILTIN_TYPE(obj)]++;
+#endif
+    }
+    else {
+        objspace->profile.total_generated_shady_object_count++;
+#if RGENGC_PROFILE >= 2
+        objspace->profile.generated_shady_object_count_types[BUILTIN_TYPE(obj)]++;
+#endif
+    }
+#endif
+
+#if GC_DEBUG
+    RANY(obj)->file = rb_source_location_cstr(&RANY(obj)->line);
+    GC_ASSERT(!SPECIAL_CONST_P(obj)); /* check alignment */
+#endif
+
+    gc_report(5, objspace, "newobj: %s\n", obj_info(obj));
+
+#if RGENGC_OLD_NEWOBJ_CHECK > 0
+    {
+        static int newobj_cnt = RGENGC_OLD_NEWOBJ_CHECK;
+
+        if (!is_incremental_marking(objspace) &&
+            flags & FL_WB_PROTECTED &&   /* do not promote WB unprotected objects */
+            ! RB_TYPE_P(obj, T_ARRAY)) { /* array.c assumes that allocated objects are new */
+            if (--newobj_cnt == 0) {
+                newobj_cnt = RGENGC_OLD_NEWOBJ_CHECK;
+
+                gc_mark_set(objspace, obj);
+                RVALUE_AGE_SET_OLD(objspace, obj);
+
+                rb_gc_writebarrier_remember(obj);
+            }
+        }
+    }
+#endif
+    // RUBY_DEBUG_LOG("obj:%p (%s)", (void *)obj, obj_type_name(obj));
+    return obj;
+}
+
+static inline VALUE
+ractor_cached_freeobj(rb_objspace_t *objspace, rb_ractor_t *cr)
+{
+    RVALUE *p = cr->newobj_cache.freelist;
+
+    if (p) {
+        VALUE obj = (VALUE)p;
+        cr->newobj_cache.freelist = p->as.free.next;
+        asan_unpoison_object(obj, true);
+        return obj;
+    }
+    else {
+        return Qfalse;
+    }
+}
+
+static struct heap_page *
+heap_next_freepage(rb_objspace_t *objspace, rb_heap_t *heap)
+{
+    ASSERT_vm_locking();
+
+    struct heap_page *page;
+
+    while (heap->free_pages == NULL) {
+	heap_prepare(objspace, heap);
+    }
+    page = heap->free_pages;
+    heap->free_pages = page->free_next;
+
+    GC_ASSERT(page->free_slots != 0);
+    RUBY_DEBUG_LOG("page:%p freelist:%p cnt:%d", page, page->freelist, page->free_slots);
+
+    asan_unpoison_memory_region(&page->freelist, sizeof(RVALUE*), false);
+
+    return page;
+}
+
+static inline void
+ractor_cache_slots(rb_objspace_t *objspace, rb_ractor_t *cr)
+{
+    ASSERT_vm_locking();
+    GC_ASSERT(cr->newobj_cache.freelist == NULL);
+
+    struct heap_page *page = heap_next_freepage(objspace, heap_eden);
+
+    cr->newobj_cache.using_page = page;
+    cr->newobj_cache.freelist = page->freelist;
+    page->free_slots = 0;
+    page->freelist = NULL;
+
+    GC_ASSERT(RB_TYPE_P((VALUE)cr->newobj_cache.freelist, T_NONE));
+}
+
+static inline VALUE
+newobj_fill(VALUE obj, VALUE v1, VALUE v2, VALUE v3)
+{
+    RVALUE *p = (RVALUE *)obj;
+    p->as.values.v1 = v1;
+    p->as.values.v2 = v2;
+    p->as.values.v3 = v3;
+    return obj;
+}
+
+ALWAYS_INLINE(static VALUE newobj_slowpath(VALUE klass, VALUE flags, rb_objspace_t *objspace, rb_ractor_t *cr, int wb_protected));
+
+static inline VALUE
+newobj_slowpath(VALUE klass, VALUE flags, rb_objspace_t *objspace, rb_ractor_t *cr, int wb_protected)
+{
+    VALUE obj;
+    unsigned int lev;
+
+    RB_VM_LOCK_ENTER_CR_LEV(cr, &lev);
+    {
+        if (UNLIKELY(during_gc || ruby_gc_stressful)) {
+            if (during_gc) {
+                dont_gc_on();
+                during_gc = 0;
+                rb_bug("object allocation during garbage collection phase");
+            }
+
+            if (ruby_gc_stressful) {
+                if (!garbage_collect(objspace, GPR_FLAG_NEWOBJ)) {
+                    rb_memerror();
+                }
+            }
+        }
+
+        // allocate new slot
+        while ((obj = ractor_cached_freeobj(objspace, cr)) == Qfalse) {
+            ractor_cache_slots(objspace, cr);
+        }
+        GC_ASSERT(obj != 0);
+        newobj_init(klass, flags, wb_protected, objspace, obj);
+        gc_event_hook_prep(objspace, RUBY_INTERNAL_EVENT_NEWOBJ, obj, newobj_fill(obj, 0, 0, 0));
+    }
+    RB_VM_LOCK_LEAVE_CR_LEV(cr, &lev);
+
+    return obj;
+}
+
+NOINLINE(static VALUE newobj_slowpath_wb_protected(VALUE klass, VALUE flags,
+                                                   rb_objspace_t *objspace, rb_ractor_t *cr));
+NOINLINE(static VALUE newobj_slowpath_wb_unprotected(VALUE klass, VALUE flags,
+                                                     rb_objspace_t *objspace, rb_ractor_t *cr));
+
+static VALUE
+newobj_slowpath_wb_protected(VALUE klass, VALUE flags, rb_objspace_t *objspace, rb_ractor_t *cr)
+{
+    return newobj_slowpath(klass, flags, objspace, cr, TRUE);
+}
+
+static VALUE
+newobj_slowpath_wb_unprotected(VALUE klass, VALUE flags, rb_objspace_t *objspace, rb_ractor_t *cr)
+{
+    return newobj_slowpath(klass, flags, objspace, cr, FALSE);
+}
+
+static inline VALUE
+newobj_of0(VALUE klass, VALUE flags, int wb_protected, rb_ractor_t *cr)
+{
+    VALUE obj;
+    rb_objspace_t *objspace = &rb_objspace;
+
+    RB_DEBUG_COUNTER_INC(obj_newobj);
+    (void)RB_DEBUG_COUNTER_INC_IF(obj_newobj_wb_unprotected, !wb_protected);
+
+#if GC_DEBUG_STRESS_TO_CLASS
+    if (UNLIKELY(stress_to_class)) {
+        long i, cnt = RARRAY_LEN(stress_to_class);
+        for (i = 0; i < cnt; ++i) {
+            if (klass == RARRAY_AREF(stress_to_class, i)) rb_memerror();
+        }
+    }
+#endif
+
+    if ((!UNLIKELY(during_gc ||
+                   ruby_gc_stressful ||
+                   gc_event_hook_available_p(objspace)) &&
+         wb_protected &&
+         (obj = ractor_cached_freeobj(objspace, cr)) != Qfalse)) {
+
+        newobj_init(klass, flags, wb_protected, objspace, obj);
+    }
+    else {
+        RB_DEBUG_COUNTER_INC(obj_newobj_slowpath);
+
+        obj = wb_protected ?
+          newobj_slowpath_wb_protected(klass, flags, objspace, cr) :
+          newobj_slowpath_wb_unprotected(klass, flags, objspace, cr);
+    }
+
+    return obj;
+}
+
+static inline VALUE
+newobj_of(VALUE klass, VALUE flags, VALUE v1, VALUE v2, VALUE v3, int wb_protected)
+{
+    VALUE obj = newobj_of0(klass, flags, wb_protected, GET_RACTOR());
+    return newobj_fill(obj, v1, v2, v3);
+}
+
+static inline VALUE
+newobj_of_cr(rb_ractor_t *cr, VALUE klass, VALUE flags, VALUE v1, VALUE v2, VALUE v3, int wb_protected)
+{
+    VALUE obj = newobj_of0(klass, flags, wb_protected, cr);
+    return newobj_fill(obj, v1, v2, v3);
+}
+
+VALUE
+rb_wb_unprotected_newobj_of(VALUE klass, VALUE flags)
+{
+    GC_ASSERT((flags & FL_WB_PROTECTED) == 0);
+    return newobj_of(klass, flags, 0, 0, 0, FALSE);
+}
+
+VALUE
+rb_wb_protected_newobj_of(VALUE klass, VALUE flags)
+{
+    GC_ASSERT((flags & FL_WB_PROTECTED) == 0);
+    return newobj_of(klass, flags, 0, 0, 0, TRUE);
+}
+
+VALUE
+rb_ec_wb_protected_newobj_of(rb_execution_context_t *ec, VALUE klass, VALUE flags)
+{
+    GC_ASSERT((flags & FL_WB_PROTECTED) == 0);
+    return newobj_of_cr(rb_ec_ractor_ptr(ec), klass, flags, 0, 0, 0, TRUE);
+}
+
+/* for compatibility */
+
+VALUE
+rb_newobj(void)
+{
+    return newobj_of(0, T_NONE, 0, 0, 0, FALSE);
+}
+
+VALUE
+rb_newobj_of(VALUE klass, VALUE flags)
+{
+    if ((flags & RUBY_T_MASK) == T_OBJECT) {
+        return newobj_of(klass, (flags | ROBJECT_EMBED) & ~FL_WB_PROTECTED , Qundef, Qundef, Qundef, flags & FL_WB_PROTECTED);
+    } else {
+        return newobj_of(klass, flags & ~FL_WB_PROTECTED, 0, 0, 0, flags & FL_WB_PROTECTED);
+    }
+}
+
+#define UNEXPECTED_NODE(func) \
+    rb_bug(#func"(): GC does not handle T_NODE 0x%x(%p) 0x%"PRIxVALUE, \
+	   BUILTIN_TYPE(obj), (void*)(obj), RBASIC(obj)->flags)
+
+const char *
+rb_imemo_name(enum imemo_type type)
+{
+    // put no default case to get a warning if an imemo type is missing
+    switch (type) {
+#define IMEMO_NAME(x) case imemo_##x: return #x;
+        IMEMO_NAME(env);
+        IMEMO_NAME(cref);
+        IMEMO_NAME(svar);
+        IMEMO_NAME(throw_data);
+        IMEMO_NAME(ifunc);
+        IMEMO_NAME(memo);
+        IMEMO_NAME(ment);
+        IMEMO_NAME(iseq);
+        IMEMO_NAME(tmpbuf);
+        IMEMO_NAME(ast);
+        IMEMO_NAME(parser_strterm);
+        IMEMO_NAME(callinfo);
+        IMEMO_NAME(callcache);
+        IMEMO_NAME(constcache);
+#undef IMEMO_NAME
+    }
+    return "unknown";
+}
+
+#undef rb_imemo_new
+
+VALUE
+rb_imemo_new(enum imemo_type type, VALUE v1, VALUE v2, VALUE v3, VALUE v0)
+{
+    VALUE flags = T_IMEMO | (type << FL_USHIFT);
+    return newobj_of(v0, flags, v1, v2, v3, TRUE);
+}
+
+static VALUE
+rb_imemo_tmpbuf_new(VALUE v1, VALUE v2, VALUE v3, VALUE v0)
+{
+    VALUE flags = T_IMEMO | (imemo_tmpbuf << FL_USHIFT);
+    return newobj_of(v0, flags, v1, v2, v3, FALSE);
+}
+
+static VALUE
+rb_imemo_tmpbuf_auto_free_maybe_mark_buffer(void *buf, size_t cnt)
+{
+    return rb_imemo_tmpbuf_new((VALUE)buf, 0, (VALUE)cnt, 0);
+}
+
+rb_imemo_tmpbuf_t *
+rb_imemo_tmpbuf_parser_heap(void *buf, rb_imemo_tmpbuf_t *old_heap, size_t cnt)
+{
+    return (rb_imemo_tmpbuf_t *)rb_imemo_tmpbuf_new((VALUE)buf, (VALUE)old_heap, (VALUE)cnt, 0);
+}
+
+static size_t
+imemo_memsize(VALUE obj)
+{
+    size_t size = 0;
+    switch (imemo_type(obj)) {
+      case imemo_ment:
+        size += sizeof(RANY(obj)->as.imemo.ment.def);
+        break;
+      case imemo_iseq:
+        size += rb_iseq_memsize((rb_iseq_t *)obj);
+        break;
+      case imemo_env:
+        size += RANY(obj)->as.imemo.env.env_size * sizeof(VALUE);
+        break;
+      case imemo_tmpbuf:
+        size += RANY(obj)->as.imemo.alloc.cnt * sizeof(VALUE);
+        break;
+      case imemo_ast:
+        size += rb_ast_memsize(&RANY(obj)->as.imemo.ast);
+        break;
+      case imemo_cref:
+      case imemo_svar:
+      case imemo_throw_data:
+      case imemo_ifunc:
+      case imemo_memo:
+      case imemo_parser_strterm:
+        break;
+      default:
+        /* unreachable */
+        break;
+    }
+    return size;
+}
+
+#if IMEMO_DEBUG
+VALUE
+rb_imemo_new_debug(enum imemo_type type, VALUE v1, VALUE v2, VALUE v3, VALUE v0, const char *file, int line)
+{
+    VALUE memo = rb_imemo_new(type, v1, v2, v3, v0);
+    fprintf(stderr, "memo %p (type: %d) @ %s:%d\n", (void *)memo, imemo_type(memo), file, line);
+    return memo;
+}
+#endif
+
+VALUE
+rb_class_allocate_instance(VALUE klass)
+{
+    VALUE flags = T_OBJECT | ROBJECT_EMBED;
+    return newobj_of(klass, flags, Qundef, Qundef, Qundef, RGENGC_WB_PROTECTED_OBJECT);
+}
+
+VALUE
+rb_data_object_wrap(VALUE klass, void *datap, RUBY_DATA_FUNC dmark, RUBY_DATA_FUNC dfree)
+{
+    RUBY_ASSERT_ALWAYS(dfree != (RUBY_DATA_FUNC)1);
+    if (klass) Check_Type(klass, T_CLASS);
+    return newobj_of(klass, T_DATA, (VALUE)dmark, (VALUE)dfree, (VALUE)datap, FALSE);
+}
+
+VALUE
+rb_data_object_zalloc(VALUE klass, size_t size, RUBY_DATA_FUNC dmark, RUBY_DATA_FUNC dfree)
+{
+    VALUE obj = rb_data_object_wrap(klass, 0, dmark, dfree);
+    DATA_PTR(obj) = xcalloc(1, size);
+    return obj;
+}
+
+VALUE
+rb_data_typed_object_wrap(VALUE klass, void *datap, const rb_data_type_t *type)
+{
+    RUBY_ASSERT_ALWAYS(type);
+    if (klass) Check_Type(klass, T_CLASS);
+    return newobj_of(klass, T_DATA, (VALUE)type, (VALUE)1, (VALUE)datap, type->flags & RUBY_FL_WB_PROTECTED);
+}
+
+VALUE
+rb_data_typed_object_zalloc(VALUE klass, size_t size, const rb_data_type_t *type)
+{
+    VALUE obj = rb_data_typed_object_wrap(klass, 0, type);
+    DATA_PTR(obj) = xcalloc(1, size);
+    return obj;
+}
+
+size_t
+rb_objspace_data_type_memsize(VALUE obj)
+{
+    if (RTYPEDDATA_P(obj)) {
+	const rb_data_type_t *type = RTYPEDDATA_TYPE(obj);
+	const void *ptr = RTYPEDDATA_DATA(obj);
+	if (ptr && type->function.dsize) {
+	    return type->function.dsize(ptr);
+	}
+    }
+    return 0;
+}
+
+const char *
+rb_objspace_data_type_name(VALUE obj)
+{
+    if (RTYPEDDATA_P(obj)) {
+	return RTYPEDDATA_TYPE(obj)->wrap_struct_name;
+    }
+    else {
+	return 0;
+    }
+}
+
+PUREFUNC(static inline int is_pointer_to_heap(rb_objspace_t *objspace, void *ptr);)
+static inline int
+is_pointer_to_heap(rb_objspace_t *objspace, void *ptr)
+{
+    register RVALUE *p = RANY(ptr);
+    register struct heap_page *page;
+    register size_t hi, lo, mid;
+
+    RB_DEBUG_COUNTER_INC(gc_isptr_trial);
+
+    if (p < heap_pages_lomem || p > heap_pages_himem) return FALSE;
+    RB_DEBUG_COUNTER_INC(gc_isptr_range);
+
+    if ((VALUE)p % sizeof(RVALUE) != 0) return FALSE;
+    RB_DEBUG_COUNTER_INC(gc_isptr_align);
+
+    /* check if p looks like a pointer using bsearch*/
+    lo = 0;
+    hi = heap_allocated_pages;
+    while (lo < hi) {
+	mid = (lo + hi) / 2;
+	page = heap_pages_sorted[mid];
+	if (page->start <= p) {
+	    if (p < page->start + page->total_slots) {
+                RB_DEBUG_COUNTER_INC(gc_isptr_maybe);
+
+                if (page->flags.in_tomb) {
+                    return FALSE;
+                }
+                else {
+                    return TRUE;
+                }
+	    }
+	    lo = mid + 1;
+	}
+	else {
+	    hi = mid;
+	}
+    }
+    return FALSE;
+}
+
+static enum rb_id_table_iterator_result
+free_const_entry_i(VALUE value, void *data)
+{
+    rb_const_entry_t *ce = (rb_const_entry_t *)value;
+    xfree(ce);
+    return ID_TABLE_CONTINUE;
+}
+
+void
+rb_free_const_table(struct rb_id_table *tbl)
+{
+    rb_id_table_foreach_values(tbl, free_const_entry_i, 0);
+    rb_id_table_free(tbl);
+}
+
+static int
+free_iv_index_tbl_free_i(st_data_t key, st_data_t value, st_data_t data)
+{
+    xfree((void *)value);
+    return ST_CONTINUE;
+}
+
+static void
+iv_index_tbl_free(struct st_table *tbl)
+{
+    st_foreach(tbl, free_iv_index_tbl_free_i, 0);
+}
+
+// alive: if false, target pointers can be freed already.
+//        To check it, we need objspace parameter.
+static void
+vm_ccs_free(struct rb_class_cc_entries *ccs, int alive, rb_objspace_t *objspace, VALUE klass)
+{
+    if (ccs->entries) {
+        for (int i=0; i<ccs->len; i++) {
+            const struct rb_callcache *cc = ccs->entries[i].cc;
+            if (!alive) {
+                void *ptr = asan_poisoned_object_p((VALUE)cc);
+                asan_unpoison_object((VALUE)cc, false);
+                // ccs can be free'ed.
+                if (is_pointer_to_heap(objspace, (void *)cc) &&
+                    IMEMO_TYPE_P(cc, imemo_callcache) &&
+                    cc->klass == klass) {
+                    // OK. maybe target cc.
+                }
+                else {
+                    if (ptr) {
+                        asan_poison_object((VALUE)cc);
+                    }
+                    continue;
+                }
+                if (ptr) {
+                    asan_poison_object((VALUE)cc);
+                }
+            }
+            vm_cc_invalidate(cc);
+        }
+        ruby_xfree(ccs->entries);
+    }
+    ruby_xfree(ccs);
+}
+
+void
+rb_vm_ccs_free(struct rb_class_cc_entries *ccs)
+{
+    RB_DEBUG_COUNTER_INC(ccs_free);
+    vm_ccs_free(ccs, TRUE, NULL, Qundef);
+}
+
+struct cc_tbl_i_data {
+    rb_objspace_t *objspace;
+    VALUE klass;
+    bool alive;
+};
+
+static enum rb_id_table_iterator_result
+cc_table_mark_i(ID id, VALUE ccs_ptr, void *data_ptr)
+{
+    struct cc_tbl_i_data *data = data_ptr;
+    struct rb_class_cc_entries *ccs = (struct rb_class_cc_entries *)ccs_ptr;
+    VM_ASSERT(vm_ccs_p(ccs));
+    VM_ASSERT(id == ccs->cme->called_id);
+
+    if (METHOD_ENTRY_INVALIDATED(ccs->cme)) {
+        rb_vm_ccs_free(ccs);
+        return ID_TABLE_DELETE;
+    }
+    else {
+        gc_mark(data->objspace, (VALUE)ccs->cme);
+
+        for (int i=0; i<ccs->len; i++) {
+            VM_ASSERT(data->klass == ccs->entries[i].cc->klass);
+            VM_ASSERT(ccs->cme == vm_cc_cme(ccs->entries[i].cc));
+
+            gc_mark(data->objspace, (VALUE)ccs->entries[i].ci);
+            gc_mark(data->objspace, (VALUE)ccs->entries[i].cc);
+        }
+        return ID_TABLE_CONTINUE;
+    }
+}
+
+static void
+cc_table_mark(rb_objspace_t *objspace, VALUE klass)
+{
+    struct rb_id_table *cc_tbl = RCLASS_CC_TBL(klass);
+    if (cc_tbl) {
+        struct cc_tbl_i_data data = {
+            .objspace = objspace,
+            .klass = klass,
+        };
+        rb_id_table_foreach(cc_tbl, cc_table_mark_i, &data);
+    }
+}
+
+static enum rb_id_table_iterator_result
+cc_table_free_i(VALUE ccs_ptr, void *data_ptr)
+{
+    struct cc_tbl_i_data *data = data_ptr;
+    struct rb_class_cc_entries *ccs = (struct rb_class_cc_entries *)ccs_ptr;
+    VM_ASSERT(vm_ccs_p(ccs));
+    vm_ccs_free(ccs, data->alive, data->objspace, data->klass);
+    return ID_TABLE_CONTINUE;
+}
+
+static void
+cc_table_free(rb_objspace_t *objspace, VALUE klass, bool alive)
+{
+    struct rb_id_table *cc_tbl = RCLASS_CC_TBL(klass);
+
+    if (cc_tbl) {
+        struct cc_tbl_i_data data = {
+            .objspace = objspace,
+            .klass = klass,
+            .alive = alive,
+        };
+        rb_id_table_foreach_values(cc_tbl, cc_table_free_i, &data);
+        rb_id_table_free(cc_tbl);
+    }
+}
+
+void
+rb_cc_table_free(VALUE klass)
+{
+    cc_table_free(&rb_objspace, klass, TRUE);
+}
+
+static inline void
+make_zombie(rb_objspace_t *objspace, VALUE obj, void (*dfree)(void *), void *data)
+{
+    struct RZombie *zombie = RZOMBIE(obj);
+    zombie->basic.flags = T_ZOMBIE | (zombie->basic.flags & FL_SEEN_OBJ_ID);
+    zombie->dfree = dfree;
+    zombie->data = data;
+    zombie->next = heap_pages_deferred_final;
+    heap_pages_deferred_final = (VALUE)zombie;
+
+    struct heap_page *page = GET_HEAP_PAGE(obj);
+    page->final_slots++;
+    heap_pages_final_slots++;
+}
+
+static inline void
+make_io_zombie(rb_objspace_t *objspace, VALUE obj)
+{
+    rb_io_t *fptr = RANY(obj)->as.file.fptr;
+    make_zombie(objspace, obj, rb_io_fptr_finalize_internal, fptr);
+}
+
+static void
+obj_free_object_id(rb_objspace_t *objspace, VALUE obj)
+{
+    ASSERT_vm_locking();
+    st_data_t o = (st_data_t)obj, id;
+
+    GC_ASSERT(FL_TEST(obj, FL_SEEN_OBJ_ID));
+    FL_UNSET(obj, FL_SEEN_OBJ_ID);
+
+    if (st_delete(objspace->obj_to_id_tbl, &o, &id)) {
+        GC_ASSERT(id);
+        st_delete(objspace->id_to_obj_tbl, &id, NULL);
+    }
+    else {
+        rb_bug("Object ID seen, but not in mapping table: %s\n", obj_info(obj));
+    }
+}
+
+static int
+obj_free(rb_objspace_t *objspace, VALUE obj)
+{
+    RB_DEBUG_COUNTER_INC(obj_free);
+    // RUBY_DEBUG_LOG("obj:%p (%s)", (void *)obj, obj_type_name(obj));
+
+    gc_event_hook(objspace, RUBY_INTERNAL_EVENT_FREEOBJ, obj);
+
+    switch (BUILTIN_TYPE(obj)) {
+      case T_NIL:
+      case T_FIXNUM:
+      case T_TRUE:
+      case T_FALSE:
+	rb_bug("obj_free() called for broken object");
+	break;
+      default:
+        break;
+    }
+
+    if (FL_TEST(obj, FL_EXIVAR)) {
+	rb_free_generic_ivar((VALUE)obj);
+	FL_UNSET(obj, FL_EXIVAR);
+    }
+
+    if (FL_TEST(obj, FL_SEEN_OBJ_ID) && !FL_TEST(obj, FL_FINALIZE)) {
+        obj_free_object_id(objspace, obj);
+    }
+
+    if (RVALUE_WB_UNPROTECTED(obj)) CLEAR_IN_BITMAP(GET_HEAP_WB_UNPROTECTED_BITS(obj), obj);
+
+#if RGENGC_CHECK_MODE
+#define CHECK(x) if (x(obj) != FALSE) rb_bug("obj_free: " #x "(%s) != FALSE", obj_info(obj))
+	CHECK(RVALUE_WB_UNPROTECTED);
+	CHECK(RVALUE_MARKED);
+	CHECK(RVALUE_MARKING);
+	CHECK(RVALUE_UNCOLLECTIBLE);
+#undef CHECK
+#endif
+
+    switch (BUILTIN_TYPE(obj)) {
+      case T_OBJECT:
+        if (RANY(obj)->as.basic.flags & ROBJECT_EMBED) {
+            RB_DEBUG_COUNTER_INC(obj_obj_embed);
+        }
+        else if (ROBJ_TRANSIENT_P(obj)) {
+            RB_DEBUG_COUNTER_INC(obj_obj_transient);
+        }
+        else {
+            xfree(RANY(obj)->as.object.as.heap.ivptr);
+            RB_DEBUG_COUNTER_INC(obj_obj_ptr);
+        }
+        break;
+      case T_MODULE:
+      case T_CLASS:
+        mjit_remove_class_serial(RCLASS_SERIAL(obj));
+	rb_id_table_free(RCLASS_M_TBL(obj));
+        cc_table_free(objspace, obj, FALSE);
+	if (RCLASS_IV_TBL(obj)) {
+	    st_free_table(RCLASS_IV_TBL(obj));
+	}
+	if (RCLASS_CONST_TBL(obj)) {
+	    rb_free_const_table(RCLASS_CONST_TBL(obj));
+	}
+	if (RCLASS_IV_INDEX_TBL(obj)) {
+            iv_index_tbl_free(RCLASS_IV_INDEX_TBL(obj));
+	}
+	if (RCLASS_EXT(obj)->subclasses) {
+	    if (BUILTIN_TYPE(obj) == T_MODULE) {
+		rb_class_detach_module_subclasses(obj);
+	    }
+	    else {
+		rb_class_detach_subclasses(obj);
+	    }
+	    RCLASS_EXT(obj)->subclasses = NULL;
+	}
+	rb_class_remove_from_module_subclasses(obj);
+	rb_class_remove_from_super_subclasses(obj);
+	if (RANY(obj)->as.klass.ptr)
+	    xfree(RANY(obj)->as.klass.ptr);
+	RANY(obj)->as.klass.ptr = NULL;
+
+        (void)RB_DEBUG_COUNTER_INC_IF(obj_module_ptr, BUILTIN_TYPE(obj) == T_MODULE);
+        (void)RB_DEBUG_COUNTER_INC_IF(obj_class_ptr, BUILTIN_TYPE(obj) == T_CLASS);
+	break;
+      case T_STRING:
+	rb_str_free(obj);
+	break;
+      case T_ARRAY:
+        rb_ary_free(obj);
+	break;
+      case T_HASH:
+#if USE_DEBUG_COUNTER
+        switch (RHASH_SIZE(obj)) {
+          case 0:
+            RB_DEBUG_COUNTER_INC(obj_hash_empty);
+            break;
+          case 1:
+            RB_DEBUG_COUNTER_INC(obj_hash_1);
+            break;
+          case 2:
+            RB_DEBUG_COUNTER_INC(obj_hash_2);
+            break;
+          case 3:
+            RB_DEBUG_COUNTER_INC(obj_hash_3);
+            break;
+          case 4:
+            RB_DEBUG_COUNTER_INC(obj_hash_4);
+            break;
+          case 5:
+          case 6:
+          case 7:
+          case 8:
+            RB_DEBUG_COUNTER_INC(obj_hash_5_8);
+            break;
+          default:
+            GC_ASSERT(RHASH_SIZE(obj) > 8);
+            RB_DEBUG_COUNTER_INC(obj_hash_g8);
+        }
+
+        if (RHASH_AR_TABLE_P(obj)) {
+            if (RHASH_AR_TABLE(obj) == NULL) {
+                RB_DEBUG_COUNTER_INC(obj_hash_null);
+            }
+            else {
+                RB_DEBUG_COUNTER_INC(obj_hash_ar);
+            }
+        }
+        else {
+            RB_DEBUG_COUNTER_INC(obj_hash_st);
+        }
+#endif
+        if (/* RHASH_AR_TABLE_P(obj) */ !FL_TEST_RAW(obj, RHASH_ST_TABLE_FLAG)) {
+            struct ar_table_struct *tab = RHASH(obj)->as.ar;
+
+            if (tab) {
+                if (RHASH_TRANSIENT_P(obj)) {
+                    RB_DEBUG_COUNTER_INC(obj_hash_transient);
+                }
+                else {
+                    ruby_xfree(tab);
+                }
+            }
+        }
+        else {
+            GC_ASSERT(RHASH_ST_TABLE_P(obj));
+            st_free_table(RHASH(obj)->as.st);
+        }
+	break;
+      case T_REGEXP:
+	if (RANY(obj)->as.regexp.ptr) {
+	    onig_free(RANY(obj)->as.regexp.ptr);
+            RB_DEBUG_COUNTER_INC(obj_regexp_ptr);
+	}
+	break;
+      case T_DATA:
+	if (DATA_PTR(obj)) {
+	    int free_immediately = FALSE;
+	    void (*dfree)(void *);
+	    void *data = DATA_PTR(obj);
+
+	    if (RTYPEDDATA_P(obj)) {
+		free_immediately = (RANY(obj)->as.typeddata.type->flags & RUBY_TYPED_FREE_IMMEDIATELY) != 0;
+		dfree = RANY(obj)->as.typeddata.type->function.dfree;
+		if (0 && free_immediately == 0) {
+		    /* to expose non-free-immediate T_DATA */
+		    fprintf(stderr, "not immediate -> %s\n", RANY(obj)->as.typeddata.type->wrap_struct_name);
+		}
+	    }
+	    else {
+		dfree = RANY(obj)->as.data.dfree;
+	    }
+
+	    if (dfree) {
+		if (dfree == RUBY_DEFAULT_FREE) {
+		    xfree(data);
+                    RB_DEBUG_COUNTER_INC(obj_data_xfree);
+		}
+		else if (free_immediately) {
+		    (*dfree)(data);
+                    RB_DEBUG_COUNTER_INC(obj_data_imm_free);
+		}
+		else {
+		    make_zombie(objspace, obj, dfree, data);
+                    RB_DEBUG_COUNTER_INC(obj_data_zombie);
+		    return 1;
+		}
+	    }
+            else {
+                RB_DEBUG_COUNTER_INC(obj_data_empty);
+            }
+	}
+	break;
+      case T_MATCH:
+	if (RANY(obj)->as.match.rmatch) {
+            struct rmatch *rm = RANY(obj)->as.match.rmatch;
+#if USE_DEBUG_COUNTER
+            if (rm->regs.num_regs >= 8) {
+                RB_DEBUG_COUNTER_INC(obj_match_ge8);
+            }
+            else if (rm->regs.num_regs >= 4) {
+                RB_DEBUG_COUNTER_INC(obj_match_ge4);
+            }
+            else if (rm->regs.num_regs >= 1) {
+                RB_DEBUG_COUNTER_INC(obj_match_under4);
+            }
+#endif
+	    onig_region_free(&rm->regs, 0);
+            if (rm->char_offset)
+		xfree(rm->char_offset);
+	    xfree(rm);
+
+            RB_DEBUG_COUNTER_INC(obj_match_ptr);
+	}
+	break;
+      case T_FILE:
+	if (RANY(obj)->as.file.fptr) {
+	    make_io_zombie(objspace, obj);
+            RB_DEBUG_COUNTER_INC(obj_file_ptr);
+	    return 1;
+	}
+	break;
+      case T_RATIONAL:
+        RB_DEBUG_COUNTER_INC(obj_rational);
+        break;
+      case T_COMPLEX:
+        RB_DEBUG_COUNTER_INC(obj_complex);
+        break;
+      case T_MOVED:
+	break;
+      case T_ICLASS:
+	/* Basically , T_ICLASS shares table with the module */
+        if (RICLASS_OWNS_M_TBL_P(obj)) {
+            /* Method table is not shared for origin iclasses of classes */
+            rb_id_table_free(RCLASS_M_TBL(obj));
+        }
+	if (RCLASS_CALLABLE_M_TBL(obj) != NULL) {
+	    rb_id_table_free(RCLASS_CALLABLE_M_TBL(obj));
+	}
+	if (RCLASS_EXT(obj)->subclasses) {
+	    rb_class_detach_subclasses(obj);
+	    RCLASS_EXT(obj)->subclasses = NULL;
+	}
+        cc_table_free(objspace, obj, FALSE);
+	rb_class_remove_from_module_subclasses(obj);
+	rb_class_remove_from_super_subclasses(obj);
+	xfree(RANY(obj)->as.klass.ptr);
+	RANY(obj)->as.klass.ptr = NULL;
+
+        RB_DEBUG_COUNTER_INC(obj_iclass_ptr);
+	break;
+
+      case T_FLOAT:
+        RB_DEBUG_COUNTER_INC(obj_float);
+	break;
+
+      case T_BIGNUM:
+	if (!BIGNUM_EMBED_P(obj) && BIGNUM_DIGITS(obj)) {
+	    xfree(BIGNUM_DIGITS(obj));
+            RB_DEBUG_COUNTER_INC(obj_bignum_ptr);
+	}
+        else {
+            RB_DEBUG_COUNTER_INC(obj_bignum_embed);
+        }
+	break;
+
+      case T_NODE:
+	UNEXPECTED_NODE(obj_free);
+	break;
+
+      case T_STRUCT:
+        if ((RBASIC(obj)->flags & RSTRUCT_EMBED_LEN_MASK) ||
+            RANY(obj)->as.rstruct.as.heap.ptr == NULL) {
+            RB_DEBUG_COUNTER_INC(obj_struct_embed);
+        }
+        else if (RSTRUCT_TRANSIENT_P(obj)) {
+            RB_DEBUG_COUNTER_INC(obj_struct_transient);
+        }
+        else {
+            xfree((void *)RANY(obj)->as.rstruct.as.heap.ptr);
+            RB_DEBUG_COUNTER_INC(obj_struct_ptr);
+	}
+	break;
+
+      case T_SYMBOL:
+	{
+            rb_gc_free_dsymbol(obj);
+            RB_DEBUG_COUNTER_INC(obj_symbol);
+	}
+	break;
+
+      case T_IMEMO:
+	switch (imemo_type(obj)) {
+	  case imemo_ment:
+	    rb_free_method_entry(&RANY(obj)->as.imemo.ment);
+            RB_DEBUG_COUNTER_INC(obj_imemo_ment);
+	    break;
+	  case imemo_iseq:
+	    rb_iseq_free(&RANY(obj)->as.imemo.iseq);
+            RB_DEBUG_COUNTER_INC(obj_imemo_iseq);
+	    break;
+	  case imemo_env:
+	    GC_ASSERT(VM_ENV_ESCAPED_P(RANY(obj)->as.imemo.env.ep));
+	    xfree((VALUE *)RANY(obj)->as.imemo.env.env);
+            RB_DEBUG_COUNTER_INC(obj_imemo_env);
+	    break;
+	  case imemo_tmpbuf:
+	    xfree(RANY(obj)->as.imemo.alloc.ptr);
+            RB_DEBUG_COUNTER_INC(obj_imemo_tmpbuf);
+	    break;
+	  case imemo_ast:
+	    rb_ast_free(&RANY(obj)->as.imemo.ast);
+            RB_DEBUG_COUNTER_INC(obj_imemo_ast);
+	    break;
+          case imemo_cref:
+            RB_DEBUG_COUNTER_INC(obj_imemo_cref);
+            break;
+          case imemo_svar:
+            RB_DEBUG_COUNTER_INC(obj_imemo_svar);
+            break;
+          case imemo_throw_data:
+            RB_DEBUG_COUNTER_INC(obj_imemo_throw_data);
+            break;
+          case imemo_ifunc:
+            RB_DEBUG_COUNTER_INC(obj_imemo_ifunc);
+            break;
+          case imemo_memo:
+            RB_DEBUG_COUNTER_INC(obj_imemo_memo);
+            break;
+          case imemo_parser_strterm:
+            RB_DEBUG_COUNTER_INC(obj_imemo_parser_strterm);
+            break;
+          case imemo_callinfo:
+            RB_DEBUG_COUNTER_INC(obj_imemo_callinfo);
+            break;
+          case imemo_callcache:
+            RB_DEBUG_COUNTER_INC(obj_imemo_callcache);
+            break;
+          case imemo_constcache:
+            RB_DEBUG_COUNTER_INC(obj_imemo_constcache);
+            break;
+	}
+	return 0;
+
+      default:
+	rb_bug("gc_sweep(): unknown data type 0x%x(%p) 0x%"PRIxVALUE,
+	       BUILTIN_TYPE(obj), (void*)obj, RBASIC(obj)->flags);
+    }
+
+    if (FL_TEST(obj, FL_FINALIZE)) {
+        make_zombie(objspace, obj, 0, 0);
+	return 1;
+    }
+    else {
+	return 0;
+    }
+}
+
+
+#define OBJ_ID_INCREMENT (sizeof(RVALUE) / 2)
+#define OBJ_ID_INITIAL (OBJ_ID_INCREMENT * 2)
+
+static int
+object_id_cmp(st_data_t x, st_data_t y)
+{
+    if (RB_TYPE_P(x, T_BIGNUM)) {
+        return !rb_big_eql(x, y);
+    } else {
+        return x != y;
+    }
+}
+
+static st_index_t
+object_id_hash(st_data_t n)
+{
+    if (RB_TYPE_P(n, T_BIGNUM)) {
+        return FIX2LONG(rb_big_hash(n));
+    } else {
+        return st_numhash(n);
+    }
+}
+static const struct st_hash_type object_id_hash_type = {
+    object_id_cmp,
+    object_id_hash,
+};
+
+void
+Init_heap(void)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+
+#if defined(HAVE_MMAP) && !HAVE_CONST_PAGE_SIZE && !defined(PAGE_MAX_SIZE)
+    /* Need to determine if we can use mmap at runtime. */
+# ifdef PAGE_SIZE
+    /* If the PAGE_SIZE macro can be used. */
+    use_mmap_aligned_alloc = PAGE_SIZE <= HEAP_PAGE_SIZE;
+# elif defined(HAVE_SYSCONF) && defined(_SC_PAGE_SIZE)
+    /* If we can use sysconf to determine the page size. */
+    use_mmap_aligned_alloc = sysconf(_SC_PAGE_SIZE) <= HEAP_PAGE_SIZE;
+# else
+    /* Otherwise we can't determine the system page size, so don't use mmap. */
+    use_mmap_aligned_alloc = FALSE;
+# endif
+#endif
+
+    objspace->next_object_id = INT2FIX(OBJ_ID_INITIAL);
+    objspace->id_to_obj_tbl = st_init_table(&object_id_hash_type);
+    objspace->obj_to_id_tbl = st_init_numtable();
+
+#if RGENGC_ESTIMATE_OLDMALLOC
+    objspace->rgengc.oldmalloc_increase_limit = gc_params.oldmalloc_limit_min;
+#endif
+
+    heap_add_pages(objspace, heap_eden, gc_params.heap_init_slots / HEAP_PAGE_OBJ_LIMIT);
+    init_mark_stack(&objspace->mark_stack);
+
+    objspace->profile.invoke_time = getrusage_time();
+    finalizer_table = st_init_numtable();
+}
+
+void
+Init_gc_stress(void)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+
+    gc_stress_set(objspace, ruby_initial_gc_stress);
+}
+
+typedef int each_obj_callback(void *, void *, size_t, void *);
+
+static void objspace_each_objects(rb_objspace_t *objspace, each_obj_callback *callback, void *data);
+static void objspace_reachable_objects_from_root(rb_objspace_t *, void (func)(const char *, VALUE, void *), void *);
+
+struct each_obj_args {
+    rb_objspace_t *objspace;
+    each_obj_callback *callback;
+    void *data;
+};
+
+static void
+objspace_each_objects_without_setup(rb_objspace_t *objspace, each_obj_callback *callback, void *data)
+{
+    size_t i;
+    struct heap_page *page;
+    RVALUE *pstart = NULL, *pend;
+
+    i = 0;
+    while (i < heap_allocated_pages) {
+	while (0 < i && pstart < heap_pages_sorted[i-1]->start)              i--;
+	while (i < heap_allocated_pages && heap_pages_sorted[i]->start <= pstart) i++;
+	if (heap_allocated_pages <= i) break;
+
+	page = heap_pages_sorted[i];
+
+	pstart = page->start;
+	pend = pstart + page->total_slots;
+
+        if ((*callback)(pstart, pend, sizeof(RVALUE), data)) {
+	    break;
+	}
+    }
+}
+
+static VALUE
+objspace_each_objects_protected(VALUE arg)
+{
+    struct each_obj_args *args = (struct each_obj_args *)arg;
+    objspace_each_objects_without_setup(args->objspace, args->callback, args->data);
+    return Qnil;
+}
+
+static VALUE
+incremental_enable(VALUE _)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+
+    objspace->flags.dont_incremental = FALSE;
+    return Qnil;
+}
+
+/*
+ * rb_objspace_each_objects() is special C API to walk through
+ * Ruby object space.  This C API is too difficult to use it.
+ * To be frank, you should not use it. Or you need to read the
+ * source code of this function and understand what this function does.
+ *
+ * 'callback' will be called several times (the number of heap page,
+ * at current implementation) with:
+ *   vstart: a pointer to the first living object of the heap_page.
+ *   vend: a pointer to next to the valid heap_page area.
+ *   stride: a distance to next VALUE.
+ *
+ * If callback() returns non-zero, the iteration will be stopped.
+ *
+ * This is a sample callback code to iterate liveness objects:
+ *
+ *   int
+ *   sample_callback(void *vstart, void *vend, int stride, void *data) {
+ *     VALUE v = (VALUE)vstart;
+ *     for (; v != (VALUE)vend; v += stride) {
+ *       if (RBASIC(v)->flags) { // liveness check
+ *       // do something with live object 'v'
+ *     }
+ *     return 0; // continue to iteration
+ *   }
+ *
+ * Note: 'vstart' is not a top of heap_page.  This point the first
+ *       living object to grasp at least one object to avoid GC issue.
+ *       This means that you can not walk through all Ruby object page
+ *       including freed object page.
+ *
+ * Note: On this implementation, 'stride' is same as sizeof(RVALUE).
+ *       However, there are possibilities to pass variable values with
+ *       'stride' with some reasons.  You must use stride instead of
+ *       use some constant value in the iteration.
+ */
+void
+rb_objspace_each_objects(each_obj_callback *callback, void *data)
+{
+    objspace_each_objects(&rb_objspace, callback, data);
+}
+
+static void
+objspace_each_objects(rb_objspace_t *objspace, each_obj_callback *callback, void *data)
+{
+    int prev_dont_incremental = objspace->flags.dont_incremental;
+
+    gc_rest(objspace);
+    objspace->flags.dont_incremental = TRUE;
+
+    if (prev_dont_incremental) {
+        objspace_each_objects_without_setup(objspace, callback, data);
+    }
+    else {
+        struct each_obj_args args = {objspace, callback, data};
+        rb_ensure(objspace_each_objects_protected, (VALUE)&args, incremental_enable, Qnil);
+    }
+}
+
+void
+rb_objspace_each_objects_without_setup(each_obj_callback *callback, void *data)
+{
+    objspace_each_objects_without_setup(&rb_objspace, callback, data);
+}
+
+struct os_each_struct {
+    size_t num;
+    VALUE of;
+};
+
+static int
+internal_object_p(VALUE obj)
+{
+    RVALUE *p = (RVALUE *)obj;
+    void *ptr = __asan_region_is_poisoned(p, SIZEOF_VALUE);
+    asan_unpoison_object(obj, false);
+    bool used_p = p->as.basic.flags;
+
+    if (used_p) {
+        switch (BUILTIN_TYPE(obj)) {
+	  case T_NODE:
+	    UNEXPECTED_NODE(internal_object_p);
+	    break;
+	  case T_NONE:
+          case T_MOVED:
+	  case T_IMEMO:
+	  case T_ICLASS:
+	  case T_ZOMBIE:
+	    break;
+	  case T_CLASS:
+	    if (!p->as.basic.klass) break;
+	    if (FL_TEST(obj, FL_SINGLETON)) {
+		return rb_singleton_class_internal_p(obj);
+	    }
+	    return 0;
+	  default:
+	    if (!p->as.basic.klass) break;
+	    return 0;
+	}
+    }
+    if (ptr || ! used_p) {
+        asan_poison_object(obj);
+    }
+    return 1;
+}
+
+int
+rb_objspace_internal_object_p(VALUE obj)
+{
+    return internal_object_p(obj);
+}
+
+static int
+os_obj_of_i(void *vstart, void *vend, size_t stride, void *data)
+{
+    struct os_each_struct *oes = (struct os_each_struct *)data;
+    RVALUE *p = (RVALUE *)vstart, *pend = (RVALUE *)vend;
+
+    for (; p != pend; p++) {
+	volatile VALUE v = (VALUE)p;
+	if (!internal_object_p(v)) {
+	    if (!oes->of || rb_obj_is_kind_of(v, oes->of)) {
+                if (!rb_multi_ractor_p() || rb_ractor_shareable_p(v)) {
+                    rb_yield(v);
+                    oes->num++;
+                }
+	    }
+	}
+    }
+
+    return 0;
+}
+
+static VALUE
+os_obj_of(VALUE of)
+{
+    struct os_each_struct oes;
+
+    oes.num = 0;
+    oes.of = of;
+    rb_objspace_each_objects(os_obj_of_i, &oes);
+    return SIZET2NUM(oes.num);
+}
+
+/*
+ *  call-seq:
+ *     ObjectSpace.each_object([module]) {|obj| ... } -> integer
+ *     ObjectSpace.each_object([module])              -> an_enumerator
+ *
+ *  Calls the block once for each living, nonimmediate object in this
+ *  Ruby process. If <i>module</i> is specified, calls the block
+ *  for only those classes or modules that match (or are a subclass of)
+ *  <i>module</i>. Returns the number of objects found. Immediate
+ *  objects (<code>Fixnum</code>s, <code>Symbol</code>s
+ *  <code>true</code>, <code>false</code>, and <code>nil</code>) are
+ *  never returned. In the example below, #each_object returns both
+ *  the numbers we defined and several constants defined in the Math
+ *  module.
+ *
+ *  If no block is given, an enumerator is returned instead.
+ *
+ *     a = 102.7
+ *     b = 95       # Won't be returned
+ *     c = 12345678987654321
+ *     count = ObjectSpace.each_object(Numeric) {|x| p x }
+ *     puts "Total count: #{count}"
+ *
+ *  <em>produces:</em>
+ *
+ *     12345678987654321
+ *     102.7
+ *     2.71828182845905
+ *     3.14159265358979
+ *     2.22044604925031e-16
+ *     1.7976931348623157e+308
+ *     2.2250738585072e-308
+ *     Total count: 7
+ *
+ */
+
+static VALUE
+os_each_obj(int argc, VALUE *argv, VALUE os)
+{
+    VALUE of;
+
+    of = (!rb_check_arity(argc, 0, 1) ? 0 : argv[0]);
+    RETURN_ENUMERATOR(os, 1, &of);
+    return os_obj_of(of);
+}
+
+/*
+ *  call-seq:
+ *     ObjectSpace.undefine_finalizer(obj)
+ *
+ *  Removes all finalizers for <i>obj</i>.
+ *
+ */
+
+static VALUE
+undefine_final(VALUE os, VALUE obj)
+{
+    return rb_undefine_finalizer(obj);
+}
+
+VALUE
+rb_undefine_finalizer(VALUE obj)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    st_data_t data = obj;
+    rb_check_frozen(obj);
+    st_delete(finalizer_table, &data, 0);
+    FL_UNSET(obj, FL_FINALIZE);
+    return obj;
+}
+
+static void
+should_be_callable(VALUE block)
+{
+    if (!rb_obj_respond_to(block, idCall, TRUE)) {
+	rb_raise(rb_eArgError, "wrong type argument %"PRIsVALUE" (should be callable)",
+		 rb_obj_class(block));
+    }
+}
+
+static void
+should_be_finalizable(VALUE obj)
+{
+    if (!FL_ABLE(obj)) {
+	rb_raise(rb_eArgError, "cannot define finalizer for %s",
+		 rb_obj_classname(obj));
+    }
+    rb_check_frozen(obj);
+}
+
+/*
+ *  call-seq:
+ *     ObjectSpace.define_finalizer(obj, aProc=proc())
+ *
+ *  Adds <i>aProc</i> as a finalizer, to be called after <i>obj</i>
+ *  was destroyed. The object ID of the <i>obj</i> will be passed
+ *  as an argument to <i>aProc</i>. If <i>aProc</i> is a lambda or
+ *  method, make sure it can be called with a single argument.
+ *
+ *  The return value is an array <code>[0, aProc]</code>.
+ *
+ *  The two recommended patterns are to either create the finaliser proc
+ *  in a non-instance method where it can safely capture the needed state,
+ *  or to use a custom callable object that stores the needed state
+ *  explicitly as instance variables.
+ *
+ *      class Foo
+ *        def initialize(data_needed_for_finalization)
+ *          ObjectSpace.define_finalizer(self, self.class.create_finalizer(data_needed_for_finalization))
+ *        end
+ *
+ *        def self.create_finalizer(data_needed_for_finalization)
+ *          proc {
+ *            puts "finalizing #{data_needed_for_finalization}"
+ *          }
+ *        end
+ *      end
+ *
+ *      class Bar
+ *       class Remover
+ *          def initialize(data_needed_for_finalization)
+ *            @data_needed_for_finalization = data_needed_for_finalization
+ *          end
+ *
+ *          def call(id)
+ *            puts "finalizing #{@data_needed_for_finalization}"
+ *          end
+ *        end
+ *
+ *        def initialize(data_needed_for_finalization)
+ *          ObjectSpace.define_finalizer(self, Remover.new(data_needed_for_finalization))
+ *        end
+ *      end
+ *
+ *  Note that if your finalizer references the object to be
+ *  finalized it will never be run on GC, although it will still be
+ *  run at exit. You will get a warning if you capture the object
+ *  to be finalized as the receiver of the finalizer.
+ *
+ *      class CapturesSelf
+ *        def initialize(name)
+ *          ObjectSpace.define_finalizer(self, proc {
+ *            # this finalizer will only be run on exit
+ *            puts "finalizing #{name}"
+ *          })
+ *        end
+ *      end
+ *
+ *  Also note that finalization can be unpredictable and is never guaranteed
+ *  to be run except on exit.
+ */
+
+static VALUE
+define_final(int argc, VALUE *argv, VALUE os)
+{
+    VALUE obj, block;
+
+    rb_scan_args(argc, argv, "11", &obj, &block);
+    should_be_finalizable(obj);
+    if (argc == 1) {
+	block = rb_block_proc();
+    }
+    else {
+	should_be_callable(block);
+    }
+
+    if (rb_callable_receiver(block) == obj) {
+        rb_warn("finalizer references object to be finalized");
+    }
+
+    return define_final0(obj, block);
+}
+
+static VALUE
+define_final0(VALUE obj, VALUE block)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    VALUE table;
+    st_data_t data;
+
+    RBASIC(obj)->flags |= FL_FINALIZE;
+
+    block = rb_ary_new3(2, INT2FIX(0), block);
+    OBJ_FREEZE(block);
+
+    if (st_lookup(finalizer_table, obj, &data)) {
+	table = (VALUE)data;
+
+	/* avoid duplicate block, table is usually small */
+	{
+	    long len = RARRAY_LEN(table);
+	    long i;
+
+            for (i = 0; i < len; i++) {
+                VALUE recv = RARRAY_AREF(table, i);
+                if (rb_funcall(recv, idEq, 1, block)) {
+                    return recv;
+		}
+	    }
+	}
+
+	rb_ary_push(table, block);
+    }
+    else {
+	table = rb_ary_new3(1, block);
+	RBASIC_CLEAR_CLASS(table);
+	st_add_direct(finalizer_table, obj, table);
+    }
+    return block;
+}
+
+VALUE
+rb_define_finalizer(VALUE obj, VALUE block)
+{
+    should_be_finalizable(obj);
+    should_be_callable(block);
+    return define_final0(obj, block);
+}
+
+void
+rb_gc_copy_finalizer(VALUE dest, VALUE obj)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    VALUE table;
+    st_data_t data;
+
+    if (!FL_TEST(obj, FL_FINALIZE)) return;
+    if (st_lookup(finalizer_table, obj, &data)) {
+	table = (VALUE)data;
+	st_insert(finalizer_table, dest, table);
+    }
+    FL_SET(dest, FL_FINALIZE);
+}
+
+static VALUE
+run_single_final(VALUE final, VALUE objid)
+{
+    const VALUE cmd = RARRAY_AREF(final, 1);
+    return rb_check_funcall(cmd, idCall, 1, &objid);
+}
+
+static void
+run_finalizer(rb_objspace_t *objspace, VALUE obj, VALUE table)
+{
+    long i;
+    enum ruby_tag_type state;
+    volatile struct {
+	VALUE errinfo;
+	VALUE objid;
+	rb_control_frame_t *cfp;
+	long finished;
+    } saved;
+    rb_execution_context_t * volatile ec = GET_EC();
+#define RESTORE_FINALIZER() (\
+	ec->cfp = saved.cfp, \
+	rb_set_errinfo(saved.errinfo))
+
+    saved.errinfo = rb_errinfo();
+    saved.objid = rb_obj_id(obj);
+    saved.cfp = ec->cfp;
+    saved.finished = 0;
+
+    EC_PUSH_TAG(ec);
+    state = EC_EXEC_TAG();
+    if (state != TAG_NONE) {
+	++saved.finished;	/* skip failed finalizer */
+    }
+    for (i = saved.finished;
+	 RESTORE_FINALIZER(), i<RARRAY_LEN(table);
+	 saved.finished = ++i) {
+	run_single_final(RARRAY_AREF(table, i), saved.objid);
+    }
+    EC_POP_TAG();
+#undef RESTORE_FINALIZER
+}
+
+static void
+run_final(rb_objspace_t *objspace, VALUE zombie)
+{
+    st_data_t key, table;
+
+    if (RZOMBIE(zombie)->dfree) {
+	RZOMBIE(zombie)->dfree(RZOMBIE(zombie)->data);
+    }
+
+    key = (st_data_t)zombie;
+    if (st_delete(finalizer_table, &key, &table)) {
+	run_finalizer(objspace, zombie, (VALUE)table);
+    }
+}
+
+static void
+finalize_list(rb_objspace_t *objspace, VALUE zombie)
+{
+    while (zombie) {
+        VALUE next_zombie;
+        struct heap_page *page;
+        asan_unpoison_object(zombie, false);
+        next_zombie = RZOMBIE(zombie)->next;
+        page = GET_HEAP_PAGE(zombie);
+
+	run_final(objspace, zombie);
+
+        RB_VM_LOCK_ENTER();
+        {
+            GC_ASSERT(BUILTIN_TYPE(zombie) == T_ZOMBIE);
+            if (FL_TEST(zombie, FL_SEEN_OBJ_ID)) {
+                obj_free_object_id(objspace, zombie);
+            }
+
+            RZOMBIE(zombie)->basic.flags = 0;
+            GC_ASSERT(heap_pages_final_slots > 0);
+            GC_ASSERT(page->final_slots > 0);
+
+            heap_pages_final_slots--;
+            page->final_slots--;
+            page->free_slots++;
+            heap_page_add_freeobj(objspace, GET_HEAP_PAGE(zombie), zombie);
+            objspace->profile.total_freed_objects++;
+        }
+        RB_VM_LOCK_LEAVE();
+
+        zombie = next_zombie;
+    }
+}
+
+static void
+finalize_deferred(rb_objspace_t *objspace)
+{
+    VALUE zombie;
+
+    while ((zombie = ATOMIC_VALUE_EXCHANGE(heap_pages_deferred_final, 0)) != 0) {
+	finalize_list(objspace, zombie);
+    }
+}
+
+static void
+gc_finalize_deferred(void *dmy)
+{
+    rb_objspace_t *objspace = dmy;
+    if (ATOMIC_EXCHANGE(finalizing, 1)) return;
+
+    RB_VM_LOCK_ENTER();
+    {
+        finalize_deferred(objspace);
+        ATOMIC_SET(finalizing, 0);
+    }
+    RB_VM_LOCK_LEAVE();
+}
+
+static void
+gc_finalize_deferred_register(rb_objspace_t *objspace)
+{
+    if (rb_postponed_job_register_one(0, gc_finalize_deferred, objspace) == 0) {
+	rb_bug("gc_finalize_deferred_register: can't register finalizer.");
+    }
+}
+
+struct force_finalize_list {
+    VALUE obj;
+    VALUE table;
+    struct force_finalize_list *next;
+};
+
+static int
+force_chain_object(st_data_t key, st_data_t val, st_data_t arg)
+{
+    struct force_finalize_list **prev = (struct force_finalize_list **)arg;
+    struct force_finalize_list *curr = ALLOC(struct force_finalize_list);
+    curr->obj = key;
+    curr->table = val;
+    curr->next = *prev;
+    *prev = curr;
+    return ST_CONTINUE;
+}
+
+bool rb_obj_is_main_ractor(VALUE gv);
+
+void
+rb_objspace_call_finalizer(rb_objspace_t *objspace)
+{
+    RVALUE *p, *pend;
+    size_t i;
+
+#if RGENGC_CHECK_MODE >= 2
+    gc_verify_internal_consistency(objspace);
+#endif
+    gc_rest(objspace);
+
+    if (ATOMIC_EXCHANGE(finalizing, 1)) return;
+
+    /* run finalizers */
+    finalize_deferred(objspace);
+    GC_ASSERT(heap_pages_deferred_final == 0);
+
+    gc_rest(objspace);
+    /* prohibit incremental GC */
+    objspace->flags.dont_incremental = 1;
+
+    /* force to run finalizer */
+    while (finalizer_table->num_entries) {
+	struct force_finalize_list *list = 0;
+	st_foreach(finalizer_table, force_chain_object, (st_data_t)&list);
+	while (list) {
+	    struct force_finalize_list *curr = list;
+	    st_data_t obj = (st_data_t)curr->obj;
+	    run_finalizer(objspace, curr->obj, curr->table);
+	    st_delete(finalizer_table, &obj, 0);
+	    list = curr->next;
+	    xfree(curr);
+	}
+    }
+
+    /* prohibit GC because force T_DATA finalizers can break an object graph consistency */
+    dont_gc_on();
+
+    /* running data/file finalizers are part of garbage collection */
+    unsigned int lock_lev;
+    gc_enter(objspace, gc_enter_event_finalizer, &lock_lev);
+
+    /* run data/file object's finalizers */
+    for (i = 0; i < heap_allocated_pages; i++) {
+	p = heap_pages_sorted[i]->start; pend = p + heap_pages_sorted[i]->total_slots;
+	while (p < pend) {
+            VALUE vp = (VALUE)p;
+            void *poisoned = asan_poisoned_object_p(vp);
+            asan_unpoison_object(vp, false);
+            switch (BUILTIN_TYPE(vp)) {
+	      case T_DATA:
+		if (!DATA_PTR(p) || !RANY(p)->as.data.dfree) break;
+                if (rb_obj_is_thread(vp)) break;
+                if (rb_obj_is_mutex(vp)) break;
+                if (rb_obj_is_fiber(vp)) break;
+                if (rb_obj_is_main_ractor(vp)) break;
+                if (RTYPEDDATA_P(vp)) {
+		    RDATA(p)->dfree = RANY(p)->as.typeddata.type->function.dfree;
+		}
+                p->as.free.flags = 0;
+		if (RANY(p)->as.data.dfree == RUBY_DEFAULT_FREE) {
+		    xfree(DATA_PTR(p));
+		}
+		else if (RANY(p)->as.data.dfree) {
+                    make_zombie(objspace, vp, RANY(p)->as.data.dfree, RANY(p)->as.data.data);
+		}
+		break;
+	      case T_FILE:
+		if (RANY(p)->as.file.fptr) {
+                    make_io_zombie(objspace, vp);
+		}
+		break;
+              default:
+                break;
+	    }
+            if (poisoned) {
+                GC_ASSERT(BUILTIN_TYPE(vp) == T_NONE);
+                asan_poison_object(vp);
+            }
+	    p++;
+	}
+    }
+
+    gc_exit(objspace, gc_enter_event_finalizer, &lock_lev);
+
+    if (heap_pages_deferred_final) {
+	finalize_list(objspace, heap_pages_deferred_final);
+    }
+
+    st_free_table(finalizer_table);
+    finalizer_table = 0;
+    ATOMIC_SET(finalizing, 0);
+}
+
+static inline int
+heap_is_swept_object(rb_objspace_t *objspace, rb_heap_t *heap, VALUE ptr)
+{
+    struct heap_page *page = GET_HEAP_PAGE(ptr);
+    return page->flags.before_sweep ? FALSE : TRUE;
+}
+
+static inline int
+is_swept_object(rb_objspace_t *objspace, VALUE ptr)
+{
+    if (heap_is_swept_object(objspace, heap_eden, ptr)) {
+	return TRUE;
+    }
+    else {
+	return FALSE;
+    }
+}
+
+/* garbage objects will be collected soon. */
+static inline int
+is_garbage_object(rb_objspace_t *objspace, VALUE ptr)
+{
+    if (!is_lazy_sweeping(heap_eden) ||
+	is_swept_object(objspace, ptr) ||
+	MARKED_IN_BITMAP(GET_HEAP_MARK_BITS(ptr), ptr)) {
+
+	return FALSE;
+    }
+    else {
+	return TRUE;
+    }
+}
+
+static inline int
+is_live_object(rb_objspace_t *objspace, VALUE ptr)
+{
+    switch (BUILTIN_TYPE(ptr)) {
+      case T_NONE:
+      case T_MOVED:
+      case T_ZOMBIE:
+	return FALSE;
+      default:
+        break;
+    }
+
+    if (!is_garbage_object(objspace, ptr)) {
+	return TRUE;
+    }
+    else {
+	return FALSE;
+    }
+}
+
+static inline int
+is_markable_object(rb_objspace_t *objspace, VALUE obj)
+{
+    if (rb_special_const_p(obj)) return FALSE; /* special const is not markable */
+    check_rvalue_consistency(obj);
+    return TRUE;
+}
+
+int
+rb_objspace_markable_object_p(VALUE obj)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return is_markable_object(objspace, obj) && is_live_object(objspace, obj);
+}
+
+int
+rb_objspace_garbage_object_p(VALUE obj)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return is_garbage_object(objspace, obj);
+}
+
+static VALUE
+id2ref_obj_tbl(rb_objspace_t *objspace, VALUE objid)
+{
+    VALUE orig;
+    if (st_lookup(objspace->id_to_obj_tbl, objid, &orig)) {
+        return orig;
+    }
+    else {
+        return Qundef;
+    }
+}
+
+/*
+ *  call-seq:
+ *     ObjectSpace._id2ref(object_id) -> an_object
+ *
+ *  Converts an object id to a reference to the object. May not be
+ *  called on an object id passed as a parameter to a finalizer.
+ *
+ *     s = "I am a string"                    #=> "I am a string"
+ *     r = ObjectSpace._id2ref(s.object_id)   #=> "I am a string"
+ *     r == s                                 #=> true
+ *
+ *  On multi-ractor mode, if the object is not sharable, it raises
+ *  RangeError.
+ */
+
+static VALUE
+id2ref(VALUE objid)
+{
+#if SIZEOF_LONG == SIZEOF_VOIDP
+#define NUM2PTR(x) NUM2ULONG(x)
+#elif SIZEOF_LONG_LONG == SIZEOF_VOIDP
+#define NUM2PTR(x) NUM2ULL(x)
+#endif
+    rb_objspace_t *objspace = &rb_objspace;
+    VALUE ptr;
+    VALUE orig;
+    void *p0;
+
+    objid = rb_to_int(objid);
+    if (FIXNUM_P(objid) || rb_big_size(objid) <= SIZEOF_VOIDP) {
+        ptr = NUM2PTR(objid);
+        if (ptr == Qtrue) return Qtrue;
+        if (ptr == Qfalse) return Qfalse;
+        if (ptr == Qnil) return Qnil;
+        if (FIXNUM_P(ptr)) return (VALUE)ptr;
+        if (FLONUM_P(ptr)) return (VALUE)ptr;
+
+        ptr = obj_id_to_ref(objid);
+        if ((ptr % sizeof(RVALUE)) == (4 << 2)) {
+            ID symid = ptr / sizeof(RVALUE);
+            p0 = (void *)ptr;
+            if (rb_id2str(symid) == 0)
+                rb_raise(rb_eRangeError, "%p is not symbol id value", p0);
+            return ID2SYM(symid);
+        }
+    }
+
+    if ((orig = id2ref_obj_tbl(objspace, objid)) != Qundef &&
+        is_live_object(objspace, orig)) {
+
+        if (!rb_multi_ractor_p() || rb_ractor_shareable_p(orig)) {
+            return orig;
+        }
+        else {
+            rb_raise(rb_eRangeError, "%+"PRIsVALUE" is id of the unshareable object on multi-ractor", rb_int2str(objid, 10));
+        }
+    }
+
+    if (rb_int_ge(objid, objspace->next_object_id)) {
+        rb_raise(rb_eRangeError, "%+"PRIsVALUE" is not id value", rb_int2str(objid, 10));
+    } else {
+        rb_raise(rb_eRangeError, "%+"PRIsVALUE" is recycled object", rb_int2str(objid, 10));
+    }
+}
+
+static VALUE
+os_id2ref(VALUE os, VALUE objid)
+{
+    return id2ref(objid);
+}
+
+static VALUE
+rb_find_object_id(VALUE obj, VALUE (*get_heap_object_id)(VALUE))
+{
+    if (STATIC_SYM_P(obj)) {
+        return (SYM2ID(obj) * sizeof(RVALUE) + (4 << 2)) | FIXNUM_FLAG;
+    }
+    else if (FLONUM_P(obj)) {
+#if SIZEOF_LONG == SIZEOF_VOIDP
+        return LONG2NUM((SIGNED_VALUE)obj);
+#else
+        return LL2NUM((SIGNED_VALUE)obj);
+#endif
+    }
+    else if (SPECIAL_CONST_P(obj)) {
+        return LONG2NUM((SIGNED_VALUE)obj);
+    }
+
+    return get_heap_object_id(obj);
+}
+
+static VALUE
+cached_object_id(VALUE obj)
+{
+    VALUE id;
+    rb_objspace_t *objspace = &rb_objspace;
+
+    RB_VM_LOCK_ENTER();
+    if (st_lookup(objspace->obj_to_id_tbl, (st_data_t)obj, &id)) {
+        GC_ASSERT(FL_TEST(obj, FL_SEEN_OBJ_ID));
+    }
+    else {
+        GC_ASSERT(!FL_TEST(obj, FL_SEEN_OBJ_ID));
+
+        id = objspace->next_object_id;
+        objspace->next_object_id = rb_int_plus(id, INT2FIX(OBJ_ID_INCREMENT));
+
+        VALUE already_disabled = rb_gc_disable_no_rest();
+        st_insert(objspace->obj_to_id_tbl, (st_data_t)obj, (st_data_t)id);
+        st_insert(objspace->id_to_obj_tbl, (st_data_t)id, (st_data_t)obj);
+        if (already_disabled == Qfalse) rb_objspace_gc_enable(objspace);
+        FL_SET(obj, FL_SEEN_OBJ_ID);
+    }
+    RB_VM_LOCK_LEAVE();
+
+    return id;
+}
+
+static VALUE
+nonspecial_obj_id_(VALUE obj)
+{
+    return nonspecial_obj_id(obj);
+}
+
+
+VALUE
+rb_memory_id(VALUE obj)
+{
+    return rb_find_object_id(obj, nonspecial_obj_id_);
+}
+
+/*
+ *  Document-method: __id__
+ *  Document-method: object_id
+ *
+ *  call-seq:
+ *     obj.__id__       -> integer
+ *     obj.object_id    -> integer
+ *
+ *  Returns an integer identifier for +obj+.
+ *
+ *  The same number will be returned on all calls to +object_id+ for a given
+ *  object, and no two active objects will share an id.
+ *
+ *  Note: that some objects of builtin classes are reused for optimization.
+ *  This is the case for immediate values and frozen string literals.
+ *
+ *  BasicObject implements +__id__+, Kernel implements +object_id+.
+ *
+ *  Immediate values are not passed by reference but are passed by value:
+ *  +nil+, +true+, +false+, Fixnums, Symbols, and some Floats.
+ *
+ *      Object.new.object_id  == Object.new.object_id  # => false
+ *      (21 * 2).object_id    == (21 * 2).object_id    # => true
+ *      "hello".object_id     == "hello".object_id     # => false
+ *      "hi".freeze.object_id == "hi".freeze.object_id # => true
+ */
+
+VALUE
+rb_obj_id(VALUE obj)
+{
+    /*
+     *                32-bit VALUE space
+     *          MSB ------------------------ LSB
+     *  false   00000000000000000000000000000000
+     *  true    00000000000000000000000000000010
+     *  nil     00000000000000000000000000000100
+     *  undef   00000000000000000000000000000110
+     *  symbol  ssssssssssssssssssssssss00001110
+     *  object  oooooooooooooooooooooooooooooo00        = 0 (mod sizeof(RVALUE))
+     *  fixnum  fffffffffffffffffffffffffffffff1
+     *
+     *                    object_id space
+     *                                       LSB
+     *  false   00000000000000000000000000000000
+     *  true    00000000000000000000000000000010
+     *  nil     00000000000000000000000000000100
+     *  undef   00000000000000000000000000000110
+     *  symbol   000SSSSSSSSSSSSSSSSSSSSSSSSSSS0        S...S % A = 4 (S...S = s...s * A + 4)
+     *  object   oooooooooooooooooooooooooooooo0        o...o % A = 0
+     *  fixnum  fffffffffffffffffffffffffffffff1        bignum if required
+     *
+     *  where A = sizeof(RVALUE)/4
+     *
+     *  sizeof(RVALUE) is
+     *  20 if 32-bit, double is 4-byte aligned
+     *  24 if 32-bit, double is 8-byte aligned
+     *  40 if 64-bit
+     */
+
+    return rb_find_object_id(obj, cached_object_id);
+}
+
+static enum rb_id_table_iterator_result
+cc_table_memsize_i(VALUE ccs_ptr, void *data_ptr)
+{
+    size_t *total_size = data_ptr;
+    struct rb_class_cc_entries *ccs = (struct rb_class_cc_entries *)ccs_ptr;
+    *total_size += sizeof(*ccs);
+    *total_size += sizeof(ccs->entries[0]) * ccs->capa;
+    return ID_TABLE_CONTINUE;
+}
+
+static size_t
+cc_table_memsize(struct rb_id_table *cc_table)
+{
+    size_t total = rb_id_table_memsize(cc_table);
+    rb_id_table_foreach_values(cc_table, cc_table_memsize_i, &total);
+    return total;
+}
+
+static size_t
+obj_memsize_of(VALUE obj, int use_all_types)
+{
+    size_t size = 0;
+
+    if (SPECIAL_CONST_P(obj)) {
+	return 0;
+    }
+
+    if (FL_TEST(obj, FL_EXIVAR)) {
+	size += rb_generic_ivar_memsize(obj);
+    }
+
+    switch (BUILTIN_TYPE(obj)) {
+      case T_OBJECT:
+	if (!(RBASIC(obj)->flags & ROBJECT_EMBED)) {
+	    size += ROBJECT_NUMIV(obj) * sizeof(VALUE);
+	}
+	break;
+      case T_MODULE:
+      case T_CLASS:
+	if (RCLASS_EXT(obj)) {
+            if (RCLASS_M_TBL(obj)) {
+                size += rb_id_table_memsize(RCLASS_M_TBL(obj));
+            }
+	    if (RCLASS_IV_TBL(obj)) {
+		size += st_memsize(RCLASS_IV_TBL(obj));
+	    }
+	    if (RCLASS_IV_INDEX_TBL(obj)) {
+                // TODO: more correct value
+		size += st_memsize(RCLASS_IV_INDEX_TBL(obj));
+	    }
+	    if (RCLASS(obj)->ptr->iv_tbl) {
+		size += st_memsize(RCLASS(obj)->ptr->iv_tbl);
+	    }
+	    if (RCLASS(obj)->ptr->const_tbl) {
+		size += rb_id_table_memsize(RCLASS(obj)->ptr->const_tbl);
+	    }
+            if (RCLASS_CC_TBL(obj)) {
+                size += cc_table_memsize(RCLASS_CC_TBL(obj));
+            }
+	    size += sizeof(rb_classext_t);
+	}
+	break;
+      case T_ICLASS:
+        if (RICLASS_OWNS_M_TBL_P(obj)) {
+	    if (RCLASS_M_TBL(obj)) {
+		size += rb_id_table_memsize(RCLASS_M_TBL(obj));
+	    }
+	}
+        if (RCLASS_EXT(obj) && RCLASS_CC_TBL(obj)) {
+            size += cc_table_memsize(RCLASS_CC_TBL(obj));
+        }
+	break;
+      case T_STRING:
+	size += rb_str_memsize(obj);
+	break;
+      case T_ARRAY:
+	size += rb_ary_memsize(obj);
+	break;
+      case T_HASH:
+        if (RHASH_AR_TABLE_P(obj)) {
+            if (RHASH_AR_TABLE(obj) != NULL) {
+                size_t rb_hash_ar_table_size();
+                size += rb_hash_ar_table_size();
+            }
+	}
+        else {
+            VM_ASSERT(RHASH_ST_TABLE(obj) != NULL);
+            size += st_memsize(RHASH_ST_TABLE(obj));
+        }
+	break;
+      case T_REGEXP:
+	if (RREGEXP_PTR(obj)) {
+	    size += onig_memsize(RREGEXP_PTR(obj));
+	}
+	break;
+      case T_DATA:
+	if (use_all_types) size += rb_objspace_data_type_memsize(obj);
+	break;
+      case T_MATCH:
+	if (RMATCH(obj)->rmatch) {
+            struct rmatch *rm = RMATCH(obj)->rmatch;
+	    size += onig_region_memsize(&rm->regs);
+	    size += sizeof(struct rmatch_offset) * rm->char_offset_num_allocated;
+	    size += sizeof(struct rmatch);
+	}
+	break;
+      case T_FILE:
+	if (RFILE(obj)->fptr) {
+	    size += rb_io_memsize(RFILE(obj)->fptr);
+	}
+	break;
+      case T_RATIONAL:
+      case T_COMPLEX:
+        break;
+      case T_IMEMO:
+        size += imemo_memsize(obj);
+	break;
+
+      case T_FLOAT:
+      case T_SYMBOL:
+	break;
+
+      case T_BIGNUM:
+	if (!(RBASIC(obj)->flags & BIGNUM_EMBED_FLAG) && BIGNUM_DIGITS(obj)) {
+	    size += BIGNUM_LEN(obj) * sizeof(BDIGIT);
+	}
+	break;
+
+      case T_NODE:
+	UNEXPECTED_NODE(obj_memsize_of);
+	break;
+
+      case T_STRUCT:
+	if ((RBASIC(obj)->flags & RSTRUCT_EMBED_LEN_MASK) == 0 &&
+	    RSTRUCT(obj)->as.heap.ptr) {
+	    size += sizeof(VALUE) * RSTRUCT_LEN(obj);
+	}
+	break;
+
+      case T_ZOMBIE:
+      case T_MOVED:
+	break;
+
+      default:
+	rb_bug("objspace/memsize_of(): unknown data type 0x%x(%p)",
+	       BUILTIN_TYPE(obj), (void*)obj);
+    }
+
+    return size + sizeof(RVALUE);
+}
+
+size_t
+rb_obj_memsize_of(VALUE obj)
+{
+    return obj_memsize_of(obj, TRUE);
+}
+
+static int
+set_zero(st_data_t key, st_data_t val, st_data_t arg)
+{
+    VALUE k = (VALUE)key;
+    VALUE hash = (VALUE)arg;
+    rb_hash_aset(hash, k, INT2FIX(0));
+    return ST_CONTINUE;
+}
+
+static VALUE
+type_sym(size_t type)
+{
+    switch (type) {
+#define COUNT_TYPE(t) case (t): return ID2SYM(rb_intern(#t)); break;
+        COUNT_TYPE(T_NONE);
+        COUNT_TYPE(T_OBJECT);
+        COUNT_TYPE(T_CLASS);
+        COUNT_TYPE(T_MODULE);
+        COUNT_TYPE(T_FLOAT);
+        COUNT_TYPE(T_STRING);
+        COUNT_TYPE(T_REGEXP);
+        COUNT_TYPE(T_ARRAY);
+        COUNT_TYPE(T_HASH);
+        COUNT_TYPE(T_STRUCT);
+        COUNT_TYPE(T_BIGNUM);
+        COUNT_TYPE(T_FILE);
+        COUNT_TYPE(T_DATA);
+        COUNT_TYPE(T_MATCH);
+        COUNT_TYPE(T_COMPLEX);
+        COUNT_TYPE(T_RATIONAL);
+        COUNT_TYPE(T_NIL);
+        COUNT_TYPE(T_TRUE);
+        COUNT_TYPE(T_FALSE);
+        COUNT_TYPE(T_SYMBOL);
+        COUNT_TYPE(T_FIXNUM);
+        COUNT_TYPE(T_IMEMO);
+        COUNT_TYPE(T_UNDEF);
+        COUNT_TYPE(T_NODE);
+        COUNT_TYPE(T_ICLASS);
+        COUNT_TYPE(T_ZOMBIE);
+        COUNT_TYPE(T_MOVED);
+#undef COUNT_TYPE
+        default:              return SIZET2NUM(type); break;
+    }
+}
+
+/*
+ *  call-seq:
+ *     ObjectSpace.count_objects([result_hash]) -> hash
+ *
+ *  Counts all objects grouped by type.
+ *
+ *  It returns a hash, such as:
+ *	{
+ *	  :TOTAL=>10000,
+ *	  :FREE=>3011,
+ *	  :T_OBJECT=>6,
+ *	  :T_CLASS=>404,
+ *	  # ...
+ *	}
+ *
+ *  The contents of the returned hash are implementation specific.
+ *  It may be changed in future.
+ *
+ *  The keys starting with +:T_+ means live objects.
+ *  For example, +:T_ARRAY+ is the number of arrays.
+ *  +:FREE+ means object slots which is not used now.
+ *  +:TOTAL+ means sum of above.
+ *
+ *  If the optional argument +result_hash+ is given,
+ *  it is overwritten and returned. This is intended to avoid probe effect.
+ *
+ *    h = {}
+ *    ObjectSpace.count_objects(h)
+ *    puts h
+ *    # => { :TOTAL=>10000, :T_CLASS=>158280, :T_MODULE=>20672, :T_STRING=>527249 }
+ *
+ *  This method is only expected to work on C Ruby.
+ *
+ */
+
+static VALUE
+count_objects(int argc, VALUE *argv, VALUE os)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    size_t counts[T_MASK+1];
+    size_t freed = 0;
+    size_t total = 0;
+    size_t i;
+    VALUE hash = Qnil;
+
+    if (rb_check_arity(argc, 0, 1) == 1) {
+        hash = argv[0];
+        if (!RB_TYPE_P(hash, T_HASH))
+            rb_raise(rb_eTypeError, "non-hash given");
+    }
+
+    for (i = 0; i <= T_MASK; i++) {
+        counts[i] = 0;
+    }
+
+    for (i = 0; i < heap_allocated_pages; i++) {
+	struct heap_page *page = heap_pages_sorted[i];
+	RVALUE *p, *pend;
+
+	p = page->start; pend = p + page->total_slots;
+	for (;p < pend; p++) {
+            VALUE vp = (VALUE)p;
+            void *poisoned = asan_poisoned_object_p(vp);
+            asan_unpoison_object(vp, false);
+	    if (p->as.basic.flags) {
+                counts[BUILTIN_TYPE(vp)]++;
+	    }
+	    else {
+		freed++;
+	    }
+            if (poisoned) {
+                GC_ASSERT(BUILTIN_TYPE(vp) == T_NONE);
+                asan_poison_object(vp);
+            }
+	}
+	total += page->total_slots;
+    }
+
+    if (hash == Qnil) {
+        hash = rb_hash_new();
+    }
+    else if (!RHASH_EMPTY_P(hash)) {
+        rb_hash_stlike_foreach(hash, set_zero, hash);
+    }
+    rb_hash_aset(hash, ID2SYM(rb_intern("TOTAL")), SIZET2NUM(total));
+    rb_hash_aset(hash, ID2SYM(rb_intern("FREE")), SIZET2NUM(freed));
+
+    for (i = 0; i <= T_MASK; i++) {
+        VALUE type = type_sym(i);
+        if (counts[i])
+            rb_hash_aset(hash, type, SIZET2NUM(counts[i]));
+    }
+
+    return hash;
+}
+
+/*
+  ------------------------ Garbage Collection ------------------------
+*/
+
+/* Sweeping */
+
+static size_t
+objspace_available_slots(rb_objspace_t *objspace)
+{
+    return heap_eden->total_slots + heap_tomb->total_slots;
+}
+
+static size_t
+objspace_live_slots(rb_objspace_t *objspace)
+{
+    return (objspace->total_allocated_objects - objspace->profile.total_freed_objects) - heap_pages_final_slots;
+}
+
+static size_t
+objspace_free_slots(rb_objspace_t *objspace)
+{
+    return objspace_available_slots(objspace) - objspace_live_slots(objspace) - heap_pages_final_slots;
+}
+
+static void
+gc_setup_mark_bits(struct heap_page *page)
+{
+    /* copy oldgen bitmap to mark bitmap */
+    memcpy(&page->mark_bits[0], &page->uncollectible_bits[0], HEAP_PAGE_BITMAP_SIZE);
+}
+
+static int gc_is_moveable_obj(rb_objspace_t *objspace, VALUE obj);
+static VALUE gc_move(rb_objspace_t *objspace, VALUE scan, VALUE free);
+
+static void
+lock_page_body(rb_objspace_t *objspace, struct heap_page_body *body)
+{
+#if defined(_WIN32)
+    DWORD old_protect;
+
+    if (!VirtualProtect(body, HEAP_PAGE_SIZE, PAGE_NOACCESS, &old_protect)) {
+#else
+    if(mprotect(body, HEAP_PAGE_SIZE, PROT_NONE)) {
+#endif
+        rb_bug("Couldn't protect page %p", (void *)body);
+    } else {
+        gc_report(5, objspace, "Protecting page in move %p\n", (void *)body);
+    }
+}
+
+static void
+unlock_page_body(rb_objspace_t *objspace, struct heap_page_body *body)
+{
+#if defined(_WIN32)
+    DWORD old_protect;
+
+    if (!VirtualProtect(body, HEAP_PAGE_SIZE, PAGE_READWRITE, &old_protect)) {
+#else
+    if(mprotect(body, HEAP_PAGE_SIZE, PROT_READ | PROT_WRITE)) {
+#endif
+        rb_bug("Couldn't unprotect page %p", (void *)body);
+    } else {
+        gc_report(5, objspace, "Unprotecting page in move %p\n", (void *)body);
+    }
+}
+
+static short
+try_move(rb_objspace_t *objspace, rb_heap_t *heap, struct heap_page *sweep_page, VALUE dest)
+{
+    struct heap_page * cursor = heap->compact_cursor;
+    char from_freelist = 0;
+
+    GC_ASSERT(!MARKED_IN_BITMAP(GET_HEAP_MARK_BITS(dest), dest));
+
+    /* T_NONE objects came from the free list.  If the object is *not* a
+     * T_NONE, it is an object that just got freed but hasn't been
+     * added to the freelist yet */
+
+    if (BUILTIN_TYPE(dest) == T_NONE) {
+        from_freelist = 1;
+    }
+
+    while(1) {
+        size_t index = heap->compact_cursor_index;
+
+        bits_t *mark_bits = cursor->mark_bits;
+        bits_t *pin_bits = cursor->pinned_bits;
+        RVALUE * p = cursor->start;
+        RVALUE * offset = p - NUM_IN_PAGE(p);
+
+        /* Find an object to move and move it. Movable objects must be
+         * marked, so we iterate using the marking bitmap */
+        for (size_t i = index; i < HEAP_PAGE_BITMAP_LIMIT; i++) {
+            bits_t bits = mark_bits[i] & ~pin_bits[i];
+
+            if (bits) {
+                p = offset + i * BITS_BITLENGTH;
+
+                do {
+                    if (bits & 1) {
+                        /* We're trying to move "p" */
+                        objspace->rcompactor.considered_count_table[BUILTIN_TYPE((VALUE)p)]++;
+
+                        if (gc_is_moveable_obj(objspace, (VALUE)p)) {
+                            /* We were able to move "p" */
+                            objspace->rcompactor.moved_count_table[BUILTIN_TYPE((VALUE)p)]++;
+                            objspace->rcompactor.total_moved++;
+                            gc_move(objspace, (VALUE)p, dest);
+                            gc_pin(objspace, (VALUE)p);
+                            heap->compact_cursor_index = i;
+                            if (from_freelist) {
+                                FL_SET((VALUE)p, FL_FROM_FREELIST);
+                            }
+
+                            return 1;
+                        }
+                    }
+                    p++;
+                    bits >>= 1;
+                } while (bits);
+            }
+        }
+
+        /* We couldn't find a movable object on the compact cursor, so lets
+         * move to the next page (previous page since we are traveling in the
+         * opposite direction of the sweep cursor) and look there. */
+
+        struct heap_page * next;
+
+        next = list_prev(&heap->pages, cursor, page_node);
+
+        /* Protect the current cursor since it probably has T_MOVED slots. */
+        lock_page_body(objspace, GET_PAGE_BODY(cursor->start));
+
+        heap->compact_cursor = next;
+        heap->compact_cursor_index = 0;
+        cursor = next;
+
+        // Cursors have met, lets quit.  We set `heap->compact_cursor` equal
+        // to `heap->sweeping_page` so we know how far to iterate through
+        // the heap when unprotecting pages.
+        if (next == sweep_page) {
+            break;
+        }
+    }
+
+    return 0;
+}
+
+static void
+gc_unprotect_pages(rb_objspace_t *objspace, rb_heap_t *heap)
+{
+    struct heap_page *cursor = heap->compact_cursor;
+
+    while(cursor) {
+        unlock_page_body(objspace, GET_PAGE_BODY(cursor->start));
+        cursor = list_next(&heap->pages, cursor, page_node);
+    }
+}
+
+static void gc_update_references(rb_objspace_t * objspace, rb_heap_t *heap);
+static void invalidate_moved_page(rb_objspace_t *objspace, struct heap_page *page);
+
+static void read_barrier_handler(intptr_t address)
+{
+    VALUE obj;
+    rb_objspace_t * objspace = &rb_objspace;
+
+    address -= address % sizeof(RVALUE);
+
+    obj = (VALUE)address;
+
+    RB_VM_LOCK_ENTER();
+    {
+        unlock_page_body(objspace, GET_PAGE_BODY(obj));
+
+        objspace->profile.read_barrier_faults++;
+
+        invalidate_moved_page(objspace, GET_HEAP_PAGE(obj));
+    }
+    RB_VM_LOCK_LEAVE();
+}
+
+#if defined(_WIN32)
+static LPTOP_LEVEL_EXCEPTION_FILTER old_handler;
+typedef void (*signal_handler)(int);
+static signal_handler old_sigsegv_handler;
+
+static LONG WINAPI read_barrier_signal(EXCEPTION_POINTERS * info)
+{
+    /* EXCEPTION_ACCESS_VIOLATION is what's raised by access to protected pages */
+    if (info->ExceptionRecord->ExceptionCode == EXCEPTION_ACCESS_VIOLATION) {
+        /* > The second array element specifies the virtual address of the inaccessible data.
+         * https://docs.microsoft.com/en-us/windows/win32/api/winnt/ns-winnt-exception_record
+         *
+         * Use this address to invalidate the page */
+        read_barrier_handler((intptr_t)info->ExceptionRecord->ExceptionInformation[1]);
+        return EXCEPTION_CONTINUE_EXECUTION;
+    } else {
+        return EXCEPTION_CONTINUE_SEARCH;
+    }
+}
+
+static void
+uninstall_handlers(void)
+{
+    signal(SIGSEGV, old_sigsegv_handler);
+    SetUnhandledExceptionFilter(old_handler);
+}
+
+static void
+install_handlers(void)
+{
+    /* Remove SEGV handler so that the Unhandled Exception Filter handles it */
+    old_sigsegv_handler = signal(SIGSEGV, NULL);
+    /* Unhandled Exception Filter has access to the violation address similar
+     * to si_addr from sigaction */
+    old_handler = SetUnhandledExceptionFilter(read_barrier_signal);
+}
+#else
+static struct sigaction old_sigbus_handler;
+static struct sigaction old_sigsegv_handler;
+
+static void
+read_barrier_signal(int sig, siginfo_t * info, void * data)
+{
+    // setup SEGV/BUS handlers for errors
+    struct sigaction prev_sigbus, prev_sigsegv;
+    sigaction(SIGBUS, &old_sigbus_handler, &prev_sigbus);
+    sigaction(SIGSEGV, &old_sigsegv_handler, &prev_sigsegv);
+
+    // enable SIGBUS/SEGV
+    sigset_t set, prev_set;
+    sigemptyset(&set);
+    sigaddset(&set, SIGBUS);
+    sigaddset(&set, SIGSEGV);
+    sigprocmask(SIG_UNBLOCK, &set, &prev_set);
+
+    // run handler
+    read_barrier_handler((intptr_t)info->si_addr);
+
+    // reset SEGV/BUS handlers
+    sigaction(SIGBUS, &prev_sigbus, NULL);
+    sigaction(SIGSEGV, &prev_sigsegv, NULL);
+    sigprocmask(SIG_SETMASK, &prev_set, NULL);
+}
+
+static void
+uninstall_handlers(void)
+{
+    sigaction(SIGBUS, &old_sigbus_handler, NULL);
+    sigaction(SIGSEGV, &old_sigsegv_handler, NULL);
+}
+
+static void
+install_handlers(void)
+{
+    struct sigaction action;
+    memset(&action, 0, sizeof(struct sigaction));
+    sigemptyset(&action.sa_mask);
+    action.sa_sigaction = read_barrier_signal;
+    action.sa_flags = SA_SIGINFO | SA_ONSTACK;
+
+    sigaction(SIGBUS, &action, &old_sigbus_handler);
+    sigaction(SIGSEGV, &action, &old_sigsegv_handler);
+}
+#endif
+
+static void
+revert_stack_objects(VALUE stack_obj, void *ctx)
+{
+    rb_objspace_t * objspace = (rb_objspace_t*)ctx;
+
+    if (BUILTIN_TYPE(stack_obj) == T_MOVED) {
+        /* For now we'll revert the whole page if the object made it to the
+         * stack.  I think we can change this to move just the one object
+         * back though */
+        invalidate_moved_page(objspace, GET_HEAP_PAGE(stack_obj));
+    }
+}
+
+static void
+check_stack_for_moved(rb_objspace_t *objspace)
+{
+    rb_execution_context_t *ec = GET_EC();
+    rb_vm_t *vm = rb_ec_vm_ptr(ec);
+    rb_vm_each_stack_value(vm, revert_stack_objects, (void*)objspace);
+}
+
+static void
+gc_compact_finish(rb_objspace_t *objspace, rb_heap_t *heap)
+{
+    GC_ASSERT(heap->sweeping_page == heap->compact_cursor);
+
+    gc_unprotect_pages(objspace, heap);
+    uninstall_handlers();
+
+    /* The mutator is allowed to run during incremental sweeping. T_MOVED
+     * objects can get pushed on the stack and when the compaction process
+     * finishes up, it may remove the read barrier before anything has a
+     * chance to read from the T_MOVED address. To fix this, we scan the stack
+     * then revert any moved objects that made it to the stack. */
+    check_stack_for_moved(objspace);
+
+    gc_update_references(objspace, heap);
+    heap->compact_cursor = NULL;
+    heap->compact_cursor_index = 0;
+    objspace->profile.compact_count++;
+    if (gc_prof_enabled(objspace)) {
+        gc_profile_record *record = gc_prof_record(objspace);
+        record->moved_objects = objspace->rcompactor.total_moved - record->moved_objects;
+    }
+    rb_clear_constant_cache();
+    objspace->flags.during_compacting = FALSE;
+}
+
+static int
+gc_fill_swept_page(rb_objspace_t *objspace, rb_heap_t *heap, struct heap_page *sweep_page, int *freed_slots, int *empty_slots)
+{
+    /* Find any pinned but not marked objects and try to fill those slots */
+    int i;
+    int moved_slots = 0;
+    int finished_compacting = 0;
+    bits_t *mark_bits, *pin_bits;
+    bits_t bitset;
+    RVALUE *p, *offset;
+
+    mark_bits = sweep_page->mark_bits;
+    pin_bits = sweep_page->pinned_bits;
+
+    p = sweep_page->start;
+    offset = p - NUM_IN_PAGE(p);
+
+    struct heap_page * cursor = heap->compact_cursor;
+
+    unlock_page_body(objspace, GET_PAGE_BODY(cursor->start));
+
+    for (i=0; i < HEAP_PAGE_BITMAP_LIMIT; i++) {
+        /* *Want to move* objects are pinned but not marked. */
+        bitset = pin_bits[i] & ~mark_bits[i];
+
+        if (bitset) {
+            p = offset + i * BITS_BITLENGTH;
+            do {
+                if (bitset & 1) {
+                    VALUE dest = (VALUE)p;
+
+                    GC_ASSERT(MARKED_IN_BITMAP(GET_HEAP_PINNED_BITS(dest), dest));
+                    GC_ASSERT(!MARKED_IN_BITMAP(GET_HEAP_MARK_BITS(dest), dest));
+
+                    CLEAR_IN_BITMAP(GET_HEAP_PINNED_BITS(dest), dest);
+
+                    if (finished_compacting) {
+                        if (BUILTIN_TYPE(dest) == T_NONE) {
+                            (*empty_slots)++;
+                        } else {
+                            (*freed_slots)++;
+                        }
+                        (void)VALGRIND_MAKE_MEM_UNDEFINED((void*)dest, sizeof(RVALUE));
+                        heap_page_add_freeobj(objspace, sweep_page, dest);
+                    } else {
+                        /* Zombie slots don't get marked, but we can't reuse
+                         * their memory until they have their finalizers run.*/
+                        if (BUILTIN_TYPE(dest) != T_ZOMBIE) {
+                            if(!try_move(objspace, heap, sweep_page, dest)) {
+                                finished_compacting = 1;
+                                (void)VALGRIND_MAKE_MEM_UNDEFINED((void*)p, sizeof(RVALUE));
+                                gc_report(5, objspace, "Quit compacting, couldn't find an object to move\n");
+                                if (BUILTIN_TYPE(dest) == T_NONE) {
+                                    (*empty_slots)++;
+                                } else {
+                                    (*freed_slots)++;
+                                }
+                                heap_page_add_freeobj(objspace, sweep_page, dest);
+                                gc_report(3, objspace, "page_sweep: %s is added to freelist\n", obj_info(dest));
+                            } else {
+                                moved_slots++;
+                            }
+                        }
+                    }
+                }
+                p++;
+                bitset >>= 1;
+            } while (bitset);
+        }
+    }
+
+    lock_page_body(objspace, GET_PAGE_BODY(heap->compact_cursor->start));
+
+    return finished_compacting;
+}
+
+static inline int
+gc_page_sweep(rb_objspace_t *objspace, rb_heap_t *heap, struct heap_page *sweep_page)
+{
+    int i;
+    int empty_slots = 0, freed_slots = 0, final_slots = 0;
+    int was_compacting = 0;
+    RVALUE *p, *offset;
+    bits_t *bits, bitset;
+
+    gc_report(2, objspace, "page_sweep: start.\n");
+
+    if (heap->compact_cursor) {
+        if (sweep_page == heap->compact_cursor) {
+            /* The compaction cursor and sweep page met, so we need to quit compacting */
+            gc_report(5, objspace, "Quit compacting, mark and compact cursor met\n");
+            gc_compact_finish(objspace, heap);
+        } else {
+            /* We anticipate filling the page, so NULL out the freelist. */
+            asan_unpoison_memory_region(&sweep_page->freelist, sizeof(RVALUE*), false);
+            sweep_page->freelist = NULL;
+            asan_poison_memory_region(&sweep_page->freelist, sizeof(RVALUE*));
+            was_compacting = 1;
+        }
+    }
+
+    sweep_page->flags.before_sweep = FALSE;
+
+    p = sweep_page->start;
+    offset = p - NUM_IN_PAGE(p);
+    bits = sweep_page->mark_bits;
+
+    /* create guard : fill 1 out-of-range */
+    bits[BITMAP_INDEX(p)] |= BITMAP_BIT(p)-1;
+
+    int out_of_range_bits = (NUM_IN_PAGE(p) + sweep_page->total_slots) % BITS_BITLENGTH;
+    if (out_of_range_bits != 0) { // sizeof(RVALUE) == 64
+        bits[BITMAP_INDEX(p) + sweep_page->total_slots / BITS_BITLENGTH] |= ~(((bits_t)1 << out_of_range_bits) - 1);
+    }
+
+    for (i=0; i < HEAP_PAGE_BITMAP_LIMIT; i++) {
+	bitset = ~bits[i];
+	if (bitset) {
+	    p = offset  + i * BITS_BITLENGTH;
+	    do {
+                VALUE vp = (VALUE)p;
+                asan_unpoison_object(vp, false);
+		if (bitset & 1) {
+                    switch (BUILTIN_TYPE(vp)) {
+		      default: /* majority case */
+                        gc_report(2, objspace, "page_sweep: free %p\n", (void *)p);
+#if RGENGC_CHECK_MODE
+                        if (!is_full_marking(objspace)) {
+                            if (RVALUE_OLD_P(vp)) rb_bug("page_sweep: %p - old while minor GC.", (void *)p);
+                            if (rgengc_remembered_sweep(objspace, vp)) rb_bug("page_sweep: %p - remembered.", (void *)p);
+                        }
+#endif
+                        if (obj_free(objspace, vp)) {
+                            final_slots++;
+                        }
+                        else {
+                            if (heap->compact_cursor) {
+                                /* We *want* to fill this slot */
+                                MARK_IN_BITMAP(GET_HEAP_PINNED_BITS(vp), vp);
+                            } else {
+                                (void)VALGRIND_MAKE_MEM_UNDEFINED((void*)p, sizeof(RVALUE));
+                                heap_page_add_freeobj(objspace, sweep_page, vp);
+                                gc_report(3, objspace, "page_sweep: %s is added to freelist\n", obj_info(vp));
+                                freed_slots++;
+                            }
+
+                        }
+                        break;
+
+			/* minor cases */
+		      case T_MOVED:
+                        if (objspace->flags.during_compacting) {
+                            /* The sweep cursor shouldn't have made it to any
+                             * T_MOVED slots while the compact flag is enabled.
+                             * The sweep cursor and compact cursor move in
+                             * opposite directions, and when they meet references will
+                             * get updated and "during_compacting" should get disabled */
+                            rb_bug("T_MOVED shouldn't be seen until compaction is finished\n");
+                        }
+                        gc_report(3, objspace, "page_sweep: %s is added to freelist\n", obj_info(vp));
+                        if (FL_TEST(vp, FL_FROM_FREELIST)) {
+                            empty_slots++;
+                        } else {
+                            freed_slots++;
+                        }
+                        heap_page_add_freeobj(objspace, sweep_page, vp);
+                        break;
+		      case T_ZOMBIE:
+			/* already counted */
+			break;
+		      case T_NONE:
+                        if (heap->compact_cursor) {
+                            /* We *want* to fill this slot */
+                            MARK_IN_BITMAP(GET_HEAP_PINNED_BITS(vp), vp);
+                        } else {
+                            /* When we started sweeping this page, we were in
+                             * compacting mode and nulled the free list for
+                             * the page. But compaction finished, so we need to
+                             * put any T_NONE slots back on the freelist. */
+                            if (was_compacting) {
+                                heap_page_add_freeobj(objspace, sweep_page, vp);
+                            }
+                            empty_slots++; /* already freed */
+                        }
+			break;
+		    }
+		}
+		p++;
+		bitset >>= 1;
+	    } while (bitset);
+	}
+    }
+
+    if (heap->compact_cursor) {
+        if (gc_fill_swept_page(objspace, heap, sweep_page, &freed_slots, &empty_slots)) {
+            gc_compact_finish(objspace, heap);
+        }
+    }
+
+    if (!heap->compact_cursor) {
+        gc_setup_mark_bits(sweep_page);
+    }
+
+#if GC_PROFILE_MORE_DETAIL
+    if (gc_prof_enabled(objspace)) {
+	gc_profile_record *record = gc_prof_record(objspace);
+	record->removing_objects += final_slots + freed_slots;
+	record->empty_objects += empty_slots;
+    }
+#endif
+    if (0) fprintf(stderr, "gc_page_sweep(%"PRIdSIZE"): total_slots: %d, freed_slots: %d, empty_slots: %d, final_slots: %d\n",
+		   rb_gc_count(),
+		   sweep_page->total_slots,
+		   freed_slots, empty_slots, final_slots);
+
+    sweep_page->free_slots = freed_slots + empty_slots;
+    objspace->profile.total_freed_objects += freed_slots;
+
+    if (heap_pages_deferred_final && !finalizing) {
+        rb_thread_t *th = GET_THREAD();
+        if (th) {
+	    gc_finalize_deferred_register(objspace);
+        }
+    }
+
+    gc_report(2, objspace, "page_sweep: end.\n");
+
+    return freed_slots + empty_slots;
+}
+
+/* allocate additional minimum page to work */
+static void
+gc_heap_prepare_minimum_pages(rb_objspace_t *objspace, rb_heap_t *heap)
+{
+    if (!heap->free_pages && heap_increment(objspace, heap) == FALSE) {
+	/* there is no free after page_sweep() */
+	heap_set_increment(objspace, 1);
+	if (!heap_increment(objspace, heap)) { /* can't allocate additional free objects */
+	    rb_memerror();
+	}
+    }
+}
+
+static const char *
+gc_mode_name(enum gc_mode mode)
+{
+    switch (mode) {
+      case gc_mode_none: return "none";
+      case gc_mode_marking: return "marking";
+      case gc_mode_sweeping: return "sweeping";
+      default: rb_bug("gc_mode_name: unknown mode: %d", (int)mode);
+    }
+}
+
+static void
+gc_mode_transition(rb_objspace_t *objspace, enum gc_mode mode)
+{
+#if RGENGC_CHECK_MODE
+    enum gc_mode prev_mode = gc_mode(objspace);
+    switch (prev_mode) {
+      case gc_mode_none:     GC_ASSERT(mode == gc_mode_marking); break;
+      case gc_mode_marking:  GC_ASSERT(mode == gc_mode_sweeping); break;
+      case gc_mode_sweeping: GC_ASSERT(mode == gc_mode_none); break;
+    }
+#endif
+    if (0) fprintf(stderr, "gc_mode_transition: %s->%s\n", gc_mode_name(gc_mode(objspace)), gc_mode_name(mode));
+    gc_mode_set(objspace, mode);
+}
+
+static void
+gc_sweep_start_heap(rb_objspace_t *objspace, rb_heap_t *heap)
+{
+    heap->sweeping_page = list_top(&heap->pages, struct heap_page, page_node);
+    heap->free_pages = NULL;
+#if GC_ENABLE_INCREMENTAL_MARK
+    heap->pooled_pages = NULL;
+    objspace->rincgc.pooled_slots = 0;
+#endif
+
+    rb_ractor_t *r = NULL;
+    list_for_each(&GET_VM()->ractor.set, r, vmlr_node) {
+        rb_gc_ractor_newobj_cache_clear(&r->newobj_cache);
+    }
+}
+
+#if defined(__GNUC__) && __GNUC__ == 4 && __GNUC_MINOR__ == 4
+__attribute__((noinline))
+#endif
+static void
+gc_sweep_start(rb_objspace_t *objspace)
+{
+    gc_mode_transition(objspace, gc_mode_sweeping);
+    gc_sweep_start_heap(objspace, heap_eden);
+}
+
+static void
+gc_sweep_finish(rb_objspace_t *objspace)
+{
+    gc_report(1, objspace, "gc_sweep_finish\n");
+
+    gc_prof_set_heap_info(objspace);
+    heap_pages_free_unused_pages(objspace);
+
+    /* if heap_pages has unused pages, then assign them to increment */
+    if (heap_allocatable_pages < heap_tomb->total_pages) {
+	heap_allocatable_pages_set(objspace, heap_tomb->total_pages);
+    }
+
+    gc_event_hook(objspace, RUBY_INTERNAL_EVENT_GC_END_SWEEP, 0);
+    gc_mode_transition(objspace, gc_mode_none);
+
+#if RGENGC_CHECK_MODE >= 2
+    gc_verify_internal_consistency(objspace);
+#endif
+}
+
+static int
+gc_sweep_step(rb_objspace_t *objspace, rb_heap_t *heap)
+{
+    struct heap_page *sweep_page = heap->sweeping_page;
+    int unlink_limit = 3;
+    int swept_slots = 0;
+
+#if GC_ENABLE_INCREMENTAL_MARK
+    int need_pool = will_be_incremental_marking(objspace) ? TRUE : FALSE;
+
+    gc_report(2, objspace, "gc_sweep_step (need_pool: %d)\n", need_pool);
+#else
+    gc_report(2, objspace, "gc_sweep_step\n");
+#endif
+
+    if (sweep_page == NULL) return FALSE;
+
+#if GC_ENABLE_LAZY_SWEEP
+    gc_prof_sweep_timer_start(objspace);
+#endif
+
+    do {
+        RUBY_DEBUG_LOG("sweep_page:%p", sweep_page);
+	int free_slots = gc_page_sweep(objspace, heap, sweep_page);
+        heap->sweeping_page = list_next(&heap->pages, sweep_page, page_node);
+
+	if (sweep_page->final_slots + free_slots == sweep_page->total_slots &&
+	    heap_pages_freeable_pages > 0 &&
+	    unlink_limit > 0) {
+	    heap_pages_freeable_pages--;
+	    unlink_limit--;
+	    /* there are no living objects -> move this page to tomb heap */
+	    heap_unlink_page(objspace, heap, sweep_page);
+	    heap_add_page(objspace, heap_tomb, sweep_page);
+	}
+	else if (free_slots > 0) {
+#if GC_ENABLE_INCREMENTAL_MARK
+	    if (need_pool) {
+                heap_add_poolpage(objspace, heap, sweep_page);
+                need_pool = FALSE;
+	    }
+	    else {
+                heap_add_freepage(heap, sweep_page);
+                swept_slots += free_slots;
+                if (swept_slots > 2048) {
+                    break;
+                }
+	    }
+#else
+            heap_add_freepage(heap, sweep_page);
+#endif
+	}
+	else {
+	    sweep_page->free_next = NULL;
+	}
+    } while ((sweep_page = heap->sweeping_page));
+
+    if (!heap->sweeping_page) {
+	gc_sweep_finish(objspace);
+    }
+
+#if GC_ENABLE_LAZY_SWEEP
+    gc_prof_sweep_timer_stop(objspace);
+#endif
+
+    GC_ASSERT(gc_mode(objspace) == gc_mode_sweeping ? heap->free_pages != NULL : 1);
+
+    return heap->free_pages != NULL;
+}
+
+static void
+gc_sweep_rest(rb_objspace_t *objspace)
+{
+    rb_heap_t *heap = heap_eden; /* lazy sweep only for eden */
+
+    while (has_sweeping_pages(heap)) {
+	gc_sweep_step(objspace, heap);
+    }
+}
+
+static void
+gc_sweep_continue(rb_objspace_t *objspace, rb_heap_t *heap)
+{
+    GC_ASSERT(dont_gc_val() == FALSE);
+    if (!GC_ENABLE_LAZY_SWEEP) return;
+
+    unsigned int lock_lev;
+    gc_enter(objspace, gc_enter_event_sweep_continue, &lock_lev);
+    gc_sweep_step(objspace, heap);
+    gc_exit(objspace, gc_enter_event_sweep_continue, &lock_lev);
+}
+
+static void
+invalidate_moved_page(rb_objspace_t *objspace, struct heap_page *page)
+{
+    int i;
+    int empty_slots = 0, freed_slots = 0;
+    bits_t *mark_bits, *pin_bits;
+    bits_t bitset;
+    RVALUE *p, *offset;
+
+    mark_bits = page->mark_bits;
+    pin_bits = page->pinned_bits;
+
+    p = page->start;
+    offset = p - NUM_IN_PAGE(p);
+
+    for (i=0; i < HEAP_PAGE_BITMAP_LIMIT; i++) {
+        /* Moved objects are pinned but never marked. We reuse the pin bits
+         * to indicate there is a moved object in this slot. */
+        bitset = pin_bits[i] & ~mark_bits[i];
+
+        if (bitset) {
+            p = offset + i * BITS_BITLENGTH;
+            do {
+                if (bitset & 1) {
+                    VALUE forwarding_object = (VALUE)p;
+                    VALUE object;
+
+                    if (BUILTIN_TYPE(forwarding_object) == T_MOVED) {
+                        GC_ASSERT(MARKED_IN_BITMAP(GET_HEAP_PINNED_BITS(forwarding_object), forwarding_object));
+                        GC_ASSERT(!MARKED_IN_BITMAP(GET_HEAP_MARK_BITS(forwarding_object), forwarding_object));
+
+                        CLEAR_IN_BITMAP(GET_HEAP_PINNED_BITS(forwarding_object), forwarding_object);
+
+                        object = rb_gc_location(forwarding_object);
+
+                        if (FL_TEST(forwarding_object, FL_FROM_FREELIST)) {
+                            empty_slots++; /* already freed */
+                        } else {
+                            freed_slots++;
+                        }
+
+                        gc_move(objspace, object, forwarding_object);
+                        /* forwarding_object is now our actual object, and "object"
+                         * is the free slot for the original page */
+                        heap_page_add_freeobj(objspace, GET_HEAP_PAGE(object), object);
+
+                        GC_ASSERT(MARKED_IN_BITMAP(GET_HEAP_MARK_BITS(forwarding_object), forwarding_object));
+                        GC_ASSERT(BUILTIN_TYPE(forwarding_object) != T_MOVED);
+                        GC_ASSERT(BUILTIN_TYPE(forwarding_object) != T_NONE);
+                    }
+                }
+                p++;
+                bitset >>= 1;
+            } while (bitset);
+        }
+    }
+
+    page->free_slots += (empty_slots + freed_slots);
+    objspace->profile.total_freed_objects += freed_slots;
+}
+
+static void
+gc_compact_start(rb_objspace_t *objspace, rb_heap_t *heap)
+{
+    heap->compact_cursor = list_tail(&heap->pages, struct heap_page, page_node);
+    heap->compact_cursor_index = 0;
+
+    if (gc_prof_enabled(objspace)) {
+        gc_profile_record *record = gc_prof_record(objspace);
+        record->moved_objects = objspace->rcompactor.total_moved;
+    }
+
+    memset(objspace->rcompactor.considered_count_table, 0, T_MASK * sizeof(size_t));
+    memset(objspace->rcompactor.moved_count_table, 0, T_MASK * sizeof(size_t));
+
+    /* Set up read barrier for pages containing MOVED objects */
+    install_handlers();
+}
+
+static void
+gc_sweep(rb_objspace_t *objspace)
+{
+    const unsigned int immediate_sweep = objspace->flags.immediate_sweep;
+
+    gc_report(1, objspace, "gc_sweep: immediate: %d\n", immediate_sweep);
+
+    if (immediate_sweep) {
+#if !GC_ENABLE_LAZY_SWEEP
+	gc_prof_sweep_timer_start(objspace);
+#endif
+	gc_sweep_start(objspace);
+        if (objspace->flags.during_compacting) {
+            struct heap_page *page = NULL;
+
+            list_for_each(&heap_eden->pages, page, page_node) {
+                page->flags.before_sweep = TRUE;
+            }
+
+            gc_compact_start(objspace, heap_eden);
+        }
+
+	gc_sweep_rest(objspace);
+#if !GC_ENABLE_LAZY_SWEEP
+	gc_prof_sweep_timer_stop(objspace);
+#endif
+    }
+    else {
+	struct heap_page *page = NULL;
+	gc_sweep_start(objspace);
+
+        if (ruby_enable_autocompact && is_full_marking(objspace)) {
+            gc_compact_start(objspace, heap_eden);
+        }
+
+        list_for_each(&heap_eden->pages, page, page_node) {
+            page->flags.before_sweep = TRUE;
+        }
+	gc_sweep_step(objspace, heap_eden);
+    }
+
+    gc_heap_prepare_minimum_pages(objspace, heap_eden);
+}
+
+/* Marking - Marking stack */
+
+static stack_chunk_t *
+stack_chunk_alloc(void)
+{
+    stack_chunk_t *res;
+
+    res = malloc(sizeof(stack_chunk_t));
+    if (!res)
+        rb_memerror();
+
+    return res;
+}
+
+static inline int
+is_mark_stack_empty(mark_stack_t *stack)
+{
+    return stack->chunk == NULL;
+}
+
+static size_t
+mark_stack_size(mark_stack_t *stack)
+{
+    size_t size = stack->index;
+    stack_chunk_t *chunk = stack->chunk ? stack->chunk->next : NULL;
+
+    while (chunk) {
+	size += stack->limit;
+	chunk = chunk->next;
+    }
+    return size;
+}
+
+static void
+add_stack_chunk_cache(mark_stack_t *stack, stack_chunk_t *chunk)
+{
+    chunk->next = stack->cache;
+    stack->cache = chunk;
+    stack->cache_size++;
+}
+
+static void
+shrink_stack_chunk_cache(mark_stack_t *stack)
+{
+    stack_chunk_t *chunk;
+
+    if (stack->unused_cache_size > (stack->cache_size/2)) {
+        chunk = stack->cache;
+        stack->cache = stack->cache->next;
+        stack->cache_size--;
+        free(chunk);
+    }
+    stack->unused_cache_size = stack->cache_size;
+}
+
+static void
+push_mark_stack_chunk(mark_stack_t *stack)
+{
+    stack_chunk_t *next;
+
+    GC_ASSERT(stack->index == stack->limit);
+
+    if (stack->cache_size > 0) {
+        next = stack->cache;
+        stack->cache = stack->cache->next;
+        stack->cache_size--;
+        if (stack->unused_cache_size > stack->cache_size)
+            stack->unused_cache_size = stack->cache_size;
+    }
+    else {
+        next = stack_chunk_alloc();
+    }
+    next->next = stack->chunk;
+    stack->chunk = next;
+    stack->index = 0;
+}
+
+static void
+pop_mark_stack_chunk(mark_stack_t *stack)
+{
+    stack_chunk_t *prev;
+
+    prev = stack->chunk->next;
+    GC_ASSERT(stack->index == 0);
+    add_stack_chunk_cache(stack, stack->chunk);
+    stack->chunk = prev;
+    stack->index = stack->limit;
+}
+
+static void
+free_stack_chunks(mark_stack_t *stack)
+{
+    stack_chunk_t *chunk = stack->chunk;
+    stack_chunk_t *next = NULL;
+
+    while (chunk != NULL) {
+        next = chunk->next;
+        free(chunk);
+        chunk = next;
+    }
+}
+
+static void
+push_mark_stack(mark_stack_t *stack, VALUE data)
+{
+    VALUE obj = data;
+    switch (BUILTIN_TYPE(obj)) {
+      case T_NIL:
+      case T_FIXNUM:
+      case T_MOVED:
+	rb_bug("push_mark_stack() called for broken object");
+	break;
+
+      case T_NODE:
+	UNEXPECTED_NODE(push_mark_stack);
+        break;
+
+      default:
+        break;
+    }
+
+    if (stack->index == stack->limit) {
+        push_mark_stack_chunk(stack);
+    }
+    stack->chunk->data[stack->index++] = data;
+}
+
+static int
+pop_mark_stack(mark_stack_t *stack, VALUE *data)
+{
+    if (is_mark_stack_empty(stack)) {
+        return FALSE;
+    }
+    if (stack->index == 1) {
+        *data = stack->chunk->data[--stack->index];
+        pop_mark_stack_chunk(stack);
+    }
+    else {
+	*data = stack->chunk->data[--stack->index];
+    }
+    return TRUE;
+}
+
+#if GC_ENABLE_INCREMENTAL_MARK
+static int
+invalidate_mark_stack_chunk(stack_chunk_t *chunk, int limit, VALUE obj)
+{
+    int i;
+    for (i=0; i<limit; i++) {
+	if (chunk->data[i] == obj) {
+	    chunk->data[i] = Qundef;
+	    return TRUE;
+	}
+    }
+    return FALSE;
+}
+
+static void
+invalidate_mark_stack(mark_stack_t *stack, VALUE obj)
+{
+    stack_chunk_t *chunk = stack->chunk;
+    int limit = stack->index;
+
+    while (chunk) {
+	if (invalidate_mark_stack_chunk(chunk, limit, obj)) return;
+	chunk = chunk->next;
+	limit = stack->limit;
+    }
+    rb_bug("invalid_mark_stack: unreachable");
+}
+#endif
+
+static void
+init_mark_stack(mark_stack_t *stack)
+{
+    int i;
+
+    MEMZERO(stack, mark_stack_t, 1);
+    stack->index = stack->limit = STACK_CHUNK_SIZE;
+    stack->cache_size = 0;
+
+    for (i=0; i < 4; i++) {
+        add_stack_chunk_cache(stack, stack_chunk_alloc());
+    }
+    stack->unused_cache_size = stack->cache_size;
+}
+
+/* Marking */
+
+#define SET_STACK_END SET_MACHINE_STACK_END(&ec->machine.stack_end)
+
+#define STACK_START (ec->machine.stack_start)
+#define STACK_END (ec->machine.stack_end)
+#define STACK_LEVEL_MAX (ec->machine.stack_maxsize/sizeof(VALUE))
+
+#ifdef __EMSCRIPTEN__
+#undef STACK_GROW_DIRECTION
+#define STACK_GROW_DIRECTION 1
+#endif
+
+#if STACK_GROW_DIRECTION < 0
+# define STACK_LENGTH  (size_t)(STACK_START - STACK_END)
+#elif STACK_GROW_DIRECTION > 0
+# define STACK_LENGTH  (size_t)(STACK_END - STACK_START + 1)
+#else
+# define STACK_LENGTH  ((STACK_END < STACK_START) ? (size_t)(STACK_START - STACK_END) \
+			: (size_t)(STACK_END - STACK_START + 1))
+#endif
+#if !STACK_GROW_DIRECTION
+int ruby_stack_grow_direction;
+int
+ruby_get_stack_grow_direction(volatile VALUE *addr)
+{
+    VALUE *end;
+    SET_MACHINE_STACK_END(&end);
+
+    if (end > addr) return ruby_stack_grow_direction = 1;
+    return ruby_stack_grow_direction = -1;
+}
+#endif
+
+size_t
+ruby_stack_length(VALUE **p)
+{
+    rb_execution_context_t *ec = GET_EC();
+    SET_STACK_END;
+    if (p) *p = STACK_UPPER(STACK_END, STACK_START, STACK_END);
+    return STACK_LENGTH;
+}
+
+#define PREVENT_STACK_OVERFLOW 1
+#ifndef PREVENT_STACK_OVERFLOW
+#if !(defined(POSIX_SIGNAL) && defined(SIGSEGV) && defined(HAVE_SIGALTSTACK))
+# define PREVENT_STACK_OVERFLOW 1
+#else
+# define PREVENT_STACK_OVERFLOW 0
+#endif
+#endif
+#if PREVENT_STACK_OVERFLOW
+static int
+stack_check(rb_execution_context_t *ec, int water_mark)
+{
+    SET_STACK_END;
+
+    size_t length = STACK_LENGTH;
+    size_t maximum_length = STACK_LEVEL_MAX - water_mark;
+
+    return length > maximum_length;
+}
+#else
+#define stack_check(ec, water_mark) FALSE
+#endif
+
+#define STACKFRAME_FOR_CALL_CFUNC 2048
+
+MJIT_FUNC_EXPORTED int
+rb_ec_stack_check(rb_execution_context_t *ec)
+{
+    return stack_check(ec, STACKFRAME_FOR_CALL_CFUNC);
+}
+
+int
+ruby_stack_check(void)
+{
+    return stack_check(GET_EC(), STACKFRAME_FOR_CALL_CFUNC);
+}
+
+ATTRIBUTE_NO_ADDRESS_SAFETY_ANALYSIS(static void mark_locations_array(rb_objspace_t *objspace, register const VALUE *x, register long n));
+static void
+mark_locations_array(rb_objspace_t *objspace, register const VALUE *x, register long n)
+{
+    VALUE v;
+    while (n--) {
+        v = *x;
+        gc_mark_maybe(objspace, v);
+	x++;
+    }
+}
+
+static void
+gc_mark_locations(rb_objspace_t *objspace, const VALUE *start, const VALUE *end)
+{
+    long n;
+
+    if (end <= start) return;
+    n = end - start;
+    mark_locations_array(objspace, start, n);
+}
+
+void
+rb_gc_mark_locations(const VALUE *start, const VALUE *end)
+{
+    gc_mark_locations(&rb_objspace, start, end);
+}
+
+static void
+gc_mark_values(rb_objspace_t *objspace, long n, const VALUE *values)
+{
+    long i;
+
+    for (i=0; i<n; i++) {
+        gc_mark(objspace, values[i]);
+    }
+}
+
+void
+rb_gc_mark_values(long n, const VALUE *values)
+{
+    long i;
+    rb_objspace_t *objspace = &rb_objspace;
+
+    for (i=0; i<n; i++) {
+        gc_mark_and_pin(objspace, values[i]);
+    }
+}
+
+static void
+gc_mark_stack_values(rb_objspace_t *objspace, long n, const VALUE *values)
+{
+    long i;
+
+    for (i=0; i<n; i++) {
+        if (is_markable_object(objspace, values[i])) {
+            gc_mark_and_pin(objspace, values[i]);
+        }
+    }
+}
+
+void
+rb_gc_mark_vm_stack_values(long n, const VALUE *values)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    gc_mark_stack_values(objspace, n, values);
+}
+
+static int
+mark_value(st_data_t key, st_data_t value, st_data_t data)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)data;
+    gc_mark(objspace, (VALUE)value);
+    return ST_CONTINUE;
+}
+
+static int
+mark_value_pin(st_data_t key, st_data_t value, st_data_t data)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)data;
+    gc_mark_and_pin(objspace, (VALUE)value);
+    return ST_CONTINUE;
+}
+
+static void
+mark_tbl_no_pin(rb_objspace_t *objspace, st_table *tbl)
+{
+    if (!tbl || tbl->num_entries == 0) return;
+    st_foreach(tbl, mark_value, (st_data_t)objspace);
+}
+
+static void
+mark_tbl(rb_objspace_t *objspace, st_table *tbl)
+{
+    if (!tbl || tbl->num_entries == 0) return;
+    st_foreach(tbl, mark_value_pin, (st_data_t)objspace);
+}
+
+static int
+mark_key(st_data_t key, st_data_t value, st_data_t data)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)data;
+    gc_mark_and_pin(objspace, (VALUE)key);
+    return ST_CONTINUE;
+}
+
+static void
+mark_set(rb_objspace_t *objspace, st_table *tbl)
+{
+    if (!tbl) return;
+    st_foreach(tbl, mark_key, (st_data_t)objspace);
+}
+
+static int
+pin_value(st_data_t key, st_data_t value, st_data_t data)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)data;
+    gc_mark_and_pin(objspace, (VALUE)value);
+    return ST_CONTINUE;
+}
+
+static void
+mark_finalizer_tbl(rb_objspace_t *objspace, st_table *tbl)
+{
+    if (!tbl) return;
+    st_foreach(tbl, pin_value, (st_data_t)objspace);
+}
+
+void
+rb_mark_set(st_table *tbl)
+{
+    mark_set(&rb_objspace, tbl);
+}
+
+static int
+mark_keyvalue(st_data_t key, st_data_t value, st_data_t data)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)data;
+
+    gc_mark(objspace, (VALUE)key);
+    gc_mark(objspace, (VALUE)value);
+    return ST_CONTINUE;
+}
+
+static int
+pin_key_pin_value(st_data_t key, st_data_t value, st_data_t data)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)data;
+
+    gc_mark_and_pin(objspace, (VALUE)key);
+    gc_mark_and_pin(objspace, (VALUE)value);
+    return ST_CONTINUE;
+}
+
+static int
+pin_key_mark_value(st_data_t key, st_data_t value, st_data_t data)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)data;
+
+    gc_mark_and_pin(objspace, (VALUE)key);
+    gc_mark(objspace, (VALUE)value);
+    return ST_CONTINUE;
+}
+
+static void
+mark_hash(rb_objspace_t *objspace, VALUE hash)
+{
+    if (rb_hash_compare_by_id_p(hash)) {
+        rb_hash_stlike_foreach(hash, pin_key_mark_value, (st_data_t)objspace);
+    }
+    else {
+        rb_hash_stlike_foreach(hash, mark_keyvalue, (st_data_t)objspace);
+    }
+
+    if (RHASH_AR_TABLE_P(hash)) {
+        if (LIKELY(during_gc) && RHASH_TRANSIENT_P(hash)) {
+            rb_transient_heap_mark(hash, RHASH_AR_TABLE(hash));
+        }
+    }
+    else {
+        VM_ASSERT(!RHASH_TRANSIENT_P(hash));
+    }
+    gc_mark(objspace, RHASH(hash)->ifnone);
+}
+
+static void
+mark_st(rb_objspace_t *objspace, st_table *tbl)
+{
+    if (!tbl) return;
+    st_foreach(tbl, pin_key_pin_value, (st_data_t)objspace);
+}
+
+void
+rb_mark_hash(st_table *tbl)
+{
+    mark_st(&rb_objspace, tbl);
+}
+
+static void
+mark_method_entry(rb_objspace_t *objspace, const rb_method_entry_t *me)
+{
+    const rb_method_definition_t *def = me->def;
+
+    gc_mark(objspace, me->owner);
+    gc_mark(objspace, me->defined_class);
+
+    if (def) {
+	switch (def->type) {
+	  case VM_METHOD_TYPE_ISEQ:
+	    if (def->body.iseq.iseqptr) gc_mark(objspace, (VALUE)def->body.iseq.iseqptr);
+	    gc_mark(objspace, (VALUE)def->body.iseq.cref);
+	    break;
+	  case VM_METHOD_TYPE_ATTRSET:
+	  case VM_METHOD_TYPE_IVAR:
+	    gc_mark(objspace, def->body.attr.location);
+	    break;
+	  case VM_METHOD_TYPE_BMETHOD:
+            gc_mark(objspace, def->body.bmethod.proc);
+            if (def->body.bmethod.hooks) rb_hook_list_mark(def->body.bmethod.hooks);
+	    break;
+	  case VM_METHOD_TYPE_ALIAS:
+	    gc_mark(objspace, (VALUE)def->body.alias.original_me);
+	    return;
+	  case VM_METHOD_TYPE_REFINED:
+	    gc_mark(objspace, (VALUE)def->body.refined.orig_me);
+	    gc_mark(objspace, (VALUE)def->body.refined.owner);
+	    break;
+	  case VM_METHOD_TYPE_CFUNC:
+	  case VM_METHOD_TYPE_ZSUPER:
+	  case VM_METHOD_TYPE_MISSING:
+	  case VM_METHOD_TYPE_OPTIMIZED:
+	  case VM_METHOD_TYPE_UNDEF:
+	  case VM_METHOD_TYPE_NOTIMPLEMENTED:
+	    break;
+	}
+    }
+}
+
+static enum rb_id_table_iterator_result
+mark_method_entry_i(VALUE me, void *data)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)data;
+
+    gc_mark(objspace, me);
+    return ID_TABLE_CONTINUE;
+}
+
+static void
+mark_m_tbl(rb_objspace_t *objspace, struct rb_id_table *tbl)
+{
+    if (tbl) {
+	rb_id_table_foreach_values(tbl, mark_method_entry_i, objspace);
+    }
+}
+
+static enum rb_id_table_iterator_result
+mark_const_entry_i(VALUE value, void *data)
+{
+    const rb_const_entry_t *ce = (const rb_const_entry_t *)value;
+    rb_objspace_t *objspace = data;
+
+    gc_mark(objspace, ce->value);
+    gc_mark(objspace, ce->file);
+    return ID_TABLE_CONTINUE;
+}
+
+static void
+mark_const_tbl(rb_objspace_t *objspace, struct rb_id_table *tbl)
+{
+    if (!tbl) return;
+    rb_id_table_foreach_values(tbl, mark_const_entry_i, objspace);
+}
+
+#if STACK_GROW_DIRECTION < 0
+#define GET_STACK_BOUNDS(start, end, appendix) ((start) = STACK_END, (end) = STACK_START)
+#elif STACK_GROW_DIRECTION > 0
+#define GET_STACK_BOUNDS(start, end, appendix) ((start) = STACK_START, (end) = STACK_END+(appendix))
+#else
+#define GET_STACK_BOUNDS(start, end, appendix) \
+    ((STACK_END < STACK_START) ? \
+     ((start) = STACK_END, (end) = STACK_START) : ((start) = STACK_START, (end) = STACK_END+(appendix)))
+#endif
+
+static void mark_stack_locations(rb_objspace_t *objspace, const rb_execution_context_t *ec,
+				 const VALUE *stack_start, const VALUE *stack_end);
+
+static void
+mark_current_machine_context(rb_objspace_t *objspace, rb_execution_context_t *ec)
+{
+    union {
+	rb_jmp_buf j;
+	VALUE v[sizeof(rb_jmp_buf) / sizeof(VALUE)];
+    } save_regs_gc_mark;
+    VALUE *stack_start, *stack_end;
+
+    FLUSH_REGISTER_WINDOWS;
+    memset(&save_regs_gc_mark, 0, sizeof(save_regs_gc_mark));
+    /* This assumes that all registers are saved into the jmp_buf (and stack) */
+    rb_setjmp(save_regs_gc_mark.j);
+
+    /* SET_STACK_END must be called in this function because
+     * the stack frame of this function may contain
+     * callee save registers and they should be marked. */
+    SET_STACK_END;
+    GET_STACK_BOUNDS(stack_start, stack_end, 1);
+
+    mark_locations_array(objspace, save_regs_gc_mark.v, numberof(save_regs_gc_mark.v));
+
+    mark_stack_locations(objspace, ec, stack_start, stack_end);
+}
+
+void
+rb_gc_mark_machine_stack(const rb_execution_context_t *ec)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    VALUE *stack_start, *stack_end;
+
+    GET_STACK_BOUNDS(stack_start, stack_end, 0);
+    mark_stack_locations(objspace, ec, stack_start, stack_end);
+}
+
+static void
+mark_stack_locations(rb_objspace_t *objspace, const rb_execution_context_t *ec,
+		     const VALUE *stack_start, const VALUE *stack_end)
+{
+
+    gc_mark_locations(objspace, stack_start, stack_end);
+
+#if defined(__mc68000__)
+    gc_mark_locations(objspace,
+		      (VALUE*)((char*)stack_start + 2),
+		      (VALUE*)((char*)stack_end - 2));
+#endif
+}
+
+void
+rb_mark_tbl(st_table *tbl)
+{
+    mark_tbl(&rb_objspace, tbl);
+}
+
+void
+rb_mark_tbl_no_pin(st_table *tbl)
+{
+    mark_tbl_no_pin(&rb_objspace, tbl);
+}
+
+static void
+gc_mark_maybe(rb_objspace_t *objspace, VALUE obj)
+{
+    (void)VALGRIND_MAKE_MEM_DEFINED(&obj, sizeof(obj));
+
+    if (is_pointer_to_heap(objspace, (void *)obj)) {
+        void *ptr = __asan_region_is_poisoned((void *)obj, SIZEOF_VALUE);
+        asan_unpoison_object(obj, false);
+
+        /* Garbage can live on the stack, so do not mark or pin */
+        switch (BUILTIN_TYPE(obj)) {
+          case T_ZOMBIE:
+          case T_NONE:
+            break;
+          default:
+            gc_mark_and_pin(objspace, obj);
+            break;
+        }
+
+        if (ptr) {
+            GC_ASSERT(BUILTIN_TYPE(obj) == T_NONE);
+            asan_poison_object(obj);
+        }
+    }
+}
+
+void
+rb_gc_mark_maybe(VALUE obj)
+{
+    gc_mark_maybe(&rb_objspace, obj);
+}
+
+static inline int
+gc_mark_set(rb_objspace_t *objspace, VALUE obj)
+{
+    ASSERT_vm_locking();
+    if (RVALUE_MARKED(obj)) return 0;
+    MARK_IN_BITMAP(GET_HEAP_MARK_BITS(obj), obj);
+    return 1;
+}
+
+static int
+gc_remember_unprotected(rb_objspace_t *objspace, VALUE obj)
+{
+    struct heap_page *page = GET_HEAP_PAGE(obj);
+    bits_t *uncollectible_bits = &page->uncollectible_bits[0];
+
+    if (!MARKED_IN_BITMAP(uncollectible_bits, obj)) {
+	page->flags.has_uncollectible_shady_objects = TRUE;
+	MARK_IN_BITMAP(uncollectible_bits, obj);
+	objspace->rgengc.uncollectible_wb_unprotected_objects++;
+
+#if RGENGC_PROFILE > 0
+	objspace->profile.total_remembered_shady_object_count++;
+#if RGENGC_PROFILE >= 2
+	objspace->profile.remembered_shady_object_count_types[BUILTIN_TYPE(obj)]++;
+#endif
+#endif
+	return TRUE;
+    }
+    else {
+	return FALSE;
+    }
+}
+
+static void
+rgengc_check_relation(rb_objspace_t *objspace, VALUE obj)
+{
+    const VALUE old_parent = objspace->rgengc.parent_object;
+
+    if (old_parent) { /* parent object is old */
+	if (RVALUE_WB_UNPROTECTED(obj)) {
+	    if (gc_remember_unprotected(objspace, obj)) {
+		gc_report(2, objspace, "relation: (O->S) %s -> %s\n", obj_info(old_parent), obj_info(obj));
+	    }
+	}
+	else {
+	    if (!RVALUE_OLD_P(obj)) {
+		if (RVALUE_MARKED(obj)) {
+		    /* An object pointed from an OLD object should be OLD. */
+		    gc_report(2, objspace, "relation: (O->unmarked Y) %s -> %s\n", obj_info(old_parent), obj_info(obj));
+		    RVALUE_AGE_SET_OLD(objspace, obj);
+		    if (is_incremental_marking(objspace)) {
+			if (!RVALUE_MARKING(obj)) {
+			    gc_grey(objspace, obj);
+			}
+		    }
+		    else {
+			rgengc_remember(objspace, obj);
+		    }
+		}
+		else {
+		    gc_report(2, objspace, "relation: (O->Y) %s -> %s\n", obj_info(old_parent), obj_info(obj));
+		    RVALUE_AGE_SET_CANDIDATE(objspace, obj);
+		}
+	    }
+	}
+    }
+
+    GC_ASSERT(old_parent == objspace->rgengc.parent_object);
+}
+
+static void
+gc_grey(rb_objspace_t *objspace, VALUE obj)
+{
+#if RGENGC_CHECK_MODE
+    if (RVALUE_MARKED(obj) == FALSE) rb_bug("gc_grey: %s is not marked.", obj_info(obj));
+    if (RVALUE_MARKING(obj) == TRUE) rb_bug("gc_grey: %s is marking/remembered.", obj_info(obj));
+#endif
+
+#if GC_ENABLE_INCREMENTAL_MARK
+    if (is_incremental_marking(objspace)) {
+	MARK_IN_BITMAP(GET_HEAP_MARKING_BITS(obj), obj);
+    }
+#endif
+
+    push_mark_stack(&objspace->mark_stack, obj);
+}
+
+static void
+gc_aging(rb_objspace_t *objspace, VALUE obj)
+{
+    struct heap_page *page = GET_HEAP_PAGE(obj);
+
+    GC_ASSERT(RVALUE_MARKING(obj) == FALSE);
+    check_rvalue_consistency(obj);
+
+    if (!RVALUE_PAGE_WB_UNPROTECTED(page, obj)) {
+	if (!RVALUE_OLD_P(obj)) {
+	    gc_report(3, objspace, "gc_aging: YOUNG: %s\n", obj_info(obj));
+	    RVALUE_AGE_INC(objspace, obj);
+	}
+	else if (is_full_marking(objspace)) {
+	    GC_ASSERT(RVALUE_PAGE_UNCOLLECTIBLE(page, obj) == FALSE);
+	    RVALUE_PAGE_OLD_UNCOLLECTIBLE_SET(objspace, page, obj);
+	}
+    }
+    check_rvalue_consistency(obj);
+
+    objspace->marked_slots++;
+}
+
+NOINLINE(static void gc_mark_ptr(rb_objspace_t *objspace, VALUE obj));
+static void reachable_objects_from_callback(VALUE obj);
+
+static void
+gc_mark_ptr(rb_objspace_t *objspace, VALUE obj)
+{
+    if (LIKELY(during_gc)) {
+	rgengc_check_relation(objspace, obj);
+	if (!gc_mark_set(objspace, obj)) return; /* already marked */
+
+        if (0) { // for debug GC marking miss
+            if (objspace->rgengc.parent_object) {
+                RUBY_DEBUG_LOG("%p (%s) parent:%p (%s)",
+                               (void *)obj, obj_type_name(obj),
+                               (void *)objspace->rgengc.parent_object, obj_type_name(objspace->rgengc.parent_object));
+            }
+            else {
+                RUBY_DEBUG_LOG("%p (%s)", (void *)obj, obj_type_name(obj));
+            }
+        }
+
+        if (UNLIKELY(RB_TYPE_P(obj, T_NONE))) {
+            rp(obj);
+            rb_bug("try to mark T_NONE object"); /* check here will help debugging */
+        }
+	gc_aging(objspace, obj);
+	gc_grey(objspace, obj);
+    }
+    else {
+        reachable_objects_from_callback(obj);
+    }
+}
+
+static inline void
+gc_pin(rb_objspace_t *objspace, VALUE obj)
+{
+    GC_ASSERT(is_markable_object(objspace, obj));
+    if (UNLIKELY(objspace->flags.during_compacting)) {
+        if (LIKELY(during_gc)) {
+            MARK_IN_BITMAP(GET_HEAP_PINNED_BITS(obj), obj);
+        }
+    }
+}
+
+static inline void
+gc_mark_and_pin(rb_objspace_t *objspace, VALUE obj)
+{
+    if (!is_markable_object(objspace, obj)) return;
+    gc_pin(objspace, obj);
+    gc_mark_ptr(objspace, obj);
+}
+
+static inline void
+gc_mark(rb_objspace_t *objspace, VALUE obj)
+{
+    if (!is_markable_object(objspace, obj)) return;
+    gc_mark_ptr(objspace, obj);
+}
+
+void
+rb_gc_mark_movable(VALUE ptr)
+{
+    gc_mark(&rb_objspace, ptr);
+}
+
+void
+rb_gc_mark(VALUE ptr)
+{
+    gc_mark_and_pin(&rb_objspace, ptr);
+}
+
+/* CAUTION: THIS FUNCTION ENABLE *ONLY BEFORE* SWEEPING.
+ * This function is only for GC_END_MARK timing.
+ */
+
+int
+rb_objspace_marked_object_p(VALUE obj)
+{
+    return RVALUE_MARKED(obj) ? TRUE : FALSE;
+}
+
+static inline void
+gc_mark_set_parent(rb_objspace_t *objspace, VALUE obj)
+{
+    if (RVALUE_OLD_P(obj)) {
+	objspace->rgengc.parent_object = obj;
+    }
+    else {
+	objspace->rgengc.parent_object = Qfalse;
+    }
+}
+
+static void
+gc_mark_imemo(rb_objspace_t *objspace, VALUE obj)
+{
+    switch (imemo_type(obj)) {
+      case imemo_env:
+	{
+	    const rb_env_t *env = (const rb_env_t *)obj;
+
+            if (LIKELY(env->ep)) {
+                // just after newobj() can be NULL here.
+                GC_ASSERT(env->ep[VM_ENV_DATA_INDEX_ENV] == obj);
+                GC_ASSERT(VM_ENV_ESCAPED_P(env->ep));
+                gc_mark_values(objspace, (long)env->env_size, env->env);
+                VM_ENV_FLAGS_SET(env->ep, VM_ENV_FLAG_WB_REQUIRED);
+                gc_mark(objspace, (VALUE)rb_vm_env_prev_env(env));
+                gc_mark(objspace, (VALUE)env->iseq);
+            }
+	}
+	return;
+      case imemo_cref:
+	gc_mark(objspace, RANY(obj)->as.imemo.cref.klass);
+	gc_mark(objspace, (VALUE)RANY(obj)->as.imemo.cref.next);
+	gc_mark(objspace, RANY(obj)->as.imemo.cref.refinements);
+	return;
+      case imemo_svar:
+	gc_mark(objspace, RANY(obj)->as.imemo.svar.cref_or_me);
+	gc_mark(objspace, RANY(obj)->as.imemo.svar.lastline);
+	gc_mark(objspace, RANY(obj)->as.imemo.svar.backref);
+	gc_mark(objspace, RANY(obj)->as.imemo.svar.others);
+	return;
+      case imemo_throw_data:
+	gc_mark(objspace, RANY(obj)->as.imemo.throw_data.throw_obj);
+	return;
+      case imemo_ifunc:
+	gc_mark_maybe(objspace, (VALUE)RANY(obj)->as.imemo.ifunc.data);
+	return;
+      case imemo_memo:
+	gc_mark(objspace, RANY(obj)->as.imemo.memo.v1);
+	gc_mark(objspace, RANY(obj)->as.imemo.memo.v2);
+	gc_mark_maybe(objspace, RANY(obj)->as.imemo.memo.u3.value);
+	return;
+      case imemo_ment:
+	mark_method_entry(objspace, &RANY(obj)->as.imemo.ment);
+	return;
+      case imemo_iseq:
+	rb_iseq_mark((rb_iseq_t *)obj);
+	return;
+      case imemo_tmpbuf:
+	{
+	    const rb_imemo_tmpbuf_t *m = &RANY(obj)->as.imemo.alloc;
+	    do {
+		rb_gc_mark_locations(m->ptr, m->ptr + m->cnt);
+	    } while ((m = m->next) != NULL);
+	}
+	return;
+      case imemo_ast:
+	rb_ast_mark(&RANY(obj)->as.imemo.ast);
+	return;
+      case imemo_parser_strterm:
+	rb_strterm_mark(obj);
+	return;
+      case imemo_callinfo:
+        return;
+      case imemo_callcache:
+        {
+            const struct rb_callcache *cc = (const struct rb_callcache *)obj;
+            // should not mark klass here
+            gc_mark(objspace, (VALUE)vm_cc_cme(cc));
+        }
+        return;
+      case imemo_constcache:
+        {
+            const struct iseq_inline_constant_cache_entry *ice = (struct iseq_inline_constant_cache_entry *)obj;
+            gc_mark(objspace, ice->value);
+        }
+        return;
+#if VM_CHECK_MODE > 0
+      default:
+	VM_UNREACHABLE(gc_mark_imemo);
+#endif
+    }
+}
+
+static void
+gc_mark_children(rb_objspace_t *objspace, VALUE obj)
+{
+    register RVALUE *any = RANY(obj);
+    gc_mark_set_parent(objspace, obj);
+
+    if (FL_TEST(obj, FL_EXIVAR)) {
+	rb_mark_generic_ivar(obj);
+    }
+
+    switch (BUILTIN_TYPE(obj)) {
+      case T_FLOAT:
+      case T_BIGNUM:
+      case T_SYMBOL:
+        /* Not immediates, but does not have references and singleton
+         * class */
+        return;
+
+      case T_NIL:
+      case T_FIXNUM:
+	rb_bug("rb_gc_mark() called for broken object");
+	break;
+
+      case T_NODE:
+	UNEXPECTED_NODE(rb_gc_mark);
+	break;
+
+      case T_IMEMO:
+	gc_mark_imemo(objspace, obj);
+	return;
+
+      default:
+        break;
+    }
+
+    gc_mark(objspace, any->as.basic.klass);
+
+    switch (BUILTIN_TYPE(obj)) {
+      case T_CLASS:
+      case T_MODULE:
+        if (RCLASS_SUPER(obj)) {
+            gc_mark(objspace, RCLASS_SUPER(obj));
+        }
+	if (!RCLASS_EXT(obj)) break;
+
+        mark_m_tbl(objspace, RCLASS_M_TBL(obj));
+        cc_table_mark(objspace, obj);
+        mark_tbl_no_pin(objspace, RCLASS_IV_TBL(obj));
+	mark_const_tbl(objspace, RCLASS_CONST_TBL(obj));
+	break;
+
+      case T_ICLASS:
+        if (RICLASS_OWNS_M_TBL_P(obj)) {
+	    mark_m_tbl(objspace, RCLASS_M_TBL(obj));
+	}
+        if (RCLASS_SUPER(obj)) {
+            gc_mark(objspace, RCLASS_SUPER(obj));
+        }
+	if (!RCLASS_EXT(obj)) break;
+	mark_m_tbl(objspace, RCLASS_CALLABLE_M_TBL(obj));
+        cc_table_mark(objspace, obj);
+	break;
+
+      case T_ARRAY:
+        if (FL_TEST(obj, ELTS_SHARED)) {
+            VALUE root = any->as.array.as.heap.aux.shared_root;
+            gc_mark(objspace, root);
+	}
+	else {
+	    long i, len = RARRAY_LEN(obj);
+            const VALUE *ptr = RARRAY_CONST_PTR_TRANSIENT(obj);
+	    for (i=0; i < len; i++) {
+                gc_mark(objspace, ptr[i]);
+	    }
+
+            if (LIKELY(during_gc)) {
+                if (!FL_TEST_RAW(obj, RARRAY_EMBED_FLAG) &&
+                    RARRAY_TRANSIENT_P(obj)) {
+                    rb_transient_heap_mark(obj, ptr);
+                }
+            }
+        }
+	break;
+
+      case T_HASH:
+        mark_hash(objspace, obj);
+	break;
+
+      case T_STRING:
+	if (STR_SHARED_P(obj)) {
+	    gc_mark(objspace, any->as.string.as.heap.aux.shared);
+	}
+	break;
+
+      case T_DATA:
+	{
+	    void *const ptr = DATA_PTR(obj);
+	    if (ptr) {
+		RUBY_DATA_FUNC mark_func = RTYPEDDATA_P(obj) ?
+		    any->as.typeddata.type->function.dmark :
+		    any->as.data.dmark;
+		if (mark_func) (*mark_func)(ptr);
+	    }
+	}
+	break;
+
+      case T_OBJECT:
+        {
+            const VALUE * const ptr = ROBJECT_IVPTR(obj);
+
+            uint32_t i, len = ROBJECT_NUMIV(obj);
+            for (i  = 0; i < len; i++) {
+                gc_mark(objspace, ptr[i]);
+            }
+
+            if (LIKELY(during_gc) &&
+                    ROBJ_TRANSIENT_P(obj)) {
+                rb_transient_heap_mark(obj, ptr);
+            }
+        }
+	break;
+
+      case T_FILE:
+        if (any->as.file.fptr) {
+            gc_mark(objspace, any->as.file.fptr->self);
+            gc_mark(objspace, any->as.file.fptr->pathv);
+            gc_mark(objspace, any->as.file.fptr->tied_io_for_writing);
+            gc_mark(objspace, any->as.file.fptr->writeconv_asciicompat);
+            gc_mark(objspace, any->as.file.fptr->writeconv_pre_ecopts);
+            gc_mark(objspace, any->as.file.fptr->encs.ecopts);
+            gc_mark(objspace, any->as.file.fptr->write_lock);
+        }
+        break;
+
+      case T_REGEXP:
+        gc_mark(objspace, any->as.regexp.src);
+	break;
+
+      case T_MATCH:
+	gc_mark(objspace, any->as.match.regexp);
+	if (any->as.match.str) {
+	    gc_mark(objspace, any->as.match.str);
+	}
+	break;
+
+      case T_RATIONAL:
+	gc_mark(objspace, any->as.rational.num);
+	gc_mark(objspace, any->as.rational.den);
+	break;
+
+      case T_COMPLEX:
+	gc_mark(objspace, any->as.complex.real);
+	gc_mark(objspace, any->as.complex.imag);
+	break;
+
+      case T_STRUCT:
+	{
+            long i;
+            const long len = RSTRUCT_LEN(obj);
+            const VALUE * const ptr = RSTRUCT_CONST_PTR(obj);
+
+            for (i=0; i<len; i++) {
+                gc_mark(objspace, ptr[i]);
+            }
+
+            if (LIKELY(during_gc) &&
+                RSTRUCT_TRANSIENT_P(obj)) {
+                rb_transient_heap_mark(obj, ptr);
+            }
+	}
+	break;
+
+      default:
+#if GC_DEBUG
+	rb_gcdebug_print_obj_condition((VALUE)obj);
+#endif
+        if (BUILTIN_TYPE(obj) == T_MOVED)   rb_bug("rb_gc_mark(): %p is T_MOVED", (void *)obj);
+	if (BUILTIN_TYPE(obj) == T_NONE)   rb_bug("rb_gc_mark(): %p is T_NONE", (void *)obj);
+	if (BUILTIN_TYPE(obj) == T_ZOMBIE) rb_bug("rb_gc_mark(): %p is T_ZOMBIE", (void *)obj);
+	rb_bug("rb_gc_mark(): unknown data type 0x%x(%p) %s",
+	       BUILTIN_TYPE(obj), (void *)any,
+	       is_pointer_to_heap(objspace, any) ? "corrupted object" : "non object");
+    }
+}
+
+/**
+ * incremental: 0 -> not incremental (do all)
+ * incremental: n -> mark at most `n' objects
+ */
+static inline int
+gc_mark_stacked_objects(rb_objspace_t *objspace, int incremental, size_t count)
+{
+    mark_stack_t *mstack = &objspace->mark_stack;
+    VALUE obj;
+#if GC_ENABLE_INCREMENTAL_MARK
+    size_t marked_slots_at_the_beginning = objspace->marked_slots;
+    size_t popped_count = 0;
+#endif
+
+    while (pop_mark_stack(mstack, &obj)) {
+	if (obj == Qundef) continue; /* skip */
+
+	if (RGENGC_CHECK_MODE && !RVALUE_MARKED(obj)) {
+	    rb_bug("gc_mark_stacked_objects: %s is not marked.", obj_info(obj));
+	}
+        gc_mark_children(objspace, obj);
+
+#if GC_ENABLE_INCREMENTAL_MARK
+	if (incremental) {
+	    if (RGENGC_CHECK_MODE && !RVALUE_MARKING(obj)) {
+		rb_bug("gc_mark_stacked_objects: incremental, but marking bit is 0");
+	    }
+	    CLEAR_IN_BITMAP(GET_HEAP_MARKING_BITS(obj), obj);
+	    popped_count++;
+
+	    if (popped_count + (objspace->marked_slots - marked_slots_at_the_beginning) > count) {
+		break;
+	    }
+	}
+	else {
+	    /* just ignore marking bits */
+	}
+#endif
+    }
+
+    if (RGENGC_CHECK_MODE >= 3) gc_verify_internal_consistency(objspace);
+
+    if (is_mark_stack_empty(mstack)) {
+	shrink_stack_chunk_cache(mstack);
+	return TRUE;
+    }
+    else {
+	return FALSE;
+    }
+}
+
+static int
+gc_mark_stacked_objects_incremental(rb_objspace_t *objspace, size_t count)
+{
+    return gc_mark_stacked_objects(objspace, TRUE, count);
+}
+
+static int
+gc_mark_stacked_objects_all(rb_objspace_t *objspace)
+{
+    return gc_mark_stacked_objects(objspace, FALSE, 0);
+}
+
+#if PRINT_ROOT_TICKS
+#define MAX_TICKS 0x100
+static tick_t mark_ticks[MAX_TICKS];
+static const char *mark_ticks_categories[MAX_TICKS];
+
+static void
+show_mark_ticks(void)
+{
+    int i;
+    fprintf(stderr, "mark ticks result:\n");
+    for (i=0; i<MAX_TICKS; i++) {
+	const char *category = mark_ticks_categories[i];
+	if (category) {
+	    fprintf(stderr, "%s\t%8lu\n", category, (unsigned long)mark_ticks[i]);
+	}
+	else {
+	    break;
+	}
+    }
+}
+
+#endif /* PRINT_ROOT_TICKS */
+
+static void
+gc_mark_roots(rb_objspace_t *objspace, const char **categoryp)
+{
+    struct gc_list *list;
+    rb_execution_context_t *ec = GET_EC();
+    rb_vm_t *vm = rb_ec_vm_ptr(ec);
+
+#if PRINT_ROOT_TICKS
+    tick_t start_tick = tick();
+    int tick_count = 0;
+    const char *prev_category = 0;
+
+    if (mark_ticks_categories[0] == 0) {
+	atexit(show_mark_ticks);
+    }
+#endif
+
+    if (categoryp) *categoryp = "xxx";
+
+    objspace->rgengc.parent_object = Qfalse;
+
+#if PRINT_ROOT_TICKS
+#define MARK_CHECKPOINT_PRINT_TICK(category) do { \
+    if (prev_category) { \
+	tick_t t = tick(); \
+	mark_ticks[tick_count] = t - start_tick; \
+	mark_ticks_categories[tick_count] = prev_category; \
+	tick_count++; \
+    } \
+    prev_category = category; \
+    start_tick = tick(); \
+} while (0)
+#else /* PRINT_ROOT_TICKS */
+#define MARK_CHECKPOINT_PRINT_TICK(category)
+#endif
+
+#define MARK_CHECKPOINT(category) do { \
+    if (categoryp) *categoryp = category; \
+    MARK_CHECKPOINT_PRINT_TICK(category); \
+} while (0)
+
+    MARK_CHECKPOINT("vm");
+    SET_STACK_END;
+    rb_vm_mark(vm);
+    if (vm->self) gc_mark(objspace, vm->self);
+
+    MARK_CHECKPOINT("finalizers");
+    mark_finalizer_tbl(objspace, finalizer_table);
+
+    MARK_CHECKPOINT("machine_context");
+    mark_current_machine_context(objspace, ec);
+
+    /* mark protected global variables */
+    MARK_CHECKPOINT("global_list");
+    for (list = global_list; list; list = list->next) {
+        gc_mark_maybe(objspace, *list->varptr);
+    }
+
+    MARK_CHECKPOINT("end_proc");
+    rb_mark_end_proc();
+
+    MARK_CHECKPOINT("global_tbl");
+    rb_gc_mark_global_tbl();
+
+    MARK_CHECKPOINT("object_id");
+    rb_gc_mark(objspace->next_object_id);
+    mark_tbl_no_pin(objspace, objspace->obj_to_id_tbl); /* Only mark ids */
+
+    if (stress_to_class) rb_gc_mark(stress_to_class);
+
+    MARK_CHECKPOINT("finish");
+#undef MARK_CHECKPOINT
+}
+
+#if RGENGC_CHECK_MODE >= 4
+
+#define MAKE_ROOTSIG(obj) (((VALUE)(obj) << 1) | 0x01)
+#define IS_ROOTSIG(obj)   ((VALUE)(obj) & 0x01)
+#define GET_ROOTSIG(obj)  ((const char *)((VALUE)(obj) >> 1))
+
+struct reflist {
+    VALUE *list;
+    int pos;
+    int size;
+};
+
+static struct reflist *
+reflist_create(VALUE obj)
+{
+    struct reflist *refs = xmalloc(sizeof(struct reflist));
+    refs->size = 1;
+    refs->list = ALLOC_N(VALUE, refs->size);
+    refs->list[0] = obj;
+    refs->pos = 1;
+    return refs;
+}
+
+static void
+reflist_destruct(struct reflist *refs)
+{
+    xfree(refs->list);
+    xfree(refs);
+}
+
+static void
+reflist_add(struct reflist *refs, VALUE obj)
+{
+    if (refs->pos == refs->size) {
+	refs->size *= 2;
+	SIZED_REALLOC_N(refs->list, VALUE, refs->size, refs->size/2);
+    }
+
+    refs->list[refs->pos++] = obj;
+}
+
+static void
+reflist_dump(struct reflist *refs)
+{
+    int i;
+    for (i=0; i<refs->pos; i++) {
+	VALUE obj = refs->list[i];
+	if (IS_ROOTSIG(obj)) { /* root */
+	    fprintf(stderr, "<root@%s>", GET_ROOTSIG(obj));
+	}
+	else {
+	    fprintf(stderr, "<%s>", obj_info(obj));
+	}
+	if (i+1 < refs->pos) fprintf(stderr, ", ");
+    }
+}
+
+static int
+reflist_referred_from_machine_context(struct reflist *refs)
+{
+    int i;
+    for (i=0; i<refs->pos; i++) {
+	VALUE obj = refs->list[i];
+	if (IS_ROOTSIG(obj) && strcmp(GET_ROOTSIG(obj), "machine_context") == 0) return 1;
+    }
+    return 0;
+}
+
+struct allrefs {
+    rb_objspace_t *objspace;
+    /* a -> obj1
+     * b -> obj1
+     * c -> obj1
+     * c -> obj2
+     * d -> obj3
+     * #=> {obj1 => [a, b, c], obj2 => [c, d]}
+     */
+    struct st_table *references;
+    const char *category;
+    VALUE root_obj;
+    mark_stack_t mark_stack;
+};
+
+static int
+allrefs_add(struct allrefs *data, VALUE obj)
+{
+    struct reflist *refs;
+    st_data_t r;
+
+    if (st_lookup(data->references, obj, &r)) {
+        refs = (struct reflist *)r;
+	reflist_add(refs, data->root_obj);
+	return 0;
+    }
+    else {
+	refs = reflist_create(data->root_obj);
+	st_insert(data->references, obj, (st_data_t)refs);
+	return 1;
+    }
+}
+
+static void
+allrefs_i(VALUE obj, void *ptr)
+{
+    struct allrefs *data = (struct allrefs *)ptr;
+
+    if (allrefs_add(data, obj)) {
+	push_mark_stack(&data->mark_stack, obj);
+    }
+}
+
+static void
+allrefs_roots_i(VALUE obj, void *ptr)
+{
+    struct allrefs *data = (struct allrefs *)ptr;
+    if (strlen(data->category) == 0) rb_bug("!!!");
+    data->root_obj = MAKE_ROOTSIG(data->category);
+
+    if (allrefs_add(data, obj)) {
+	push_mark_stack(&data->mark_stack, obj);
+    }
+}
+
+static st_table *
+objspace_allrefs(rb_objspace_t *objspace)
+{
+    struct allrefs data;
+    struct mark_func_data_struct mfd;
+    VALUE obj;
+    int prev_dont_gc = dont_gc_val();
+    dont_gc_on();
+
+    data.objspace = objspace;
+    data.references = st_init_numtable();
+    init_mark_stack(&data.mark_stack);
+
+    mfd.mark_func = allrefs_roots_i;
+    mfd.data = &data;
+
+    /* traverse root objects */
+    PUSH_MARK_FUNC_DATA(&mfd);
+    objspace->mark_func_data = &mfd;
+    gc_mark_roots(objspace, &data.category);
+    POP_MARK_FUNC_DATA();
+
+    /* traverse rest objects reachable from root objects */
+    while (pop_mark_stack(&data.mark_stack, &obj)) {
+	rb_objspace_reachable_objects_from(data.root_obj = obj, allrefs_i, &data);
+    }
+    free_stack_chunks(&data.mark_stack);
+
+    dont_gc_set(prev_dont_gc);
+    return data.references;
+}
+
+static int
+objspace_allrefs_destruct_i(st_data_t key, st_data_t value, st_data_t ptr)
+{
+    struct reflist *refs = (struct reflist *)value;
+    reflist_destruct(refs);
+    return ST_CONTINUE;
+}
+
+static void
+objspace_allrefs_destruct(struct st_table *refs)
+{
+    st_foreach(refs, objspace_allrefs_destruct_i, 0);
+    st_free_table(refs);
+}
+
+#if RGENGC_CHECK_MODE >= 5
+static int
+allrefs_dump_i(st_data_t k, st_data_t v, st_data_t ptr)
+{
+    VALUE obj = (VALUE)k;
+    struct reflist *refs = (struct reflist *)v;
+    fprintf(stderr, "[allrefs_dump_i] %s <- ", obj_info(obj));
+    reflist_dump(refs);
+    fprintf(stderr, "\n");
+    return ST_CONTINUE;
+}
+
+static void
+allrefs_dump(rb_objspace_t *objspace)
+{
+    VALUE size = objspace->rgengc.allrefs_table->num_entries;
+    fprintf(stderr, "[all refs] (size: %"PRIuVALUE")\n", size);
+    st_foreach(objspace->rgengc.allrefs_table, allrefs_dump_i, 0);
+}
+#endif
+
+static int
+gc_check_after_marks_i(st_data_t k, st_data_t v, st_data_t ptr)
+{
+    VALUE obj = k;
+    struct reflist *refs = (struct reflist *)v;
+    rb_objspace_t *objspace = (rb_objspace_t *)ptr;
+
+    /* object should be marked or oldgen */
+    if (!MARKED_IN_BITMAP(GET_HEAP_MARK_BITS(obj), obj)) {
+	fprintf(stderr, "gc_check_after_marks_i: %s is not marked and not oldgen.\n", obj_info(obj));
+	fprintf(stderr, "gc_check_after_marks_i: %p is referred from ", (void *)obj);
+	reflist_dump(refs);
+
+	if (reflist_referred_from_machine_context(refs)) {
+	    fprintf(stderr, " (marked from machine stack).\n");
+	    /* marked from machine context can be false positive */
+	}
+	else {
+	    objspace->rgengc.error_count++;
+	    fprintf(stderr, "\n");
+	}
+    }
+    return ST_CONTINUE;
+}
+
+static void
+gc_marks_check(rb_objspace_t *objspace, st_foreach_callback_func *checker_func, const char *checker_name)
+{
+    size_t saved_malloc_increase = objspace->malloc_params.increase;
+#if RGENGC_ESTIMATE_OLDMALLOC
+    size_t saved_oldmalloc_increase = objspace->rgengc.oldmalloc_increase;
+#endif
+    VALUE already_disabled = rb_objspace_gc_disable(objspace);
+
+    objspace->rgengc.allrefs_table = objspace_allrefs(objspace);
+
+    if (checker_func) {
+	st_foreach(objspace->rgengc.allrefs_table, checker_func, (st_data_t)objspace);
+    }
+
+    if (objspace->rgengc.error_count > 0) {
+#if RGENGC_CHECK_MODE >= 5
+	allrefs_dump(objspace);
+#endif
+	if (checker_name) rb_bug("%s: GC has problem.", checker_name);
+    }
+
+    objspace_allrefs_destruct(objspace->rgengc.allrefs_table);
+    objspace->rgengc.allrefs_table = 0;
+
+    if (already_disabled == Qfalse) rb_objspace_gc_enable(objspace);
+    objspace->malloc_params.increase = saved_malloc_increase;
+#if RGENGC_ESTIMATE_OLDMALLOC
+    objspace->rgengc.oldmalloc_increase = saved_oldmalloc_increase;
+#endif
+}
+#endif /* RGENGC_CHECK_MODE >= 4 */
+
+struct verify_internal_consistency_struct {
+    rb_objspace_t *objspace;
+    int err_count;
+    size_t live_object_count;
+    size_t zombie_object_count;
+
+    VALUE parent;
+    size_t old_object_count;
+    size_t remembered_shady_count;
+};
+
+static void
+check_generation_i(const VALUE child, void *ptr)
+{
+    struct verify_internal_consistency_struct *data = (struct verify_internal_consistency_struct *)ptr;
+    const VALUE parent = data->parent;
+
+    if (RGENGC_CHECK_MODE) GC_ASSERT(RVALUE_OLD_P(parent));
+
+    if (!RVALUE_OLD_P(child)) {
+	if (!RVALUE_REMEMBERED(parent) &&
+	    !RVALUE_REMEMBERED(child) &&
+	    !RVALUE_UNCOLLECTIBLE(child)) {
+	    fprintf(stderr, "verify_internal_consistency_reachable_i: WB miss (O->Y) %s -> %s\n", obj_info(parent), obj_info(child));
+	    data->err_count++;
+	}
+    }
+}
+
+static void
+check_color_i(const VALUE child, void *ptr)
+{
+    struct verify_internal_consistency_struct *data = (struct verify_internal_consistency_struct *)ptr;
+    const VALUE parent = data->parent;
+
+    if (!RVALUE_WB_UNPROTECTED(parent) && RVALUE_WHITE_P(child)) {
+	fprintf(stderr, "verify_internal_consistency_reachable_i: WB miss (B->W) - %s -> %s\n",
+		obj_info(parent), obj_info(child));
+	data->err_count++;
+    }
+}
+
+static void
+check_children_i(const VALUE child, void *ptr)
+{
+    struct verify_internal_consistency_struct *data = (struct verify_internal_consistency_struct *)ptr;
+    if (check_rvalue_consistency_force(child, FALSE) != 0) {
+        fprintf(stderr, "check_children_i: %s has error (referenced from %s)",
+                obj_info(child), obj_info(data->parent));
+        rb_print_backtrace(); /* C backtrace will help to debug */
+
+        data->err_count++;
+    }
+}
+
+static int
+verify_internal_consistency_i(void *page_start, void *page_end, size_t stride, void *ptr)
+{
+    struct verify_internal_consistency_struct *data = (struct verify_internal_consistency_struct *)ptr;
+    VALUE obj;
+    rb_objspace_t *objspace = data->objspace;
+
+    for (obj = (VALUE)page_start; obj != (VALUE)page_end; obj += stride) {
+        void *poisoned = asan_poisoned_object_p(obj);
+        asan_unpoison_object(obj, false);
+
+	if (is_live_object(objspace, obj)) {
+	    /* count objects */
+	    data->live_object_count++;
+            data->parent = obj;
+
+            /* Normally, we don't expect T_MOVED objects to be in the heap.
+             * But they can stay alive on the stack, */
+            if (!gc_object_moved_p(objspace, obj)) {
+                /* moved slots don't have children */
+                rb_objspace_reachable_objects_from(obj, check_children_i, (void *)data);
+            }
+
+	    /* check health of children */
+	    if (RVALUE_OLD_P(obj)) data->old_object_count++;
+	    if (RVALUE_WB_UNPROTECTED(obj) && RVALUE_UNCOLLECTIBLE(obj)) data->remembered_shady_count++;
+
+	    if (!is_marking(objspace) && RVALUE_OLD_P(obj)) {
+		/* reachable objects from an oldgen object should be old or (young with remember) */
+		data->parent = obj;
+		rb_objspace_reachable_objects_from(obj, check_generation_i, (void *)data);
+	    }
+
+	    if (is_incremental_marking(objspace)) {
+		if (RVALUE_BLACK_P(obj)) {
+		    /* reachable objects from black objects should be black or grey objects */
+		    data->parent = obj;
+		    rb_objspace_reachable_objects_from(obj, check_color_i, (void *)data);
+		}
+	    }
+	}
+	else {
+	    if (BUILTIN_TYPE(obj) == T_ZOMBIE) {
+		GC_ASSERT((RBASIC(obj)->flags & ~FL_SEEN_OBJ_ID) == T_ZOMBIE);
+		data->zombie_object_count++;
+	    }
+	}
+        if (poisoned) {
+            GC_ASSERT(BUILTIN_TYPE(obj) == T_NONE);
+            asan_poison_object(obj);
+        }
+    }
+
+    return 0;
+}
+
+static int
+gc_verify_heap_page(rb_objspace_t *objspace, struct heap_page *page, VALUE obj)
+{
+    int i;
+    unsigned int has_remembered_shady = FALSE;
+    unsigned int has_remembered_old = FALSE;
+    int remembered_old_objects = 0;
+    int free_objects = 0;
+    int zombie_objects = 0;
+
+    for (i=0; i<page->total_slots; i++) {
+	VALUE val = (VALUE)&page->start[i];
+        void *poisoned = asan_poisoned_object_p(val);
+        asan_unpoison_object(val, false);
+
+	if (RBASIC(val) == 0) free_objects++;
+	if (BUILTIN_TYPE(val) == T_ZOMBIE) zombie_objects++;
+	if (RVALUE_PAGE_UNCOLLECTIBLE(page, val) && RVALUE_PAGE_WB_UNPROTECTED(page, val)) {
+	    has_remembered_shady = TRUE;
+	}
+	if (RVALUE_PAGE_MARKING(page, val)) {
+	    has_remembered_old = TRUE;
+	    remembered_old_objects++;
+	}
+
+        if (poisoned) {
+            GC_ASSERT(BUILTIN_TYPE(val) == T_NONE);
+            asan_poison_object(val);
+        }
+    }
+
+    if (!is_incremental_marking(objspace) &&
+	page->flags.has_remembered_objects == FALSE && has_remembered_old == TRUE) {
+
+	for (i=0; i<page->total_slots; i++) {
+	    VALUE val = (VALUE)&page->start[i];
+	    if (RVALUE_PAGE_MARKING(page, val)) {
+		fprintf(stderr, "marking -> %s\n", obj_info(val));
+	    }
+	}
+	rb_bug("page %p's has_remembered_objects should be false, but there are remembered old objects (%d). %s",
+	       (void *)page, remembered_old_objects, obj ? obj_info(obj) : "");
+    }
+
+    if (page->flags.has_uncollectible_shady_objects == FALSE && has_remembered_shady == TRUE) {
+	rb_bug("page %p's has_remembered_shady should be false, but there are remembered shady objects. %s",
+	       (void *)page, obj ? obj_info(obj) : "");
+    }
+
+    if (0) {
+	/* free_slots may not equal to free_objects */
+	if (page->free_slots != free_objects) {
+	    rb_bug("page %p's free_slots should be %d, but %d\n", (void *)page, page->free_slots, free_objects);
+	}
+    }
+    if (page->final_slots != zombie_objects) {
+	rb_bug("page %p's final_slots should be %d, but %d\n", (void *)page, page->final_slots, zombie_objects);
+    }
+
+    return remembered_old_objects;
+}
+
+static int
+gc_verify_heap_pages_(rb_objspace_t *objspace, struct list_head *head)
+{
+    int remembered_old_objects = 0;
+    struct heap_page *page = 0;
+
+    list_for_each(head, page, page_node) {
+        asan_unpoison_memory_region(&page->freelist, sizeof(RVALUE*), false);
+        RVALUE *p = page->freelist;
+        while (p) {
+            VALUE vp = (VALUE)p;
+            VALUE prev = vp;
+            asan_unpoison_object(vp, false);
+            if (BUILTIN_TYPE(vp) != T_NONE) {
+                fprintf(stderr, "freelist slot expected to be T_NONE but was: %s\n", obj_info(vp));
+            }
+            p = p->as.free.next;
+            asan_poison_object(prev);
+        }
+        asan_poison_memory_region(&page->freelist, sizeof(RVALUE*));
+
+	if (page->flags.has_remembered_objects == FALSE) {
+	    remembered_old_objects += gc_verify_heap_page(objspace, page, Qfalse);
+	}
+    }
+
+    return remembered_old_objects;
+}
+
+static int
+gc_verify_heap_pages(rb_objspace_t *objspace)
+{
+    int remembered_old_objects = 0;
+    remembered_old_objects += gc_verify_heap_pages_(objspace, &heap_eden->pages);
+    remembered_old_objects += gc_verify_heap_pages_(objspace, &heap_tomb->pages);
+    return remembered_old_objects;
+}
+
+/*
+ *  call-seq:
+ *     GC.verify_internal_consistency                  -> nil
+ *
+ *  Verify internal consistency.
+ *
+ *  This method is implementation specific.
+ *  Now this method checks generational consistency
+ *  if RGenGC is supported.
+ */
+static VALUE
+gc_verify_internal_consistency_m(VALUE dummy)
+{
+    gc_verify_internal_consistency(&rb_objspace);
+    return Qnil;
+}
+
+static void
+gc_verify_internal_consistency_(rb_objspace_t *objspace)
+{
+    struct verify_internal_consistency_struct data = {0};
+
+    data.objspace = objspace;
+    gc_report(5, objspace, "gc_verify_internal_consistency: start\n");
+
+    /* check relations */
+
+    objspace_each_objects_without_setup(objspace, verify_internal_consistency_i, &data);
+
+    if (data.err_count != 0) {
+#if RGENGC_CHECK_MODE >= 5
+	objspace->rgengc.error_count = data.err_count;
+	gc_marks_check(objspace, NULL, NULL);
+	allrefs_dump(objspace);
+#endif
+	rb_bug("gc_verify_internal_consistency: found internal inconsistency.");
+    }
+
+    /* check heap_page status */
+    gc_verify_heap_pages(objspace);
+
+    /* check counters */
+
+    if (!is_lazy_sweeping(heap_eden) &&
+        !finalizing &&
+        ruby_single_main_ractor != NULL) {
+	if (objspace_live_slots(objspace) != data.live_object_count) {
+	    fprintf(stderr, "heap_pages_final_slots: %"PRIdSIZE", "
+                    "objspace->profile.total_freed_objects: %"PRIdSIZE"\n",
+		    heap_pages_final_slots, objspace->profile.total_freed_objects);
+	    rb_bug("inconsistent live slot number: expect %"PRIuSIZE", but %"PRIuSIZE".",
+                   objspace_live_slots(objspace), data.live_object_count);
+	}
+    }
+
+    if (!is_marking(objspace)) {
+	if (objspace->rgengc.old_objects != data.old_object_count) {
+	    rb_bug("inconsistent old slot number: expect %"PRIuSIZE", but %"PRIuSIZE".",
+                   objspace->rgengc.old_objects, data.old_object_count);
+	}
+	if (objspace->rgengc.uncollectible_wb_unprotected_objects != data.remembered_shady_count) {
+            rb_bug("inconsistent number of wb unprotected objects: expect %"PRIuSIZE", but %"PRIuSIZE".",
+                   objspace->rgengc.uncollectible_wb_unprotected_objects, data.remembered_shady_count);
+	}
+    }
+
+    if (!finalizing) {
+	size_t list_count = 0;
+
+	{
+	    VALUE z = heap_pages_deferred_final;
+	    while (z) {
+		list_count++;
+		z = RZOMBIE(z)->next;
+	    }
+	}
+
+	if (heap_pages_final_slots != data.zombie_object_count ||
+	    heap_pages_final_slots != list_count) {
+
+	    rb_bug("inconsistent finalizing object count:\n"
+		   "  expect %"PRIuSIZE"\n"
+		   "  but    %"PRIuSIZE" zombies\n"
+		   "  heap_pages_deferred_final list has %"PRIuSIZE" items.",
+		   heap_pages_final_slots,
+		   data.zombie_object_count,
+		   list_count);
+	}
+    }
+
+    gc_report(5, objspace, "gc_verify_internal_consistency: OK\n");
+}
+
+static void
+gc_verify_internal_consistency(rb_objspace_t *objspace)
+{
+    RB_VM_LOCK_ENTER();
+    {
+        rb_vm_barrier(); // stop other ractors
+
+        unsigned int prev_during_gc = during_gc;
+        during_gc = FALSE; // stop gc here
+        {
+            gc_verify_internal_consistency_(objspace);
+        }
+        during_gc = prev_during_gc;
+    }
+    RB_VM_LOCK_LEAVE();
+}
+
+void
+rb_gc_verify_internal_consistency(void)
+{
+    gc_verify_internal_consistency(&rb_objspace);
+}
+
+static VALUE
+gc_verify_transient_heap_internal_consistency(VALUE dmy)
+{
+    rb_transient_heap_verify();
+    return Qnil;
+}
+
+/* marks */
+
+static void
+gc_marks_start(rb_objspace_t *objspace, int full_mark)
+{
+    /* start marking */
+    gc_report(1, objspace, "gc_marks_start: (%s)\n", full_mark ? "full" : "minor");
+    gc_mode_transition(objspace, gc_mode_marking);
+
+    if (full_mark) {
+#if GC_ENABLE_INCREMENTAL_MARK
+	objspace->rincgc.step_slots = (objspace->marked_slots * 2) / ((objspace->rincgc.pooled_slots / HEAP_PAGE_OBJ_LIMIT) + 1);
+
+	if (0) fprintf(stderr, "objspace->marked_slots: %"PRIdSIZE", "
+                       "objspace->rincgc.pooled_page_num: %"PRIdSIZE", "
+                       "objspace->rincgc.step_slots: %"PRIdSIZE", \n",
+                       objspace->marked_slots, objspace->rincgc.pooled_slots, objspace->rincgc.step_slots);
+#endif
+	objspace->flags.during_minor_gc = FALSE;
+        if (ruby_enable_autocompact) {
+            objspace->flags.during_compacting |= TRUE;
+        }
+	objspace->profile.major_gc_count++;
+	objspace->rgengc.uncollectible_wb_unprotected_objects = 0;
+	objspace->rgengc.old_objects = 0;
+	objspace->rgengc.last_major_gc = objspace->profile.count;
+	objspace->marked_slots = 0;
+	rgengc_mark_and_rememberset_clear(objspace, heap_eden);
+    }
+    else {
+	objspace->flags.during_minor_gc = TRUE;
+	objspace->marked_slots =
+	  objspace->rgengc.old_objects + objspace->rgengc.uncollectible_wb_unprotected_objects; /* uncollectible objects are marked already */
+	objspace->profile.minor_gc_count++;
+	rgengc_rememberset_mark(objspace, heap_eden);
+    }
+
+    gc_mark_roots(objspace, NULL);
+
+    gc_report(1, objspace, "gc_marks_start: (%s) end, stack in %"PRIdSIZE"\n",
+              full_mark ? "full" : "minor", mark_stack_size(&objspace->mark_stack));
+}
+
+#if GC_ENABLE_INCREMENTAL_MARK
+static void
+gc_marks_wb_unprotected_objects(rb_objspace_t *objspace)
+{
+    struct heap_page *page = 0;
+
+    list_for_each(&heap_eden->pages, page, page_node) {
+	bits_t *mark_bits = page->mark_bits;
+	bits_t *wbun_bits = page->wb_unprotected_bits;
+	RVALUE *p = page->start;
+	RVALUE *offset = p - NUM_IN_PAGE(p);
+	size_t j;
+
+	for (j=0; j<HEAP_PAGE_BITMAP_LIMIT; j++) {
+	    bits_t bits = mark_bits[j] & wbun_bits[j];
+
+	    if (bits) {
+		p = offset  + j * BITS_BITLENGTH;
+
+		do {
+		    if (bits & 1) {
+			gc_report(2, objspace, "gc_marks_wb_unprotected_objects: marked shady: %s\n", obj_info((VALUE)p));
+			GC_ASSERT(RVALUE_WB_UNPROTECTED((VALUE)p));
+			GC_ASSERT(RVALUE_MARKED((VALUE)p));
+			gc_mark_children(objspace, (VALUE)p);
+		    }
+		    p++;
+		    bits >>= 1;
+		} while (bits);
+	    }
+	}
+    }
+
+    gc_mark_stacked_objects_all(objspace);
+}
+
+static struct heap_page *
+heap_move_pooled_pages_to_free_pages(rb_heap_t *heap)
+{
+    struct heap_page *page = heap->pooled_pages;
+
+    if (page) {
+	heap->pooled_pages = page->free_next;
+        heap_add_freepage(heap, page);
+    }
+
+    return page;
+}
+#endif
+
+static int
+gc_marks_finish(rb_objspace_t *objspace)
+{
+#if GC_ENABLE_INCREMENTAL_MARK
+    /* finish incremental GC */
+    if (is_incremental_marking(objspace)) {
+	if (heap_eden->pooled_pages) {
+	    heap_move_pooled_pages_to_free_pages(heap_eden);
+	    gc_report(1, objspace, "gc_marks_finish: pooled pages are exists. retry.\n");
+	    return FALSE; /* continue marking phase */
+	}
+
+	if (RGENGC_CHECK_MODE && is_mark_stack_empty(&objspace->mark_stack) == 0) {
+	    rb_bug("gc_marks_finish: mark stack is not empty (%"PRIdSIZE").",
+                   mark_stack_size(&objspace->mark_stack));
+	}
+
+	gc_mark_roots(objspace, 0);
+
+	if (is_mark_stack_empty(&objspace->mark_stack) == FALSE) {
+	    gc_report(1, objspace, "gc_marks_finish: not empty (%"PRIdSIZE"). retry.\n",
+                      mark_stack_size(&objspace->mark_stack));
+	    return FALSE;
+	}
+
+#if RGENGC_CHECK_MODE >= 2
+	if (gc_verify_heap_pages(objspace) != 0) {
+	    rb_bug("gc_marks_finish (incremental): there are remembered old objects.");
+	}
+#endif
+
+	objspace->flags.during_incremental_marking = FALSE;
+	/* check children of all marked wb-unprotected objects */
+	gc_marks_wb_unprotected_objects(objspace);
+    }
+#endif /* GC_ENABLE_INCREMENTAL_MARK */
+
+#if RGENGC_CHECK_MODE >= 2
+    gc_verify_internal_consistency(objspace);
+#endif
+
+    if (is_full_marking(objspace)) {
+	/* See the comment about RUBY_GC_HEAP_OLDOBJECT_LIMIT_FACTOR */
+	const double r = gc_params.oldobject_limit_factor;
+	objspace->rgengc.uncollectible_wb_unprotected_objects_limit = (size_t)(objspace->rgengc.uncollectible_wb_unprotected_objects * r);
+	objspace->rgengc.old_objects_limit = (size_t)(objspace->rgengc.old_objects * r);
+    }
+
+#if RGENGC_CHECK_MODE >= 4
+    gc_marks_check(objspace, gc_check_after_marks_i, "after_marks");
+#endif
+
+    {
+	/* decide full GC is needed or not */
+	rb_heap_t *heap = heap_eden;
+	size_t total_slots = heap_allocatable_pages * HEAP_PAGE_OBJ_LIMIT + heap->total_slots;
+	size_t sweep_slots = total_slots - objspace->marked_slots; /* will be swept slots */
+	size_t max_free_slots = (size_t)(total_slots * gc_params.heap_free_slots_max_ratio);
+	size_t min_free_slots = (size_t)(total_slots * gc_params.heap_free_slots_min_ratio);
+	int full_marking = is_full_marking(objspace);
+        const int r_cnt = GET_VM()->ractor.cnt;
+        const int r_mul = r_cnt > 8 ? 8 : r_cnt; // upto 8
+
+	GC_ASSERT(heap->total_slots >= objspace->marked_slots);
+
+	/* setup free-able page counts */
+        if (max_free_slots < gc_params.heap_init_slots * r_mul) {
+            max_free_slots = gc_params.heap_init_slots * r_mul;
+        }
+
+	if (sweep_slots > max_free_slots) {
+	    heap_pages_freeable_pages = (sweep_slots - max_free_slots) / HEAP_PAGE_OBJ_LIMIT;
+	}
+	else {
+	    heap_pages_freeable_pages = 0;
+	}
+
+        /* check free_min */
+        if (min_free_slots < gc_params.heap_free_slots * r_mul) {
+            min_free_slots = gc_params.heap_free_slots * r_mul;
+        }
+
+	if (sweep_slots < min_free_slots) {
+	    if (!full_marking) {
+		if (objspace->profile.count - objspace->rgengc.last_major_gc < RVALUE_OLD_AGE) {
+		    full_marking = TRUE;
+		    /* do not update last_major_gc, because full marking is not done. */
+                    /* goto increment; */
+		}
+		else {
+		    gc_report(1, objspace, "gc_marks_finish: next is full GC!!)\n");
+		    objspace->rgengc.need_major_gc |= GPR_FLAG_MAJOR_BY_NOFREE;
+		}
+	    }
+            if (full_marking) {
+              /* increment: */
+		gc_report(1, objspace, "gc_marks_finish: heap_set_increment!!\n");
+		heap_set_increment(objspace, heap_extend_pages(objspace, sweep_slots, total_slots));
+		heap_increment(objspace, heap);
+	    }
+	}
+
+	if (full_marking) {
+	    /* See the comment about RUBY_GC_HEAP_OLDOBJECT_LIMIT_FACTOR */
+	    const double r = gc_params.oldobject_limit_factor;
+	    objspace->rgengc.uncollectible_wb_unprotected_objects_limit = (size_t)(objspace->rgengc.uncollectible_wb_unprotected_objects * r);
+	    objspace->rgengc.old_objects_limit = (size_t)(objspace->rgengc.old_objects * r);
+	}
+
+	if (objspace->rgengc.uncollectible_wb_unprotected_objects > objspace->rgengc.uncollectible_wb_unprotected_objects_limit) {
+	    objspace->rgengc.need_major_gc |= GPR_FLAG_MAJOR_BY_SHADY;
+	}
+	if (objspace->rgengc.old_objects > objspace->rgengc.old_objects_limit) {
+	    objspace->rgengc.need_major_gc |= GPR_FLAG_MAJOR_BY_OLDGEN;
+	}
+	if (RGENGC_FORCE_MAJOR_GC) {
+	    objspace->rgengc.need_major_gc = GPR_FLAG_MAJOR_BY_FORCE;
+	}
+
+	gc_report(1, objspace, "gc_marks_finish (marks %"PRIdSIZE" objects, "
+                  "old %"PRIdSIZE" objects, total %"PRIdSIZE" slots, "
+                  "sweep %"PRIdSIZE" slots, increment: %"PRIdSIZE", next GC: %s)\n",
+                  objspace->marked_slots, objspace->rgengc.old_objects, heap->total_slots, sweep_slots, heap_allocatable_pages,
+		  objspace->rgengc.need_major_gc ? "major" : "minor");
+    }
+
+    rb_transient_heap_finish_marking();
+    rb_ractor_finish_marking();
+
+    gc_event_hook(objspace, RUBY_INTERNAL_EVENT_GC_END_MARK, 0);
+
+    return TRUE;
+}
+
+static void
+gc_marks_step(rb_objspace_t *objspace, size_t slots)
+{
+#if GC_ENABLE_INCREMENTAL_MARK
+    GC_ASSERT(is_marking(objspace));
+
+    if (gc_mark_stacked_objects_incremental(objspace, slots)) {
+	if (gc_marks_finish(objspace)) {
+	    /* finish */
+	    gc_sweep(objspace);
+	}
+    }
+    if (0) fprintf(stderr, "objspace->marked_slots: %"PRIdSIZE"\n", objspace->marked_slots);
+#endif
+}
+
+static void
+gc_marks_rest(rb_objspace_t *objspace)
+{
+    gc_report(1, objspace, "gc_marks_rest\n");
+
+#if GC_ENABLE_INCREMENTAL_MARK
+    heap_eden->pooled_pages = NULL;
+#endif
+
+    if (is_incremental_marking(objspace)) {
+	do {
+	    while (gc_mark_stacked_objects_incremental(objspace, INT_MAX) == FALSE);
+	} while (gc_marks_finish(objspace) == FALSE);
+    }
+    else {
+	gc_mark_stacked_objects_all(objspace);
+	gc_marks_finish(objspace);
+    }
+
+    /* move to sweep */
+    gc_sweep(objspace);
+}
+
+static void
+gc_marks_continue(rb_objspace_t *objspace, rb_heap_t *heap)
+{
+    GC_ASSERT(dont_gc_val() == FALSE);
+#if GC_ENABLE_INCREMENTAL_MARK
+
+    unsigned int lock_lev;
+    gc_enter(objspace, gc_enter_event_mark_continue, &lock_lev);
+
+    int slots = 0;
+    const char *from;
+
+    if (heap->pooled_pages) {
+        while (heap->pooled_pages && slots < HEAP_PAGE_OBJ_LIMIT) {
+            struct heap_page *page = heap_move_pooled_pages_to_free_pages(heap);
+            slots += page->free_slots;
+        }
+        from = "pooled-pages";
+    }
+    else if (heap_increment(objspace, heap)) {
+        slots = heap->free_pages->free_slots;
+        from = "incremented-pages";
+    }
+
+    if (slots > 0) {
+        gc_report(2, objspace, "gc_marks_continue: provide %d slots from %s.\n",
+                  slots, from);
+        gc_marks_step(objspace, objspace->rincgc.step_slots);
+    }
+    else {
+        gc_report(2, objspace, "gc_marks_continue: no more pooled pages (stack depth: %"PRIdSIZE").\n",
+                  mark_stack_size(&objspace->mark_stack));
+        gc_marks_rest(objspace);
+    }
+
+    gc_exit(objspace, gc_enter_event_mark_continue, &lock_lev);
+#endif
+}
+
+static void
+gc_marks(rb_objspace_t *objspace, int full_mark)
+{
+    gc_prof_mark_timer_start(objspace);
+
+    /* setup marking */
+
+    gc_marks_start(objspace, full_mark);
+    if (!is_incremental_marking(objspace)) {
+        gc_marks_rest(objspace);
+    }
+
+#if RGENGC_PROFILE > 0
+    if (gc_prof_record(objspace)) {
+        gc_profile_record *record = gc_prof_record(objspace);
+        record->old_objects = objspace->rgengc.old_objects;
+    }
+#endif
+    gc_prof_mark_timer_stop(objspace);
+}
+
+/* RGENGC */
+
+static void
+gc_report_body(int level, rb_objspace_t *objspace, const char *fmt, ...)
+{
+    if (level <= RGENGC_DEBUG) {
+	char buf[1024];
+	FILE *out = stderr;
+	va_list args;
+	const char *status = " ";
+
+	if (during_gc) {
+	    status = is_full_marking(objspace) ? "+" : "-";
+	}
+	else {
+	    if (is_lazy_sweeping(heap_eden)) {
+		status = "S";
+	    }
+	    if (is_incremental_marking(objspace)) {
+		status = "M";
+	    }
+	}
+
+	va_start(args, fmt);
+	vsnprintf(buf, 1024, fmt, args);
+	va_end(args);
+
+	fprintf(out, "%s|", status);
+	fputs(buf, out);
+    }
+}
+
+/* bit operations */
+
+static int
+rgengc_remembersetbits_get(rb_objspace_t *objspace, VALUE obj)
+{
+    return RVALUE_REMEMBERED(obj);
+}
+
+static int
+rgengc_remembersetbits_set(rb_objspace_t *objspace, VALUE obj)
+{
+    struct heap_page *page = GET_HEAP_PAGE(obj);
+    bits_t *bits = &page->marking_bits[0];
+
+    GC_ASSERT(!is_incremental_marking(objspace));
+
+    if (MARKED_IN_BITMAP(bits, obj)) {
+	return FALSE;
+    }
+    else {
+	page->flags.has_remembered_objects = TRUE;
+	MARK_IN_BITMAP(bits, obj);
+	return TRUE;
+    }
+}
+
+/* wb, etc */
+
+/* return FALSE if already remembered */
+static int
+rgengc_remember(rb_objspace_t *objspace, VALUE obj)
+{
+    gc_report(6, objspace, "rgengc_remember: %s %s\n", obj_info(obj),
+	      rgengc_remembersetbits_get(objspace, obj) ? "was already remembered" : "is remembered now");
+
+    check_rvalue_consistency(obj);
+
+    if (RGENGC_CHECK_MODE) {
+	if (RVALUE_WB_UNPROTECTED(obj)) rb_bug("rgengc_remember: %s is not wb protected.", obj_info(obj));
+    }
+
+#if RGENGC_PROFILE > 0
+    if (!rgengc_remembered(objspace, obj)) {
+	if (RVALUE_WB_UNPROTECTED(obj) == 0) {
+	    objspace->profile.total_remembered_normal_object_count++;
+#if RGENGC_PROFILE >= 2
+	    objspace->profile.remembered_normal_object_count_types[BUILTIN_TYPE(obj)]++;
+#endif
+	}
+    }
+#endif /* RGENGC_PROFILE > 0 */
+
+    return rgengc_remembersetbits_set(objspace, obj);
+}
+
+static int
+rgengc_remembered_sweep(rb_objspace_t *objspace, VALUE obj)
+{
+    int result = rgengc_remembersetbits_get(objspace, obj);
+    check_rvalue_consistency(obj);
+    return result;
+}
+
+static int
+rgengc_remembered(rb_objspace_t *objspace, VALUE obj)
+{
+    gc_report(6, objspace, "rgengc_remembered: %s\n", obj_info(obj));
+    return rgengc_remembered_sweep(objspace, obj);
+}
+
+#ifndef PROFILE_REMEMBERSET_MARK
+#define PROFILE_REMEMBERSET_MARK 0
+#endif
+
+static void
+rgengc_rememberset_mark(rb_objspace_t *objspace, rb_heap_t *heap)
+{
+    size_t j;
+    struct heap_page *page = 0;
+#if PROFILE_REMEMBERSET_MARK
+    int has_old = 0, has_shady = 0, has_both = 0, skip = 0;
+#endif
+    gc_report(1, objspace, "rgengc_rememberset_mark: start\n");
+
+    list_for_each(&heap->pages, page, page_node) {
+	if (page->flags.has_remembered_objects | page->flags.has_uncollectible_shady_objects) {
+	    RVALUE *p = page->start;
+	    RVALUE *offset = p - NUM_IN_PAGE(p);
+	    bits_t bitset, bits[HEAP_PAGE_BITMAP_LIMIT];
+	    bits_t *marking_bits = page->marking_bits;
+	    bits_t *uncollectible_bits = page->uncollectible_bits;
+	    bits_t *wb_unprotected_bits = page->wb_unprotected_bits;
+#if PROFILE_REMEMBERSET_MARK
+	    if (page->flags.has_remembered_objects && page->flags.has_uncollectible_shady_objects) has_both++;
+	    else if (page->flags.has_remembered_objects) has_old++;
+	    else if (page->flags.has_uncollectible_shady_objects) has_shady++;
+#endif
+	    for (j=0; j<HEAP_PAGE_BITMAP_LIMIT; j++) {
+		bits[j] = marking_bits[j] | (uncollectible_bits[j] & wb_unprotected_bits[j]);
+		marking_bits[j] = 0;
+	    }
+	    page->flags.has_remembered_objects = FALSE;
+
+	    for (j=0; j < HEAP_PAGE_BITMAP_LIMIT; j++) {
+		bitset = bits[j];
+
+		if (bitset) {
+		    p = offset  + j * BITS_BITLENGTH;
+
+		    do {
+			if (bitset & 1) {
+			    VALUE obj = (VALUE)p;
+			    gc_report(2, objspace, "rgengc_rememberset_mark: mark %s\n", obj_info(obj));
+			    GC_ASSERT(RVALUE_UNCOLLECTIBLE(obj));
+			    GC_ASSERT(RVALUE_OLD_P(obj) || RVALUE_WB_UNPROTECTED(obj));
+
+			    gc_mark_children(objspace, obj);
+			}
+			p++;
+			bitset >>= 1;
+		    } while (bitset);
+		}
+	    }
+	}
+#if PROFILE_REMEMBERSET_MARK
+	else {
+	    skip++;
+	}
+#endif
+    }
+
+#if PROFILE_REMEMBERSET_MARK
+    fprintf(stderr, "%d\t%d\t%d\t%d\n", has_both, has_old, has_shady, skip);
+#endif
+    gc_report(1, objspace, "rgengc_rememberset_mark: finished\n");
+}
+
+static void
+rgengc_mark_and_rememberset_clear(rb_objspace_t *objspace, rb_heap_t *heap)
+{
+    struct heap_page *page = 0;
+
+    list_for_each(&heap->pages, page, page_node) {
+	memset(&page->mark_bits[0],       0, HEAP_PAGE_BITMAP_SIZE);
+	memset(&page->uncollectible_bits[0], 0, HEAP_PAGE_BITMAP_SIZE);
+        memset(&page->marking_bits[0],    0, HEAP_PAGE_BITMAP_SIZE);
+        memset(&page->pinned_bits[0],     0, HEAP_PAGE_BITMAP_SIZE);
+	page->flags.has_uncollectible_shady_objects = FALSE;
+	page->flags.has_remembered_objects = FALSE;
+    }
+}
+
+/* RGENGC: APIs */
+
+NOINLINE(static void gc_writebarrier_generational(VALUE a, VALUE b, rb_objspace_t *objspace));
+
+static void
+gc_writebarrier_generational(VALUE a, VALUE b, rb_objspace_t *objspace)
+{
+    if (RGENGC_CHECK_MODE) {
+	if (!RVALUE_OLD_P(a)) rb_bug("gc_writebarrier_generational: %s is not an old object.", obj_info(a));
+	if ( RVALUE_OLD_P(b)) rb_bug("gc_writebarrier_generational: %s is an old object.", obj_info(b));
+	if (is_incremental_marking(objspace)) rb_bug("gc_writebarrier_generational: called while incremental marking: %s -> %s", obj_info(a), obj_info(b));
+    }
+
+#if 1
+    /* mark `a' and remember (default behavior) */
+    if (!rgengc_remembered(objspace, a)) {
+        RB_VM_LOCK_ENTER_NO_BARRIER();
+        {
+            rgengc_remember(objspace, a);
+        }
+        RB_VM_LOCK_LEAVE_NO_BARRIER();
+	gc_report(1, objspace, "gc_writebarrier_generational: %s (remembered) -> %s\n", obj_info(a), obj_info(b));
+    }
+#else
+    /* mark `b' and remember */
+    MARK_IN_BITMAP(GET_HEAP_MARK_BITS(b), b);
+    if (RVALUE_WB_UNPROTECTED(b)) {
+	gc_remember_unprotected(objspace, b);
+    }
+    else {
+	RVALUE_AGE_SET_OLD(objspace, b);
+	rgengc_remember(objspace, b);
+    }
+
+    gc_report(1, objspace, "gc_writebarrier_generational: %s -> %s (remembered)\n", obj_info(a), obj_info(b));
+#endif
+
+    check_rvalue_consistency(a);
+    check_rvalue_consistency(b);
+}
+
+#if GC_ENABLE_INCREMENTAL_MARK
+static void
+gc_mark_from(rb_objspace_t *objspace, VALUE obj, VALUE parent)
+{
+    gc_mark_set_parent(objspace, parent);
+    rgengc_check_relation(objspace, obj);
+    if (gc_mark_set(objspace, obj) == FALSE) return;
+    gc_aging(objspace, obj);
+    gc_grey(objspace, obj);
+}
+
+NOINLINE(static void gc_writebarrier_incremental(VALUE a, VALUE b, rb_objspace_t *objspace));
+
+static void
+gc_writebarrier_incremental(VALUE a, VALUE b, rb_objspace_t *objspace)
+{
+    gc_report(2, objspace, "gc_writebarrier_incremental: [LG] %p -> %s\n", (void *)a, obj_info(b));
+
+    if (RVALUE_BLACK_P(a)) {
+	if (RVALUE_WHITE_P(b)) {
+	    if (!RVALUE_WB_UNPROTECTED(a)) {
+		gc_report(2, objspace, "gc_writebarrier_incremental: [IN] %p -> %s\n", (void *)a, obj_info(b));
+		gc_mark_from(objspace, b, a);
+	    }
+	}
+	else if (RVALUE_OLD_P(a) && !RVALUE_OLD_P(b)) {
+	    if (!RVALUE_WB_UNPROTECTED(b)) {
+		gc_report(1, objspace, "gc_writebarrier_incremental: [GN] %p -> %s\n", (void *)a, obj_info(b));
+		RVALUE_AGE_SET_OLD(objspace, b);
+
+		if (RVALUE_BLACK_P(b)) {
+		    gc_grey(objspace, b);
+		}
+	    }
+	    else {
+		gc_report(1, objspace, "gc_writebarrier_incremental: [LL] %p -> %s\n", (void *)a, obj_info(b));
+		gc_remember_unprotected(objspace, b);
+	    }
+	}
+
+        if (UNLIKELY(objspace->flags.during_compacting)) {
+            MARK_IN_BITMAP(GET_HEAP_PINNED_BITS(b), b);
+        }
+    }
+}
+#else
+#define gc_writebarrier_incremental(a, b, objspace)
+#endif
+
+void
+rb_gc_writebarrier(VALUE a, VALUE b)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+
+    if (RGENGC_CHECK_MODE && SPECIAL_CONST_P(a)) rb_bug("rb_gc_writebarrier: a is special const");
+    if (RGENGC_CHECK_MODE && SPECIAL_CONST_P(b)) rb_bug("rb_gc_writebarrier: b is special const");
+
+    if (!is_incremental_marking(objspace)) {
+        if (!RVALUE_OLD_P(a) || RVALUE_OLD_P(b)) {
+            // do nothing
+        }
+        else {
+            gc_writebarrier_generational(a, b, objspace);
+        }
+    }
+    else {
+        /* slow path */
+        RB_VM_LOCK_ENTER_NO_BARRIER();
+        {
+            gc_writebarrier_incremental(a, b, objspace);
+        }
+        RB_VM_LOCK_LEAVE_NO_BARRIER();
+    }
+    return;
+}
+
+void
+rb_gc_writebarrier_unprotect(VALUE obj)
+{
+    if (RVALUE_WB_UNPROTECTED(obj)) {
+	return;
+    }
+    else {
+	rb_objspace_t *objspace = &rb_objspace;
+
+	gc_report(2, objspace, "rb_gc_writebarrier_unprotect: %s %s\n", obj_info(obj),
+		  rgengc_remembered(objspace, obj) ? " (already remembered)" : "");
+
+	if (RVALUE_OLD_P(obj)) {
+	    gc_report(1, objspace, "rb_gc_writebarrier_unprotect: %s\n", obj_info(obj));
+	    RVALUE_DEMOTE(objspace, obj);
+	    gc_mark_set(objspace, obj);
+	    gc_remember_unprotected(objspace, obj);
+
+#if RGENGC_PROFILE
+	    objspace->profile.total_shade_operation_count++;
+#if RGENGC_PROFILE >= 2
+	    objspace->profile.shade_operation_count_types[BUILTIN_TYPE(obj)]++;
+#endif /* RGENGC_PROFILE >= 2 */
+#endif /* RGENGC_PROFILE */
+	}
+	else {
+	    RVALUE_AGE_RESET(obj);
+	}
+
+        RB_DEBUG_COUNTER_INC(obj_wb_unprotect);
+	MARK_IN_BITMAP(GET_HEAP_WB_UNPROTECTED_BITS(obj), obj);
+    }
+}
+
+/*
+ * remember `obj' if needed.
+ */
+MJIT_FUNC_EXPORTED void
+rb_gc_writebarrier_remember(VALUE obj)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+
+    gc_report(1, objspace, "rb_gc_writebarrier_remember: %s\n", obj_info(obj));
+
+    if (is_incremental_marking(objspace)) {
+	if (RVALUE_BLACK_P(obj)) {
+	    gc_grey(objspace, obj);
+	}
+    }
+    else {
+	if (RVALUE_OLD_P(obj)) {
+	    rgengc_remember(objspace, obj);
+	}
+    }
+}
+
+static st_table *rgengc_unprotect_logging_table;
+
+VALUE
+rb_gc_enable_stats()
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    int old = collect_gc_stats;
+    collect_gc_stats = 1;
+    return old ? Qtrue : Qfalse;
+}
+
+static VALUE
+gc_enable_stats(rb_execution_context_t *ec, VALUE _)
+{
+    return rb_gc_enable_stats();
+}
+
+VALUE
+rb_gc_disable_stats()
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    int old = collect_gc_stats;
+    collect_gc_stats = 0;
+    return old ? Qtrue : Qfalse;
+}
+
+static VALUE
+gc_disable_stats(rb_execution_context_t *ec, VALUE _)
+{
+    return rb_gc_disable_stats();
+}
+
+
+VALUE
+rb_gc_stats_enabled()
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return collect_gc_stats ? Qtrue : Qfalse;
+}
+
+static VALUE
+gc_stats_enabled(rb_execution_context_t *ec, VALUE _)
+{
+    return rb_gc_stats_enabled();
+}
+
+double rb_gc_total_time()
+{
+    return rb_objspace.profile.time;
+}
+
+static VALUE
+gc_time(rb_execution_context_t *ec, VALUE _)
+{
+    return DBL2NUM(1000000*rb_objspace.profile.time);
+}
+
+VALUE
+rb_gc_heap_slots()
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return SIZET2NUM(heap_allocated_pages * HEAP_PAGE_OBJ_LIMIT);
+}
+
+static
+VALUE gc_heap_slots(rb_execution_context_t *ec, VALUE _)
+{
+    return rb_gc_heap_slots();
+}
+
+VALUE
+rb_gc_heap_slots_live_after_last_gc()
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return SIZET2NUM(objspace->profile.live_after_last_sweep);
+}
+
+static
+VALUE gc_heap_slots_live_after_last_gc(rb_execution_context_t *ec, VALUE _)
+{
+    return rb_gc_heap_slots_live_after_last_gc();
+}
+
+size_t rb_gc_total_mallocs() {
+    return rb_objspace.profile.total_mallocs;
+}
+
+static VALUE
+gc_total_mallocs(rb_execution_context_t *ec, VALUE _)
+{
+    return SIZET2NUM(rb_objspace.profile.total_mallocs);
+}
+
+size_t rb_gc_total_malloced_bytes(void) {
+    return rb_objspace.profile.total_malloced_bytes;
+}
+
+static VALUE
+gc_total_malloced_bytes(rb_execution_context_t *ec, VALUE _)
+{
+    return SIZET2NUM(rb_objspace.profile.total_malloced_bytes);
+}
+
+static int
+rgengc_unprotect_logging_exit_func_i(st_data_t key, st_data_t val, st_data_t arg)
+{
+    fprintf(stderr, "%s\t%"PRIuVALUE"\n", (char *)key, (VALUE)val);
+    return ST_CONTINUE;
+}
+
+static void
+rgengc_unprotect_logging_exit_func(void)
+{
+    st_foreach(rgengc_unprotect_logging_table, rgengc_unprotect_logging_exit_func_i, 0);
+}
+
+void
+rb_gc_unprotect_logging(void *objptr, const char *filename, int line)
+{
+    VALUE obj = (VALUE)objptr;
+
+    if (rgengc_unprotect_logging_table == 0) {
+	rgengc_unprotect_logging_table = st_init_strtable();
+	atexit(rgengc_unprotect_logging_exit_func);
+    }
+
+    if (RVALUE_WB_UNPROTECTED(obj) == 0) {
+	char buff[0x100];
+	st_data_t cnt = 1;
+	char *ptr = buff;
+
+	snprintf(ptr, 0x100 - 1, "%s|%s:%d", obj_info(obj), filename, line);
+
+	if (st_lookup(rgengc_unprotect_logging_table, (st_data_t)ptr, &cnt)) {
+	    cnt++;
+	}
+	else {
+	    ptr = (strdup)(buff);
+	    if (!ptr) rb_memerror();
+	}
+	st_insert(rgengc_unprotect_logging_table, (st_data_t)ptr, cnt);
+    }
+}
+
+void
+rb_copy_wb_protected_attribute(VALUE dest, VALUE obj)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+
+    if (RVALUE_WB_UNPROTECTED(obj) && !RVALUE_WB_UNPROTECTED(dest)) {
+	if (!RVALUE_OLD_P(dest)) {
+	    MARK_IN_BITMAP(GET_HEAP_WB_UNPROTECTED_BITS(dest), dest);
+	    RVALUE_AGE_RESET_RAW(dest);
+	}
+	else {
+	    RVALUE_DEMOTE(objspace, dest);
+	}
+    }
+
+    check_rvalue_consistency(dest);
+}
+
+/* RGENGC analysis information */
+
+VALUE
+rb_obj_rgengc_writebarrier_protected_p(VALUE obj)
+{
+    return RVALUE_WB_UNPROTECTED(obj) ? Qfalse : Qtrue;
+}
+
+VALUE
+rb_obj_rgengc_promoted_p(VALUE obj)
+{
+    return OBJ_PROMOTED(obj) ? Qtrue : Qfalse;
+}
+
+size_t
+rb_obj_gc_flags(VALUE obj, ID* flags, size_t max)
+{
+    size_t n = 0;
+    static ID ID_marked;
+    static ID ID_wb_protected, ID_old, ID_marking, ID_uncollectible, ID_pinned;
+
+    if (!ID_marked) {
+#define I(s) ID_##s = rb_intern(#s);
+	I(marked);
+	I(wb_protected);
+	I(old);
+	I(marking);
+	I(uncollectible);
+        I(pinned);
+#undef I
+    }
+
+    if (RVALUE_WB_UNPROTECTED(obj) == 0 && n<max)                   flags[n++] = ID_wb_protected;
+    if (RVALUE_OLD_P(obj) && n<max)                                 flags[n++] = ID_old;
+    if (RVALUE_UNCOLLECTIBLE(obj) && n<max)                         flags[n++] = ID_uncollectible;
+    if (MARKED_IN_BITMAP(GET_HEAP_MARKING_BITS(obj), obj) && n<max) flags[n++] = ID_marking;
+    if (MARKED_IN_BITMAP(GET_HEAP_MARK_BITS(obj), obj) && n<max)    flags[n++] = ID_marked;
+    if (MARKED_IN_BITMAP(GET_HEAP_PINNED_BITS(obj), obj) && n<max)  flags[n++] = ID_pinned;
+    return n;
+}
+
+/* GC */
+
+void
+rb_gc_ractor_newobj_cache_clear(rb_ractor_newobj_cache_t *newobj_cache)
+{
+    struct heap_page *page = newobj_cache->using_page;
+    RVALUE *freelist = newobj_cache->freelist;
+    RUBY_DEBUG_LOG("ractor using_page:%p freelist:%p", page, freelist);
+
+    if (page && freelist) {
+        asan_unpoison_memory_region(&page->freelist, sizeof(RVALUE*), false);
+        if (page->freelist) {
+            RVALUE *p = page->freelist;
+            asan_unpoison_object((VALUE)p, false);
+            while (p->as.free.next) {
+                RVALUE *prev = p;
+                p = p->as.free.next;
+                asan_poison_object((VALUE)prev);
+                asan_unpoison_object((VALUE)p, false);
+            }
+            p->as.free.next = freelist;
+            asan_poison_object((VALUE)p);
+        }
+        else {
+            page->freelist = freelist;
+        }
+        asan_poison_memory_region(&page->freelist, sizeof(RVALUE*));
+    }
+
+    newobj_cache->using_page = NULL;
+    newobj_cache->freelist = NULL;
+}
+
+void
+rb_gc_force_recycle(VALUE obj)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    RB_VM_LOCK_ENTER();
+    {
+        int is_old = RVALUE_OLD_P(obj);
+
+        gc_report(2, objspace, "rb_gc_force_recycle: %s\n", obj_info(obj));
+
+        if (is_old) {
+            if (RVALUE_MARKED(obj)) {
+                objspace->rgengc.old_objects--;
+            }
+        }
+        CLEAR_IN_BITMAP(GET_HEAP_UNCOLLECTIBLE_BITS(obj), obj);
+        CLEAR_IN_BITMAP(GET_HEAP_WB_UNPROTECTED_BITS(obj), obj);
+        CLEAR_IN_BITMAP(GET_HEAP_PINNED_BITS(obj), obj);
+
+#if GC_ENABLE_INCREMENTAL_MARK
+        if (is_incremental_marking(objspace)) {
+            if (MARKED_IN_BITMAP(GET_HEAP_MARKING_BITS(obj), obj)) {
+                invalidate_mark_stack(&objspace->mark_stack, obj);
+                CLEAR_IN_BITMAP(GET_HEAP_MARKING_BITS(obj), obj);
+            }
+            CLEAR_IN_BITMAP(GET_HEAP_MARK_BITS(obj), obj);
+        }
+        else {
+#endif
+            if (is_old || GET_HEAP_PAGE(obj)->flags.before_sweep) {
+                CLEAR_IN_BITMAP(GET_HEAP_MARK_BITS(obj), obj);
+            }
+            CLEAR_IN_BITMAP(GET_HEAP_MARKING_BITS(obj), obj);
+#if GC_ENABLE_INCREMENTAL_MARK
+        }
+#endif
+
+        objspace->profile.total_freed_objects++;
+
+        heap_page_add_freeobj(objspace, GET_HEAP_PAGE(obj), obj);
+
+        /* Disable counting swept_slots because there are no meaning.
+         * if (!MARKED_IN_BITMAP(GET_HEAP_MARK_BITS(p), p)) {
+         *   objspace->heap.swept_slots++;
+         * }
+         */
+    }
+    RB_VM_LOCK_LEAVE();
+}
+
+#ifndef MARK_OBJECT_ARY_BUCKET_SIZE
+#define MARK_OBJECT_ARY_BUCKET_SIZE 1024
+#endif
+
+void
+rb_gc_register_mark_object(VALUE obj)
+{
+    RB_VM_LOCK_ENTER();
+    {
+        VALUE ary_ary = GET_VM()->mark_object_ary;
+        VALUE ary = rb_ary_last(0, 0, ary_ary);
+
+        if (ary == Qnil || RARRAY_LEN(ary) >= MARK_OBJECT_ARY_BUCKET_SIZE) {
+            ary = rb_ary_tmp_new(MARK_OBJECT_ARY_BUCKET_SIZE);
+            rb_ary_push(ary_ary, ary);
+        }
+
+        rb_ary_push(ary, obj);
+    }
+    RB_VM_LOCK_LEAVE();
+}
+
+void
+rb_gc_register_address(VALUE *addr)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    struct gc_list *tmp;
+
+    tmp = ALLOC(struct gc_list);
+    tmp->next = global_list;
+    tmp->varptr = addr;
+    global_list = tmp;
+}
+
+void
+rb_gc_unregister_address(VALUE *addr)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    struct gc_list *tmp = global_list;
+
+    if (tmp->varptr == addr) {
+	global_list = tmp->next;
+	xfree(tmp);
+	return;
+    }
+    while (tmp->next) {
+	if (tmp->next->varptr == addr) {
+	    struct gc_list *t = tmp->next;
+
+	    tmp->next = tmp->next->next;
+	    xfree(t);
+	    break;
+	}
+	tmp = tmp->next;
+    }
+}
+
+void
+rb_global_variable(VALUE *var)
+{
+    rb_gc_register_address(var);
+}
+
+#define GC_NOTIFY 0
+
+enum {
+    gc_stress_no_major,
+    gc_stress_no_immediate_sweep,
+    gc_stress_full_mark_after_malloc,
+    gc_stress_max
+};
+
+#define gc_stress_full_mark_after_malloc_p() \
+    (FIXNUM_P(ruby_gc_stress_mode) && (FIX2LONG(ruby_gc_stress_mode) & (1<<gc_stress_full_mark_after_malloc)))
+
+static void
+heap_ready_to_gc(rb_objspace_t *objspace, rb_heap_t *heap)
+{
+    if (!heap->free_pages) {
+	if (!heap_increment(objspace, heap)) {
+	    heap_set_increment(objspace, 1);
+	    heap_increment(objspace, heap);
+	}
+    }
+}
+
+static int
+ready_to_gc(rb_objspace_t *objspace)
+{
+    if (dont_gc_val() || during_gc || ruby_disable_gc) {
+	heap_ready_to_gc(objspace, heap_eden);
+	return FALSE;
+    }
+    else {
+	return TRUE;
+    }
+}
+
+static void
+gc_reset_malloc_info(rb_objspace_t *objspace)
+{
+    gc_prof_set_malloc_info(objspace);
+    {
+	size_t inc = ATOMIC_SIZE_EXCHANGE(malloc_increase, 0);
+	size_t old_limit = malloc_limit;
+
+	if (inc > malloc_limit) {
+	    malloc_limit = (size_t)(inc * gc_params.malloc_limit_growth_factor);
+	    if (malloc_limit > gc_params.malloc_limit_max) {
+		malloc_limit = gc_params.malloc_limit_max;
+	    }
+	}
+	else {
+	    malloc_limit = (size_t)(malloc_limit * 0.98); /* magic number */
+	    if (malloc_limit < gc_params.malloc_limit_min) {
+		malloc_limit = gc_params.malloc_limit_min;
+	    }
+	}
+
+	if (0) {
+	    if (old_limit != malloc_limit) {
+		fprintf(stderr, "[%"PRIuSIZE"] malloc_limit: %"PRIuSIZE" -> %"PRIuSIZE"\n",
+			rb_gc_count(), old_limit, malloc_limit);
+	    }
+	    else {
+		fprintf(stderr, "[%"PRIuSIZE"] malloc_limit: not changed (%"PRIuSIZE")\n",
+			rb_gc_count(), malloc_limit);
+	    }
+	}
+    }
+
+    /* reset oldmalloc info */
+#if RGENGC_ESTIMATE_OLDMALLOC
+    if (!is_full_marking(objspace)) {
+	if (objspace->rgengc.oldmalloc_increase > objspace->rgengc.oldmalloc_increase_limit) {
+	    objspace->rgengc.need_major_gc |= GPR_FLAG_MAJOR_BY_OLDMALLOC;
+	    objspace->rgengc.oldmalloc_increase_limit =
+	      (size_t)(objspace->rgengc.oldmalloc_increase_limit * gc_params.oldmalloc_limit_growth_factor);
+
+	    if (objspace->rgengc.oldmalloc_increase_limit > gc_params.oldmalloc_limit_max) {
+		objspace->rgengc.oldmalloc_increase_limit = gc_params.oldmalloc_limit_max;
+	    }
+	}
+
+	if (0) fprintf(stderr, "%"PRIdSIZE"\t%d\t%"PRIuSIZE"\t%"PRIuSIZE"\t%"PRIdSIZE"\n",
+		       rb_gc_count(),
+		       objspace->rgengc.need_major_gc,
+		       objspace->rgengc.oldmalloc_increase,
+		       objspace->rgengc.oldmalloc_increase_limit,
+		       gc_params.oldmalloc_limit_max);
+    }
+    else {
+	/* major GC */
+	objspace->rgengc.oldmalloc_increase = 0;
+
+	if ((objspace->profile.latest_gc_info & GPR_FLAG_MAJOR_BY_OLDMALLOC) == 0) {
+	    objspace->rgengc.oldmalloc_increase_limit =
+	      (size_t)(objspace->rgengc.oldmalloc_increase_limit / ((gc_params.oldmalloc_limit_growth_factor - 1)/10 + 1));
+	    if (objspace->rgengc.oldmalloc_increase_limit < gc_params.oldmalloc_limit_min) {
+		objspace->rgengc.oldmalloc_increase_limit = gc_params.oldmalloc_limit_min;
+	    }
+	}
+    }
+#endif
+}
+
+static int
+garbage_collect(rb_objspace_t *objspace, int reason)
+{
+    int ret;
+
+    RB_VM_LOCK_ENTER();
+    {
+#if GC_PROFILE_MORE_DETAIL
+        objspace->profile.prepare_time = getrusage_time();
+#endif
+
+        gc_rest(objspace);
+
+#if GC_PROFILE_MORE_DETAIL
+        objspace->profile.prepare_time = getrusage_time() - objspace->profile.prepare_time;
+#endif
+
+        ret = gc_start(objspace, reason);
+    }
+    RB_VM_LOCK_LEAVE();
+
+    return ret;
+}
+
+static int
+gc_start(rb_objspace_t *objspace, int reason)
+{
+    unsigned int do_full_mark = !!((unsigned)reason & GPR_FLAG_FULL_MARK);
+    unsigned int immediate_mark = (unsigned)reason & GPR_FLAG_IMMEDIATE_MARK;
+
+    /* reason may be clobbered, later, so keep set immediate_sweep here */
+    objspace->flags.immediate_sweep = !!((unsigned)reason & GPR_FLAG_IMMEDIATE_SWEEP);
+
+    /* Explicitly enable compaction (GC.compact) */
+    objspace->flags.during_compacting = !!(reason & GPR_FLAG_COMPACT);
+
+    if (!heap_allocated_pages) return FALSE; /* heap is not ready */
+    if (!(reason & GPR_FLAG_METHOD) && !ready_to_gc(objspace)) return TRUE; /* GC is not allowed */
+
+    GC_ASSERT(gc_mode(objspace) == gc_mode_none);
+    GC_ASSERT(!is_lazy_sweeping(heap_eden));
+    GC_ASSERT(!is_incremental_marking(objspace));
+
+    unsigned int lock_lev;
+    gc_enter(objspace, gc_enter_event_start, &lock_lev);
+
+#if RGENGC_CHECK_MODE >= 2
+    gc_verify_internal_consistency(objspace);
+#endif
+
+    if (ruby_gc_stressful) {
+	int flag = FIXNUM_P(ruby_gc_stress_mode) ? FIX2INT(ruby_gc_stress_mode) : 0;
+
+	if ((flag & (1<<gc_stress_no_major)) == 0) {
+	    do_full_mark = TRUE;
+	}
+
+	objspace->flags.immediate_sweep = !(flag & (1<<gc_stress_no_immediate_sweep));
+    }
+    else {
+	if (objspace->rgengc.need_major_gc) {
+	    reason |= objspace->rgengc.need_major_gc;
+	    do_full_mark = TRUE;
+	}
+	else if (RGENGC_FORCE_MAJOR_GC) {
+	    reason = GPR_FLAG_MAJOR_BY_FORCE;
+	    do_full_mark = TRUE;
+	}
+
+	objspace->rgengc.need_major_gc = GPR_FLAG_NONE;
+    }
+
+    if (do_full_mark && (reason & GPR_FLAG_MAJOR_MASK) == 0) {
+	reason |= GPR_FLAG_MAJOR_BY_FORCE; /* GC by CAPI, METHOD, and so on. */
+    }
+
+#if GC_ENABLE_INCREMENTAL_MARK
+    if (!GC_ENABLE_INCREMENTAL_MARK || objspace->flags.dont_incremental || immediate_mark) {
+	objspace->flags.during_incremental_marking = FALSE;
+    }
+    else {
+	objspace->flags.during_incremental_marking = do_full_mark;
+    }
+#endif
+
+    if (!GC_ENABLE_LAZY_SWEEP || objspace->flags.dont_incremental) {
+	objspace->flags.immediate_sweep = TRUE;
+    }
+
+    if (objspace->flags.immediate_sweep) reason |= GPR_FLAG_IMMEDIATE_SWEEP;
+
+    gc_report(1, objspace, "gc_start(reason: %d) => %u, %d, %d\n",
+	      reason,
+	      do_full_mark, !is_incremental_marking(objspace), objspace->flags.immediate_sweep);
+
+#if USE_DEBUG_COUNTER
+    RB_DEBUG_COUNTER_INC(gc_count);
+
+    if (reason & GPR_FLAG_MAJOR_MASK) {
+        (void)RB_DEBUG_COUNTER_INC_IF(gc_major_nofree, reason & GPR_FLAG_MAJOR_BY_NOFREE);
+        (void)RB_DEBUG_COUNTER_INC_IF(gc_major_oldgen, reason & GPR_FLAG_MAJOR_BY_OLDGEN);
+        (void)RB_DEBUG_COUNTER_INC_IF(gc_major_shady,  reason & GPR_FLAG_MAJOR_BY_SHADY);
+        (void)RB_DEBUG_COUNTER_INC_IF(gc_major_force,  reason & GPR_FLAG_MAJOR_BY_FORCE);
+#if RGENGC_ESTIMATE_OLDMALLOC
+        (void)RB_DEBUG_COUNTER_INC_IF(gc_major_oldmalloc, reason & GPR_FLAG_MAJOR_BY_OLDMALLOC);
+#endif
+    }
+    else {
+        (void)RB_DEBUG_COUNTER_INC_IF(gc_minor_newobj, reason & GPR_FLAG_NEWOBJ);
+        (void)RB_DEBUG_COUNTER_INC_IF(gc_minor_malloc, reason & GPR_FLAG_MALLOC);
+        (void)RB_DEBUG_COUNTER_INC_IF(gc_minor_method, reason & GPR_FLAG_METHOD);
+        (void)RB_DEBUG_COUNTER_INC_IF(gc_minor_capi,   reason & GPR_FLAG_CAPI);
+        (void)RB_DEBUG_COUNTER_INC_IF(gc_minor_stress, reason & GPR_FLAG_STRESS);
+    }
+#endif
+
+    objspace->profile.count++;
+    objspace->profile.latest_gc_info = reason;
+    objspace->profile.total_allocated_objects_at_gc_start = objspace->total_allocated_objects;
+    objspace->profile.heap_used_at_gc_start = heap_allocated_pages;
+    gc_prof_setup_new_record(objspace, reason);
+    gc_reset_malloc_info(objspace);
+    rb_transient_heap_start_marking(do_full_mark);
+
+    gc_event_hook(objspace, RUBY_INTERNAL_EVENT_GC_START, 0 /* TODO: pass minor/immediate flag? */);
+    GC_ASSERT(during_gc);
+
+    gc_prof_timer_start(objspace);
+    {
+	gc_marks(objspace, do_full_mark);
+    }
+    gc_prof_timer_stop(objspace);
+
+    gc_exit(objspace, gc_enter_event_start, &lock_lev);
+    return TRUE;
+}
+
+static void
+gc_rest(rb_objspace_t *objspace)
+{
+    int marking = is_incremental_marking(objspace);
+    int sweeping = is_lazy_sweeping(heap_eden);
+
+    if (marking || sweeping) {
+        unsigned int lock_lev;
+	gc_enter(objspace, gc_enter_event_rest, &lock_lev);
+
+        if (RGENGC_CHECK_MODE >= 2) gc_verify_internal_consistency(objspace);
+
+	if (is_incremental_marking(objspace)) {
+            gc_marks_rest(objspace);
+        }
+	if (is_lazy_sweeping(heap_eden)) {
+	    gc_sweep_rest(objspace);
+	}
+	gc_exit(objspace, gc_enter_event_rest, &lock_lev);
+    }
+}
+
+struct objspace_and_reason {
+    rb_objspace_t *objspace;
+    int reason;
+};
+
+static void
+gc_current_status_fill(rb_objspace_t *objspace, char *buff)
+{
+    int i = 0;
+    if (is_marking(objspace)) {
+	buff[i++] = 'M';
+	if (is_full_marking(objspace))        buff[i++] = 'F';
+#if GC_ENABLE_INCREMENTAL_MARK
+	if (is_incremental_marking(objspace)) buff[i++] = 'I';
+#endif
+    }
+    else if (is_sweeping(objspace)) {
+	buff[i++] = 'S';
+	if (is_lazy_sweeping(heap_eden))      buff[i++] = 'L';
+    }
+    else {
+	buff[i++] = 'N';
+    }
+    buff[i] = '\0';
+}
+
+static const char *
+gc_current_status(rb_objspace_t *objspace)
+{
+    static char buff[0x10];
+    gc_current_status_fill(objspace, buff);
+    return buff;
+}
+
+#if PRINT_ENTER_EXIT_TICK
+
+static tick_t last_exit_tick;
+static tick_t enter_tick;
+static int enter_count = 0;
+static char last_gc_status[0x10];
+
+static inline void
+gc_record(rb_objspace_t *objspace, int direction, const char *event)
+{
+    if (direction == 0) { /* enter */
+	enter_count++;
+	enter_tick = tick();
+	gc_current_status_fill(objspace, last_gc_status);
+    }
+    else { /* exit */
+	tick_t exit_tick = tick();
+	char current_gc_status[0x10];
+	gc_current_status_fill(objspace, current_gc_status);
+#if 1
+	/* [last mutator time] [gc time] [event] */
+	fprintf(stderr, "%"PRItick"\t%"PRItick"\t%s\t[%s->%s|%c]\n",
+		enter_tick - last_exit_tick,
+		exit_tick - enter_tick,
+		event,
+		last_gc_status, current_gc_status,
+		(objspace->profile.latest_gc_info & GPR_FLAG_MAJOR_MASK) ? '+' : '-');
+	last_exit_tick = exit_tick;
+#else
+	/* [enter_tick] [gc time] [event] */
+	fprintf(stderr, "%"PRItick"\t%"PRItick"\t%s\t[%s->%s|%c]\n",
+		enter_tick,
+		exit_tick - enter_tick,
+		event,
+		last_gc_status, current_gc_status,
+		(objspace->profile.latest_gc_info & GPR_FLAG_MAJOR_MASK) ? '+' : '-');
+#endif
+    }
+}
+#else /* PRINT_ENTER_EXIT_TICK */
+static inline void
+gc_record(rb_objspace_t *objspace, int direction, const char *event)
+{
+    /* null */
+}
+#endif /* PRINT_ENTER_EXIT_TICK */
+
+static const char *
+gc_enter_event_cstr(enum gc_enter_event event)
+{
+    switch (event) {
+      case gc_enter_event_start: return "start";
+      case gc_enter_event_mark_continue: return "mark_continue";
+      case gc_enter_event_sweep_continue: return "sweep_continue";
+      case gc_enter_event_rest: return "rest";
+      case gc_enter_event_finalizer: return "finalizer";
+      case gc_enter_event_rb_memerror: return "rb_memerror";
+    }
+    return NULL;
+}
+
+static void
+gc_enter_count(enum gc_enter_event event)
+{
+    switch (event) {
+      case gc_enter_event_start:          RB_DEBUG_COUNTER_INC(gc_enter_start); break;
+      case gc_enter_event_mark_continue:  RB_DEBUG_COUNTER_INC(gc_enter_mark_continue); break;
+      case gc_enter_event_sweep_continue: RB_DEBUG_COUNTER_INC(gc_enter_sweep_continue); break;
+      case gc_enter_event_rest:           RB_DEBUG_COUNTER_INC(gc_enter_rest); break;
+      case gc_enter_event_finalizer:      RB_DEBUG_COUNTER_INC(gc_enter_finalizer); break;
+      case gc_enter_event_rb_memerror:    /* nothing */ break;
+    }
+}
+
+static inline void
+gc_enter(rb_objspace_t *objspace, enum gc_enter_event event, unsigned int *lock_lev)
+{
+    RB_VM_LOCK_ENTER_LEV(lock_lev);
+
+    switch (event) {
+      case gc_enter_event_rest:
+        if (!is_marking(objspace)) break;
+        // fall through
+      case gc_enter_event_start:
+      case gc_enter_event_mark_continue:
+        // stop other ractors
+        rb_vm_barrier();
+        break;
+      default:
+        break;
+    }
+
+    gc_enter_count(event);
+    if (UNLIKELY(during_gc != 0)) rb_bug("during_gc != 0");
+    if (RGENGC_CHECK_MODE >= 3) gc_verify_internal_consistency(objspace);
+
+    mjit_gc_start_hook();
+
+    during_gc = TRUE;
+    RUBY_DEBUG_LOG("%s (%s)",gc_enter_event_cstr(event), gc_current_status(objspace));
+    gc_report(1, objspace, "gc_enter: %s [%s]\n", gc_enter_event_cstr(event), gc_current_status(objspace));
+    gc_record(objspace, 0, gc_enter_event_cstr(event));
+    gc_event_hook(objspace, RUBY_INTERNAL_EVENT_GC_ENTER, 0); /* TODO: which parameter should be passed? */
+}
+
+static inline void
+gc_exit(rb_objspace_t *objspace, enum gc_enter_event event, unsigned int *lock_lev)
+{
+    GC_ASSERT(during_gc != 0);
+
+    gc_event_hook(objspace, RUBY_INTERNAL_EVENT_GC_EXIT, 0); /* TODO: which parameter should be passsed? */
+    gc_record(objspace, 1, gc_enter_event_cstr(event));
+    RUBY_DEBUG_LOG("%s (%s)", gc_enter_event_cstr(event), gc_current_status(objspace));
+    gc_report(1, objspace, "gc_exit: %s [%s]\n", gc_enter_event_cstr(event), gc_current_status(objspace));
+    during_gc = FALSE;
+
+    mjit_gc_exit_hook();
+    RB_VM_LOCK_LEAVE_LEV(lock_lev);
+}
+
+static void *
+gc_with_gvl(void *ptr)
+{
+    struct objspace_and_reason *oar = (struct objspace_and_reason *)ptr;
+    return (void *)(VALUE)garbage_collect(oar->objspace, oar->reason);
+}
+
+static int
+garbage_collect_with_gvl(rb_objspace_t *objspace, int reason)
+{
+    if (dont_gc_val()) return TRUE;
+    if (ruby_thread_has_gvl_p()) {
+	return garbage_collect(objspace, reason);
+    }
+    else {
+	if (ruby_native_thread_p()) {
+	    struct objspace_and_reason oar;
+	    oar.objspace = objspace;
+	    oar.reason = reason;
+	    return (int)(VALUE)rb_thread_call_with_gvl(gc_with_gvl, (void *)&oar);
+	}
+	else {
+	    /* no ruby thread */
+	    fprintf(stderr, "[FATAL] failed to allocate memory\n");
+	    exit(EXIT_FAILURE);
+	}
+    }
+}
+
+static VALUE
+gc_start_internal(rb_execution_context_t *ec, VALUE self, VALUE full_mark, VALUE immediate_mark, VALUE immediate_sweep, VALUE compact)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    int reason = GPR_FLAG_FULL_MARK |
+                 GPR_FLAG_IMMEDIATE_MARK |
+                 GPR_FLAG_IMMEDIATE_SWEEP |
+                 GPR_FLAG_METHOD;
+
+    /* For now, compact implies full mark / sweep, so ignore other flags */
+    if (RTEST(compact)) {
+        /* If not MinGW, Windows, or does not have mmap, we cannot use mprotect for
+         * the read barrier, so we must disable compaction. */
+#if !defined(__MINGW32__) && !defined(_WIN32)
+        if (!USE_MMAP_ALIGNED_ALLOC) {
+            rb_raise(rb_eNotImpError, "Compaction isn't available on this platform");
+        }
+#endif
+
+        reason |= GPR_FLAG_COMPACT;
+    } else {
+        if (!RTEST(full_mark))       reason &= ~GPR_FLAG_FULL_MARK;
+        if (!RTEST(immediate_mark))  reason &= ~GPR_FLAG_IMMEDIATE_MARK;
+        if (!RTEST(immediate_sweep)) reason &= ~GPR_FLAG_IMMEDIATE_SWEEP;
+    }
+
+    garbage_collect(objspace, reason);
+    gc_finalize_deferred(objspace);
+
+    return Qnil;
+}
+
+static int
+gc_is_moveable_obj(rb_objspace_t *objspace, VALUE obj)
+{
+    GC_ASSERT(!SPECIAL_CONST_P(obj));
+
+    switch (BUILTIN_TYPE(obj)) {
+      case T_NONE:
+      case T_NIL:
+      case T_MOVED:
+      case T_ZOMBIE:
+        return FALSE;
+      case T_SYMBOL:
+        if (DYNAMIC_SYM_P(obj) && (RSYMBOL(obj)->id & ~ID_SCOPE_MASK)) {
+            return FALSE;
+        }
+        /* fall through */
+      case T_STRING:
+      case T_OBJECT:
+      case T_FLOAT:
+      case T_IMEMO:
+      case T_ARRAY:
+      case T_BIGNUM:
+      case T_ICLASS:
+      case T_MODULE:
+      case T_REGEXP:
+      case T_DATA:
+      case T_MATCH:
+      case T_STRUCT:
+      case T_HASH:
+      case T_FILE:
+      case T_COMPLEX:
+      case T_RATIONAL:
+      case T_NODE:
+      case T_CLASS:
+        if (FL_TEST(obj, FL_FINALIZE)) {
+            /* The finalizer table is a numtable. It looks up objects by address.
+             * We can't mark the keys in the finalizer table because that would
+             * prevent the objects from being collected.  This check prevents
+             * objects that are keys in the finalizer table from being moved
+             * without directly pinning them. */
+            if (st_is_member(finalizer_table, obj)) {
+                return FALSE;
+            }
+        }
+        GC_ASSERT(RVALUE_MARKED(obj));
+        GC_ASSERT(!RVALUE_PINNED(obj));
+
+        return TRUE;
+
+      default:
+        rb_bug("gc_is_moveable_obj: unreachable (%d)", (int)BUILTIN_TYPE(obj));
+        break;
+    }
+
+    return FALSE;
+}
+
+static VALUE
+gc_move(rb_objspace_t *objspace, VALUE scan, VALUE free)
+{
+    int marked;
+    int wb_unprotected;
+    int uncollectible;
+    int marking;
+    RVALUE *dest = (RVALUE *)free;
+    RVALUE *src = (RVALUE *)scan;
+
+    gc_report(4, objspace, "Moving object: %p -> %p\n", (void*)scan, (void *)free);
+
+    GC_ASSERT(BUILTIN_TYPE(scan) != T_NONE);
+    GC_ASSERT(!MARKED_IN_BITMAP(GET_HEAP_MARK_BITS(free), free));
+
+    /* Save off bits for current object. */
+    marked = rb_objspace_marked_object_p((VALUE)src);
+    wb_unprotected = RVALUE_WB_UNPROTECTED((VALUE)src);
+    uncollectible = RVALUE_UNCOLLECTIBLE((VALUE)src);
+    marking = RVALUE_MARKING((VALUE)src);
+
+    /* Clear bits for eventual T_MOVED */
+    CLEAR_IN_BITMAP(GET_HEAP_MARK_BITS((VALUE)src), (VALUE)src);
+    CLEAR_IN_BITMAP(GET_HEAP_WB_UNPROTECTED_BITS((VALUE)src), (VALUE)src);
+    CLEAR_IN_BITMAP(GET_HEAP_UNCOLLECTIBLE_BITS((VALUE)src), (VALUE)src);
+    CLEAR_IN_BITMAP(GET_HEAP_MARKING_BITS((VALUE)src), (VALUE)src);
+
+    if (FL_TEST((VALUE)src, FL_EXIVAR)) {
+        /* Same deal as below. Generic ivars are held in st tables.
+         * Resizing the table could cause a GC to happen and we can't allow it */
+        VALUE already_disabled = rb_gc_disable_no_rest();
+        rb_mv_generic_ivar((VALUE)src, (VALUE)dest);
+        if (already_disabled == Qfalse) rb_objspace_gc_enable(objspace);
+    }
+
+    st_data_t srcid = (st_data_t)src, id;
+
+    /* If the source object's object_id has been seen, we need to update
+     * the object to object id mapping. */
+    if (st_lookup(objspace->obj_to_id_tbl, srcid, &id)) {
+        gc_report(4, objspace, "Moving object with seen id: %p -> %p\n", (void *)src, (void *)dest);
+        /* inserting in the st table can cause the GC to run. We need to
+         * prevent re-entry in to the GC since `gc_move` is running in the GC,
+         * so temporarily disable the GC around the st table mutation */
+        VALUE already_disabled = rb_gc_disable_no_rest();
+        st_delete(objspace->obj_to_id_tbl, &srcid, 0);
+        st_insert(objspace->obj_to_id_tbl, (st_data_t)dest, id);
+        if (already_disabled == Qfalse) rb_objspace_gc_enable(objspace);
+    }
+
+    /* Move the object */
+    memcpy(dest, src, sizeof(RVALUE));
+    memset(src, 0, sizeof(RVALUE));
+
+    /* Set bits for object in new location */
+    if (marking) {
+        MARK_IN_BITMAP(GET_HEAP_MARKING_BITS((VALUE)dest), (VALUE)dest);
+    }
+    else {
+        CLEAR_IN_BITMAP(GET_HEAP_MARKING_BITS((VALUE)dest), (VALUE)dest);
+    }
+
+    if (marked) {
+        MARK_IN_BITMAP(GET_HEAP_MARK_BITS((VALUE)dest), (VALUE)dest);
+    }
+    else {
+        CLEAR_IN_BITMAP(GET_HEAP_MARK_BITS((VALUE)dest), (VALUE)dest);
+    }
+
+    if (wb_unprotected) {
+        MARK_IN_BITMAP(GET_HEAP_WB_UNPROTECTED_BITS((VALUE)dest), (VALUE)dest);
+    }
+    else {
+        CLEAR_IN_BITMAP(GET_HEAP_WB_UNPROTECTED_BITS((VALUE)dest), (VALUE)dest);
+    }
+
+    if (uncollectible) {
+        MARK_IN_BITMAP(GET_HEAP_UNCOLLECTIBLE_BITS((VALUE)dest), (VALUE)dest);
+    }
+    else {
+        CLEAR_IN_BITMAP(GET_HEAP_UNCOLLECTIBLE_BITS((VALUE)dest), (VALUE)dest);
+    }
+
+    /* Assign forwarding address */
+    src->as.moved.flags = T_MOVED;
+    src->as.moved.dummy = Qundef;
+    src->as.moved.destination = (VALUE)dest;
+    GC_ASSERT(BUILTIN_TYPE((VALUE)dest) != T_NONE);
+
+    return (VALUE)src;
+}
+
+static int
+compare_free_slots(const void *left, const void *right, void *dummy)
+{
+    struct heap_page *left_page;
+    struct heap_page *right_page;
+
+    left_page = *(struct heap_page * const *)left;
+    right_page = *(struct heap_page * const *)right;
+
+    return left_page->free_slots - right_page->free_slots;
+}
+
+static void
+gc_sort_heap_by_empty_slots(rb_objspace_t *objspace)
+{
+    size_t total_pages = heap_eden->total_pages;
+    size_t size = size_mul_or_raise(total_pages, sizeof(struct heap_page *), rb_eRuntimeError);
+    struct heap_page *page = 0, **page_list = malloc(size);
+    size_t i = 0;
+
+    list_for_each(&heap_eden->pages, page, page_node) {
+        page_list[i++] = page;
+        assert(page != NULL);
+    }
+    assert(total_pages > 0);
+    assert((size_t)i == total_pages);
+
+    /* Sort the heap so "filled pages" are first. `heap_add_page` adds to the
+     * head of the list, so empty pages will end up at the start of the heap */
+    ruby_qsort(page_list, total_pages, sizeof(struct heap_page *), compare_free_slots, NULL);
+
+    /* Reset the eden heap */
+    list_head_init(&objspace->eden_heap.pages);
+
+    for (i = 0; i < total_pages; i++) {
+        list_add(&heap_eden->pages, &page_list[i]->page_node);
+        if (page_list[i]->free_slots != 0) {
+            heap_add_freepage(heap_eden, page_list[i]);
+        }
+    }
+
+    free(page_list);
+}
+
+static void
+gc_ref_update_array(rb_objspace_t * objspace, VALUE v)
+{
+    long i, len;
+
+    if (FL_TEST(v, ELTS_SHARED))
+        return;
+
+    len = RARRAY_LEN(v);
+    if (len > 0) {
+        VALUE *ptr = (VALUE *)RARRAY_CONST_PTR_TRANSIENT(v);
+        for (i = 0; i < len; i++) {
+            UPDATE_IF_MOVED(objspace, ptr[i]);
+        }
+    }
+}
+
+static void
+gc_ref_update_object(rb_objspace_t * objspace, VALUE v)
+{
+    VALUE *ptr = ROBJECT_IVPTR(v);
+
+    uint32_t i, len = ROBJECT_NUMIV(v);
+    for (i = 0; i < len; i++) {
+        UPDATE_IF_MOVED(objspace, ptr[i]);
+    }
+}
+
+static int
+hash_replace_ref(st_data_t *key, st_data_t *value, st_data_t argp, int existing)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)argp;
+
+    if (gc_object_moved_p(objspace, (VALUE)*key)) {
+        *key = rb_gc_location((VALUE)*key);
+    }
+
+    if (gc_object_moved_p(objspace, (VALUE)*value)) {
+        *value = rb_gc_location((VALUE)*value);
+    }
+
+    return ST_CONTINUE;
+}
+
+static int
+hash_foreach_replace(st_data_t key, st_data_t value, st_data_t argp, int error)
+{
+    rb_objspace_t *objspace;
+
+    objspace = (rb_objspace_t *)argp;
+
+    if (gc_object_moved_p(objspace, (VALUE)key)) {
+        return ST_REPLACE;
+    }
+
+    if (gc_object_moved_p(objspace, (VALUE)value)) {
+        return ST_REPLACE;
+    }
+    return ST_CONTINUE;
+}
+
+static int
+hash_replace_ref_value(st_data_t *key, st_data_t *value, st_data_t argp, int existing)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)argp;
+
+    if (gc_object_moved_p(objspace, (VALUE)*value)) {
+        *value = rb_gc_location((VALUE)*value);
+    }
+
+    return ST_CONTINUE;
+}
+
+static int
+hash_foreach_replace_value(st_data_t key, st_data_t value, st_data_t argp, int error)
+{
+    rb_objspace_t *objspace;
+
+    objspace = (rb_objspace_t *)argp;
+
+    if (gc_object_moved_p(objspace, (VALUE)value)) {
+        return ST_REPLACE;
+    }
+    return ST_CONTINUE;
+}
+
+static void
+gc_update_tbl_refs(rb_objspace_t * objspace, st_table *tbl)
+{
+    if (!tbl || tbl->num_entries == 0) return;
+
+    if (st_foreach_with_replace(tbl, hash_foreach_replace_value, hash_replace_ref_value, (st_data_t)objspace)) {
+        rb_raise(rb_eRuntimeError, "hash modified during iteration");
+    }
+}
+
+static void
+gc_update_table_refs(rb_objspace_t * objspace, st_table *tbl)
+{
+    if (!tbl || tbl->num_entries == 0) return;
+
+    if (st_foreach_with_replace(tbl, hash_foreach_replace, hash_replace_ref, (st_data_t)objspace)) {
+        rb_raise(rb_eRuntimeError, "hash modified during iteration");
+    }
+}
+
+/* Update MOVED references in an st_table */
+void
+rb_gc_update_tbl_refs(st_table *ptr)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    gc_update_table_refs(objspace, ptr);
+}
+
+static void
+gc_ref_update_hash(rb_objspace_t * objspace, VALUE v)
+{
+    rb_hash_stlike_foreach_with_replace(v, hash_foreach_replace, hash_replace_ref, (st_data_t)objspace);
+}
+
+static void
+gc_ref_update_method_entry(rb_objspace_t *objspace, rb_method_entry_t *me)
+{
+    rb_method_definition_t *def = me->def;
+
+    UPDATE_IF_MOVED(objspace, me->owner);
+    UPDATE_IF_MOVED(objspace, me->defined_class);
+
+    if (def) {
+        switch (def->type) {
+          case VM_METHOD_TYPE_ISEQ:
+            if (def->body.iseq.iseqptr) {
+                TYPED_UPDATE_IF_MOVED(objspace, rb_iseq_t *, def->body.iseq.iseqptr);
+            }
+            TYPED_UPDATE_IF_MOVED(objspace, rb_cref_t *, def->body.iseq.cref);
+            break;
+          case VM_METHOD_TYPE_ATTRSET:
+          case VM_METHOD_TYPE_IVAR:
+            UPDATE_IF_MOVED(objspace, def->body.attr.location);
+            break;
+          case VM_METHOD_TYPE_BMETHOD:
+            UPDATE_IF_MOVED(objspace, def->body.bmethod.proc);
+            break;
+          case VM_METHOD_TYPE_ALIAS:
+            TYPED_UPDATE_IF_MOVED(objspace, struct rb_method_entry_struct *, def->body.alias.original_me);
+            return;
+          case VM_METHOD_TYPE_REFINED:
+            TYPED_UPDATE_IF_MOVED(objspace, struct rb_method_entry_struct *, def->body.refined.orig_me);
+            UPDATE_IF_MOVED(objspace, def->body.refined.owner);
+            break;
+          case VM_METHOD_TYPE_CFUNC:
+          case VM_METHOD_TYPE_ZSUPER:
+          case VM_METHOD_TYPE_MISSING:
+          case VM_METHOD_TYPE_OPTIMIZED:
+          case VM_METHOD_TYPE_UNDEF:
+          case VM_METHOD_TYPE_NOTIMPLEMENTED:
+            break;
+        }
+    }
+}
+
+static void
+gc_update_values(rb_objspace_t *objspace, long n, VALUE *values)
+{
+    long i;
+
+    for (i=0; i<n; i++) {
+        UPDATE_IF_MOVED(objspace, values[i]);
+    }
+}
+
+static void
+gc_ref_update_imemo(rb_objspace_t *objspace, VALUE obj)
+{
+    switch (imemo_type(obj)) {
+      case imemo_env:
+        {
+            rb_env_t *env = (rb_env_t *)obj;
+            TYPED_UPDATE_IF_MOVED(objspace, rb_iseq_t *, env->iseq);
+            UPDATE_IF_MOVED(objspace, env->ep[VM_ENV_DATA_INDEX_ENV]);
+            gc_update_values(objspace, (long)env->env_size, (VALUE *)env->env);
+        }
+        break;
+      case imemo_cref:
+        UPDATE_IF_MOVED(objspace, RANY(obj)->as.imemo.cref.klass);
+        TYPED_UPDATE_IF_MOVED(objspace, struct rb_cref_struct *, RANY(obj)->as.imemo.cref.next);
+        UPDATE_IF_MOVED(objspace, RANY(obj)->as.imemo.cref.refinements);
+        break;
+      case imemo_svar:
+        UPDATE_IF_MOVED(objspace, RANY(obj)->as.imemo.svar.cref_or_me);
+        UPDATE_IF_MOVED(objspace, RANY(obj)->as.imemo.svar.lastline);
+        UPDATE_IF_MOVED(objspace, RANY(obj)->as.imemo.svar.backref);
+        UPDATE_IF_MOVED(objspace, RANY(obj)->as.imemo.svar.others);
+        break;
+      case imemo_throw_data:
+        UPDATE_IF_MOVED(objspace, RANY(obj)->as.imemo.throw_data.throw_obj);
+        break;
+      case imemo_ifunc:
+        break;
+      case imemo_memo:
+        UPDATE_IF_MOVED(objspace, RANY(obj)->as.imemo.memo.v1);
+        UPDATE_IF_MOVED(objspace, RANY(obj)->as.imemo.memo.v2);
+        break;
+      case imemo_ment:
+        gc_ref_update_method_entry(objspace, &RANY(obj)->as.imemo.ment);
+        break;
+      case imemo_iseq:
+        rb_iseq_update_references((rb_iseq_t *)obj);
+        break;
+      case imemo_ast:
+        rb_ast_update_references((rb_ast_t *)obj);
+        break;
+      case imemo_callcache:
+        {
+            const struct rb_callcache *cc = (const struct rb_callcache *)obj;
+            if (cc->klass) {
+                UPDATE_IF_MOVED(objspace, cc->klass);
+                if (!is_live_object(objspace, cc->klass)) {
+                    *((VALUE *)(&cc->klass)) = (VALUE)0;
+                }
+            }
+
+            if (cc->cme_) {
+                TYPED_UPDATE_IF_MOVED(objspace, struct rb_callable_method_entry_struct *, cc->cme_);
+                if (!is_live_object(objspace, (VALUE)cc->cme_)) {
+                    *((struct rb_callable_method_entry_struct **)(&cc->cme_)) = (struct rb_callable_method_entry_struct *)0;
+                }
+            }
+        }
+        break;
+      case imemo_constcache:
+        {
+            const struct iseq_inline_constant_cache_entry *ice = (struct iseq_inline_constant_cache_entry *)obj;
+            UPDATE_IF_MOVED(objspace, ice->value);
+        }
+        break;
+      case imemo_parser_strterm:
+      case imemo_tmpbuf:
+      case imemo_callinfo:
+        break;
+      default:
+        rb_bug("not reachable %d", imemo_type(obj));
+        break;
+    }
+}
+
+static enum rb_id_table_iterator_result
+check_id_table_move(ID id, VALUE value, void *data)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)data;
+
+    if (gc_object_moved_p(objspace, (VALUE)value)) {
+        return ID_TABLE_REPLACE;
+    }
+
+    return ID_TABLE_CONTINUE;
+}
+
+/* Returns the new location of an object, if it moved.  Otherwise returns
+ * the existing location. */
+VALUE
+rb_gc_location(VALUE value)
+{
+
+    VALUE destination;
+
+    if (!SPECIAL_CONST_P(value)) {
+        void *poisoned = asan_poisoned_object_p(value);
+        asan_unpoison_object(value, false);
+
+        if (BUILTIN_TYPE(value) == T_MOVED) {
+            destination = (VALUE)RMOVED(value)->destination;
+            GC_ASSERT(BUILTIN_TYPE(destination) != T_NONE);
+        }
+        else {
+            destination = value;
+        }
+
+        /* Re-poison slot if it's not the one we want */
+        if (poisoned) {
+            GC_ASSERT(BUILTIN_TYPE(value) == T_NONE);
+            asan_poison_object(value);
+        }
+    }
+    else {
+        destination = value;
+    }
+
+    return destination;
+}
+
+static enum rb_id_table_iterator_result
+update_id_table(ID *key, VALUE * value, void *data, int existing)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)data;
+
+    if (gc_object_moved_p(objspace, (VALUE)*value)) {
+        *value = rb_gc_location((VALUE)*value);
+    }
+
+    return ID_TABLE_CONTINUE;
+}
+
+static void
+update_m_tbl(rb_objspace_t *objspace, struct rb_id_table *tbl)
+{
+    if (tbl) {
+        rb_id_table_foreach_with_replace(tbl, check_id_table_move, update_id_table, objspace);
+    }
+}
+
+static enum rb_id_table_iterator_result
+update_cc_tbl_i(ID id, VALUE ccs_ptr, void *data)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)data;
+    struct rb_class_cc_entries *ccs = (struct rb_class_cc_entries *)ccs_ptr;
+    VM_ASSERT(vm_ccs_p(ccs));
+
+    if (gc_object_moved_p(objspace, (VALUE)ccs->cme)) {
+        ccs->cme = (const rb_callable_method_entry_t *)rb_gc_location((VALUE)ccs->cme);
+    }
+
+    for (int i=0; i<ccs->len; i++) {
+        if (gc_object_moved_p(objspace, (VALUE)ccs->entries[i].ci)) {
+            ccs->entries[i].ci = (struct rb_callinfo *)rb_gc_location((VALUE)ccs->entries[i].ci);
+        }
+        if (gc_object_moved_p(objspace, (VALUE)ccs->entries[i].cc)) {
+            ccs->entries[i].cc = (struct rb_callcache *)rb_gc_location((VALUE)ccs->entries[i].cc);
+        }
+    }
+
+    // do not replace
+    return ID_TABLE_CONTINUE;
+}
+
+static void
+update_cc_tbl(rb_objspace_t *objspace, VALUE klass)
+{
+    struct rb_id_table *tbl = RCLASS_CC_TBL(klass);
+    if (tbl) {
+        rb_id_table_foreach_with_replace(tbl, update_cc_tbl_i, 0, objspace);
+    }
+}
+
+static enum rb_id_table_iterator_result
+update_const_table(VALUE value, void *data)
+{
+    rb_const_entry_t *ce = (rb_const_entry_t *)value;
+    rb_objspace_t * objspace = (rb_objspace_t *)data;
+
+    if (gc_object_moved_p(objspace, ce->value)) {
+        ce->value = rb_gc_location(ce->value);
+    }
+
+    if (gc_object_moved_p(objspace, ce->file)) {
+        ce->file = rb_gc_location(ce->file);
+    }
+
+    return ID_TABLE_CONTINUE;
+}
+
+static void
+update_const_tbl(rb_objspace_t *objspace, struct rb_id_table *tbl)
+{
+    if (!tbl) return;
+    rb_id_table_foreach_values(tbl, update_const_table, objspace);
+}
+
+static void
+update_subclass_entries(rb_objspace_t *objspace, rb_subclass_entry_t *entry)
+{
+    while (entry) {
+        UPDATE_IF_MOVED(objspace, entry->klass);
+        entry = entry->next;
+    }
+}
+
+static int
+update_iv_index_tbl_i(st_data_t key, st_data_t value, st_data_t arg)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)arg;
+    struct rb_iv_index_tbl_entry *ent = (struct rb_iv_index_tbl_entry *)value;
+    UPDATE_IF_MOVED(objspace, ent->class_value);
+    return ST_CONTINUE;
+}
+
+static void
+update_class_ext(rb_objspace_t *objspace, rb_classext_t *ext)
+{
+    UPDATE_IF_MOVED(objspace, ext->origin_);
+    UPDATE_IF_MOVED(objspace, ext->refined_class);
+    update_subclass_entries(objspace, ext->subclasses);
+
+    // ext->iv_index_tbl
+    if (ext->iv_index_tbl) {
+        st_foreach(ext->iv_index_tbl, update_iv_index_tbl_i, (st_data_t)objspace);
+    }
+}
+
+static void
+gc_update_object_references(rb_objspace_t *objspace, VALUE obj)
+{
+    RVALUE *any = RANY(obj);
+
+    gc_report(4, objspace, "update-refs: %p ->\n", (void *)obj);
+
+    switch (BUILTIN_TYPE(obj)) {
+      case T_CLASS:
+      case T_MODULE:
+        if (RCLASS_SUPER((VALUE)obj)) {
+            UPDATE_IF_MOVED(objspace, RCLASS(obj)->super);
+        }
+        if (!RCLASS_EXT(obj)) break;
+        update_m_tbl(objspace, RCLASS_M_TBL(obj));
+        update_cc_tbl(objspace, obj);
+
+        gc_update_tbl_refs(objspace, RCLASS_IV_TBL(obj));
+
+        update_class_ext(objspace, RCLASS_EXT(obj));
+        update_const_tbl(objspace, RCLASS_CONST_TBL(obj));
+        break;
+
+      case T_ICLASS:
+        if (FL_TEST(obj, RICLASS_IS_ORIGIN) &&
+                !FL_TEST(obj, RICLASS_ORIGIN_SHARED_MTBL)) {
+            update_m_tbl(objspace, RCLASS_M_TBL(obj));
+        }
+        if (RCLASS_SUPER((VALUE)obj)) {
+            UPDATE_IF_MOVED(objspace, RCLASS(obj)->super);
+        }
+        if (!RCLASS_EXT(obj)) break;
+        if (RCLASS_IV_TBL(obj)) {
+            gc_update_tbl_refs(objspace, RCLASS_IV_TBL(obj));
+        }
+        update_class_ext(objspace, RCLASS_EXT(obj));
+        update_m_tbl(objspace, RCLASS_CALLABLE_M_TBL(obj));
+        update_cc_tbl(objspace, obj);
+        break;
+
+      case T_IMEMO:
+        gc_ref_update_imemo(objspace, obj);
+        return;
+
+      case T_NIL:
+      case T_FIXNUM:
+      case T_NODE:
+      case T_MOVED:
+      case T_NONE:
+        /* These can't move */
+        return;
+
+      case T_ARRAY:
+        if (FL_TEST(obj, ELTS_SHARED)) {
+            UPDATE_IF_MOVED(objspace, any->as.array.as.heap.aux.shared_root);
+        }
+        else {
+            gc_ref_update_array(objspace, obj);
+        }
+        break;
+
+      case T_HASH:
+        gc_ref_update_hash(objspace, obj);
+        UPDATE_IF_MOVED(objspace, any->as.hash.ifnone);
+        break;
+
+      case T_STRING:
+        if (STR_SHARED_P(obj)) {
+            UPDATE_IF_MOVED(objspace, any->as.string.as.heap.aux.shared);
+        }
+        break;
+
+      case T_DATA:
+        /* Call the compaction callback, if it exists */
+        {
+            void *const ptr = DATA_PTR(obj);
+            if (ptr) {
+                if (RTYPEDDATA_P(obj)) {
+                    RUBY_DATA_FUNC compact_func = any->as.typeddata.type->function.dcompact;
+                    if (compact_func) (*compact_func)(ptr);
+                }
+            }
+        }
+        break;
+
+      case T_OBJECT:
+        gc_ref_update_object(objspace, obj);
+        break;
+
+      case T_FILE:
+        if (any->as.file.fptr) {
+            UPDATE_IF_MOVED(objspace, any->as.file.fptr->self);
+            UPDATE_IF_MOVED(objspace, any->as.file.fptr->pathv);
+            UPDATE_IF_MOVED(objspace, any->as.file.fptr->tied_io_for_writing);
+            UPDATE_IF_MOVED(objspace, any->as.file.fptr->writeconv_asciicompat);
+            UPDATE_IF_MOVED(objspace, any->as.file.fptr->writeconv_pre_ecopts);
+            UPDATE_IF_MOVED(objspace, any->as.file.fptr->encs.ecopts);
+            UPDATE_IF_MOVED(objspace, any->as.file.fptr->write_lock);
+        }
+        break;
+      case T_REGEXP:
+        UPDATE_IF_MOVED(objspace, any->as.regexp.src);
+        break;
+
+      case T_SYMBOL:
+        if (DYNAMIC_SYM_P((VALUE)any)) {
+            UPDATE_IF_MOVED(objspace, RSYMBOL(any)->fstr);
+        }
+        break;
+
+      case T_FLOAT:
+      case T_BIGNUM:
+        break;
+
+      case T_MATCH:
+        UPDATE_IF_MOVED(objspace, any->as.match.regexp);
+
+        if (any->as.match.str) {
+            UPDATE_IF_MOVED(objspace, any->as.match.str);
+        }
+        break;
+
+      case T_RATIONAL:
+        UPDATE_IF_MOVED(objspace, any->as.rational.num);
+        UPDATE_IF_MOVED(objspace, any->as.rational.den);
+        break;
+
+      case T_COMPLEX:
+        UPDATE_IF_MOVED(objspace, any->as.complex.real);
+        UPDATE_IF_MOVED(objspace, any->as.complex.imag);
+
+        break;
+
+      case T_STRUCT:
+        {
+            long i, len = RSTRUCT_LEN(obj);
+            VALUE *ptr = (VALUE *)RSTRUCT_CONST_PTR(obj);
+
+            for (i = 0; i < len; i++) {
+                UPDATE_IF_MOVED(objspace, ptr[i]);
+            }
+        }
+        break;
+      default:
+#if GC_DEBUG
+        rb_gcdebug_print_obj_condition((VALUE)obj);
+        rb_obj_info_dump(obj);
+        rb_bug("unreachable");
+#endif
+        break;
+
+    }
+
+    UPDATE_IF_MOVED(objspace, RBASIC(obj)->klass);
+
+    gc_report(4, objspace, "update-refs: %p <-\n", (void *)obj);
+}
+
+static int
+gc_ref_update(void *vstart, void *vend, size_t stride, rb_objspace_t * objspace, struct heap_page *page)
+{
+    VALUE v = (VALUE)vstart;
+    asan_unpoison_memory_region(&page->freelist, sizeof(RVALUE*), false);
+    asan_poison_memory_region(&page->freelist, sizeof(RVALUE*));
+    page->flags.has_uncollectible_shady_objects = FALSE;
+    page->flags.has_remembered_objects = FALSE;
+
+    /* For each object on the page */
+    for (; v != (VALUE)vend; v += stride) {
+        void *poisoned = asan_poisoned_object_p(v);
+        asan_unpoison_object(v, false);
+
+        switch (BUILTIN_TYPE(v)) {
+          case T_NONE:
+          case T_MOVED:
+          case T_ZOMBIE:
+            break;
+          default:
+            if (RVALUE_WB_UNPROTECTED(v)) {
+                page->flags.has_uncollectible_shady_objects = TRUE;
+            }
+            if (RVALUE_PAGE_MARKING(page, v)) {
+                page->flags.has_remembered_objects = TRUE;
+            }
+            if (page->flags.before_sweep) {
+                if (RVALUE_MARKED(v)) {
+                    gc_update_object_references(objspace, v);
+                }
+            } else {
+                gc_update_object_references(objspace, v);
+            }
+        }
+
+        if (poisoned) {
+            asan_poison_object(v);
+        }
+    }
+
+    return 0;
+}
+
+extern rb_symbols_t ruby_global_symbols;
+#define global_symbols ruby_global_symbols
+
+static void
+gc_update_references(rb_objspace_t * objspace, rb_heap_t *heap)
+{
+    rb_execution_context_t *ec = GET_EC();
+    rb_vm_t *vm = rb_ec_vm_ptr(ec);
+    short should_set_mark_bits = 1;
+
+    struct heap_page *page = NULL;
+
+    list_for_each(&heap->pages, page, page_node) {
+        gc_ref_update(page->start, page->start + page->total_slots, sizeof(RVALUE), objspace, page);
+        if (page == heap->sweeping_page) {
+            should_set_mark_bits = 0;
+        }
+        if (should_set_mark_bits) {
+            gc_setup_mark_bits(page);
+        }
+    }
+    rb_vm_update_references(vm);
+    rb_transient_heap_update_references();
+    rb_gc_update_global_tbl();
+    global_symbols.ids = rb_gc_location(global_symbols.ids);
+    global_symbols.dsymbol_fstr_hash = rb_gc_location(global_symbols.dsymbol_fstr_hash);
+    gc_update_tbl_refs(objspace, objspace->obj_to_id_tbl);
+    gc_update_table_refs(objspace, objspace->id_to_obj_tbl);
+    gc_update_table_refs(objspace, global_symbols.str_sym);
+    gc_update_table_refs(objspace, finalizer_table);
+}
+
+static VALUE type_sym(size_t type);
+
+static VALUE
+gc_compact_stats(rb_execution_context_t *ec, VALUE self)
+{
+    size_t i;
+    rb_objspace_t *objspace = &rb_objspace;
+    VALUE h = rb_hash_new();
+    VALUE considered = rb_hash_new();
+    VALUE moved = rb_hash_new();
+
+    for (i=0; i<T_MASK; i++) {
+        if(objspace->rcompactor.considered_count_table[i]) {
+            rb_hash_aset(considered, type_sym(i), SIZET2NUM(objspace->rcompactor.considered_count_table[i]));
+        }
+
+        if(objspace->rcompactor.moved_count_table[i]) {
+            rb_hash_aset(moved, type_sym(i), SIZET2NUM(objspace->rcompactor.moved_count_table[i]));
+        }
+    }
+
+    rb_hash_aset(h, ID2SYM(rb_intern("considered")), considered);
+    rb_hash_aset(h, ID2SYM(rb_intern("moved")), moved);
+
+    return h;
+}
+
+static void
+root_obj_check_moved_i(const char *category, VALUE obj, void *data)
+{
+    if (gc_object_moved_p(&rb_objspace, obj)) {
+        rb_bug("ROOT %s points to MOVED: %p -> %s\n", category, (void *)obj, obj_info(rb_gc_location(obj)));
+    }
+}
+
+static void
+reachable_object_check_moved_i(VALUE ref, void *data)
+{
+    VALUE parent = (VALUE)data;
+    if (gc_object_moved_p(&rb_objspace, ref)) {
+        rb_bug("Object %s points to MOVED: %p -> %s\n", obj_info(parent), (void *)ref, obj_info(rb_gc_location(ref)));
+    }
+}
+
+static int
+heap_check_moved_i(void *vstart, void *vend, size_t stride, void *data)
+{
+    VALUE v = (VALUE)vstart;
+    for (; v != (VALUE)vend; v += stride) {
+        if (gc_object_moved_p(&rb_objspace, v)) {
+            /* Moved object still on the heap, something may have a reference. */
+        }
+        else {
+            void *poisoned = asan_poisoned_object_p(v);
+            asan_unpoison_object(v, false);
+
+            switch (BUILTIN_TYPE(v)) {
+              case T_NONE:
+              case T_ZOMBIE:
+                break;
+              default:
+                if (!rb_objspace_garbage_object_p(v)) {
+                    rb_objspace_reachable_objects_from(v, reachable_object_check_moved_i, (void *)v);
+                }
+            }
+
+            if (poisoned) {
+                GC_ASSERT(BUILTIN_TYPE(v) == T_NONE);
+                asan_poison_object(v);
+            }
+        }
+    }
+
+    return 0;
+}
+
+static VALUE
+gc_compact(rb_execution_context_t *ec, VALUE self)
+{
+    /* Run GC with compaction enabled */
+    gc_start_internal(ec, self, Qtrue, Qtrue, Qtrue, Qtrue);
+
+    return gc_compact_stats(ec, self);
+}
+
+static VALUE
+gc_verify_compaction_references(rb_execution_context_t *ec, VALUE self, VALUE double_heap, VALUE toward_empty)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+
+    /* Clear the heap. */
+    gc_start_internal(ec, self, Qtrue, Qtrue, Qtrue, Qfalse);
+
+    RB_VM_LOCK_ENTER();
+    {
+        gc_rest(objspace);
+
+        if (RTEST(double_heap)) {
+            heap_add_pages(objspace, heap_eden, heap_allocated_pages);
+        }
+
+        if (RTEST(toward_empty)) {
+            gc_sort_heap_by_empty_slots(objspace);
+        }
+    }
+    RB_VM_LOCK_LEAVE();
+
+    gc_start_internal(ec, self, Qtrue, Qtrue, Qtrue, Qtrue);
+
+    objspace_reachable_objects_from_root(objspace, root_obj_check_moved_i, NULL);
+    objspace_each_objects(objspace, heap_check_moved_i, NULL);
+
+    return gc_compact_stats(ec, self);
+}
+
+VALUE
+rb_gc_start(void)
+{
+    rb_gc();
+    return Qnil;
+}
+
+void
+rb_gc(void)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    int reason = GPR_DEFAULT_REASON;
+    garbage_collect(objspace, reason);
+}
+
+int
+rb_during_gc(void)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return during_gc;
+}
+
+#if RGENGC_PROFILE >= 2
+
+static const char *type_name(int type, VALUE obj);
+
+static void
+gc_count_add_each_types(VALUE hash, const char *name, const size_t *types)
+{
+    VALUE result = rb_hash_new_with_size(T_MASK);
+    int i;
+    for (i=0; i<T_MASK; i++) {
+        const char *type = type_name(i, 0);
+        rb_hash_aset(result, ID2SYM(rb_intern(type)), SIZET2NUM(types[i]));
+    }
+    rb_hash_aset(hash, ID2SYM(rb_intern(name)), result);
+}
+#endif
+
+size_t
+rb_gc_count(void)
+{
+    return rb_objspace.profile.count;
+}
+
+static VALUE
+gc_count(rb_execution_context_t *ec, VALUE self)
+{
+    return SIZET2NUM(rb_gc_count());
+}
+
+static VALUE
+gc_info_decode(rb_objspace_t *objspace, const VALUE hash_or_key, const int orig_flags)
+{
+    static VALUE sym_major_by = Qnil, sym_gc_by, sym_immediate_sweep, sym_have_finalizer, sym_state;
+    static VALUE sym_nofree, sym_oldgen, sym_shady, sym_force, sym_stress;
+#if RGENGC_ESTIMATE_OLDMALLOC
+    static VALUE sym_oldmalloc;
+#endif
+    static VALUE sym_newobj, sym_malloc, sym_method, sym_capi;
+    static VALUE sym_none, sym_marking, sym_sweeping;
+    VALUE hash = Qnil, key = Qnil;
+    VALUE major_by;
+    VALUE flags = orig_flags ? orig_flags : objspace->profile.latest_gc_info;
+
+    if (SYMBOL_P(hash_or_key)) {
+        key = hash_or_key;
+    }
+    else if (RB_TYPE_P(hash_or_key, T_HASH)) {
+        hash = hash_or_key;
+    }
+    else {
+        rb_raise(rb_eTypeError, "non-hash or symbol given");
+    }
+
+    if (sym_major_by == Qnil) {
+#define S(s) sym_##s = ID2SYM(rb_intern_const(#s))
+        S(major_by);
+        S(gc_by);
+        S(immediate_sweep);
+        S(have_finalizer);
+        S(state);
+
+        S(stress);
+        S(nofree);
+        S(oldgen);
+        S(shady);
+        S(force);
+#if RGENGC_ESTIMATE_OLDMALLOC
+        S(oldmalloc);
+#endif
+        S(newobj);
+        S(malloc);
+        S(method);
+        S(capi);
+
+        S(none);
+        S(marking);
+        S(sweeping);
+#undef S
+    }
+
+#define SET(name, attr) \
+    if (key == sym_##name) \
+        return (attr); \
+    else if (hash != Qnil) \
+        rb_hash_aset(hash, sym_##name, (attr));
+
+    major_by =
+      (flags & GPR_FLAG_MAJOR_BY_NOFREE) ? sym_nofree :
+      (flags & GPR_FLAG_MAJOR_BY_OLDGEN) ? sym_oldgen :
+      (flags & GPR_FLAG_MAJOR_BY_SHADY)  ? sym_shady :
+      (flags & GPR_FLAG_MAJOR_BY_FORCE)  ? sym_force :
+#if RGENGC_ESTIMATE_OLDMALLOC
+      (flags & GPR_FLAG_MAJOR_BY_OLDMALLOC) ? sym_oldmalloc :
+#endif
+      Qnil;
+    SET(major_by, major_by);
+
+    SET(gc_by,
+        (flags & GPR_FLAG_NEWOBJ) ? sym_newobj :
+        (flags & GPR_FLAG_MALLOC) ? sym_malloc :
+        (flags & GPR_FLAG_METHOD) ? sym_method :
+        (flags & GPR_FLAG_CAPI)   ? sym_capi :
+        (flags & GPR_FLAG_STRESS) ? sym_stress :
+        Qnil
+    );
+
+    SET(have_finalizer, (flags & GPR_FLAG_HAVE_FINALIZE) ? Qtrue : Qfalse);
+    SET(immediate_sweep, (flags & GPR_FLAG_IMMEDIATE_SWEEP) ? Qtrue : Qfalse);
+
+    if (orig_flags == 0) {
+        SET(state, gc_mode(objspace) == gc_mode_none ? sym_none :
+                   gc_mode(objspace) == gc_mode_marking ? sym_marking : sym_sweeping);
+    }
+#undef SET
+
+    if (!NIL_P(key)) {/* matched key should return above */
+        rb_raise(rb_eArgError, "unknown key: %"PRIsVALUE, rb_sym2str(key));
+    }
+
+    return hash;
+}
+
+VALUE
+rb_gc_latest_gc_info(VALUE key)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return gc_info_decode(objspace, key, 0);
+}
+
+static VALUE
+gc_latest_gc_info(rb_execution_context_t *ec, VALUE self, VALUE arg)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+
+    if (NIL_P(arg)) {
+        arg = rb_hash_new();
+    }
+    else if (!SYMBOL_P(arg) && !RB_TYPE_P(arg, T_HASH)) {
+        rb_raise(rb_eTypeError, "non-hash or symbol given");
+    }
+
+    return gc_info_decode(objspace, arg, 0);
+}
+
+enum gc_stat_sym {
+    gc_stat_sym_count,
+    gc_stat_sym_heap_allocated_pages,
+    gc_stat_sym_heap_sorted_length,
+    gc_stat_sym_heap_allocatable_pages,
+    gc_stat_sym_heap_available_slots,
+    gc_stat_sym_heap_live_slots,
+    gc_stat_sym_heap_free_slots,
+    gc_stat_sym_heap_final_slots,
+    gc_stat_sym_heap_marked_slots,
+    gc_stat_sym_heap_eden_pages,
+    gc_stat_sym_heap_tomb_pages,
+    gc_stat_sym_total_allocated_pages,
+    gc_stat_sym_total_freed_pages,
+    gc_stat_sym_total_allocated_objects,
+    gc_stat_sym_total_freed_objects,
+    gc_stat_sym_malloc_increase_bytes,
+    gc_stat_sym_malloc_increase_bytes_limit,
+    gc_stat_sym_minor_gc_count,
+    gc_stat_sym_major_gc_count,
+    gc_stat_sym_compact_count,
+    gc_stat_sym_read_barrier_faults,
+    gc_stat_sym_total_moved_objects,
+    gc_stat_sym_remembered_wb_unprotected_objects,
+    gc_stat_sym_remembered_wb_unprotected_objects_limit,
+    gc_stat_sym_old_objects,
+    gc_stat_sym_old_objects_limit,
+#if RGENGC_ESTIMATE_OLDMALLOC
+    gc_stat_sym_oldmalloc_increase_bytes,
+    gc_stat_sym_oldmalloc_increase_bytes_limit,
+#endif
+#if RGENGC_PROFILE
+    gc_stat_sym_total_generated_normal_object_count,
+    gc_stat_sym_total_generated_shady_object_count,
+    gc_stat_sym_total_shade_operation_count,
+    gc_stat_sym_total_promoted_count,
+    gc_stat_sym_total_remembered_normal_object_count,
+    gc_stat_sym_total_remembered_shady_object_count,
+#endif
+    gc_stat_sym_last
+};
+
+static VALUE gc_stat_symbols[gc_stat_sym_last];
+
+static void
+setup_gc_stat_symbols(void)
+{
+    if (gc_stat_symbols[0] == 0) {
+#define S(s) gc_stat_symbols[gc_stat_sym_##s] = ID2SYM(rb_intern_const(#s))
+	S(count);
+	S(heap_allocated_pages);
+	S(heap_sorted_length);
+	S(heap_allocatable_pages);
+	S(heap_available_slots);
+	S(heap_live_slots);
+	S(heap_free_slots);
+	S(heap_final_slots);
+	S(heap_marked_slots);
+	S(heap_eden_pages);
+	S(heap_tomb_pages);
+	S(total_allocated_pages);
+	S(total_freed_pages);
+	S(total_allocated_objects);
+	S(total_freed_objects);
+	S(malloc_increase_bytes);
+	S(malloc_increase_bytes_limit);
+	S(minor_gc_count);
+	S(major_gc_count);
+	S(compact_count);
+	S(read_barrier_faults);
+	S(total_moved_objects);
+	S(remembered_wb_unprotected_objects);
+	S(remembered_wb_unprotected_objects_limit);
+	S(old_objects);
+	S(old_objects_limit);
+#if RGENGC_ESTIMATE_OLDMALLOC
+	S(oldmalloc_increase_bytes);
+	S(oldmalloc_increase_bytes_limit);
+#endif
+#if RGENGC_PROFILE
+	S(total_generated_normal_object_count);
+	S(total_generated_shady_object_count);
+	S(total_shade_operation_count);
+	S(total_promoted_count);
+	S(total_remembered_normal_object_count);
+	S(total_remembered_shady_object_count);
+#endif /* RGENGC_PROFILE */
+#undef S
+    }
+}
+
+static size_t
+gc_stat_internal(VALUE hash_or_sym)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    VALUE hash = Qnil, key = Qnil;
+
+    setup_gc_stat_symbols();
+
+    if (RB_TYPE_P(hash_or_sym, T_HASH)) {
+	hash = hash_or_sym;
+    }
+    else if (SYMBOL_P(hash_or_sym)) {
+	key = hash_or_sym;
+    }
+    else {
+	rb_raise(rb_eTypeError, "non-hash or symbol argument");
+    }
+
+#define SET(name, attr) \
+    if (key == gc_stat_symbols[gc_stat_sym_##name]) \
+	return attr; \
+    else if (hash != Qnil) \
+	rb_hash_aset(hash, gc_stat_symbols[gc_stat_sym_##name], SIZET2NUM(attr));
+
+    SET(count, objspace->profile.count);
+
+    /* implementation dependent counters */
+    SET(heap_allocated_pages, heap_allocated_pages);
+    SET(heap_sorted_length, heap_pages_sorted_length);
+    SET(heap_allocatable_pages, heap_allocatable_pages);
+    SET(heap_available_slots, objspace_available_slots(objspace));
+    SET(heap_live_slots, objspace_live_slots(objspace));
+    SET(heap_free_slots, objspace_free_slots(objspace));
+    SET(heap_final_slots, heap_pages_final_slots);
+    SET(heap_marked_slots, objspace->marked_slots);
+    SET(heap_eden_pages, heap_eden->total_pages);
+    SET(heap_tomb_pages, heap_tomb->total_pages);
+    SET(total_allocated_pages, objspace->profile.total_allocated_pages);
+    SET(total_freed_pages, objspace->profile.total_freed_pages);
+    SET(total_allocated_objects, objspace->total_allocated_objects);
+    SET(total_freed_objects, objspace->profile.total_freed_objects);
+    SET(malloc_increase_bytes, malloc_increase);
+    SET(malloc_increase_bytes_limit, malloc_limit);
+    SET(minor_gc_count, objspace->profile.minor_gc_count);
+    SET(major_gc_count, objspace->profile.major_gc_count);
+    SET(compact_count, objspace->profile.compact_count);
+    SET(read_barrier_faults, objspace->profile.read_barrier_faults);
+    SET(total_moved_objects, objspace->rcompactor.total_moved);
+    SET(remembered_wb_unprotected_objects, objspace->rgengc.uncollectible_wb_unprotected_objects);
+    SET(remembered_wb_unprotected_objects_limit, objspace->rgengc.uncollectible_wb_unprotected_objects_limit);
+    SET(old_objects, objspace->rgengc.old_objects);
+    SET(old_objects_limit, objspace->rgengc.old_objects_limit);
+#if RGENGC_ESTIMATE_OLDMALLOC
+    SET(oldmalloc_increase_bytes, objspace->rgengc.oldmalloc_increase);
+    SET(oldmalloc_increase_bytes_limit, objspace->rgengc.oldmalloc_increase_limit);
+#endif
+
+#if RGENGC_PROFILE
+    SET(total_generated_normal_object_count, objspace->profile.total_generated_normal_object_count);
+    SET(total_generated_shady_object_count, objspace->profile.total_generated_shady_object_count);
+    SET(total_shade_operation_count, objspace->profile.total_shade_operation_count);
+    SET(total_promoted_count, objspace->profile.total_promoted_count);
+    SET(total_remembered_normal_object_count, objspace->profile.total_remembered_normal_object_count);
+    SET(total_remembered_shady_object_count, objspace->profile.total_remembered_shady_object_count);
+#endif /* RGENGC_PROFILE */
+#undef SET
+
+    if (!NIL_P(key)) { /* matched key should return above */
+	rb_raise(rb_eArgError, "unknown key: %"PRIsVALUE, rb_sym2str(key));
+    }
+
+#if defined(RGENGC_PROFILE) && RGENGC_PROFILE >= 2
+    if (hash != Qnil) {
+	gc_count_add_each_types(hash, "generated_normal_object_count_types", objspace->profile.generated_normal_object_count_types);
+	gc_count_add_each_types(hash, "generated_shady_object_count_types", objspace->profile.generated_shady_object_count_types);
+	gc_count_add_each_types(hash, "shade_operation_count_types", objspace->profile.shade_operation_count_types);
+	gc_count_add_each_types(hash, "promoted_types", objspace->profile.promoted_types);
+	gc_count_add_each_types(hash, "remembered_normal_object_count_types", objspace->profile.remembered_normal_object_count_types);
+	gc_count_add_each_types(hash, "remembered_shady_object_count_types", objspace->profile.remembered_shady_object_count_types);
+    }
+#endif
+
+    return 0;
+}
+
+static VALUE
+gc_stat(rb_execution_context_t *ec, VALUE self, VALUE arg) // arg is (nil || hash || symbol)
+{
+    if (NIL_P(arg)) {
+        arg = rb_hash_new();
+    }
+    else if (SYMBOL_P(arg)) {
+        size_t value = gc_stat_internal(arg);
+        return SIZET2NUM(value);
+    }
+    else if (RB_TYPE_P(arg, T_HASH)) {
+        // ok
+    }
+    else {
+        rb_raise(rb_eTypeError, "non-hash or symbol given");
+    }
+
+    gc_stat_internal(arg);
+    return arg;
+}
+
+size_t
+rb_gc_stat(VALUE key)
+{
+    if (SYMBOL_P(key)) {
+	size_t value = gc_stat_internal(key);
+	return value;
+    }
+    else {
+	gc_stat_internal(key);
+	return 0;
+    }
+}
+
+static VALUE
+gc_stress_get(rb_execution_context_t *ec, VALUE self)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return ruby_gc_stress_mode;
+}
+
+static void
+gc_stress_set(rb_objspace_t *objspace, VALUE flag)
+{
+    objspace->flags.gc_stressful = RTEST(flag);
+    objspace->gc_stress_mode = flag;
+}
+
+static VALUE
+gc_stress_set_m(rb_execution_context_t *ec, VALUE self, VALUE flag)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    gc_stress_set(objspace, flag);
+    return flag;
+}
+
+VALUE
+rb_gc_enable(void)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return rb_objspace_gc_enable(objspace);
+}
+
+VALUE
+rb_objspace_gc_enable(rb_objspace_t *objspace)
+{
+    int old = dont_gc_val();
+
+    dont_gc_off();
+    return old ? Qtrue : Qfalse;
+}
+
+static VALUE
+gc_enable(rb_execution_context_t *ec, VALUE _)
+{
+    return rb_gc_enable();
+}
+
+VALUE
+rb_gc_disable_no_rest(void)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return gc_disable_no_rest(objspace);
+}
+
+static VALUE
+gc_disable_no_rest(rb_objspace_t *objspace)
+{
+    int old = dont_gc_val();
+    dont_gc_on();
+    return old ? Qtrue : Qfalse;
+}
+
+VALUE
+rb_gc_disable(void)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return rb_objspace_gc_disable(objspace);
+}
+
+VALUE
+rb_objspace_gc_disable(rb_objspace_t *objspace)
+{
+    gc_rest(objspace);
+    return gc_disable_no_rest(objspace);
+}
+
+static VALUE
+gc_disable(rb_execution_context_t *ec, VALUE _)
+{
+    return rb_gc_disable();
+}
+
+static VALUE
+gc_set_auto_compact(rb_execution_context_t *ec, VALUE _, VALUE v)
+{
+    /* If not MinGW, Windows, or does not have mmap, we cannot use mprotect for
+     * the read barrier, so we must disable automatic compaction. */
+#if !defined(__MINGW32__) && !defined(_WIN32)
+    if (!USE_MMAP_ALIGNED_ALLOC) {
+        rb_raise(rb_eNotImpError, "Automatic compaction isn't available on this platform");
+    }
+#endif
+
+    ruby_enable_autocompact = RTEST(v);
+    return v;
+}
+
+static VALUE
+gc_get_auto_compact(rb_execution_context_t *ec, VALUE _)
+{
+    return ruby_enable_autocompact ? Qtrue : Qfalse;
+}
+
+static int
+get_envparam_size(const char *name, size_t *default_value, size_t lower_bound)
+{
+    char *ptr = getenv(name);
+    ssize_t val;
+
+    if (ptr != NULL && *ptr) {
+	size_t unit = 0;
+	char *end;
+#if SIZEOF_SIZE_T == SIZEOF_LONG_LONG
+	val = strtoll(ptr, &end, 0);
+#else
+	val = strtol(ptr, &end, 0);
+#endif
+	switch (*end) {
+	  case 'k': case 'K':
+	    unit = 1024;
+	    ++end;
+	    break;
+	  case 'm': case 'M':
+	    unit = 1024*1024;
+	    ++end;
+	    break;
+	  case 'g': case 'G':
+	    unit = 1024*1024*1024;
+	    ++end;
+	    break;
+	}
+	while (*end && isspace((unsigned char)*end)) end++;
+	if (*end) {
+	    if (RTEST(ruby_verbose)) fprintf(stderr, "invalid string for %s: %s\n", name, ptr);
+	    return 0;
+	}
+	if (unit > 0) {
+	    if (val < -(ssize_t)(SIZE_MAX / 2 / unit) || (ssize_t)(SIZE_MAX / 2 / unit) < val) {
+		if (RTEST(ruby_verbose)) fprintf(stderr, "%s=%s is ignored because it overflows\n", name, ptr);
+		return 0;
+	    }
+	    val *= unit;
+	}
+	if (val > 0 && (size_t)val > lower_bound) {
+	    if (RTEST(ruby_verbose)) {
+		fprintf(stderr, "%s=%"PRIdSIZE" (default value: %"PRIuSIZE")\n", name, val, *default_value);
+	    }
+	    *default_value = (size_t)val;
+	    return 1;
+	}
+	else {
+	    if (RTEST(ruby_verbose)) {
+		fprintf(stderr, "%s=%"PRIdSIZE" (default value: %"PRIuSIZE") is ignored because it must be greater than %"PRIuSIZE".\n",
+			name, val, *default_value, lower_bound);
+	    }
+	    return 0;
+	}
+    }
+    return 0;
+}
+
+static int
+get_envparam_double(const char *name, double *default_value, double lower_bound, double upper_bound, int accept_zero)
+{
+    char *ptr = getenv(name);
+    double val;
+
+    if (ptr != NULL && *ptr) {
+	char *end;
+	val = strtod(ptr, &end);
+	if (!*ptr || *end) {
+	    if (RTEST(ruby_verbose)) fprintf(stderr, "invalid string for %s: %s\n", name, ptr);
+	    return 0;
+	}
+
+	if (accept_zero && val == 0.0) {
+	    goto accept;
+	}
+	else if (val <= lower_bound) {
+	    if (RTEST(ruby_verbose)) {
+		fprintf(stderr, "%s=%f (default value: %f) is ignored because it must be greater than %f.\n",
+			name, val, *default_value, lower_bound);
+	    }
+	}
+	else if (upper_bound != 0.0 && /* ignore upper_bound if it is 0.0 */
+		 val > upper_bound) {
+	    if (RTEST(ruby_verbose)) {
+		fprintf(stderr, "%s=%f (default value: %f) is ignored because it must be lower than %f.\n",
+			name, val, *default_value, upper_bound);
+	    }
+	}
+	else {
+            goto accept;
+	}
+    }
+    return 0;
+
+  accept:
+    if (RTEST(ruby_verbose)) fprintf(stderr, "%s=%f (default value: %f)\n", name, val, *default_value);
+    *default_value = val;
+    return 1;
+}
+
+static void
+gc_set_initial_pages(void)
+{
+    size_t min_pages;
+    rb_objspace_t *objspace = &rb_objspace;
+
+    min_pages = gc_params.heap_init_slots / HEAP_PAGE_OBJ_LIMIT;
+    if (min_pages > heap_eden->total_pages) {
+	heap_add_pages(objspace, heap_eden, min_pages - heap_eden->total_pages);
+    }
+}
+
+/*
+ * GC tuning environment variables
+ *
+ * * RUBY_GC_HEAP_INIT_SLOTS
+ *   - Initial allocation slots.
+ * * RUBY_GC_HEAP_FREE_SLOTS
+ *   - Prepare at least this amount of slots after GC.
+ *   - Allocate slots if there are not enough slots.
+ * * RUBY_GC_HEAP_GROWTH_FACTOR (new from 2.1)
+ *   - Allocate slots by this factor.
+ *   - (next slots number) = (current slots number) * (this factor)
+ * * RUBY_GC_HEAP_GROWTH_MAX_SLOTS (new from 2.1)
+ *   - Allocation rate is limited to this number of slots.
+ * * RUBY_GC_HEAP_FREE_SLOTS_MIN_RATIO (new from 2.4)
+ *   - Allocate additional pages when the number of free slots is
+ *     lower than the value (total_slots * (this ratio)).
+ * * RUBY_GC_HEAP_FREE_SLOTS_GOAL_RATIO (new from 2.4)
+ *   - Allocate slots to satisfy this formula:
+ *       free_slots = total_slots * goal_ratio
+ *   - In other words, prepare (total_slots * goal_ratio) free slots.
+ *   - if this value is 0.0, then use RUBY_GC_HEAP_GROWTH_FACTOR directly.
+ * * RUBY_GC_HEAP_FREE_SLOTS_MAX_RATIO (new from 2.4)
+ *   - Allow to free pages when the number of free slots is
+ *     greater than the value (total_slots * (this ratio)).
+ * * RUBY_GC_HEAP_OLDOBJECT_LIMIT_FACTOR (new from 2.1.1)
+ *   - Do full GC when the number of old objects is more than R * N
+ *     where R is this factor and
+ *           N is the number of old objects just after last full GC.
+ *
+ *  * obsolete
+ *    * RUBY_FREE_MIN       -> RUBY_GC_HEAP_FREE_SLOTS (from 2.1)
+ *    * RUBY_HEAP_MIN_SLOTS -> RUBY_GC_HEAP_INIT_SLOTS (from 2.1)
+ *
+ * * RUBY_GC_MALLOC_LIMIT
+ * * RUBY_GC_MALLOC_LIMIT_MAX (new from 2.1)
+ * * RUBY_GC_MALLOC_LIMIT_GROWTH_FACTOR (new from 2.1)
+ *
+ * * RUBY_GC_OLDMALLOC_LIMIT (new from 2.1)
+ * * RUBY_GC_OLDMALLOC_LIMIT_MAX (new from 2.1)
+ * * RUBY_GC_OLDMALLOC_LIMIT_GROWTH_FACTOR (new from 2.1)
+ */
+
+void
+ruby_gc_set_params(void)
+{
+    /* RUBY_GC_HEAP_FREE_SLOTS */
+    if (get_envparam_size("RUBY_GC_HEAP_FREE_SLOTS", &gc_params.heap_free_slots, 0)) {
+	/* ok */
+    }
+
+    /* RUBY_GC_HEAP_INIT_SLOTS */
+    if (get_envparam_size("RUBY_GC_HEAP_INIT_SLOTS", &gc_params.heap_init_slots, 0)) {
+	gc_set_initial_pages();
+    }
+
+    get_envparam_double("RUBY_GC_HEAP_GROWTH_FACTOR", &gc_params.growth_factor, 1.0, 0.0, FALSE);
+    get_envparam_size  ("RUBY_GC_HEAP_GROWTH_MAX_SLOTS", &gc_params.growth_max_slots, 0);
+    get_envparam_double("RUBY_GC_HEAP_FREE_SLOTS_MIN_RATIO", &gc_params.heap_free_slots_min_ratio,
+			0.0, 1.0, FALSE);
+    get_envparam_double("RUBY_GC_HEAP_FREE_SLOTS_MAX_RATIO", &gc_params.heap_free_slots_max_ratio,
+			gc_params.heap_free_slots_min_ratio, 1.0, FALSE);
+    get_envparam_double("RUBY_GC_HEAP_FREE_SLOTS_GOAL_RATIO", &gc_params.heap_free_slots_goal_ratio,
+			gc_params.heap_free_slots_min_ratio, gc_params.heap_free_slots_max_ratio, TRUE);
+    get_envparam_double("RUBY_GC_HEAP_OLDOBJECT_LIMIT_FACTOR", &gc_params.oldobject_limit_factor, 0.0, 0.0, TRUE);
+
+    get_envparam_size  ("RUBY_GC_MALLOC_LIMIT", &gc_params.malloc_limit_min, 0);
+    get_envparam_size  ("RUBY_GC_MALLOC_LIMIT_MAX", &gc_params.malloc_limit_max, 0);
+    if (!gc_params.malloc_limit_max) { /* ignore max-check if 0 */
+        gc_params.malloc_limit_max = SIZE_MAX;
+    }
+    get_envparam_double("RUBY_GC_MALLOC_LIMIT_GROWTH_FACTOR", &gc_params.malloc_limit_growth_factor, 1.0, 0.0, FALSE);
+
+#if RGENGC_ESTIMATE_OLDMALLOC
+    if (get_envparam_size("RUBY_GC_OLDMALLOC_LIMIT", &gc_params.oldmalloc_limit_min, 0)) {
+	rb_objspace_t *objspace = &rb_objspace;
+	objspace->rgengc.oldmalloc_increase_limit = gc_params.oldmalloc_limit_min;
+    }
+    get_envparam_size  ("RUBY_GC_OLDMALLOC_LIMIT_MAX", &gc_params.oldmalloc_limit_max, 0);
+    get_envparam_double("RUBY_GC_OLDMALLOC_LIMIT_GROWTH_FACTOR", &gc_params.oldmalloc_limit_growth_factor, 1.0, 0.0, FALSE);
+#endif
+}
+
+static void
+reachable_objects_from_callback(VALUE obj)
+{
+    rb_ractor_t *cr = GET_RACTOR();
+    cr->mfd->mark_func(obj, cr->mfd->data);
+}
+
+void
+rb_objspace_reachable_objects_from(VALUE obj, void (func)(VALUE, void *), void *data)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+
+    if (during_gc) rb_bug("rb_objspace_reachable_objects_from() is not supported while during_gc == true");
+
+    if (is_markable_object(objspace, obj)) {
+        rb_ractor_t *cr = GET_RACTOR();
+        struct gc_mark_func_data_struct mfd = {
+            .mark_func = func,
+            .data = data,
+        }, *prev_mfd = cr->mfd;
+
+        cr->mfd = &mfd;
+	gc_mark_children(objspace, obj);
+        cr->mfd = prev_mfd;
+    }
+}
+
+struct root_objects_data {
+    const char *category;
+    void (*func)(const char *category, VALUE, void *);
+    void *data;
+};
+
+static void
+root_objects_from(VALUE obj, void *ptr)
+{
+    const struct root_objects_data *data = (struct root_objects_data *)ptr;
+    (*data->func)(data->category, obj, data->data);
+}
+
+void
+rb_objspace_reachable_objects_from_root(void (func)(const char *category, VALUE, void *), void *passing_data)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    objspace_reachable_objects_from_root(objspace, func, passing_data);
+}
+
+static void
+objspace_reachable_objects_from_root(rb_objspace_t *objspace, void (func)(const char *category, VALUE, void *), void *passing_data)
+{
+    if (during_gc) rb_bug("objspace_reachable_objects_from_root() is not supported while during_gc == true");
+
+    rb_ractor_t *cr = GET_RACTOR();
+    struct root_objects_data data = {
+        .func = func,
+        .data = passing_data,
+    };
+    struct gc_mark_func_data_struct mfd = {
+        .mark_func = root_objects_from,
+        .data = &data,
+    }, *prev_mfd = cr->mfd;
+
+    cr->mfd = &mfd;
+    gc_mark_roots(objspace, &data.category);
+    cr->mfd = prev_mfd;
+}
+
+/*
+  ------------------------ Extended allocator ------------------------
+*/
+
+struct gc_raise_tag {
+    VALUE exc;
+    const char *fmt;
+    va_list *ap;
+};
+
+static void *
+gc_vraise(void *ptr)
+{
+    struct gc_raise_tag *argv = ptr;
+    rb_vraise(argv->exc, argv->fmt, *argv->ap);
+    UNREACHABLE_RETURN(NULL);
+}
+
+static void
+gc_raise(VALUE exc, const char *fmt, ...)
+{
+    va_list ap;
+    va_start(ap, fmt);
+    struct gc_raise_tag argv = {
+        exc, fmt, &ap,
+    };
+
+    if (ruby_thread_has_gvl_p()) {
+        gc_vraise(&argv);
+        UNREACHABLE;
+    }
+    else if (ruby_native_thread_p()) {
+        rb_thread_call_with_gvl(gc_vraise, &argv);
+        UNREACHABLE;
+    }
+    else {
+        /* Not in a ruby thread */
+        fprintf(stderr, "%s", "[FATAL] ");
+        vfprintf(stderr, fmt, ap);
+    }
+
+    va_end(ap);
+    abort();
+}
+
+static void objspace_xfree(rb_objspace_t *objspace, void *ptr, size_t size);
+
+static void
+negative_size_allocation_error(const char *msg)
+{
+    gc_raise(rb_eNoMemError, "%s", msg);
+}
+
+static void *
+ruby_memerror_body(void *dummy)
+{
+    rb_memerror();
+    return 0;
+}
+
+NORETURN(static void ruby_memerror(void));
+RBIMPL_ATTR_MAYBE_UNUSED()
+static void
+ruby_memerror(void)
+{
+    if (ruby_thread_has_gvl_p()) {
+	rb_memerror();
+    }
+    else {
+	if (ruby_native_thread_p()) {
+	    rb_thread_call_with_gvl(ruby_memerror_body, 0);
+	}
+	else {
+	    /* no ruby thread */
+	    fprintf(stderr, "[FATAL] failed to allocate memory\n");
+	}
+    }
+    exit(EXIT_FAILURE);
+}
+
+void
+rb_memerror(void)
+{
+    rb_execution_context_t *ec = GET_EC();
+    rb_objspace_t *objspace = rb_objspace_of(rb_ec_vm_ptr(ec));
+    VALUE exc;
+
+    if (0) {
+        // Print out pid, sleep, so you can attach debugger to see what went wrong:
+        fprintf(stderr, "rb_memerror pid=%"PRI_PIDT_PREFIX"d\n", getpid());
+        sleep(60);
+    }
+
+    if (during_gc) {
+        // TODO: OMG!! How to implement it?
+        gc_exit(objspace, gc_enter_event_rb_memerror, NULL);
+    }
+
+    exc = nomem_error;
+    if (!exc ||
+	rb_ec_raised_p(ec, RAISED_NOMEMORY)) {
+	fprintf(stderr, "[FATAL] failed to allocate memory\n");
+	exit(EXIT_FAILURE);
+    }
+    if (rb_ec_raised_p(ec, RAISED_NOMEMORY)) {
+	rb_ec_raised_clear(ec);
+    }
+    else {
+	rb_ec_raised_set(ec, RAISED_NOMEMORY);
+	exc = ruby_vm_special_exception_copy(exc);
+    }
+    ec->errinfo = exc;
+    EC_JUMP_TAG(ec, TAG_RAISE);
+}
+
+void *
+rb_aligned_malloc(size_t alignment, size_t size)
+{
+    void *res;
+
+#if defined __MINGW32__
+    res = __mingw_aligned_malloc(size, alignment);
+#elif defined _WIN32
+    void *_aligned_malloc(size_t, size_t);
+    res = _aligned_malloc(size, alignment);
+#else
+    if (USE_MMAP_ALIGNED_ALLOC) {
+        GC_ASSERT(alignment % sysconf(_SC_PAGE_SIZE) == 0);
+
+        char *ptr = mmap(NULL, alignment + size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
+        if (ptr == MAP_FAILED) {
+            return NULL;
+        }
+
+        char *aligned = ptr + alignment;
+        aligned -= ((VALUE)aligned & (alignment - 1));
+        GC_ASSERT(aligned > ptr);
+        GC_ASSERT(aligned <= ptr + alignment);
+
+        size_t start_out_of_range_size = aligned - ptr;
+        GC_ASSERT(start_out_of_range_size % sysconf(_SC_PAGE_SIZE) == 0);
+        if (start_out_of_range_size > 0) {
+            if (munmap(ptr, start_out_of_range_size)) {
+                rb_bug("rb_aligned_malloc: munmap failed for start");
+            }
+        }
+
+        size_t end_out_of_range_size = alignment - start_out_of_range_size;
+        GC_ASSERT(end_out_of_range_size % sysconf(_SC_PAGE_SIZE) == 0);
+        if (end_out_of_range_size > 0) {
+            if (munmap(aligned + size, end_out_of_range_size)) {
+                rb_bug("rb_aligned_malloc: munmap failed for end");
+            }
+        }
+
+        res = (void *)aligned;
+    }
+    else {
+# if defined(HAVE_POSIX_MEMALIGN)
+        if (posix_memalign(&res, alignment, size) != 0) {
+            return NULL;
+        }
+# elif defined(HAVE_MEMALIGN)
+        res = memalign(alignment, size);
+# else
+        char* aligned;
+        res = malloc(alignment + size + sizeof(void*));
+        aligned = (char*)res + alignment + sizeof(void*);
+        aligned -= ((VALUE)aligned & (alignment - 1));
+        ((void**)aligned)[-1] = res;
+        res = (void*)aligned;
+# endif
+    }
+#endif
+
+    /* alignment must be a power of 2 */
+    GC_ASSERT(((alignment - 1) & alignment) == 0);
+    GC_ASSERT(alignment % sizeof(void*) == 0);
+    return res;
+}
+
+static void
+rb_aligned_free(void *ptr, size_t size)
+{
+#if defined __MINGW32__
+    __mingw_aligned_free(ptr);
+#elif defined _WIN32
+    _aligned_free(ptr);
+#else
+    if (USE_MMAP_ALIGNED_ALLOC) {
+        GC_ASSERT(size % sysconf(_SC_PAGE_SIZE) == 0);
+        if (munmap(ptr, size)) {
+            rb_bug("rb_aligned_free: munmap failed");
+        }
+    }
+    else {
+# if defined(HAVE_POSIX_MEMALIGN) || defined(HAVE_MEMALIGN)
+        free(ptr);
+# else
+        free(((void**)ptr)[-1]);
+# endif
+    }
+#endif
+}
+
+static inline size_t
+objspace_malloc_size(rb_objspace_t *objspace, void *ptr, size_t hint)
+{
+#ifdef HAVE_MALLOC_USABLE_SIZE
+    return malloc_usable_size(ptr);
+#else
+    return hint;
+#endif
+}
+
+enum memop_type {
+    MEMOP_TYPE_MALLOC  = 0,
+    MEMOP_TYPE_FREE,
+    MEMOP_TYPE_REALLOC
+};
+
+static inline void
+atomic_sub_nounderflow(size_t *var, size_t sub)
+{
+    if (sub == 0) return;
+
+    while (1) {
+	size_t val = *var;
+	if (val < sub) sub = val;
+	if (ATOMIC_SIZE_CAS(*var, val, val-sub) == val) break;
+    }
+}
+
+static void
+objspace_malloc_gc_stress(rb_objspace_t *objspace)
+{
+    if (ruby_gc_stressful && ruby_native_thread_p()) {
+        int reason = GPR_FLAG_IMMEDIATE_MARK | GPR_FLAG_IMMEDIATE_SWEEP |
+                                     GPR_FLAG_STRESS | GPR_FLAG_MALLOC;
+
+        if (gc_stress_full_mark_after_malloc_p()) {
+            reason |= GPR_FLAG_FULL_MARK;
+        }
+        garbage_collect_with_gvl(objspace, reason);
+    }
+}
+
+static void
+objspace_malloc_increase(rb_objspace_t *objspace, void *mem, size_t new_size, size_t old_size, enum memop_type type)
+{
+    if (new_size > old_size) {
+	ATOMIC_SIZE_ADD(malloc_increase, new_size - old_size);
+        if (collect_gc_stats) {
+            ATOMIC_SIZE_ADD(objspace->profile.total_mallocs, 1);
+            ATOMIC_SIZE_ADD(objspace->profile.total_malloced_bytes, new_size - old_size);
+        }
+#if RGENGC_ESTIMATE_OLDMALLOC
+	ATOMIC_SIZE_ADD(objspace->rgengc.oldmalloc_increase, new_size - old_size);
+#endif
+    }
+    else {
+	atomic_sub_nounderflow(&malloc_increase, old_size - new_size);
+#if RGENGC_ESTIMATE_OLDMALLOC
+	atomic_sub_nounderflow(&objspace->rgengc.oldmalloc_increase, old_size - new_size);
+#endif
+    }
+
+    if (type == MEMOP_TYPE_MALLOC) {
+      retry:
+	if (malloc_increase > malloc_limit && ruby_native_thread_p() && !dont_gc_val()) {
+	    if (ruby_thread_has_gvl_p() && is_lazy_sweeping(heap_eden)) {
+		gc_rest(objspace); /* gc_rest can reduce malloc_increase */
+		goto retry;
+	    }
+	    garbage_collect_with_gvl(objspace, GPR_FLAG_MALLOC);
+	}
+    }
+
+#if MALLOC_ALLOCATED_SIZE
+    if (new_size >= old_size) {
+	ATOMIC_SIZE_ADD(objspace->malloc_params.allocated_size, new_size - old_size);
+    }
+    else {
+	size_t dec_size = old_size - new_size;
+	size_t allocated_size = objspace->malloc_params.allocated_size;
+
+#if MALLOC_ALLOCATED_SIZE_CHECK
+	if (allocated_size < dec_size) {
+	    rb_bug("objspace_malloc_increase: underflow malloc_params.allocated_size.");
+	}
+#endif
+	atomic_sub_nounderflow(&objspace->malloc_params.allocated_size, dec_size);
+    }
+
+    if (0) fprintf(stderr, "increase - ptr: %p, type: %s, new_size: %"PRIdSIZE", old_size: %"PRIdSIZE"\n",
+		   mem,
+		   type == MEMOP_TYPE_MALLOC  ? "malloc" :
+		   type == MEMOP_TYPE_FREE    ? "free  " :
+		   type == MEMOP_TYPE_REALLOC ? "realloc": "error",
+		   new_size, old_size);
+
+    switch (type) {
+      case MEMOP_TYPE_MALLOC:
+	ATOMIC_SIZE_INC(objspace->malloc_params.allocations);
+	break;
+      case MEMOP_TYPE_FREE:
+	{
+	    size_t allocations = objspace->malloc_params.allocations;
+	    if (allocations > 0) {
+		atomic_sub_nounderflow(&objspace->malloc_params.allocations, 1);
+	    }
+#if MALLOC_ALLOCATED_SIZE_CHECK
+	    else {
+		GC_ASSERT(objspace->malloc_params.allocations > 0);
+	    }
+#endif
+	}
+	break;
+      case MEMOP_TYPE_REALLOC: /* ignore */ break;
+    }
+#endif
+}
+
+struct malloc_obj_info { /* 4 words */
+    size_t size;
+#if USE_GC_MALLOC_OBJ_INFO_DETAILS
+    size_t gen;
+    const char *file;
+    size_t line;
+#endif
+};
+
+#if USE_GC_MALLOC_OBJ_INFO_DETAILS
+const char *ruby_malloc_info_file;
+int ruby_malloc_info_line;
+#endif
+
+static inline size_t
+objspace_malloc_prepare(rb_objspace_t *objspace, size_t size)
+{
+    if (size == 0) size = 1;
+
+#if CALC_EXACT_MALLOC_SIZE
+    size += sizeof(struct malloc_obj_info);
+#endif
+
+    return size;
+}
+
+static inline void *
+objspace_malloc_fixup(rb_objspace_t *objspace, void *mem, size_t size)
+{
+    size = objspace_malloc_size(objspace, mem, size);
+    objspace_malloc_increase(objspace, mem, size, 0, MEMOP_TYPE_MALLOC);
+
+#if CALC_EXACT_MALLOC_SIZE
+    {
+        struct malloc_obj_info *info = mem;
+        info->size = size;
+#if USE_GC_MALLOC_OBJ_INFO_DETAILS
+        info->gen = objspace->profile.count;
+        info->file = ruby_malloc_info_file;
+        info->line = info->file ? ruby_malloc_info_line : 0;
+#endif
+        mem = info + 1;
+    }
+#endif
+
+    return mem;
+}
+
+#if defined(__GNUC__) && RUBY_DEBUG
+#define RB_BUG_INSTEAD_OF_RB_MEMERROR
+#endif
+
+#ifdef RB_BUG_INSTEAD_OF_RB_MEMERROR
+#define TRY_WITH_GC(siz, expr) do {                          \
+        const gc_profile_record_flag gpr =                   \
+            GPR_FLAG_FULL_MARK           |                   \
+            GPR_FLAG_IMMEDIATE_MARK      |                   \
+            GPR_FLAG_IMMEDIATE_SWEEP     |                   \
+            GPR_FLAG_MALLOC;                                 \
+        objspace_malloc_gc_stress(objspace);                 \
+                                                             \
+        if (LIKELY((expr))) {                                \
+            /* Success on 1st try */                         \
+        }                                                    \
+        else if (!garbage_collect_with_gvl(objspace, gpr)) { \
+            /* @shyouhei thinks this doesn't happen */       \
+            rb_bug("TRY_WITH_GC: could not GC");             \
+        }                                                    \
+        else if ((expr)) {                                   \
+            /* Success on 2nd try */                         \
+        }                                                    \
+        else {                                               \
+            rb_bug("TRY_WITH_GC: could not allocate:"        \
+                   "%"PRIdSIZE" bytes for %s",               \
+                   siz, # expr);                             \
+        }                                                    \
+    } while (0)
+#else
+#define TRY_WITH_GC(siz, alloc) do { \
+        objspace_malloc_gc_stress(objspace); \
+	if (!(alloc) && \
+            (!garbage_collect_with_gvl(objspace, GPR_FLAG_FULL_MARK | \
+                GPR_FLAG_IMMEDIATE_MARK | GPR_FLAG_IMMEDIATE_SWEEP | \
+                GPR_FLAG_MALLOC) || \
+	     !(alloc))) { \
+	    ruby_memerror(); \
+	} \
+    } while (0)
+#endif
+
+/* these shouldn't be called directly.
+ * objspace_* functions do not check allocation size.
+ */
+static void *
+objspace_xmalloc0(rb_objspace_t *objspace, size_t size)
+{
+    void *mem;
+
+    size = objspace_malloc_prepare(objspace, size);
+    TRY_WITH_GC(size, mem = malloc(size));
+    RB_DEBUG_COUNTER_INC(heap_xmalloc);
+    return objspace_malloc_fixup(objspace, mem, size);
+}
+
+static inline size_t
+xmalloc2_size(const size_t count, const size_t elsize)
+{
+    return size_mul_or_raise(count, elsize, rb_eArgError);
+}
+
+static void *
+objspace_xrealloc(rb_objspace_t *objspace, void *ptr, size_t new_size, size_t old_size)
+{
+    void *mem;
+
+    if (!ptr) return objspace_xmalloc0(objspace, new_size);
+
+    /*
+     * The behavior of realloc(ptr, 0) is implementation defined.
+     * Therefore we don't use realloc(ptr, 0) for portability reason.
+     * see http://www.open-std.org/jtc1/sc22/wg14/www/docs/dr_400.htm
+     */
+    if (new_size == 0) {
+        if ((mem = objspace_xmalloc0(objspace, 0)) != NULL) {
+            /*
+             * - OpenBSD's malloc(3) man page says that when 0 is passed, it
+             *   returns a non-NULL pointer to an access-protected memory page.
+             *   The returned pointer cannot be read / written at all, but
+             *   still be a valid argument of free().
+             *
+             *   https://man.openbsd.org/malloc.3
+             *
+             * - Linux's malloc(3) man page says that it _might_ perhaps return
+             *   a non-NULL pointer when its argument is 0.  That return value
+             *   is safe (and is expected) to be passed to free().
+             *
+             *   http://man7.org/linux/man-pages/man3/malloc.3.html
+             *
+             * - As I read the implementation jemalloc's malloc() returns fully
+             *   normal 16 bytes memory region when its argument is 0.
+             *
+             * - As I read the implementation musl libc's malloc() returns
+             *   fully normal 32 bytes memory region when its argument is 0.
+             *
+             * - Other malloc implementations can also return non-NULL.
+             */
+            objspace_xfree(objspace, ptr, old_size);
+            return mem;
+        }
+        else {
+            /*
+             * It is dangerous to return NULL here, because that could lead to
+             * RCE.  Fallback to 1 byte instead of zero.
+             *
+             * https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-11932
+             */
+            new_size = 1;
+        }
+    }
+
+#if CALC_EXACT_MALLOC_SIZE
+    {
+        struct malloc_obj_info *info = (struct malloc_obj_info *)ptr - 1;
+        new_size += sizeof(struct malloc_obj_info);
+        ptr = info;
+        old_size = info->size;
+    }
+#endif
+
+    old_size = objspace_malloc_size(objspace, ptr, old_size);
+    TRY_WITH_GC(new_size, mem = realloc(ptr, new_size));
+    new_size = objspace_malloc_size(objspace, mem, new_size);
+
+#if CALC_EXACT_MALLOC_SIZE
+    {
+        struct malloc_obj_info *info = mem;
+        info->size = new_size;
+        mem = info + 1;
+    }
+#endif
+
+    objspace_malloc_increase(objspace, mem, new_size, old_size, MEMOP_TYPE_REALLOC);
+
+    RB_DEBUG_COUNTER_INC(heap_xrealloc);
+    return mem;
+}
+
+#if CALC_EXACT_MALLOC_SIZE && USE_GC_MALLOC_OBJ_INFO_DETAILS
+
+#define MALLOC_INFO_GEN_SIZE 100
+#define MALLOC_INFO_SIZE_SIZE 10
+static size_t malloc_info_gen_cnt[MALLOC_INFO_GEN_SIZE];
+static size_t malloc_info_gen_size[MALLOC_INFO_GEN_SIZE];
+static size_t malloc_info_size[MALLOC_INFO_SIZE_SIZE+1];
+static st_table *malloc_info_file_table;
+
+static int
+mmalloc_info_file_i(st_data_t key, st_data_t val, st_data_t dmy)
+{
+    const char *file = (void *)key;
+    const size_t *data = (void *)val;
+
+    fprintf(stderr, "%s\t%"PRIdSIZE"\t%"PRIdSIZE"\n", file, data[0], data[1]);
+
+    return ST_CONTINUE;
+}
+
+__attribute__((destructor))
+void
+rb_malloc_info_show_results(void)
+{
+    int i;
+
+    fprintf(stderr, "* malloc_info gen statistics\n");
+    for (i=0; i<MALLOC_INFO_GEN_SIZE; i++) {
+        if (i == MALLOC_INFO_GEN_SIZE-1) {
+            fprintf(stderr, "more\t%"PRIdSIZE"\t%"PRIdSIZE"\n", malloc_info_gen_cnt[i], malloc_info_gen_size[i]);
+        }
+        else {
+            fprintf(stderr, "%d\t%"PRIdSIZE"\t%"PRIdSIZE"\n", i, malloc_info_gen_cnt[i], malloc_info_gen_size[i]);
+        }
+    }
+
+    fprintf(stderr, "* malloc_info size statistics\n");
+    for (i=0; i<MALLOC_INFO_SIZE_SIZE; i++) {
+        int s = 16 << i;
+        fprintf(stderr, "%d\t%"PRIdSIZE"\n", s, malloc_info_size[i]);
+    }
+    fprintf(stderr, "more\t%"PRIdSIZE"\n", malloc_info_size[i]);
+
+    if (malloc_info_file_table) {
+        fprintf(stderr, "* malloc_info file statistics\n");
+        st_foreach(malloc_info_file_table, mmalloc_info_file_i, 0);
+    }
+}
+#else
+void
+rb_malloc_info_show_results(void)
+{
+}
+#endif
+
+static void
+objspace_xfree(rb_objspace_t *objspace, void *ptr, size_t old_size)
+{
+    if (!ptr) {
+        /*
+         * ISO/IEC 9899 says "If ptr is a null pointer, no action occurs" since
+         * its first version.  We would better follow.
+         */
+        return;
+    }
+#if CALC_EXACT_MALLOC_SIZE
+    struct malloc_obj_info *info = (struct malloc_obj_info *)ptr - 1;
+    ptr = info;
+    old_size = info->size;
+
+#if USE_GC_MALLOC_OBJ_INFO_DETAILS
+    {
+        int gen = (int)(objspace->profile.count - info->gen);
+        int gen_index = gen >= MALLOC_INFO_GEN_SIZE ? MALLOC_INFO_GEN_SIZE-1 : gen;
+        int i;
+
+        malloc_info_gen_cnt[gen_index]++;
+        malloc_info_gen_size[gen_index] += info->size;
+
+        for (i=0; i<MALLOC_INFO_SIZE_SIZE; i++) {
+            size_t s = 16 << i;
+            if (info->size <= s) {
+                malloc_info_size[i]++;
+                goto found;
+            }
+        }
+        malloc_info_size[i]++;
+      found:;
+
+        {
+            st_data_t key = (st_data_t)info->file, d;
+            size_t *data;
+
+            if (malloc_info_file_table == NULL) {
+                malloc_info_file_table = st_init_numtable_with_size(1024);
+            }
+            if (st_lookup(malloc_info_file_table, key, &d)) {
+                /* hit */
+                data = (size_t *)d;
+            }
+            else {
+                data = malloc(xmalloc2_size(2, sizeof(size_t)));
+                if (data == NULL) rb_bug("objspace_xfree: can not allocate memory");
+                data[0] = data[1] = 0;
+                st_insert(malloc_info_file_table, key, (st_data_t)data);
+            }
+            data[0] ++;
+            data[1] += info->size;
+        };
+        if (0 && gen >= 2) {         /* verbose output */
+            if (info->file) {
+                fprintf(stderr, "free - size:%"PRIdSIZE", gen:%d, pos: %s:%"PRIdSIZE"\n",
+                        info->size, gen, info->file, info->line);
+            }
+            else {
+                fprintf(stderr, "free - size:%"PRIdSIZE", gen:%d\n",
+                        info->size, gen);
+            }
+        }
+    }
+#endif
+#endif
+    old_size = objspace_malloc_size(objspace, ptr, old_size);
+
+    free(ptr);
+    RB_DEBUG_COUNTER_INC(heap_xfree);
+
+    objspace_malloc_increase(objspace, ptr, 0, old_size, MEMOP_TYPE_FREE);
+}
+
+static void *
+ruby_xmalloc0(size_t size)
+{
+    return objspace_xmalloc0(&rb_objspace, size);
+}
+
+void *
+ruby_xmalloc_body(size_t size)
+{
+    if ((ssize_t)size < 0) {
+	negative_size_allocation_error("too large allocation size");
+    }
+    return ruby_xmalloc0(size);
+}
+
+void
+ruby_malloc_size_overflow(size_t count, size_t elsize)
+{
+    rb_raise(rb_eArgError,
+	     "malloc: possible integer overflow (%"PRIuSIZE"*%"PRIuSIZE")",
+	     count, elsize);
+}
+
+void *
+ruby_xmalloc2_body(size_t n, size_t size)
+{
+    return objspace_xmalloc0(&rb_objspace, xmalloc2_size(n, size));
+}
+
+static void *
+objspace_xcalloc(rb_objspace_t *objspace, size_t size)
+{
+    void *mem;
+
+    size = objspace_malloc_prepare(objspace, size);
+    TRY_WITH_GC(size, mem = calloc1(size));
+    return objspace_malloc_fixup(objspace, mem, size);
+}
+
+void *
+ruby_xcalloc_body(size_t n, size_t size)
+{
+    return objspace_xcalloc(&rb_objspace, xmalloc2_size(n, size));
+}
+
+#ifdef ruby_sized_xrealloc
+#undef ruby_sized_xrealloc
+#endif
+void *
+ruby_sized_xrealloc(void *ptr, size_t new_size, size_t old_size)
+{
+    if ((ssize_t)new_size < 0) {
+	negative_size_allocation_error("too large allocation size");
+    }
+
+    return objspace_xrealloc(&rb_objspace, ptr, new_size, old_size);
+}
+
+void *
+ruby_xrealloc_body(void *ptr, size_t new_size)
+{
+    return ruby_sized_xrealloc(ptr, new_size, 0);
+}
+
+#ifdef ruby_sized_xrealloc2
+#undef ruby_sized_xrealloc2
+#endif
+void *
+ruby_sized_xrealloc2(void *ptr, size_t n, size_t size, size_t old_n)
+{
+    size_t len = xmalloc2_size(n, size);
+    return objspace_xrealloc(&rb_objspace, ptr, len, old_n * size);
+}
+
+void *
+ruby_xrealloc2_body(void *ptr, size_t n, size_t size)
+{
+    return ruby_sized_xrealloc2(ptr, n, size, 0);
+}
+
+#ifdef ruby_sized_xfree
+#undef ruby_sized_xfree
+#endif
+void
+ruby_sized_xfree(void *x, size_t size)
+{
+    if (x) {
+	objspace_xfree(&rb_objspace, x, size);
+    }
+}
+
+void
+ruby_xfree(void *x)
+{
+    ruby_sized_xfree(x, 0);
+}
+
+void *
+rb_xmalloc_mul_add(size_t x, size_t y, size_t z) /* x * y + z */
+{
+    size_t w = size_mul_add_or_raise(x, y, z, rb_eArgError);
+    return ruby_xmalloc(w);
+}
+
+void *
+rb_xrealloc_mul_add(const void *p, size_t x, size_t y, size_t z) /* x * y + z */
+{
+    size_t w = size_mul_add_or_raise(x, y, z, rb_eArgError);
+    return ruby_xrealloc((void *)p, w);
+}
+
+void *
+rb_xmalloc_mul_add_mul(size_t x, size_t y, size_t z, size_t w) /* x * y + z * w */
+{
+    size_t u = size_mul_add_mul_or_raise(x, y, z, w, rb_eArgError);
+    return ruby_xmalloc(u);
+}
+
+void *
+rb_xcalloc_mul_add_mul(size_t x, size_t y, size_t z, size_t w) /* x * y + z * w */
+{
+    size_t u = size_mul_add_mul_or_raise(x, y, z, w, rb_eArgError);
+    return ruby_xcalloc(u, 1);
+}
+
+/* Mimic ruby_xmalloc, but need not rb_objspace.
+ * should return pointer suitable for ruby_xfree
+ */
+void *
+ruby_mimmalloc(size_t size)
+{
+    void *mem;
+#if CALC_EXACT_MALLOC_SIZE
+    size += sizeof(struct malloc_obj_info);
+#endif
+    mem = malloc(size);
+#if CALC_EXACT_MALLOC_SIZE
+    if (!mem) {
+        return NULL;
+    }
+    else
+    /* set 0 for consistency of allocated_size/allocations */
+    {
+        struct malloc_obj_info *info = mem;
+        info->size = 0;
+#if USE_GC_MALLOC_OBJ_INFO_DETAILS
+        info->gen = 0;
+        info->file = NULL;
+        info->line = 0;
+#endif
+        mem = info + 1;
+    }
+#endif
+    return mem;
+}
+
+void
+ruby_mimfree(void *ptr)
+{
+#if CALC_EXACT_MALLOC_SIZE
+    struct malloc_obj_info *info = (struct malloc_obj_info *)ptr - 1;
+    ptr = info;
+#endif
+    free(ptr);
+}
+
+void *
+rb_alloc_tmp_buffer_with_count(volatile VALUE *store, size_t size, size_t cnt)
+{
+    void *ptr;
+    VALUE imemo;
+    rb_imemo_tmpbuf_t *tmpbuf;
+
+    /* Keep the order; allocate an empty imemo first then xmalloc, to
+     * get rid of potential memory leak */
+    imemo = rb_imemo_tmpbuf_auto_free_maybe_mark_buffer(NULL, 0);
+    *store = imemo;
+    ptr = ruby_xmalloc0(size);
+    tmpbuf = (rb_imemo_tmpbuf_t *)imemo;
+    tmpbuf->ptr = ptr;
+    tmpbuf->cnt = cnt;
+    return ptr;
+}
+
+void *
+rb_alloc_tmp_buffer(volatile VALUE *store, long len)
+{
+    long cnt;
+
+    if (len < 0 || (cnt = (long)roomof(len, sizeof(VALUE))) < 0) {
+	rb_raise(rb_eArgError, "negative buffer size (or size too big)");
+    }
+
+    return rb_alloc_tmp_buffer_with_count(store, len, cnt);
+}
+
+void
+rb_free_tmp_buffer(volatile VALUE *store)
+{
+    rb_imemo_tmpbuf_t *s = (rb_imemo_tmpbuf_t*)ATOMIC_VALUE_EXCHANGE(*store, 0);
+    if (s) {
+	void *ptr = ATOMIC_PTR_EXCHANGE(s->ptr, 0);
+	s->cnt = 0;
+	ruby_xfree(ptr);
+    }
+}
+
+#if MALLOC_ALLOCATED_SIZE
+/*
+ *  call-seq:
+ *     GC.malloc_allocated_size -> Integer
+ *
+ *  Returns the size of memory allocated by malloc().
+ *
+ *  Only available if ruby was built with +CALC_EXACT_MALLOC_SIZE+.
+ */
+
+static VALUE
+gc_malloc_allocated_size(VALUE self)
+{
+    return UINT2NUM(rb_objspace.malloc_params.allocated_size);
+}
+
+size_t
+rb_gc_malloc_allocated_size(void)
+{
+    return rb_objspace.malloc_params.allocated_size;
+}
+
+/*
+ *  call-seq:
+ *     GC.malloc_allocations -> Integer
+ *
+ *  Returns the number of malloc() allocations.
+ *
+ *  Only available if ruby was built with +CALC_EXACT_MALLOC_SIZE+.
+ */
+
+static VALUE
+gc_malloc_allocations(VALUE self)
+{
+    return UINT2NUM(rb_objspace.malloc_params.allocations);
+}
+
+size_t
+rb_gc_malloc_allocations(void)
+{
+    return rb_objspace.malloc_params.allocations;
+}
+#endif
+
+void
+rb_gc_adjust_memory_usage(ssize_t diff)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    if (diff > 0) {
+	objspace_malloc_increase(objspace, 0, diff, 0, MEMOP_TYPE_REALLOC);
+    }
+    else if (diff < 0) {
+	objspace_malloc_increase(objspace, 0, 0, -diff, MEMOP_TYPE_REALLOC);
+    }
+}
+
+/*
+  ------------------------------ WeakMap ------------------------------
+*/
+
+struct weakmap {
+    st_table *obj2wmap;		/* obj -> [ref,...] */
+    st_table *wmap2obj;		/* ref -> obj */
+    VALUE final;
+};
+
+#define WMAP_DELETE_DEAD_OBJECT_IN_MARK 0
+
+#if WMAP_DELETE_DEAD_OBJECT_IN_MARK
+static int
+wmap_mark_map(st_data_t key, st_data_t val, st_data_t arg)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)arg;
+    VALUE obj = (VALUE)val;
+    if (!is_live_object(objspace, obj)) return ST_DELETE;
+    return ST_CONTINUE;
+}
+#endif
+
+static void
+wmap_compact(void *ptr)
+{
+    struct weakmap *w = ptr;
+    if (w->wmap2obj) rb_gc_update_tbl_refs(w->wmap2obj);
+    if (w->obj2wmap) rb_gc_update_tbl_refs(w->obj2wmap);
+    w->final = rb_gc_location(w->final);
+}
+
+static void
+wmap_mark(void *ptr)
+{
+    struct weakmap *w = ptr;
+#if WMAP_DELETE_DEAD_OBJECT_IN_MARK
+    if (w->obj2wmap) st_foreach(w->obj2wmap, wmap_mark_map, (st_data_t)&rb_objspace);
+#endif
+    rb_gc_mark_movable(w->final);
+}
+
+static int
+wmap_free_map(st_data_t key, st_data_t val, st_data_t arg)
+{
+    VALUE *ptr = (VALUE *)val;
+    ruby_sized_xfree(ptr, (ptr[0] + 1) * sizeof(VALUE));
+    return ST_CONTINUE;
+}
+
+static void
+wmap_free(void *ptr)
+{
+    struct weakmap *w = ptr;
+    st_foreach(w->obj2wmap, wmap_free_map, 0);
+    st_free_table(w->obj2wmap);
+    st_free_table(w->wmap2obj);
+}
+
+static int
+wmap_memsize_map(st_data_t key, st_data_t val, st_data_t arg)
+{
+    VALUE *ptr = (VALUE *)val;
+    *(size_t *)arg += (ptr[0] + 1) * sizeof(VALUE);
+    return ST_CONTINUE;
+}
+
+static size_t
+wmap_memsize(const void *ptr)
+{
+    size_t size;
+    const struct weakmap *w = ptr;
+    size = sizeof(*w);
+    size += st_memsize(w->obj2wmap);
+    size += st_memsize(w->wmap2obj);
+    st_foreach(w->obj2wmap, wmap_memsize_map, (st_data_t)&size);
+    return size;
+}
+
+static const rb_data_type_t weakmap_type = {
+    "weakmap",
+    {
+	wmap_mark,
+	wmap_free,
+	wmap_memsize,
+        wmap_compact,
+    },
+    0, 0, RUBY_TYPED_FREE_IMMEDIATELY
+};
+
+static VALUE wmap_finalize(RB_BLOCK_CALL_FUNC_ARGLIST(objid, self));
+
+static VALUE
+wmap_allocate(VALUE klass)
+{
+    struct weakmap *w;
+    VALUE obj = TypedData_Make_Struct(klass, struct weakmap, &weakmap_type, w);
+    w->obj2wmap = rb_init_identtable();
+    w->wmap2obj = rb_init_identtable();
+    w->final = rb_func_lambda_new(wmap_finalize, obj, 1, 1);
+    return obj;
+}
+
+static int
+wmap_live_p(rb_objspace_t *objspace, VALUE obj)
+{
+    if (SPECIAL_CONST_P(obj)) return TRUE;
+    if (is_pointer_to_heap(objspace, (void *)obj)) {
+        void *poisoned = asan_unpoison_object_temporary(obj);
+
+        enum ruby_value_type t = BUILTIN_TYPE(obj);
+        int ret = (!(t == T_NONE || t >= T_FIXNUM || t == T_ICLASS) &&
+                   is_live_object(objspace, obj));
+
+        if (poisoned) {
+            asan_poison_object(obj);
+        }
+
+        return ret;
+    }
+    return TRUE;
+}
+
+static int
+wmap_final_func(st_data_t *key, st_data_t *value, st_data_t arg, int existing)
+{
+    VALUE wmap, *ptr, size, i, j;
+    if (!existing) return ST_STOP;
+    wmap = (VALUE)arg, ptr = (VALUE *)*value;
+    for (i = j = 1, size = ptr[0]; i <= size; ++i) {
+	if (ptr[i] != wmap) {
+	    ptr[j++] = ptr[i];
+	}
+    }
+    if (j == 1) {
+	ruby_sized_xfree(ptr, i * sizeof(VALUE));
+	return ST_DELETE;
+    }
+    if (j < i) {
+        SIZED_REALLOC_N(ptr, VALUE, j + 1, i);
+	ptr[0] = j;
+	*value = (st_data_t)ptr;
+    }
+    return ST_CONTINUE;
+}
+
+/* :nodoc: */
+static VALUE
+wmap_finalize(RB_BLOCK_CALL_FUNC_ARGLIST(objid, self))
+{
+    st_data_t orig, wmap, data;
+    VALUE obj, *rids, i, size;
+    struct weakmap *w;
+
+    TypedData_Get_Struct(self, struct weakmap, &weakmap_type, w);
+    /* Get reference from object id. */
+    if ((obj = id2ref_obj_tbl(&rb_objspace, objid)) == Qundef) {
+        rb_bug("wmap_finalize: objid is not found.");
+    }
+
+    /* obj is original referenced object and/or weak reference. */
+    orig = (st_data_t)obj;
+    if (st_delete(w->obj2wmap, &orig, &data)) {
+	rids = (VALUE *)data;
+	size = *rids++;
+	for (i = 0; i < size; ++i) {
+	    wmap = (st_data_t)rids[i];
+	    st_delete(w->wmap2obj, &wmap, NULL);
+	}
+	ruby_sized_xfree((VALUE *)data, (size + 1) * sizeof(VALUE));
+    }
+
+    wmap = (st_data_t)obj;
+    if (st_delete(w->wmap2obj, &wmap, &orig)) {
+	wmap = (st_data_t)obj;
+	st_update(w->obj2wmap, orig, wmap_final_func, wmap);
+    }
+    return self;
+}
+
+struct wmap_iter_arg {
+    rb_objspace_t *objspace;
+    VALUE value;
+};
+
+static VALUE
+wmap_inspect_append(rb_objspace_t *objspace, VALUE str, VALUE obj)
+{
+    if (SPECIAL_CONST_P(obj)) {
+        return rb_str_append(str, rb_inspect(obj));
+    }
+    else if (wmap_live_p(objspace, obj)) {
+        return rb_str_append(str, rb_any_to_s(obj));
+    }
+    else {
+        return rb_str_catf(str, "#<collected:%p>", (void*)obj);
+    }
+}
+
+static int
+wmap_inspect_i(st_data_t key, st_data_t val, st_data_t arg)
+{
+    struct wmap_iter_arg *argp = (struct wmap_iter_arg *)arg;
+    rb_objspace_t *objspace = argp->objspace;
+    VALUE str = argp->value;
+    VALUE k = (VALUE)key, v = (VALUE)val;
+
+    if (RSTRING_PTR(str)[0] == '#') {
+	rb_str_cat2(str, ", ");
+    }
+    else {
+	rb_str_cat2(str, ": ");
+	RSTRING_PTR(str)[0] = '#';
+    }
+    wmap_inspect_append(objspace, str, k);
+    rb_str_cat2(str, " => ");
+    wmap_inspect_append(objspace, str, v);
+
+    return ST_CONTINUE;
+}
+
+static VALUE
+wmap_inspect(VALUE self)
+{
+    VALUE str;
+    VALUE c = rb_class_name(CLASS_OF(self));
+    struct weakmap *w;
+    struct wmap_iter_arg args;
+
+    TypedData_Get_Struct(self, struct weakmap, &weakmap_type, w);
+    str = rb_sprintf("-<%"PRIsVALUE":%p", c, (void *)self);
+    if (w->wmap2obj) {
+	args.objspace = &rb_objspace;
+	args.value = str;
+	st_foreach(w->wmap2obj, wmap_inspect_i, (st_data_t)&args);
+    }
+    RSTRING_PTR(str)[0] = '#';
+    rb_str_cat2(str, ">");
+    return str;
+}
+
+static int
+wmap_each_i(st_data_t key, st_data_t val, st_data_t arg)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)arg;
+    VALUE obj = (VALUE)val;
+    if (wmap_live_p(objspace, obj)) {
+	rb_yield_values(2, (VALUE)key, obj);
+    }
+    return ST_CONTINUE;
+}
+
+/* Iterates over keys and objects in a weakly referenced object */
+static VALUE
+wmap_each(VALUE self)
+{
+    struct weakmap *w;
+    rb_objspace_t *objspace = &rb_objspace;
+
+    TypedData_Get_Struct(self, struct weakmap, &weakmap_type, w);
+    st_foreach(w->wmap2obj, wmap_each_i, (st_data_t)objspace);
+    return self;
+}
+
+static int
+wmap_each_key_i(st_data_t key, st_data_t val, st_data_t arg)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)arg;
+    VALUE obj = (VALUE)val;
+    if (wmap_live_p(objspace, obj)) {
+	rb_yield((VALUE)key);
+    }
+    return ST_CONTINUE;
+}
+
+/* Iterates over keys and objects in a weakly referenced object */
+static VALUE
+wmap_each_key(VALUE self)
+{
+    struct weakmap *w;
+    rb_objspace_t *objspace = &rb_objspace;
+
+    TypedData_Get_Struct(self, struct weakmap, &weakmap_type, w);
+    st_foreach(w->wmap2obj, wmap_each_key_i, (st_data_t)objspace);
+    return self;
+}
+
+static int
+wmap_each_value_i(st_data_t key, st_data_t val, st_data_t arg)
+{
+    rb_objspace_t *objspace = (rb_objspace_t *)arg;
+    VALUE obj = (VALUE)val;
+    if (wmap_live_p(objspace, obj)) {
+	rb_yield(obj);
+    }
+    return ST_CONTINUE;
+}
+
+/* Iterates over keys and objects in a weakly referenced object */
+static VALUE
+wmap_each_value(VALUE self)
+{
+    struct weakmap *w;
+    rb_objspace_t *objspace = &rb_objspace;
+
+    TypedData_Get_Struct(self, struct weakmap, &weakmap_type, w);
+    st_foreach(w->wmap2obj, wmap_each_value_i, (st_data_t)objspace);
+    return self;
+}
+
+static int
+wmap_keys_i(st_data_t key, st_data_t val, st_data_t arg)
+{
+    struct wmap_iter_arg *argp = (struct wmap_iter_arg *)arg;
+    rb_objspace_t *objspace = argp->objspace;
+    VALUE ary = argp->value;
+    VALUE obj = (VALUE)val;
+    if (wmap_live_p(objspace, obj)) {
+	rb_ary_push(ary, (VALUE)key);
+    }
+    return ST_CONTINUE;
+}
+
+/* Iterates over keys and objects in a weakly referenced object */
+static VALUE
+wmap_keys(VALUE self)
+{
+    struct weakmap *w;
+    struct wmap_iter_arg args;
+
+    TypedData_Get_Struct(self, struct weakmap, &weakmap_type, w);
+    args.objspace = &rb_objspace;
+    args.value = rb_ary_new();
+    st_foreach(w->wmap2obj, wmap_keys_i, (st_data_t)&args);
+    return args.value;
+}
+
+static int
+wmap_values_i(st_data_t key, st_data_t val, st_data_t arg)
+{
+    struct wmap_iter_arg *argp = (struct wmap_iter_arg *)arg;
+    rb_objspace_t *objspace = argp->objspace;
+    VALUE ary = argp->value;
+    VALUE obj = (VALUE)val;
+    if (wmap_live_p(objspace, obj)) {
+	rb_ary_push(ary, obj);
+    }
+    return ST_CONTINUE;
+}
+
+/* Iterates over values and objects in a weakly referenced object */
+static VALUE
+wmap_values(VALUE self)
+{
+    struct weakmap *w;
+    struct wmap_iter_arg args;
+
+    TypedData_Get_Struct(self, struct weakmap, &weakmap_type, w);
+    args.objspace = &rb_objspace;
+    args.value = rb_ary_new();
+    st_foreach(w->wmap2obj, wmap_values_i, (st_data_t)&args);
+    return args.value;
+}
+
+static int
+wmap_aset_update(st_data_t *key, st_data_t *val, st_data_t arg, int existing)
+{
+    VALUE size, *ptr, *optr;
+    if (existing) {
+	size = (ptr = optr = (VALUE *)*val)[0];
+	++size;
+        SIZED_REALLOC_N(ptr, VALUE, size + 1, size);
+    }
+    else {
+	optr = 0;
+	size = 1;
+	ptr = ruby_xmalloc0(2 * sizeof(VALUE));
+    }
+    ptr[0] = size;
+    ptr[size] = (VALUE)arg;
+    if (ptr == optr) return ST_STOP;
+    *val = (st_data_t)ptr;
+    return ST_CONTINUE;
+}
+
+/* Creates a weak reference from the given key to the given value */
+static VALUE
+wmap_aset(VALUE self, VALUE key, VALUE value)
+{
+    struct weakmap *w;
+
+    TypedData_Get_Struct(self, struct weakmap, &weakmap_type, w);
+    if (FL_ABLE(value)) {
+        define_final0(value, w->final);
+    }
+    if (FL_ABLE(key)) {
+        define_final0(key, w->final);
+    }
+
+    st_update(w->obj2wmap, (st_data_t)value, wmap_aset_update, key);
+    st_insert(w->wmap2obj, (st_data_t)key, (st_data_t)value);
+    return nonspecial_obj_id(value);
+}
+
+/* Retrieves a weakly referenced object with the given key */
+static VALUE
+wmap_lookup(VALUE self, VALUE key)
+{
+    st_data_t data;
+    VALUE obj;
+    struct weakmap *w;
+    rb_objspace_t *objspace = &rb_objspace;
+
+    TypedData_Get_Struct(self, struct weakmap, &weakmap_type, w);
+    if (!st_lookup(w->wmap2obj, (st_data_t)key, &data)) return Qundef;
+    obj = (VALUE)data;
+    if (!wmap_live_p(objspace, obj)) return Qundef;
+    return obj;
+}
+
+/* Retrieves a weakly referenced object with the given key */
+static VALUE
+wmap_aref(VALUE self, VALUE key)
+{
+    VALUE obj = wmap_lookup(self, key);
+    return obj != Qundef ? obj : Qnil;
+}
+
+/* Returns +true+ if +key+ is registered */
+static VALUE
+wmap_has_key(VALUE self, VALUE key)
+{
+    return wmap_lookup(self, key) == Qundef ? Qfalse : Qtrue;
+}
+
+/* Returns the number of referenced objects */
+static VALUE
+wmap_size(VALUE self)
+{
+    struct weakmap *w;
+    st_index_t n;
+
+    TypedData_Get_Struct(self, struct weakmap, &weakmap_type, w);
+    n = w->wmap2obj->num_entries;
+#if SIZEOF_ST_INDEX_T <= SIZEOF_LONG
+    return ULONG2NUM(n);
+#else
+    return ULL2NUM(n);
+#endif
+}
+
+/*
+  ------------------------------ GC profiler ------------------------------
+*/
+
+#define GC_PROFILE_RECORD_DEFAULT_SIZE 100
+
+/* return sec in user time */
+static double
+getrusage_time(void)
+{
+#if defined(HAVE_CLOCK_GETTIME) && defined(CLOCK_PROCESS_CPUTIME_ID)
+    {
+        static int try_clock_gettime = 1;
+        struct timespec ts;
+        if (try_clock_gettime && clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &ts) == 0) {
+            return ts.tv_sec + ts.tv_nsec * 1e-9;
+        }
+        else {
+            try_clock_gettime = 0;
+        }
+    }
+#endif
+
+#ifdef RUSAGE_SELF
+    {
+        struct rusage usage;
+        struct timeval time;
+        if (getrusage(RUSAGE_SELF, &usage) == 0) {
+            time = usage.ru_utime;
+            return time.tv_sec + time.tv_usec * 1e-6;
+        }
+    }
+#endif
+
+#ifdef _WIN32
+    {
+	FILETIME creation_time, exit_time, kernel_time, user_time;
+	ULARGE_INTEGER ui;
+	LONG_LONG q;
+	double t;
+
+	if (GetProcessTimes(GetCurrentProcess(),
+			    &creation_time, &exit_time, &kernel_time, &user_time) != 0) {
+	    memcpy(&ui, &user_time, sizeof(FILETIME));
+	    q = ui.QuadPart / 10L;
+	    t = (DWORD)(q % 1000000L) * 1e-6;
+	    q /= 1000000L;
+#ifdef __GNUC__
+	    t += q;
+#else
+	    t += (double)(DWORD)(q >> 16) * (1 << 16);
+	    t += (DWORD)q & ~(~0 << 16);
+#endif
+	    return t;
+	}
+    }
+#endif
+
+    return 0.0;
+}
+
+static inline void
+gc_prof_setup_new_record(rb_objspace_t *objspace, int reason)
+{
+    if (objspace->profile.run) {
+	size_t index = objspace->profile.next_index;
+	gc_profile_record *record;
+
+	/* create new record */
+	objspace->profile.next_index++;
+
+	if (!objspace->profile.records) {
+	    objspace->profile.size = GC_PROFILE_RECORD_DEFAULT_SIZE;
+	    objspace->profile.records = malloc(xmalloc2_size(sizeof(gc_profile_record), objspace->profile.size));
+	}
+	if (index >= objspace->profile.size) {
+	    void *ptr;
+	    objspace->profile.size += 1000;
+	    ptr = realloc(objspace->profile.records, xmalloc2_size(sizeof(gc_profile_record), objspace->profile.size));
+	    if (!ptr) rb_memerror();
+	    objspace->profile.records = ptr;
+	}
+	if (!objspace->profile.records) {
+	    rb_bug("gc_profile malloc or realloc miss");
+	}
+	record = objspace->profile.current_record = &objspace->profile.records[objspace->profile.next_index - 1];
+	MEMZERO(record, gc_profile_record, 1);
+
+	/* setup before-GC parameter */
+	record->flags = reason | (ruby_gc_stressful ? GPR_FLAG_STRESS : 0);
+#if MALLOC_ALLOCATED_SIZE
+	record->allocated_size = malloc_allocated_size;
+#endif
+#if GC_PROFILE_MORE_DETAIL && GC_PROFILE_DETAIL_MEMORY
+#ifdef RUSAGE_SELF
+	{
+	    struct rusage usage;
+	    if (getrusage(RUSAGE_SELF, &usage) == 0) {
+		record->maxrss = usage.ru_maxrss;
+		record->minflt = usage.ru_minflt;
+		record->majflt = usage.ru_majflt;
+	    }
+	}
+#endif
+#endif
+    }
+}
+
+static inline void
+gc_prof_timer_start(rb_objspace_t *objspace)
+{
+    if (gc_prof_enabled(objspace)) {
+	gc_profile_record *record = gc_prof_record(objspace);
+#if GC_PROFILE_MORE_DETAIL
+	record->prepare_time = objspace->profile.prepare_time;
+#endif
+	record->gc_time = 0;
+	record->gc_invoke_time = getrusage_time();
+    }
+}
+
+static double
+elapsed_time_from(double time)
+{
+    double now = getrusage_time();
+    if (now > time) {
+	return now - time;
+    }
+    else {
+	return 0;
+    }
+}
+
+static inline void
+gc_prof_timer_stop(rb_objspace_t *objspace)
+{
+    if (gc_prof_enabled(objspace)) {
+	gc_profile_record *record = gc_prof_record(objspace);
+	record->gc_time = elapsed_time_from(record->gc_invoke_time);
+	record->gc_invoke_time -= objspace->profile.invoke_time;
+    }
+}
+
+#define RUBY_DTRACE_GC_HOOK(name) \
+    do {if (RUBY_DTRACE_GC_##name##_ENABLED()) RUBY_DTRACE_GC_##name();} while (0)
+static inline void
+gc_prof_mark_timer_start(rb_objspace_t *objspace)
+{
+    RUBY_DTRACE_GC_HOOK(MARK_BEGIN);
+#if GC_PROFILE_MORE_DETAIL
+    if (gc_prof_enabled(objspace)) {
+	gc_prof_record(objspace)->gc_mark_time = getrusage_time();
+    } else {
+        if (collect_gc_stats) {
+          objspace->profile.gc_mark_start_time = getrusage_time();
+        }
+    }
+#else
+    if (collect_gc_stats) {
+        objspace->profile.gc_mark_start_time = getrusage_time();
+    }
+#endif
+}
+
+static inline void
+gc_prof_mark_timer_stop(rb_objspace_t *objspace)
+{
+    RUBY_DTRACE_GC_HOOK(MARK_END);
+#if GC_PROFILE_MORE_DETAIL
+    if (gc_prof_enabled(objspace)) {
+        gc_profile_record *record = gc_prof_record(objspace);
+	record->gc_mark_time = elapsed_time_from(record->gc_mark_time);
+        if (collect_gc_stats) {
+            objspace->profile.time += record->gc_mark_time;
+        }
+    } else {
+        if (collect_gc_stats) {
+            objspace->profile.time += elapsed_time_from(objspace->profile.gc_mark_start_time);
+        }
+    }
+#else
+    if (collect_gc_stats) {
+        objspace->profile.time += elapsed_time_from(objspace->profile.gc_mark_start_time);
+    }
+#endif
+}
+
+static inline void
+gc_prof_sweep_timer_start(rb_objspace_t *objspace)
+{
+    RUBY_DTRACE_GC_HOOK(SWEEP_BEGIN);
+    if (gc_prof_enabled(objspace)) {
+	gc_profile_record *record = gc_prof_record(objspace);
+
+	if (record->gc_time > 0 || GC_PROFILE_MORE_DETAIL || collect_gc_stats) {
+	    objspace->profile.gc_sweep_start_time = getrusage_time();
+        }
+    } else {
+        if (collect_gc_stats) {
+            objspace->profile.gc_sweep_start_time = getrusage_time();
+        }
+    }
+}
+
+static inline void
+gc_prof_sweep_timer_stop(rb_objspace_t *objspace)
+{
+    RUBY_DTRACE_GC_HOOK(SWEEP_END);
+
+    if (gc_prof_enabled(objspace)) {
+	double sweep_time;
+	gc_profile_record *record = gc_prof_record(objspace);
+
+	if (record->gc_time > 0) {
+	    sweep_time = elapsed_time_from(objspace->profile.gc_sweep_start_time);
+	    /* need to accumulate GC time for lazy sweep after gc() */
+	    record->gc_time += sweep_time;
+            if (collect_gc_stats) {
+                objspace->profile.time += sweep_time;
+            }
+	}
+	else if (GC_PROFILE_MORE_DETAIL) {
+	    sweep_time = elapsed_time_from(objspace->profile.gc_sweep_start_time);
+            if (collect_gc_stats) {
+                objspace->profile.time += sweep_time;
+            }
+	} else {
+            if (collect_gc_stats) {
+                objspace->profile.time += elapsed_time_from(objspace->profile.gc_sweep_start_time);
+            }
+        }
+
+#if GC_PROFILE_MORE_DETAIL
+	record->gc_sweep_time += sweep_time;
+	if (heap_pages_deferred_final) record->flags |= GPR_FLAG_HAVE_FINALIZE;
+#endif
+	if (heap_pages_deferred_final) objspace->profile.latest_gc_info |= GPR_FLAG_HAVE_FINALIZE;
+    } else {
+        if (collect_gc_stats) {
+            objspace->profile.time += elapsed_time_from(objspace->profile.gc_sweep_start_time);
+        }
+    }
+}
+
+static inline void
+gc_prof_set_malloc_info(rb_objspace_t *objspace)
+{
+#if GC_PROFILE_MORE_DETAIL
+    if (gc_prof_enabled(objspace)) {
+        gc_profile_record *record = gc_prof_record(objspace);
+	record->allocate_increase = malloc_increase;
+	record->allocate_limit = malloc_limit;
+    }
+#endif
+}
+
+static inline void
+gc_prof_set_heap_info(rb_objspace_t *objspace)
+{
+    if (objspace->profile.total_allocated_objects_at_gc_start > objspace->profile.total_freed_objects)
+        objspace->profile.live_after_last_sweep =
+            objspace->profile.total_allocated_objects_at_gc_start - objspace->profile.total_freed_objects;
+
+    if (gc_prof_enabled(objspace)) {
+	gc_profile_record *record = gc_prof_record(objspace);
+        size_t live = objspace->profile.live_after_last_sweep;
+	size_t total = objspace->profile.heap_used_at_gc_start * HEAP_PAGE_OBJ_LIMIT;
+
+#if GC_PROFILE_MORE_DETAIL
+	record->heap_use_pages = objspace->profile.heap_used_at_gc_start;
+	record->heap_live_objects = live;
+	record->heap_free_objects = total - live;
+#endif
+
+	record->heap_total_objects = total;
+	record->heap_use_size = live * sizeof(RVALUE);
+	record->heap_total_size = total * sizeof(RVALUE);
+    }
+}
+
+/*
+ *  call-seq:
+ *    GC::Profiler.clear          -> nil
+ *
+ *  Clears the GC profiler data.
+ *
+ */
+
+static VALUE
+gc_profile_clear(VALUE _)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    void *p = objspace->profile.records;
+    objspace->profile.records = NULL;
+    objspace->profile.size = 0;
+    objspace->profile.next_index = 0;
+    objspace->profile.current_record = 0;
+    if (p) {
+        free(p);
+    }
+    return Qnil;
+}
+
+/*
+ *  call-seq:
+ *     GC::Profiler.raw_data	-> [Hash, ...]
+ *
+ *  Returns an Array of individual raw profile data Hashes ordered
+ *  from earliest to latest by +:GC_INVOKE_TIME+.
+ *
+ *  For example:
+ *
+ *    [
+ *	{
+ *	   :GC_TIME=>1.3000000000000858e-05,
+ *	   :GC_INVOKE_TIME=>0.010634999999999999,
+ *	   :HEAP_USE_SIZE=>289640,
+ *	   :HEAP_TOTAL_SIZE=>588960,
+ *	   :HEAP_TOTAL_OBJECTS=>14724,
+ *	   :GC_IS_MARKED=>false
+ *	},
+ *      # ...
+ *    ]
+ *
+ *  The keys mean:
+ *
+ *  +:GC_TIME+::
+ *	Time elapsed in seconds for this GC run
+ *  +:GC_INVOKE_TIME+::
+ *	Time elapsed in seconds from startup to when the GC was invoked
+ *  +:HEAP_USE_SIZE+::
+ *	Total bytes of heap used
+ *  +:HEAP_TOTAL_SIZE+::
+ *	Total size of heap in bytes
+ *  +:HEAP_TOTAL_OBJECTS+::
+ *	Total number of objects
+ *  +:GC_IS_MARKED+::
+ *	Returns +true+ if the GC is in mark phase
+ *
+ *  If ruby was built with +GC_PROFILE_MORE_DETAIL+, you will also have access
+ *  to the following hash keys:
+ *
+ *  +:GC_MARK_TIME+::
+ *  +:GC_SWEEP_TIME+::
+ *  +:ALLOCATE_INCREASE+::
+ *  +:ALLOCATE_LIMIT+::
+ *  +:HEAP_USE_PAGES+::
+ *  +:HEAP_LIVE_OBJECTS+::
+ *  +:HEAP_FREE_OBJECTS+::
+ *  +:HAVE_FINALIZE+::
+ *
+ */
+
+static VALUE
+gc_profile_record_get(VALUE _)
+{
+    VALUE prof;
+    VALUE gc_profile = rb_ary_new();
+    size_t i;
+    rb_objspace_t *objspace = (&rb_objspace);
+
+    if (!objspace->profile.run) {
+	return Qnil;
+    }
+
+    for (i =0; i < objspace->profile.next_index; i++) {
+	gc_profile_record *record = &objspace->profile.records[i];
+
+	prof = rb_hash_new();
+	rb_hash_aset(prof, ID2SYM(rb_intern("GC_FLAGS")), gc_info_decode(0, rb_hash_new(), record->flags));
+        rb_hash_aset(prof, ID2SYM(rb_intern("GC_TIME")), DBL2NUM(record->gc_time));
+        rb_hash_aset(prof, ID2SYM(rb_intern("GC_INVOKE_TIME")), DBL2NUM(record->gc_invoke_time));
+        rb_hash_aset(prof, ID2SYM(rb_intern("HEAP_USE_SIZE")), SIZET2NUM(record->heap_use_size));
+        rb_hash_aset(prof, ID2SYM(rb_intern("HEAP_TOTAL_SIZE")), SIZET2NUM(record->heap_total_size));
+        rb_hash_aset(prof, ID2SYM(rb_intern("HEAP_TOTAL_OBJECTS")), SIZET2NUM(record->heap_total_objects));
+        rb_hash_aset(prof, ID2SYM(rb_intern("MOVED_OBJECTS")), SIZET2NUM(record->moved_objects));
+        rb_hash_aset(prof, ID2SYM(rb_intern("GC_IS_MARKED")), Qtrue);
+#if GC_PROFILE_MORE_DETAIL
+        rb_hash_aset(prof, ID2SYM(rb_intern("GC_MARK_TIME")), DBL2NUM(record->gc_mark_time));
+        rb_hash_aset(prof, ID2SYM(rb_intern("GC_SWEEP_TIME")), DBL2NUM(record->gc_sweep_time));
+        rb_hash_aset(prof, ID2SYM(rb_intern("ALLOCATE_INCREASE")), SIZET2NUM(record->allocate_increase));
+        rb_hash_aset(prof, ID2SYM(rb_intern("ALLOCATE_LIMIT")), SIZET2NUM(record->allocate_limit));
+        rb_hash_aset(prof, ID2SYM(rb_intern("HEAP_USE_PAGES")), SIZET2NUM(record->heap_use_pages));
+        rb_hash_aset(prof, ID2SYM(rb_intern("HEAP_LIVE_OBJECTS")), SIZET2NUM(record->heap_live_objects));
+        rb_hash_aset(prof, ID2SYM(rb_intern("HEAP_FREE_OBJECTS")), SIZET2NUM(record->heap_free_objects));
+
+	rb_hash_aset(prof, ID2SYM(rb_intern("REMOVING_OBJECTS")), SIZET2NUM(record->removing_objects));
+	rb_hash_aset(prof, ID2SYM(rb_intern("EMPTY_OBJECTS")), SIZET2NUM(record->empty_objects));
+
+	rb_hash_aset(prof, ID2SYM(rb_intern("HAVE_FINALIZE")), (record->flags & GPR_FLAG_HAVE_FINALIZE) ? Qtrue : Qfalse);
+#endif
+
+#if RGENGC_PROFILE > 0
+	rb_hash_aset(prof, ID2SYM(rb_intern("OLD_OBJECTS")), SIZET2NUM(record->old_objects));
+	rb_hash_aset(prof, ID2SYM(rb_intern("REMEMBERED_NORMAL_OBJECTS")), SIZET2NUM(record->remembered_normal_objects));
+	rb_hash_aset(prof, ID2SYM(rb_intern("REMEMBERED_SHADY_OBJECTS")), SIZET2NUM(record->remembered_shady_objects));
+#endif
+	rb_ary_push(gc_profile, prof);
+    }
+
+    return gc_profile;
+}
+
+#if GC_PROFILE_MORE_DETAIL
+#define MAJOR_REASON_MAX 0x10
+
+static char *
+gc_profile_dump_major_reason(int flags, char *buff)
+{
+    int reason = flags & GPR_FLAG_MAJOR_MASK;
+    int i = 0;
+
+    if (reason == GPR_FLAG_NONE) {
+	buff[0] = '-';
+	buff[1] = 0;
+    }
+    else {
+#define C(x, s) \
+  if (reason & GPR_FLAG_MAJOR_BY_##x) { \
+      buff[i++] = #x[0]; \
+      if (i >= MAJOR_REASON_MAX) rb_bug("gc_profile_dump_major_reason: overflow"); \
+      buff[i] = 0; \
+  }
+	C(NOFREE, N);
+	C(OLDGEN, O);
+	C(SHADY,  S);
+#if RGENGC_ESTIMATE_OLDMALLOC
+	C(OLDMALLOC, M);
+#endif
+#undef C
+    }
+    return buff;
+}
+#endif
+
+static void
+gc_profile_dump_on(VALUE out, VALUE (*append)(VALUE, VALUE))
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    size_t count = objspace->profile.next_index;
+#ifdef MAJOR_REASON_MAX
+    char reason_str[MAJOR_REASON_MAX];
+#endif
+
+    if (objspace->profile.run && count /* > 1 */) {
+	size_t i;
+	const gc_profile_record *record;
+
+	append(out, rb_sprintf("GC %"PRIuSIZE" invokes.\n", objspace->profile.count));
+	append(out, rb_str_new_cstr("Index    Invoke Time(sec)       Use Size(byte)     Total Size(byte)         Total Object                    GC Time(ms)\n"));
+
+	for (i = 0; i < count; i++) {
+	    record = &objspace->profile.records[i];
+	    append(out, rb_sprintf("%5"PRIuSIZE" %19.3f %20"PRIuSIZE" %20"PRIuSIZE" %20"PRIuSIZE" %30.20f\n",
+				   i+1, record->gc_invoke_time, record->heap_use_size,
+				   record->heap_total_size, record->heap_total_objects, record->gc_time*1000));
+	}
+
+#if GC_PROFILE_MORE_DETAIL
+        const char *str = "\n\n" \
+				    "More detail.\n" \
+				    "Prepare Time = Previously GC's rest sweep time\n"
+				    "Index Flags          Allocate Inc.  Allocate Limit"
+#if CALC_EXACT_MALLOC_SIZE
+				    "  Allocated Size"
+#endif
+				    "  Use Page     Mark Time(ms)    Sweep Time(ms)  Prepare Time(ms)  LivingObj    FreeObj RemovedObj   EmptyObj"
+#if RGENGC_PROFILE
+				    " OldgenObj RemNormObj RemShadObj"
+#endif
+#if GC_PROFILE_DETAIL_MEMORY
+				    " MaxRSS(KB) MinorFLT MajorFLT"
+#endif
+                                    "\n";
+        append(out, rb_str_new_cstr(str));
+
+	for (i = 0; i < count; i++) {
+	    record = &objspace->profile.records[i];
+	    append(out, rb_sprintf("%5"PRIuSIZE" %4s/%c/%6s%c %13"PRIuSIZE" %15"PRIuSIZE
+#if CALC_EXACT_MALLOC_SIZE
+				   " %15"PRIuSIZE
+#endif
+				   " %9"PRIuSIZE" %17.12f %17.12f %17.12f %10"PRIuSIZE" %10"PRIuSIZE" %10"PRIuSIZE" %10"PRIuSIZE
+#if RGENGC_PROFILE
+				   "%10"PRIuSIZE" %10"PRIuSIZE" %10"PRIuSIZE
+#endif
+#if GC_PROFILE_DETAIL_MEMORY
+				   "%11ld %8ld %8ld"
+#endif
+
+				   "\n",
+				   i+1,
+				   gc_profile_dump_major_reason(record->flags, reason_str),
+				   (record->flags & GPR_FLAG_HAVE_FINALIZE) ? 'F' : '.',
+				   (record->flags & GPR_FLAG_NEWOBJ) ? "NEWOBJ" :
+				   (record->flags & GPR_FLAG_MALLOC) ? "MALLOC" :
+				   (record->flags & GPR_FLAG_METHOD) ? "METHOD" :
+				   (record->flags & GPR_FLAG_CAPI)   ? "CAPI__" : "??????",
+				   (record->flags & GPR_FLAG_STRESS) ? '!' : ' ',
+				   record->allocate_increase, record->allocate_limit,
+#if CALC_EXACT_MALLOC_SIZE
+				   record->allocated_size,
+#endif
+				   record->heap_use_pages,
+				   record->gc_mark_time*1000,
+				   record->gc_sweep_time*1000,
+				   record->prepare_time*1000,
+
+				   record->heap_live_objects,
+				   record->heap_free_objects,
+				   record->removing_objects,
+				   record->empty_objects
+#if RGENGC_PROFILE
+				   ,
+				   record->old_objects,
+				   record->remembered_normal_objects,
+				   record->remembered_shady_objects
+#endif
+#if GC_PROFILE_DETAIL_MEMORY
+				   ,
+				   record->maxrss / 1024,
+				   record->minflt,
+				   record->majflt
+#endif
+
+		       ));
+	}
+#endif
+    }
+}
+
+/*
+ *  call-seq:
+ *     GC::Profiler.result  -> String
+ *
+ *  Returns a profile data report such as:
+ *
+ *    GC 1 invokes.
+ *    Index    Invoke Time(sec)       Use Size(byte)     Total Size(byte)         Total Object                    GC time(ms)
+ *        1               0.012               159240               212940                10647         0.00000000000001530000
+ */
+
+static VALUE
+gc_profile_result(VALUE _)
+{
+    VALUE str = rb_str_buf_new(0);
+    gc_profile_dump_on(str, rb_str_buf_append);
+    return str;
+}
+
+/*
+ *  call-seq:
+ *     GC::Profiler.report
+ *     GC::Profiler.report(io)
+ *
+ *  Writes the GC::Profiler.result to <tt>$stdout</tt> or the given IO object.
+ *
+ */
+
+static VALUE
+gc_profile_report(int argc, VALUE *argv, VALUE self)
+{
+    VALUE out;
+
+    out = (!rb_check_arity(argc, 0, 1) ? rb_stdout : argv[0]);
+    gc_profile_dump_on(out, rb_io_write);
+
+    return Qnil;
+}
+
+/*
+ *  call-seq:
+ *     GC::Profiler.total_time	-> float
+ *
+ *  The total time used for garbage collection in seconds
+ */
+
+static VALUE
+gc_profile_total_time(VALUE self)
+{
+    double time = 0;
+    rb_objspace_t *objspace = &rb_objspace;
+
+    if (objspace->profile.run && objspace->profile.next_index > 0) {
+	size_t i;
+	size_t count = objspace->profile.next_index;
+
+	for (i = 0; i < count; i++) {
+	    time += objspace->profile.records[i].gc_time;
+	}
+    }
+    return DBL2NUM(time);
+}
+
+/*
+ *  call-seq:
+ *    GC::Profiler.enabled?	-> true or false
+ *
+ *  The current status of GC profile mode.
+ */
+
+static VALUE
+gc_profile_enable_get(VALUE self)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    return objspace->profile.run ? Qtrue : Qfalse;
+}
+
+/*
+ *  call-seq:
+ *    GC::Profiler.enable	-> nil
+ *
+ *  Starts the GC profiler.
+ *
+ */
+
+static VALUE
+gc_profile_enable(VALUE _)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    objspace->profile.run = TRUE;
+    objspace->profile.current_record = 0;
+    return Qnil;
+}
+
+/*
+ *  call-seq:
+ *    GC::Profiler.disable	-> nil
+ *
+ *  Stops the GC profiler.
+ *
+ */
+
+static VALUE
+gc_profile_disable(VALUE _)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+
+    objspace->profile.run = FALSE;
+    objspace->profile.current_record = 0;
+    return Qnil;
+}
+
+/*
+  ------------------------------ DEBUG ------------------------------
+*/
+
+static const char *
+type_name(int type, VALUE obj)
+{
+    switch (type) {
+#define TYPE_NAME(t) case (t): return #t;
+	    TYPE_NAME(T_NONE);
+	    TYPE_NAME(T_OBJECT);
+	    TYPE_NAME(T_CLASS);
+	    TYPE_NAME(T_MODULE);
+	    TYPE_NAME(T_FLOAT);
+	    TYPE_NAME(T_STRING);
+	    TYPE_NAME(T_REGEXP);
+	    TYPE_NAME(T_ARRAY);
+	    TYPE_NAME(T_HASH);
+	    TYPE_NAME(T_STRUCT);
+	    TYPE_NAME(T_BIGNUM);
+	    TYPE_NAME(T_FILE);
+	    TYPE_NAME(T_MATCH);
+	    TYPE_NAME(T_COMPLEX);
+	    TYPE_NAME(T_RATIONAL);
+	    TYPE_NAME(T_NIL);
+	    TYPE_NAME(T_TRUE);
+	    TYPE_NAME(T_FALSE);
+	    TYPE_NAME(T_SYMBOL);
+	    TYPE_NAME(T_FIXNUM);
+	    TYPE_NAME(T_UNDEF);
+	    TYPE_NAME(T_IMEMO);
+	    TYPE_NAME(T_ICLASS);
+            TYPE_NAME(T_MOVED);
+	    TYPE_NAME(T_ZOMBIE);
+      case T_DATA:
+	if (obj && rb_objspace_data_type_name(obj)) {
+	    return rb_objspace_data_type_name(obj);
+	}
+	return "T_DATA";
+#undef TYPE_NAME
+    }
+    return "unknown";
+}
+
+static const char *
+obj_type_name(VALUE obj)
+{
+    return type_name(TYPE(obj), obj);
+}
+
+const char *
+rb_method_type_name(rb_method_type_t type)
+{
+    switch (type) {
+      case VM_METHOD_TYPE_ISEQ:           return "iseq";
+      case VM_METHOD_TYPE_ATTRSET:        return "attrest";
+      case VM_METHOD_TYPE_IVAR:           return "ivar";
+      case VM_METHOD_TYPE_BMETHOD:        return "bmethod";
+      case VM_METHOD_TYPE_ALIAS:          return "alias";
+      case VM_METHOD_TYPE_REFINED:        return "refined";
+      case VM_METHOD_TYPE_CFUNC:          return "cfunc";
+      case VM_METHOD_TYPE_ZSUPER:         return "zsuper";
+      case VM_METHOD_TYPE_MISSING:        return "missing";
+      case VM_METHOD_TYPE_OPTIMIZED:      return "optimized";
+      case VM_METHOD_TYPE_UNDEF:          return "undef";
+      case VM_METHOD_TYPE_NOTIMPLEMENTED: return "notimplemented";
+    }
+    rb_bug("rb_method_type_name: unreachable (type: %d)", type);
+}
+
+/* from array.c */
+# define ARY_SHARED_P(ary) \
+    (GC_ASSERT(!FL_TEST((ary), ELTS_SHARED) || !FL_TEST((ary), RARRAY_EMBED_FLAG)), \
+     FL_TEST((ary),ELTS_SHARED)!=0)
+# define ARY_EMBED_P(ary) \
+    (GC_ASSERT(!FL_TEST((ary), ELTS_SHARED) || !FL_TEST((ary), RARRAY_EMBED_FLAG)), \
+     FL_TEST((ary), RARRAY_EMBED_FLAG)!=0)
+
+static void
+rb_raw_iseq_info(char *buff, const int buff_size, const rb_iseq_t *iseq)
+{
+    if (buff_size > 0 && iseq->body && iseq->body->location.label && !RB_TYPE_P(iseq->body->location.pathobj, T_MOVED)) {
+	VALUE path = rb_iseq_path(iseq);
+	VALUE n = iseq->body->location.first_lineno;
+        snprintf(buff, buff_size, " %s@%s:%d",
+		 RSTRING_PTR(iseq->body->location.label),
+		 RSTRING_PTR(path),
+		 n ? FIX2INT(n) : 0 );
+    }
+}
+
+bool rb_ractor_p(VALUE rv);
+
+static int
+str_len_no_raise(VALUE str)
+{
+    long len = RSTRING_LEN(str);
+    if (len < 0) return 0;
+    if (len > INT_MAX) return INT_MAX;
+    return (int)len;
+}
+
+const char *
+rb_raw_obj_info(char *buff, const int buff_size, VALUE obj)
+{
+    int pos = 0;
+    void *poisoned = asan_poisoned_object_p(obj);
+    asan_unpoison_object(obj, false);
+
+#define BUFF_ARGS buff + pos, buff_size - pos
+#define APPENDF(f) if ((pos += snprintf f) >= buff_size) goto end
+    if (SPECIAL_CONST_P(obj)) {
+        APPENDF((BUFF_ARGS, "%s", obj_type_name(obj)));
+
+        if (FIXNUM_P(obj)) {
+            APPENDF((BUFF_ARGS, " %ld", FIX2LONG(obj)));
+        }
+        else if (SYMBOL_P(obj)) {
+            APPENDF((BUFF_ARGS, " %s", rb_id2name(SYM2ID(obj))));
+        }
+    }
+    else {
+#define TF(c) ((c) != 0 ? "true" : "false")
+#define C(c, s) ((c) != 0 ? (s) : " ")
+	const int type = BUILTIN_TYPE(obj);
+	const int age = RVALUE_FLAGS_AGE(RBASIC(obj)->flags);
+
+        if (is_pointer_to_heap(&rb_objspace, (void *)obj)) {
+            APPENDF((BUFF_ARGS, "%p [%d%s%s%s%s%s] %s ",
+                     (void *)obj, age,
+                     C(RVALUE_UNCOLLECTIBLE_BITMAP(obj),  "L"),
+                     C(RVALUE_MARK_BITMAP(obj),           "M"),
+                     C(RVALUE_PIN_BITMAP(obj),            "P"),
+                     C(RVALUE_MARKING_BITMAP(obj),        "R"),
+                     C(RVALUE_WB_UNPROTECTED_BITMAP(obj), "U"),
+                     obj_type_name(obj)));
+        }
+        else {
+            /* fake */
+            APPENDF((BUFF_ARGS, "%p [%dXXXX] %s",
+                     (void *)obj, age,
+                     obj_type_name(obj)));
+        }
+
+	if (internal_object_p(obj)) {
+	    /* ignore */
+	}
+	else if (RBASIC(obj)->klass == 0) {
+            APPENDF((BUFF_ARGS, "(temporary internal)"));
+	}
+	else {
+            if (RTEST(RBASIC(obj)->klass)) {
+            VALUE class_path = rb_class_path_cached(RBASIC(obj)->klass);
+	    if (!NIL_P(class_path)) {
+                APPENDF((BUFF_ARGS, "(%s)", RSTRING_PTR(class_path)));
+	    }
+            }
+	}
+
+#if GC_DEBUG
+        APPENDF((BUFF_ARGS, "@%s:%d", RANY(obj)->file, RANY(obj)->line));
+#endif
+
+	switch (type) {
+	  case T_NODE:
+	    UNEXPECTED_NODE(rb_raw_obj_info);
+	    break;
+	  case T_ARRAY:
+            if (FL_TEST(obj, ELTS_SHARED)) {
+                APPENDF((BUFF_ARGS, "shared -> %s",
+                         rb_obj_info(RARRAY(obj)->as.heap.aux.shared_root)));
+            }
+            else if (FL_TEST(obj, RARRAY_EMBED_FLAG)) {
+                APPENDF((BUFF_ARGS, "[%s%s] len: %ld (embed)",
+                         C(ARY_EMBED_P(obj),  "E"),
+                         C(ARY_SHARED_P(obj), "S"),
+                         RARRAY_LEN(obj)));
+            }
+            else {
+                APPENDF((BUFF_ARGS, "[%s%s%s] len: %ld, capa:%ld ptr:%p",
+                         C(ARY_EMBED_P(obj),  "E"),
+                         C(ARY_SHARED_P(obj), "S"),
+                         C(RARRAY_TRANSIENT_P(obj), "T"),
+                         RARRAY_LEN(obj),
+                         ARY_EMBED_P(obj) ? -1L : RARRAY(obj)->as.heap.aux.capa,
+                         (void *)RARRAY_CONST_PTR_TRANSIENT(obj)));
+            }
+	    break;
+	  case T_STRING: {
+            if (STR_SHARED_P(obj)) APPENDF((BUFF_ARGS, " [shared] "));
+            APPENDF((BUFF_ARGS, "%.*s", str_len_no_raise(obj), RSTRING_PTR(obj)));
+	    break;
+	  }
+          case T_SYMBOL: {
+              VALUE fstr = RSYMBOL(obj)->fstr;
+              ID id = RSYMBOL(obj)->id;
+              if (RB_TYPE_P(fstr, T_STRING)) {
+                  APPENDF((BUFF_ARGS, ":%s id:%d", RSTRING_PTR(fstr), (unsigned int)id));
+              }
+              else {
+                  APPENDF((BUFF_ARGS, "(%p) id:%d", (void *)fstr, (unsigned int)id));
+              }
+              break;
+          }
+          case T_MOVED: {
+            APPENDF((BUFF_ARGS, "-> %p", (void*)rb_gc_location(obj)));
+            break;
+          }
+          case T_HASH: {
+              APPENDF((BUFF_ARGS, "[%c%c] %"PRIdSIZE,
+                       RHASH_AR_TABLE_P(obj) ? 'A' : 'S',
+                       RHASH_TRANSIENT_P(obj) ? 'T' : ' ',
+                       RHASH_SIZE(obj)));
+              break;
+          }
+          case T_CLASS:
+          case T_MODULE:
+            {
+                VALUE class_path = rb_class_path_cached(obj);
+                if (!NIL_P(class_path)) {
+                    APPENDF((BUFF_ARGS, "%s", RSTRING_PTR(class_path)));
+                }
+                else {
+                    APPENDF((BUFF_ARGS, "(annon)"));
+                }
+                break;
+            }
+          case T_ICLASS:
+            {
+                VALUE class_path = rb_class_path_cached(RBASIC_CLASS(obj));
+                if (!NIL_P(class_path)) {
+                    APPENDF((BUFF_ARGS, "src:%s", RSTRING_PTR(class_path)));
+                }
+                break;
+            }
+          case T_OBJECT:
+            {
+                uint32_t len = ROBJECT_NUMIV(obj);
+
+                if (RANY(obj)->as.basic.flags & ROBJECT_EMBED) {
+                    APPENDF((BUFF_ARGS, "(embed) len:%d", len));
+                }
+                else {
+                    VALUE *ptr = ROBJECT_IVPTR(obj);
+                    APPENDF((BUFF_ARGS, "len:%d ptr:%p", len, (void *)ptr));
+                }
+            }
+            break;
+	  case T_DATA: {
+	    const struct rb_block *block;
+	    const rb_iseq_t *iseq;
+	    if (rb_obj_is_proc(obj) &&
+		(block = vm_proc_block(obj)) != NULL &&
+		(vm_block_type(block) == block_type_iseq) &&
+		(iseq = vm_block_iseq(block)) != NULL) {
+                rb_raw_iseq_info(BUFF_ARGS, iseq);
+	    }
+            else if (rb_ractor_p(obj)) {
+                rb_ractor_t *r = (void *)DATA_PTR(obj);
+                if (r) {
+                    APPENDF((BUFF_ARGS, "r:%d", r->pub.id));
+                }
+            }
+	    else {
+		const char * const type_name = rb_objspace_data_type_name(obj);
+		if (type_name) {
+                    APPENDF((BUFF_ARGS, "%s", type_name));
+		}
+	    }
+	    break;
+	  }
+	  case T_IMEMO: {
+            APPENDF((BUFF_ARGS, "<%s> ", rb_imemo_name(imemo_type(obj))));
+
+	    switch (imemo_type(obj)) {
+	      case imemo_ment: {
+		const rb_method_entry_t *me = &RANY(obj)->as.imemo.ment;
+		if (me->def) {
+                    APPENDF((BUFF_ARGS, ":%s (%s%s%s%s) type:%s alias:%d owner:%p defined_class:%p",
+			     rb_id2name(me->called_id),
+                             METHOD_ENTRY_VISI(me) == METHOD_VISI_PUBLIC ?  "pub" :
+                             METHOD_ENTRY_VISI(me) == METHOD_VISI_PRIVATE ? "pri" : "pro",
+                             METHOD_ENTRY_COMPLEMENTED(me) ? ",cmp" : "",
+                             METHOD_ENTRY_CACHED(me) ? ",cc" : "",
+                             METHOD_ENTRY_INVALIDATED(me) ? ",inv" : "",
+                             rb_method_type_name(me->def->type),
+                             me->def->alias_count,
+                             (void *)me->owner, // obj_info(me->owner),
+                             (void *)me->defined_class)); //obj_info(me->defined_class)));
+
+                    if (me->def->type == VM_METHOD_TYPE_ISEQ) {
+                        // APPENDF((BUFF_ARGS, " (iseq:%p)", (void *)me->def->body.iseq.iseqptr));
+                        APPENDF((BUFF_ARGS, " (iseq:%s)", obj_info((VALUE)me->def->body.iseq.iseqptr)));
+                    }
+		}
+		else {
+                    APPENDF((BUFF_ARGS, "%s", rb_id2name(me->called_id)));
+		}
+		break;
+	      }
+	      case imemo_iseq: {
+		const rb_iseq_t *iseq = (const rb_iseq_t *)obj;
+                rb_raw_iseq_info(BUFF_ARGS, iseq);
+		break;
+	      }
+              case imemo_callinfo:
+                {
+                    const struct rb_callinfo *ci = (const struct rb_callinfo *)obj;
+                    APPENDF((BUFF_ARGS, "(mid:%s, flag:%x argc:%d, kwarg:%s)",
+                             rb_id2name(vm_ci_mid(ci)),
+                             vm_ci_flag(ci),
+                             vm_ci_argc(ci),
+                             vm_ci_kwarg(ci) ? "available" : "NULL"));
+                    break;
+                }
+              case imemo_callcache:
+                {
+                    const struct rb_callcache *cc = (const struct rb_callcache *)obj;
+                    VALUE class_path = cc->klass ? rb_class_path_cached(cc->klass) : Qnil;
+
+                    APPENDF((BUFF_ARGS, "(klass:%s, cme:%s (%p) call:%p",
+                             NIL_P(class_path) ? "??" : RSTRING_PTR(class_path),
+                             vm_cc_cme(cc) ? rb_id2name(vm_cc_cme(cc)->called_id) : "<NULL>",
+                             (void *)vm_cc_cme(cc), (void *)vm_cc_call(cc)));
+                    break;
+                }
+	      default:
+		break;
+	    }
+	  }
+	  default:
+	    break;
+	}
+#undef TF
+#undef C
+    }
+  end:
+    if (poisoned) {
+        asan_poison_object(obj);
+    }
+
+    return buff;
+#undef APPENDF
+#undef BUFF_ARGS
+}
+
+#if RGENGC_OBJ_INFO
+#define OBJ_INFO_BUFFERS_NUM  10
+#define OBJ_INFO_BUFFERS_SIZE 0x100
+static int obj_info_buffers_index = 0;
+static char obj_info_buffers[OBJ_INFO_BUFFERS_NUM][OBJ_INFO_BUFFERS_SIZE];
+
+static const char *
+obj_info(VALUE obj)
+{
+    const int index = obj_info_buffers_index++;
+    char *const buff = &obj_info_buffers[index][0];
+
+    if (obj_info_buffers_index >= OBJ_INFO_BUFFERS_NUM) {
+	obj_info_buffers_index = 0;
+    }
+
+    return rb_raw_obj_info(buff, OBJ_INFO_BUFFERS_SIZE, obj);
+}
+#else
+static const char *
+obj_info(VALUE obj)
+{
+    return obj_type_name(obj);
+}
+#endif
+
+MJIT_FUNC_EXPORTED const char *
+rb_obj_info(VALUE obj)
+{
+    return obj_info(obj);
+}
+
+void
+rb_obj_info_dump(VALUE obj)
+{
+    char buff[0x100];
+    fprintf(stderr, "rb_obj_info_dump: %s\n", rb_raw_obj_info(buff, 0x100, obj));
+}
+
+MJIT_FUNC_EXPORTED void
+rb_obj_info_dump_loc(VALUE obj, const char *file, int line, const char *func)
+{
+    char buff[0x100];
+    fprintf(stderr, "<OBJ_INFO:%s@%s:%d> %s\n", func, file, line, rb_raw_obj_info(buff, 0x100, obj));
+}
+
+#if GC_DEBUG
+
+void
+rb_gcdebug_print_obj_condition(VALUE obj)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+
+    fprintf(stderr, "created at: %s:%d\n", RANY(obj)->file, RANY(obj)->line);
+
+    if (BUILTIN_TYPE(obj) == T_MOVED) {
+        fprintf(stderr, "moved?: true\n");
+    }
+    else {
+        fprintf(stderr, "moved?: false\n");
+    }
+    if (is_pointer_to_heap(objspace, (void *)obj)) {
+        fprintf(stderr, "pointer to heap?: true\n");
+    }
+    else {
+        fprintf(stderr, "pointer to heap?: false\n");
+        return;
+    }
+
+    fprintf(stderr, "marked?      : %s\n", MARKED_IN_BITMAP(GET_HEAP_MARK_BITS(obj), obj) ? "true" : "false");
+    fprintf(stderr, "pinned?      : %s\n", MARKED_IN_BITMAP(GET_HEAP_PINNED_BITS(obj), obj) ? "true" : "false");
+    fprintf(stderr, "age?         : %d\n", RVALUE_AGE(obj));
+    fprintf(stderr, "old?         : %s\n", RVALUE_OLD_P(obj) ? "true" : "false");
+    fprintf(stderr, "WB-protected?: %s\n", RVALUE_WB_UNPROTECTED(obj) ? "false" : "true");
+    fprintf(stderr, "remembered?  : %s\n", RVALUE_REMEMBERED(obj) ? "true" : "false");
+
+    if (is_lazy_sweeping(heap_eden)) {
+        fprintf(stderr, "lazy sweeping?: true\n");
+        fprintf(stderr, "swept?: %s\n", is_swept_object(objspace, obj) ? "done" : "not yet");
+    }
+    else {
+        fprintf(stderr, "lazy sweeping?: false\n");
+    }
+}
+
+static VALUE
+gcdebug_sentinel(RB_BLOCK_CALL_FUNC_ARGLIST(obj, name))
+{
+    fprintf(stderr, "WARNING: object %s(%p) is inadvertently collected\n", (char *)name, (void *)obj);
+    return Qnil;
+}
+
+void
+rb_gcdebug_sentinel(VALUE obj, const char *name)
+{
+    rb_define_finalizer(obj, rb_proc_new(gcdebug_sentinel, (VALUE)name));
+}
+
+#endif /* GC_DEBUG */
+
+#if GC_DEBUG_STRESS_TO_CLASS
+/*
+ *  call-seq:
+ *    GC.add_stress_to_class(class[, ...])
+ *
+ *  Raises NoMemoryError when allocating an instance of the given classes.
+ *
+ */
+static VALUE
+rb_gcdebug_add_stress_to_class(int argc, VALUE *argv, VALUE self)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+
+    if (!stress_to_class) {
+	stress_to_class = rb_ary_tmp_new(argc);
+    }
+    rb_ary_cat(stress_to_class, argv, argc);
+    return self;
+}
+
+/*
+ *  call-seq:
+ *    GC.remove_stress_to_class(class[, ...])
+ *
+ *  No longer raises NoMemoryError when allocating an instance of the
+ *  given classes.
+ *
+ */
+static VALUE
+rb_gcdebug_remove_stress_to_class(int argc, VALUE *argv, VALUE self)
+{
+    rb_objspace_t *objspace = &rb_objspace;
+    int i;
+
+    if (stress_to_class) {
+	for (i = 0; i < argc; ++i) {
+	    rb_ary_delete_same(stress_to_class, argv[i]);
+	}
+	if (RARRAY_LEN(stress_to_class) == 0) {
+	    stress_to_class = 0;
+	}
+    }
+    return Qnil;
+}
+#endif
+
+/*
+ * Document-module: ObjectSpace
+ *
+ *  The ObjectSpace module contains a number of routines
+ *  that interact with the garbage collection facility and allow you to
+ *  traverse all living objects with an iterator.
+ *
+ *  ObjectSpace also provides support for object finalizers, procs that will be
+ *  called when a specific object is about to be destroyed by garbage
+ *  collection. See the documentation for
+ *  <code>ObjectSpace.define_finalizer</code> for important information on
+ *  how to use this method correctly.
+ *
+ *     a = "A"
+ *     b = "B"
+ *
+ *     ObjectSpace.define_finalizer(a, proc {|id| puts "Finalizer one on #{id}" })
+ *     ObjectSpace.define_finalizer(b, proc {|id| puts "Finalizer two on #{id}" })
+ *
+ *     a = nil
+ *     b = nil
+ *
+ *  _produces:_
+ *
+ *     Finalizer two on 537763470
+ *     Finalizer one on 537763480
+ */
+
+/*
+ *  Document-class: ObjectSpace::WeakMap
+ *
+ *  An ObjectSpace::WeakMap object holds references to
+ *  any objects, but those objects can get garbage collected.
+ *
+ *  This class is mostly used internally by WeakRef, please use
+ *  +lib/weakref.rb+ for the public interface.
+ */
+
+/*  Document-class: GC::Profiler
+ *
+ *  The GC profiler provides access to information on GC runs including time,
+ *  length and object space size.
+ *
+ *  Example:
+ *
+ *    GC::Profiler.enable
+ *
+ *    require 'rdoc/rdoc'
+ *
+ *    GC::Profiler.report
+ *
+ *    GC::Profiler.disable
+ *
+ *  See also GC.count, GC.malloc_allocated_size and GC.malloc_allocations
+ */
+
+#include "gc.rbinc"
+
+void
+Init_GC(void)
+{
+#undef rb_intern
+    VALUE rb_mObjSpace;
+    VALUE rb_mProfiler;
+    VALUE gc_constants;
+
+    rb_mGC = rb_define_module("GC");
+
+    gc_constants = rb_hash_new();
+    rb_hash_aset(gc_constants, ID2SYM(rb_intern("DEBUG")), GC_DEBUG ? Qtrue : Qfalse);
+    rb_hash_aset(gc_constants, ID2SYM(rb_intern("RVALUE_SIZE")), SIZET2NUM(sizeof(RVALUE)));
+    rb_hash_aset(gc_constants, ID2SYM(rb_intern("HEAP_PAGE_OBJ_LIMIT")), SIZET2NUM(HEAP_PAGE_OBJ_LIMIT));
+    rb_hash_aset(gc_constants, ID2SYM(rb_intern("HEAP_PAGE_BITMAP_SIZE")), SIZET2NUM(HEAP_PAGE_BITMAP_SIZE));
+    rb_hash_aset(gc_constants, ID2SYM(rb_intern("HEAP_PAGE_BITMAP_PLANES")), SIZET2NUM(HEAP_PAGE_BITMAP_PLANES));
+    rb_hash_aset(gc_constants, ID2SYM(rb_intern("HEAP_PAGE_SIZE")), SIZET2NUM(HEAP_PAGE_SIZE));
+    OBJ_FREEZE(gc_constants);
+    /* internal constants */
+    rb_define_const(rb_mGC, "INTERNAL_CONSTANTS", gc_constants);
+
+    rb_mProfiler = rb_define_module_under(rb_mGC, "Profiler");
+    rb_define_singleton_method(rb_mProfiler, "enabled?", gc_profile_enable_get, 0);
+    rb_define_singleton_method(rb_mProfiler, "enable", gc_profile_enable, 0);
+    rb_define_singleton_method(rb_mProfiler, "raw_data", gc_profile_record_get, 0);
+    rb_define_singleton_method(rb_mProfiler, "disable", gc_profile_disable, 0);
+    rb_define_singleton_method(rb_mProfiler, "clear", gc_profile_clear, 0);
+    rb_define_singleton_method(rb_mProfiler, "result", gc_profile_result, 0);
+    rb_define_singleton_method(rb_mProfiler, "report", gc_profile_report, -1);
+    rb_define_singleton_method(rb_mProfiler, "total_time", gc_profile_total_time, 0);
+
+    rb_mObjSpace = rb_define_module("ObjectSpace");
+
+    rb_define_module_function(rb_mObjSpace, "each_object", os_each_obj, -1);
+
+    rb_define_module_function(rb_mObjSpace, "define_finalizer", define_final, -1);
+    rb_define_module_function(rb_mObjSpace, "undefine_finalizer", undefine_final, 1);
+
+    rb_define_module_function(rb_mObjSpace, "_id2ref", os_id2ref, 1);
+
+    rb_vm_register_special_exception(ruby_error_nomemory, rb_eNoMemError, "failed to allocate memory");
+
+    rb_define_method(rb_cBasicObject, "__id__", rb_obj_id, 0);
+    rb_define_method(rb_mKernel, "object_id", rb_obj_id, 0);
+
+    rb_define_module_function(rb_mObjSpace, "count_objects", count_objects, -1);
+
+    {
+	VALUE rb_cWeakMap = rb_define_class_under(rb_mObjSpace, "WeakMap", rb_cObject);
+	rb_define_alloc_func(rb_cWeakMap, wmap_allocate);
+	rb_define_method(rb_cWeakMap, "[]=", wmap_aset, 2);
+	rb_define_method(rb_cWeakMap, "[]", wmap_aref, 1);
+	rb_define_method(rb_cWeakMap, "include?", wmap_has_key, 1);
+	rb_define_method(rb_cWeakMap, "member?", wmap_has_key, 1);
+	rb_define_method(rb_cWeakMap, "key?", wmap_has_key, 1);
+	rb_define_method(rb_cWeakMap, "inspect", wmap_inspect, 0);
+	rb_define_method(rb_cWeakMap, "each", wmap_each, 0);
+	rb_define_method(rb_cWeakMap, "each_pair", wmap_each, 0);
+	rb_define_method(rb_cWeakMap, "each_key", wmap_each_key, 0);
+	rb_define_method(rb_cWeakMap, "each_value", wmap_each_value, 0);
+	rb_define_method(rb_cWeakMap, "keys", wmap_keys, 0);
+	rb_define_method(rb_cWeakMap, "values", wmap_values, 0);
+	rb_define_method(rb_cWeakMap, "size", wmap_size, 0);
+	rb_define_method(rb_cWeakMap, "length", wmap_size, 0);
+	rb_include_module(rb_cWeakMap, rb_mEnumerable);
+    }
+
+    /* internal methods */
+    rb_define_singleton_method(rb_mGC, "verify_internal_consistency", gc_verify_internal_consistency_m, 0);
+    rb_define_singleton_method(rb_mGC, "verify_transient_heap_internal_consistency", gc_verify_transient_heap_internal_consistency, 0);
+#if MALLOC_ALLOCATED_SIZE
+    rb_define_singleton_method(rb_mGC, "malloc_allocated_size", gc_malloc_allocated_size, 0);
+    rb_define_singleton_method(rb_mGC, "malloc_allocations", gc_malloc_allocations, 0);
+#endif
+
+#if GC_DEBUG_STRESS_TO_CLASS
+    rb_define_singleton_method(rb_mGC, "add_stress_to_class", rb_gcdebug_add_stress_to_class, -1);
+    rb_define_singleton_method(rb_mGC, "remove_stress_to_class", rb_gcdebug_remove_stress_to_class, -1);
+#endif
+
+    {
+	VALUE opts;
+	/* GC build options */
+	rb_define_const(rb_mGC, "OPTS", opts = rb_ary_new());
+#define OPT(o) if (o) rb_ary_push(opts, rb_fstring_lit(#o))
+	OPT(GC_DEBUG);
+	OPT(USE_RGENGC);
+	OPT(RGENGC_DEBUG);
+	OPT(RGENGC_CHECK_MODE);
+	OPT(RGENGC_PROFILE);
+	OPT(RGENGC_ESTIMATE_OLDMALLOC);
+	OPT(GC_PROFILE_MORE_DETAIL);
+	OPT(GC_ENABLE_LAZY_SWEEP);
+	OPT(CALC_EXACT_MALLOC_SIZE);
+	OPT(MALLOC_ALLOCATED_SIZE);
+	OPT(MALLOC_ALLOCATED_SIZE_CHECK);
+	OPT(GC_PROFILE_DETAIL_MEMORY);
+#undef OPT
+	OBJ_FREEZE(opts);
+    }
+}
+
+#ifdef ruby_xmalloc
+#undef ruby_xmalloc
+#endif
+#ifdef ruby_xmalloc2
+#undef ruby_xmalloc2
+#endif
+#ifdef ruby_xcalloc
+#undef ruby_xcalloc
+#endif
+#ifdef ruby_xrealloc
+#undef ruby_xrealloc
+#endif
+#ifdef ruby_xrealloc2
+#undef ruby_xrealloc2
+#endif
+
+void *
+ruby_xmalloc(size_t size)
+{
+#if USE_GC_MALLOC_OBJ_INFO_DETAILS
+    ruby_malloc_info_file = __FILE__;
+    ruby_malloc_info_line = __LINE__;
+#endif
+    return ruby_xmalloc_body(size);
+}
+
+void *
+ruby_xmalloc2(size_t n, size_t size)
+{
+#if USE_GC_MALLOC_OBJ_INFO_DETAILS
+    ruby_malloc_info_file = __FILE__;
+    ruby_malloc_info_line = __LINE__;
+#endif
+    return ruby_xmalloc2_body(n, size);
+}
+
+void *
+ruby_xcalloc(size_t n, size_t size)
+{
+#if USE_GC_MALLOC_OBJ_INFO_DETAILS
+    ruby_malloc_info_file = __FILE__;
+    ruby_malloc_info_line = __LINE__;
+#endif
+    return ruby_xcalloc_body(n, size);
+}
+
+void *
+ruby_xrealloc(void *ptr, size_t new_size)
+{
+#if USE_GC_MALLOC_OBJ_INFO_DETAILS
+    ruby_malloc_info_file = __FILE__;
+    ruby_malloc_info_line = __LINE__;
+#endif
+    return ruby_xrealloc_body(ptr, new_size);
+}
+
+void *
+ruby_xrealloc2(void *ptr, size_t n, size_t new_size)
+{
+#if USE_GC_MALLOC_OBJ_INFO_DETAILS
+    ruby_malloc_info_file = __FILE__;
+    ruby_malloc_info_line = __LINE__;
+#endif
+    return ruby_xrealloc2_body(ptr, n, new_size);
+}
diff -Nuarp ruby-3.0.5.a/gc.rb ruby-3.0.5.b/gc.rb
--- ruby-3.0.5.a/gc.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/gc.rb	2023-02-02 23:12:34.596462504 -0500
@@ -230,6 +230,92 @@ module GC
   def self.verify_compaction_references(toward: nil, double_heap: false)
     Primitive.gc_verify_compaction_references(double_heap, toward == :empty)
   end
+
+  # call-seq:
+  #    GC.enable_stats	  => true or false
+  #
+  # Enables garbage collection statistics, returning <code>true</code> if garbage
+  # collection statistics was already enabled.
+  #
+  #    GC.enable_stats	 #=> false or true
+  #    GC.enable_stats	 #=> true
+  def self.enable_stats
+    __builtin_gc_enable_stats
+  end
+
+  #   call-seq:
+  #    GC.disable_stats	   => true or false
+  #
+  # Disables garbage collection statistics, returning <code>true</code> if garbage
+  # collection statistics was already disabled.
+  #
+  #    GC.disable_stats	  #=> false or true
+  #    GC.disable_stats	  #=> true
+  def self.disable_stats
+    __builtin_gc_disable_stats
+  end
+
+  # call-seq:
+  #    GC.stats_enabled?    => true or false
+  #
+  # Check whether GC stats have been enabled.
+  #
+  #    GC.stats_enabled?   #=> false or true
+  def self.stats_enabled?
+    __builtin_gc_stats_enabled
+  end
+
+  #   call-seq:
+  #    GC.time	  => Integer
+  #
+  # Returns the time spent during garbage collection while GC statistics collection
+  # was enabled (in micro seconds).
+  #
+  #    GC.time	  #=> 20000
+  def self.time
+    __builtin_gc_time
+  end
+
+  #  call-seq:
+  #	GC.heap_slots	=> Integer
+  #
+  #  Returns the number of heap slots available for object allocations.
+  #
+  #	GC.heap_slots	#=> 10000
+  def self.heap_slots
+    __builtin_gc_heap_slots
+  end
+
+  # call-seq:
+  #    GC.heap_slots_live_after_last_gc	   => Integer
+  #
+  # Returns the number of heap slots which were live after the last garbage collection.
+  #
+  #    GC.heap_slots_live_after_last_gc	   #=> 231223
+  def self.heap_slots_live_after_last_gc
+    __builtin_gc_heap_slots_live_after_last_gc
+  end
+
+  #   call-seq:
+  #	 GC.total_mallocs	   => Integer
+  #
+  #   Returns the number malloc calls. Might wrap around.
+  #
+  #	 GC.total_mallocs	   #=> 324234323246
+  def self.total_mallocs
+    __builtin_gc_total_mallocs
+  end
+
+  #   call-seq:
+  #	 GC.total_malloced_bytes	   => Integer
+  #
+  #   Returns the number of bytes allocated. Might wrap around.
+  #
+  #	 GC.total_malloced_bytes	   #=> 354656256432446
+  def self.total_malloced_bytes
+    __builtin_gc_total_malloced_bytes
+  end
+
 end
 
 module ObjectSpace
diff -Nuarp ruby-3.0.5.a/gc.rbinc ruby-3.0.5.b/gc.rbinc
--- ruby-3.0.5.a/gc.rbinc	2022-11-24 06:04:58.000000000 -0500
+++ ruby-3.0.5.b/gc.rbinc	2023-02-02 23:12:58.372651316 -0500
@@ -168,6 +168,78 @@ mjit_compile_invokebuiltin_for_gc_verify
     fprintf(f, "    val = f(ec, self, argv[0], argv[1]);\n");
 }
 
+static void
+mjit_compile_invokebuiltin_for_gc_enable_stats(FILE *f, long index, unsigned stack_size, bool inlinable_p)
+{
+    fprintf(f, "    VALUE self = GET_SELF();\n");
+    fprintf(f, "    typedef VALUE (*func)(rb_execution_context_t *, VALUE);\n");
+    fprintf(f, "    func f = (func)%"PRIdPTR"; /* == gc_enable_stats */\n", (intptr_t)gc_enable_stats);
+    fprintf(f, "    val = f(ec, self);\n");
+}
+
+static void
+mjit_compile_invokebuiltin_for_gc_disable_stats(FILE *f, long index, unsigned stack_size, bool inlinable_p)
+{
+    fprintf(f, "    VALUE self = GET_SELF();\n");
+    fprintf(f, "    typedef VALUE (*func)(rb_execution_context_t *, VALUE);\n");
+    fprintf(f, "    func f = (func)%"PRIdPTR"; /* == gc_disable_stats */\n", (intptr_t)gc_disable_stats);
+    fprintf(f, "    val = f(ec, self);\n");
+}
+
+static void
+mjit_compile_invokebuiltin_for_gc_stats_enabled(FILE *f, long index, unsigned stack_size, bool inlinable_p)
+{
+    fprintf(f, "    VALUE self = GET_SELF();\n");
+    fprintf(f, "    typedef VALUE (*func)(rb_execution_context_t *, VALUE);\n");
+    fprintf(f, "    func f = (func)%"PRIdPTR"; /* == gc_stats_enabled */\n", (intptr_t)gc_stats_enabled);
+    fprintf(f, "    val = f(ec, self);\n");
+}
+
+static void
+mjit_compile_invokebuiltin_for_gc_time(FILE *f, long index, unsigned stack_size, bool inlinable_p)
+{
+    fprintf(f, "    VALUE self = GET_SELF();\n");
+    fprintf(f, "    typedef VALUE (*func)(rb_execution_context_t *, VALUE);\n");
+    fprintf(f, "    func f = (func)%"PRIdPTR"; /* == gc_time */\n", (intptr_t)gc_time);
+    fprintf(f, "    val = f(ec, self);\n");
+}
+
+static void
+mjit_compile_invokebuiltin_for_gc_heap_slots(FILE *f, long index, unsigned stack_size, bool inlinable_p)
+{
+    fprintf(f, "    VALUE self = GET_SELF();\n");
+    fprintf(f, "    typedef VALUE (*func)(rb_execution_context_t *, VALUE);\n");
+    fprintf(f, "    func f = (func)%"PRIdPTR"; /* == gc_heap_slots */\n", (intptr_t)gc_heap_slots);
+    fprintf(f, "    val = f(ec, self);\n");
+}
+
+static void
+mjit_compile_invokebuiltin_for_gc_heap_slots_live_after_last_gc(FILE *f, long index, unsigned stack_size, bool inlinable_p)
+{
+    fprintf(f, "    VALUE self = GET_SELF();\n");
+    fprintf(f, "    typedef VALUE (*func)(rb_execution_context_t *, VALUE);\n");
+    fprintf(f, "    func f = (func)%"PRIdPTR"; /* == gc_heap_slots_live_after_last_gc */\n", (intptr_t)gc_heap_slots_live_after_last_gc);
+    fprintf(f, "    val = f(ec, self);\n");
+}
+
+static void
+mjit_compile_invokebuiltin_for_gc_total_mallocs(FILE *f, long index, unsigned stack_size, bool inlinable_p)
+{
+    fprintf(f, "    VALUE self = GET_SELF();\n");
+    fprintf(f, "    typedef VALUE (*func)(rb_execution_context_t *, VALUE);\n");
+    fprintf(f, "    func f = (func)%"PRIdPTR"; /* == gc_total_mallocs */\n", (intptr_t)gc_total_mallocs);
+    fprintf(f, "    val = f(ec, self);\n");
+}
+
+static void
+mjit_compile_invokebuiltin_for_gc_total_malloced_bytes(FILE *f, long index, unsigned stack_size, bool inlinable_p)
+{
+    fprintf(f, "    VALUE self = GET_SELF();\n");
+    fprintf(f, "    typedef VALUE (*func)(rb_execution_context_t *, VALUE);\n");
+    fprintf(f, "    func f = (func)%"PRIdPTR"; /* == gc_total_malloced_bytes */\n", (intptr_t)gc_total_malloced_bytes);
+    fprintf(f, "    val = f(ec, self);\n");
+}
+
 void Init_builtin_gc(void)
 {
   // table definition
@@ -185,6 +257,14 @@ void Init_builtin_gc(void)
     RB_BUILTIN_FUNCTION(10, gc_compact_stats, gc_compact_stats, 0, mjit_compile_invokebuiltin_for_gc_compact_stats),
     RB_BUILTIN_FUNCTION(11, gc_compact, gc_compact, 0, mjit_compile_invokebuiltin_for_gc_compact),
     RB_BUILTIN_FUNCTION(12, gc_verify_compaction_references, gc_verify_compaction_references, 2, mjit_compile_invokebuiltin_for_gc_verify_compaction_references),
+    RB_BUILTIN_FUNCTION(13, gc_enable_stats, gc_enable_stats, 0, mjit_compile_invokebuiltin_for_gc_enable_stats),
+    RB_BUILTIN_FUNCTION(14, gc_disable_stats, gc_disable_stats, 0, mjit_compile_invokebuiltin_for_gc_disable_stats),
+    RB_BUILTIN_FUNCTION(15, gc_stats_enabled, gc_stats_enabled, 0, mjit_compile_invokebuiltin_for_gc_stats_enabled),
+    RB_BUILTIN_FUNCTION(16, gc_time, gc_time, 0, mjit_compile_invokebuiltin_for_gc_time),
+    RB_BUILTIN_FUNCTION(17, gc_heap_slots, gc_heap_slots, 0, mjit_compile_invokebuiltin_for_gc_heap_slots),
+    RB_BUILTIN_FUNCTION(18, gc_heap_slots_live_after_last_gc, gc_heap_slots_live_after_last_gc, 0, mjit_compile_invokebuiltin_for_gc_heap_slots_live_after_last_gc),
+    RB_BUILTIN_FUNCTION(19, gc_total_mallocs, gc_total_mallocs, 0, mjit_compile_invokebuiltin_for_gc_total_mallocs),
+    RB_BUILTIN_FUNCTION(20, gc_total_malloced_bytes, gc_total_malloced_bytes, 0, mjit_compile_invokebuiltin_for_gc_total_malloced_bytes),
     RB_BUILTIN_FUNCTION(-1, NULL, NULL, 0, 0),
   };
 
@@ -206,6 +286,14 @@ COMPILER_WARNING_ERROR(-Wincompatible-po
   if (0) rb_builtin_function_check_arity0(gc_compact_stats);
   if (0) rb_builtin_function_check_arity0(gc_compact);
   if (0) rb_builtin_function_check_arity2(gc_verify_compaction_references);
+  if (0) rb_builtin_function_check_arity0(gc_enable_stats);
+  if (0) rb_builtin_function_check_arity0(gc_disable_stats);
+  if (0) rb_builtin_function_check_arity0(gc_stats_enabled);
+  if (0) rb_builtin_function_check_arity0(gc_time);
+  if (0) rb_builtin_function_check_arity0(gc_heap_slots);
+  if (0) rb_builtin_function_check_arity0(gc_heap_slots_live_after_last_gc);
+  if (0) rb_builtin_function_check_arity0(gc_total_mallocs);
+  if (0) rb_builtin_function_check_arity0(gc_total_malloced_bytes);
 COMPILER_WARNING_POP
 
   // load
diff -Nuarp ruby-3.0.5.a/include/ruby/internal/intern/gc.h ruby-3.0.5.b/include/ruby/internal/intern/gc.h
--- ruby-3.0.5.a/include/ruby/internal/intern/gc.h	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/include/ruby/internal/intern/gc.h	2023-02-02 23:12:34.596462504 -0500
@@ -51,6 +51,14 @@ size_t rb_gc_count(void);
 size_t rb_gc_stat(VALUE);
 VALUE rb_gc_latest_gc_info(VALUE);
 void rb_gc_adjust_memory_usage(ssize_t);
+VALUE rb_gc_enable_stats(void);
+VALUE rb_gc_disable_stats(void);
+VALUE rb_gc_stats_enabled(void);
+double rb_gc_total_time(void);
+VALUE rb_gc_heap_slots(void);
+VALUE rb_gc_heap_slots_live_after_last_gc(void);
+size_t rb_gc_total_mallocs(void);
+size_t rb_gc_total_malloced_bytes(void);
 
 RBIMPL_SYMBOL_EXPORT_END()
 
diff -Nuarp ruby-3.0.5.a/lib/cgi/cookie.rb ruby-3.0.5.b/lib/cgi/cookie.rb
--- ruby-3.0.5.a/lib/cgi/cookie.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/lib/cgi/cookie.rb	2023-02-02 23:12:17.874329699 -0500
@@ -42,7 +42,7 @@ class CGI
 
     TOKEN_RE = %r"\A[[!-~]&&[^()<>@,;:\\\"/?=\[\]{}]]+\z"
     PATH_VALUE_RE = %r"\A[[ -~]&&[^;]]*\z"
-    DOMAIN_VALUE_RE = %r"\A(?<label>(?!-)[-A-Za-z0-9]+(?<!-))(?:\.\g<label>)*\z"
+    DOMAIN_VALUE_RE = %r"\A\.?(?<label>(?!-)[-A-Za-z0-9]+(?<!-))(?:\.\g<label>)*\z"
 
     # Create a new CGI::Cookie object.
     #
diff -Nuarp ruby-3.0.5.a/lib/mkmf.rb ruby-3.0.5.b/lib/mkmf.rb
--- ruby-3.0.5.a/lib/mkmf.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/lib/mkmf.rb	2023-02-02 23:11:30.894956613 -0500
@@ -1930,7 +1930,7 @@ SRC
 SHELL = /bin/sh
 
 # V=0 quiet, V=1 verbose.  other values don't work.
-V = 0
+V = 1
 Q1 = $(V:1=)
 Q = $(Q1:0=@)
 ECHO1 = $(V:1=@ #{CONFIG['NULLCMD']})
diff -Nuarp ruby-3.0.5.a/lib/rdoc/ri/paths.rb ruby-3.0.5.b/lib/rdoc/ri/paths.rb
--- ruby-3.0.5.a/lib/rdoc/ri/paths.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/lib/rdoc/ri/paths.rb	2023-02-02 23:11:10.392793793 -0500
@@ -10,7 +10,7 @@ module RDoc::RI::Paths
   #:stopdoc:
   require 'rbconfig'
 
-  version = RbConfig::CONFIG['ruby_version']
+  version = RbConfig::CONFIG['ruby_version_dir_name'] || RbConfig::CONFIG['ruby_version']
 
   BASE    = File.join RbConfig::CONFIG['ridir'], version
 
diff -Nuarp ruby-3.0.5.a/lib/rubygems/defaults.rb ruby-3.0.5.b/lib/rubygems/defaults.rb
--- ruby-3.0.5.a/lib/rubygems/defaults.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/lib/rubygems/defaults.rb	2023-02-02 23:11:10.392793793 -0500
@@ -38,13 +38,13 @@ module Gem
              [
                File.dirname(RbConfig::CONFIG['sitedir']),
                'Gems',
-               RbConfig::CONFIG['ruby_version'],
+               RbConfig::CONFIG['ruby_version_dir_name'] || RbConfig::CONFIG['ruby_version']
              ]
            else
              [
                RbConfig::CONFIG['rubylibprefix'],
                'gems',
-               RbConfig::CONFIG['ruby_version'],
+               RbConfig::CONFIG['ruby_version_dir_name'] || RbConfig::CONFIG['ruby_version']
              ]
            end
 
@@ -117,7 +117,8 @@ module Gem
     gem_dir = File.join(Gem.user_home, ".gem")
     gem_dir = File.join(Gem.data_home, "gem") unless File.exist?(gem_dir)
     parts = [gem_dir, ruby_engine]
-    parts << RbConfig::CONFIG['ruby_version'] unless RbConfig::CONFIG['ruby_version'].empty?
+    ruby_version_dir_name = RbConfig::CONFIG['ruby_version_dir_name'] || RbConfig::CONFIG['ruby_version']
+    parts << ruby_version_dir_name unless ruby_version_dir_name.empty?
     File.join parts
   end
 
@@ -252,7 +253,7 @@ module Gem
     return nil unless RbConfig::CONFIG.key? 'vendordir'
 
     File.join RbConfig::CONFIG['vendordir'], 'gems',
-              RbConfig::CONFIG['ruby_version']
+              RbConfig::CONFIG['ruby_version_dir_name'] || RbConfig::CONFIG['ruby_version']
   end
 
   ##
diff -Nuarp ruby-3.0.5.a/lib/rubygems/requirement.rb ruby-3.0.5.b/lib/rubygems/requirement.rb
--- ruby-3.0.5.a/lib/rubygems/requirement.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/lib/rubygems/requirement.rb	2023-02-02 23:12:01.577200275 -0500
@@ -1,5 +1,5 @@
 # frozen_string_literal: true
-require_relative "deprecate"
+require_relative "version"
 
 ##
 # A Requirement is a set of one or more version restrictions. It supports a
diff -Nuarp ruby-3.0.5.a/lib/rubygems/specification.rb ruby-3.0.5.b/lib/rubygems/specification.rb
--- ruby-3.0.5.a/lib/rubygems/specification.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/lib/rubygems/specification.rb	2023-02-02 23:12:01.578200283 -0500
@@ -9,6 +9,8 @@
 require_relative 'deprecate'
 require_relative 'basic_specification'
 require_relative 'stub_specification'
+require_relative 'platform'
+require_relative 'requirement'
 require_relative 'specification_policy'
 require_relative 'util/list'
 
diff -Nuarp ruby-3.0.5.a/lib/rubygems.rb ruby-3.0.5.b/lib/rubygems.rb
--- ruby-3.0.5.a/lib/rubygems.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/lib/rubygems.rb	2023-02-02 23:12:01.579200291 -0500
@@ -1293,7 +1293,12 @@ An Array (#{env.inspect}) was passed in
     end
 
     def default_gem_load_paths
-      @default_gem_load_paths ||= $LOAD_PATH[load_path_insert_index..-1]
+      @default_gem_load_paths ||= $LOAD_PATH[load_path_insert_index..-1].map do |lp|
+        expanded = File.expand_path(lp)
+        next expanded unless File.exist?(expanded)
+
+        File.realpath(expanded)
+      end
     end
   end
 
@@ -1310,39 +1315,21 @@ An Array (#{env.inspect}) was passed in
   autoload :Licenses,           File.expand_path('rubygems/util/licenses', __dir__)
   autoload :NameTuple,          File.expand_path('rubygems/name_tuple', __dir__)
   autoload :PathSupport,        File.expand_path('rubygems/path_support', __dir__)
-  autoload :Platform,           File.expand_path('rubygems/platform', __dir__)
   autoload :RequestSet,         File.expand_path('rubygems/request_set', __dir__)
-  autoload :Requirement,        File.expand_path('rubygems/requirement', __dir__)
   autoload :Resolver,           File.expand_path('rubygems/resolver', __dir__)
   autoload :Source,             File.expand_path('rubygems/source', __dir__)
   autoload :SourceList,         File.expand_path('rubygems/source_list', __dir__)
   autoload :SpecFetcher,        File.expand_path('rubygems/spec_fetcher', __dir__)
-  autoload :Specification,      File.expand_path('rubygems/specification', __dir__)
   autoload :Util,               File.expand_path('rubygems/util', __dir__)
   autoload :Version,            File.expand_path('rubygems/version', __dir__)
 end
 
 require_relative 'rubygems/exceptions'
+require_relative 'rubygems/specification'
 
 # REFACTOR: This should be pulled out into some kind of hacks file.
 begin
   ##
-  # Defaults the Ruby implementation wants to provide for RubyGems
-
-  require "rubygems/defaults/#{RUBY_ENGINE}"
-rescue LoadError
-end
-
-##
-# Loads the default specs.
-Gem::Specification.load_defaults
-
-require_relative 'rubygems/core_ext/kernel_gem'
-require_relative 'rubygems/core_ext/kernel_require'
-require_relative 'rubygems/core_ext/kernel_warn'
-
-begin
-  ##
   # Defaults the operating system (or packager) wants to provide for RubyGems.
 
   require 'rubygems/defaults/operating_system'
@@ -1356,3 +1343,19 @@ rescue StandardError => e
     "the problem and ask for help."
   raise e.class, msg
 end
+
+begin
+  ##
+  # Defaults the Ruby implementation wants to provide for RubyGems
+
+  require "rubygems/defaults/#{RUBY_ENGINE}"
+rescue LoadError
+end
+
+##
+# Loads the default specs.
+Gem::Specification.load_defaults
+
+require_relative 'rubygems/core_ext/kernel_gem'
+require_relative 'rubygems/core_ext/kernel_require'
+require_relative 'rubygems/core_ext/kernel_warn'
diff -Nuarp ruby-3.0.5.a/loadpath.c ruby-3.0.5.b/loadpath.c
--- ruby-3.0.5.a/loadpath.c	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/loadpath.c	2023-02-02 23:11:27.109926555 -0500
@@ -65,22 +65,38 @@ const char ruby_initial_load_paths[] =
     RUBY_SEARCH_PATH "\0"
 #endif
 #ifndef NO_RUBY_SITE_LIB
+#ifdef RUBY_LIB_VERSION_BLANK
+    RUBY_SITE_LIB "\0"
+#else
     RUBY_SITE_LIB2 "\0"
+#endif
 #ifdef RUBY_THINARCH
     RUBY_SITE_ARCH_LIB_FOR(RUBY_THINARCH) "\0"
 #endif
     RUBY_SITE_ARCH_LIB_FOR(RUBY_SITEARCH) "\0"
+#ifndef RUBY_LIB_VERSION_BLANK
     RUBY_SITE_LIB "\0"
 #endif
+#endif
 
 #ifndef NO_RUBY_VENDOR_LIB
+#ifdef RUBY_LIB_VERSION_BLANK
+    RUBY_VENDOR_LIB "\0"
+#else
     RUBY_VENDOR_LIB2 "\0"
+#endif
 #ifdef RUBY_THINARCH
     RUBY_VENDOR_ARCH_LIB_FOR(RUBY_THINARCH) "\0"
 #endif
     RUBY_VENDOR_ARCH_LIB_FOR(RUBY_SITEARCH) "\0"
+#ifndef RUBY_LIB_VERSION_BLANK
     RUBY_VENDOR_LIB "\0"
 #endif
+#endif
+
+#ifdef RUBYGEMS_DIR
+    RUBYGEMS_DIR "\0"
+#endif
 
     RUBY_LIB "\0"
 #ifdef RUBY_THINARCH
diff -Nuarp ruby-3.0.5.a/miniprelude.c ruby-3.0.5.b/miniprelude.c
--- ruby-3.0.5.a/miniprelude.c	2022-11-24 06:04:58.000000000 -0500
+++ ruby-3.0.5.b/miniprelude.c	2023-02-02 23:12:48.693574454 -0500
@@ -322,8 +322,9 @@ static const char prelude_name2[] = "<in
 static const struct {
     char L0[489]; /* 1..58 */
     char L58[486]; /* 59..182 */
-    char L182[430]; /* 183..235 */
-    char L235[211]; /* 236..242 */
+    char L182[484]; /* 183..253 */
+    char L253[506]; /* 254..320 */
+    char L320[230]; /* 321..328 */
 } prelude_code2 = {
 #line 1 "gc.rb"
 "\n"/* for gc.c */
@@ -562,18 +563,106 @@ static const struct {
 "  def self.verify_compaction_references(toward: nil, double_heap: false)\n"
 "    Primitive.gc_verify_compaction_references(double_heap, toward == :empty)\n"
 "  end\n"
+"\n"
+"\n"/* call-seq: */
+"\n"/*    GC.enable_stats	  => true or false */
+"\n"/*  */
+"\n"/* Enables garbage collection statistics, returning <code>true</code> if garbage */
+"\n"/* collection statistics was already enabled. */
+"\n"/*  */
+"\n"/*    GC.enable_stats	 #=> false or true */
+"\n"/*    GC.enable_stats	 #=> true */
+"  def self.enable_stats\n"
+"    __builtin_gc_enable_stats\n"
+"  end\n"
+"\n"
+"\n"/*   call-seq: */
+"\n"/*    GC.disable_stats	   => true or false */
+"\n"/*  */
+"\n"/* Disables garbage collection statistics, returning <code>true</code> if garbage */
+"\n"/* collection statistics was already disabled. */
+"\n"/*  */
+"\n"/*    GC.disable_stats	  #=> false or true */
+"\n"/*    GC.disable_stats	  #=> true */
+,
+#line 254 "gc.rb"
+"  def self.disable_stats\n"
+"    __builtin_gc_disable_stats\n"
+"  end\n"
+"\n"
+"\n"/* call-seq: */
+"\n"/*    GC.stats_enabled?    => true or false */
+"\n"/*  */
+"\n"/* Check whether GC stats have been enabled. */
+"\n"/*  */
+"\n"/*    GC.stats_enabled?   #=> false or true */
+"  def self.stats_enabled?\n"
+"    __builtin_gc_stats_enabled\n"
+"  end\n"
+"\n"
+"\n"/*   call-seq: */
+"\n"/*    GC.time	  => Integer */
+"\n"/*  */
+"\n"/* Returns the time spent during garbage collection while GC statistics collection */
+"\n"/* was enabled (in micro seconds). */
+"\n"/*  */
+"\n"/*    GC.time	  #=> 20000 */
+"  def self.time\n"
+"    __builtin_gc_time\n"
+"  end\n"
+"\n"
+"\n"/*  call-seq: */
+"\n"/* GC.heap_slots	=> Integer */
+"\n"/*  */
+"\n"/*  Returns the number of heap slots available for object allocations. */
+"\n"/*  */
+"\n"/* GC.heap_slots	#=> 10000 */
+"  def self.heap_slots\n"
+"    __builtin_gc_heap_slots\n"
+"  end\n"
+"\n"
+"\n"/* call-seq: */
+"\n"/*    GC.heap_slots_live_after_last_gc	   => Integer */
+"\n"/*  */
+"\n"/* Returns the number of heap slots which were live after the last garbage collection. */
+"\n"/*  */
+"\n"/*    GC.heap_slots_live_after_last_gc	   #=> 231223 */
+"  def self.heap_slots_live_after_last_gc\n"
+"    __builtin_gc_heap_slots_live_after_last_gc\n"
+"  end\n"
+"\n"
+"\n"/*   call-seq: */
+"\n"/*  GC.total_mallocs	   => Integer */
+"\n"/*  */
+"\n"/*   Returns the number malloc calls. Might wrap around. */
+"\n"/*  */
+"\n"/*  GC.total_mallocs	   #=> 324234323246 */
+"  def self.total_mallocs\n"
+"    __builtin_gc_total_mallocs\n"
+"  end\n"
+"\n"
+"\n"/*   call-seq: */
+"\n"/*  GC.total_malloced_bytes	   => Integer */
+"\n"/*  */
+"\n"/*   Returns the number of bytes allocated. Might wrap around. */
+"\n"/*  */
+"\n"/*  GC.total_malloced_bytes	   #=> 354656256432446 */
+"  def self.total_malloced_bytes\n"
+"    __builtin_gc_total_malloced_bytes\n"
+"  end\n"
+"\n"
 "end\n"
 "\n"
-"module ObjectSpace\n"
 ,
-#line 236 "gc.rb"
+#line 321 "gc.rb"
+"module ObjectSpace\n"
 "  def garbage_collect full_mark: true, immediate_mark: true, immediate_sweep: true\n"
 "    Primitive.gc_start_internal full_mark, immediate_mark, immediate_sweep, false\n"
 "  end\n"
 "\n"
 "  module_function :garbage_collect\n"
 "end\n"
-#line 577 "miniprelude.c"
+#line 666 "miniprelude.c"
 };
 
 static const char prelude_name3[] = "<internal:integer>";
@@ -734,7 +823,7 @@ static const struct {
 "    Primitive.cexpr! 'rb_int_zero_p(self)'\n"
 "  end\n"
 "end\n"
-#line 738 "miniprelude.c"
+#line 827 "miniprelude.c"
 };
 
 static const char prelude_name4[] = "<internal:io>";
@@ -865,7 +954,7 @@ static const struct {
 "    Primitive.io_write_nonblock(buf, exception)\n"
 "  end\n"
 "end\n"
-#line 869 "miniprelude.c"
+#line 958 "miniprelude.c"
 };
 
 static const char prelude_name5[] = "<internal:pack>";
@@ -1156,7 +1245,7 @@ static const struct {
 "    Primitive.pack_unpack1(fmt)\n"
 "  end\n"
 "end\n"
-#line 1160 "miniprelude.c"
+#line 1249 "miniprelude.c"
 };
 
 static const char prelude_name6[] = "<internal:trace_point>";
@@ -1521,7 +1610,7 @@ static const struct {
 "    Primitive.tracepoint_attr_instruction_sequence\n"
 "  end\n"
 "end\n"
-#line 1525 "miniprelude.c"
+#line 1614 "miniprelude.c"
 };
 
 static const char prelude_name7[] = "<internal:warning>";
@@ -1582,7 +1671,7 @@ static const struct {
 "    Primitive.rb_warn_m(msgs, uplevel, category)\n"
 "  end\n"
 "end\n"
-#line 1586 "miniprelude.c"
+#line 1675 "miniprelude.c"
 };
 
 static const char prelude_name8[] = "<internal:array>";
@@ -1651,7 +1740,7 @@ static const struct {
 "    Primitive.rb_ary_sample(random, n, ary)\n"
 "  end\n"
 "end\n"
-#line 1655 "miniprelude.c"
+#line 1744 "miniprelude.c"
 };
 
 static const char prelude_name9[] = "<internal:kernel>";
@@ -1836,7 +1925,7 @@ static const struct {
 "    Primitive.rb_f_float(arg, exception)\n"
 "  end\n"
 "end\n"
-#line 1840 "miniprelude.c"
+#line 1929 "miniprelude.c"
 };
 
 static const char prelude_name10[] = "<internal:ractor>";
@@ -2703,7 +2792,7 @@ static const struct {
 "    }\n"
 "  end\n"
 "end\n"
-#line 2707 "miniprelude.c"
+#line 2796 "miniprelude.c"
 };
 
 static const char prelude_name11[] = "<internal:prelude>";
@@ -2733,7 +2822,7 @@ static const struct {
 "\n"
 "  private :pp\n"
 "end\n"
-#line 2737 "miniprelude.c"
+#line 2826 "miniprelude.c"
 };
 
 static const char prelude_name12[] = "<internal:gem_prelude>";
@@ -2752,7 +2841,7 @@ static const struct {
 "rescue LoadError\n"
 "  warn \"`did_you_mean' was not loaded.\"\n"
 "end if defined?(DidYouMean)\n"
-#line 2756 "miniprelude.c"
+#line 2845 "miniprelude.c"
 };
 
 COMPILER_WARNING_POP
diff -Nuarp ruby-3.0.5.a/ruby.c ruby-3.0.5.b/ruby.c
--- ruby-3.0.5.a/ruby.c	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/ruby.c	2023-02-02 23:11:35.059989689 -0500
@@ -1501,10 +1501,14 @@ proc_options(long argc, char **argv, rub
 
 void Init_builtin_features(void);
 
+/* abrt.c */
+void Init_abrt(void);
+
 static void
 ruby_init_prelude(void)
 {
     Init_builtin_features();
+    Init_abrt();
     rb_const_remove(rb_cObject, rb_intern_const("TMP_RUBY_PREFIX"));
 }
 
diff -Nuarp ruby-3.0.5.a/ruby.c.orig ruby-3.0.5.b/ruby.c.orig
--- ruby-3.0.5.a/ruby.c.orig	1969-12-31 19:00:00.000000000 -0500
+++ ruby-3.0.5.b/ruby.c.orig	2023-02-02 23:10:58.636700431 -0500
@@ -0,0 +1,2668 @@
+/**********************************************************************
+
+  ruby.c -
+
+  $Author$
+  created at: Tue Aug 10 12:47:31 JST 1993
+
+  Copyright (C) 1993-2007 Yukihiro Matsumoto
+  Copyright (C) 2000  Network Applied Communication Laboratory, Inc.
+  Copyright (C) 2000  Information-technology Promotion Agency, Japan
+
+**********************************************************************/
+
+#include "ruby/internal/config.h"
+
+#include <ctype.h>
+#include <stdio.h>
+#include <sys/types.h>
+
+#ifdef __CYGWIN__
+# include <windows.h>
+# include <sys/cygwin.h>
+#endif
+
+#ifdef __hpux
+# include <sys/pstat.h>
+#endif
+
+#if (defined(LOAD_RELATIVE) || defined(__MACH__)) && defined(HAVE_DLADDR)
+# include <dlfcn.h>
+#endif
+
+#ifdef HAVE_UNISTD_H
+# include <unistd.h>
+#endif
+
+#if defined(HAVE_FCNTL_H)
+# include <fcntl.h>
+#elif defined(HAVE_SYS_FCNTL_H)
+# include <sys/fcntl.h>
+#endif
+
+#ifdef HAVE_SYS_PARAM_H
+# include <sys/param.h>
+#endif
+
+#include "dln.h"
+#include "eval_intern.h"
+#include "internal.h"
+#include "internal/error.h"
+#include "internal/file.h"
+#include "internal/inits.h"
+#include "internal/io.h"
+#include "internal/load.h"
+#include "internal/loadpath.h"
+#include "internal/missing.h"
+#include "internal/object.h"
+#include "internal/parse.h"
+#include "internal/process.h"
+#include "internal/variable.h"
+#include "mjit.h"
+#include "ruby/encoding.h"
+#include "ruby/thread.h"
+#include "ruby/util.h"
+#include "ruby/version.h"
+#include "ruby/internal/error.h"
+
+#ifndef MAXPATHLEN
+# define MAXPATHLEN 1024
+#endif
+#ifndef O_ACCMODE
+# define O_ACCMODE (O_RDONLY | O_WRONLY | O_RDWR)
+#endif
+
+void Init_ruby_description(void);
+
+#ifndef HAVE_STDLIB_H
+char *getenv();
+#endif
+
+#ifndef DISABLE_RUBYGEMS
+# define DISABLE_RUBYGEMS 0
+#endif
+#if DISABLE_RUBYGEMS
+#define DEFAULT_RUBYGEMS_ENABLED "disabled"
+#else
+#define DEFAULT_RUBYGEMS_ENABLED "enabled"
+#endif
+
+void rb_warning_category_update(unsigned int mask, unsigned int bits);
+
+#define COMMA ,
+#define FEATURE_BIT(bit) (1U << feature_##bit)
+#define EACH_FEATURES(X, SEP) \
+    X(gems) \
+    SEP \
+    X(did_you_mean) \
+    SEP \
+    X(rubyopt) \
+    SEP \
+    X(frozen_string_literal) \
+    SEP \
+    X(jit) \
+    /* END OF FEATURES */
+#define EACH_DEBUG_FEATURES(X, SEP) \
+    X(frozen_string_literal) \
+    /* END OF DEBUG FEATURES */
+#define AMBIGUOUS_FEATURE_NAMES 0 /* no ambiguous feature names now */
+#define DEFINE_FEATURE(bit) feature_##bit
+#define DEFINE_DEBUG_FEATURE(bit) feature_debug_##bit
+enum feature_flag_bits {
+    EACH_FEATURES(DEFINE_FEATURE, COMMA),
+    feature_debug_flag_first,
+    feature_debug_flag_begin = feature_debug_flag_first - 1,
+    EACH_DEBUG_FEATURES(DEFINE_DEBUG_FEATURE, COMMA),
+    feature_flag_count
+};
+
+#define DEBUG_BIT(bit) (1U << feature_debug_##bit)
+
+#define DUMP_BIT(bit) (1U << dump_##bit)
+#define DEFINE_DUMP(bit) dump_##bit
+#define EACH_DUMPS(X, SEP) \
+    X(version) \
+    SEP \
+    X(copyright) \
+    SEP \
+    X(usage) \
+    SEP \
+    X(help) \
+    SEP \
+    X(yydebug) \
+    SEP \
+    X(syntax) \
+    SEP \
+    X(parsetree) \
+    SEP \
+    X(parsetree_with_comment) \
+    SEP \
+    X(insns) \
+    /* END OF DUMPS */
+enum dump_flag_bits {
+    dump_version_v,
+    EACH_DUMPS(DEFINE_DUMP, COMMA),
+    dump_exit_bits = (DUMP_BIT(yydebug) | DUMP_BIT(syntax) |
+		      DUMP_BIT(parsetree) | DUMP_BIT(parsetree_with_comment) |
+		      DUMP_BIT(insns))
+};
+
+typedef struct ruby_cmdline_options ruby_cmdline_options_t;
+
+typedef struct {
+    unsigned int mask;
+    unsigned int set;
+} ruby_features_t;
+
+static inline void
+rb_feature_set_to(ruby_features_t *feat, unsigned int bit_mask, unsigned int bit_set)
+{
+    feat->mask |= bit_mask;
+    feat->set = (feat->set & ~bit_mask) | bit_set;
+}
+
+#define FEATURE_SET_TO(feat, bit_mask, bit_set) \
+    rb_feature_set_to(&(feat), bit_mask, bit_set)
+#define FEATURE_SET(feat, bits) FEATURE_SET_TO(feat, bits, bits)
+#define FEATURE_SET_RESTORE(feat, save) FEATURE_SET_TO(feat, (save).mask, (save).set & (save).mask)
+#define FEATURE_SET_P(feat, bits) ((feat).set & (bits))
+
+struct ruby_cmdline_options {
+    const char *script;
+    VALUE script_name;
+    VALUE e_script;
+    struct {
+	struct {
+	    VALUE name;
+	    int index;
+	} enc;
+    } src, ext, intern;
+    VALUE req_list;
+    ruby_features_t features;
+    ruby_features_t warn;
+    unsigned int dump;
+#if USE_MJIT
+    struct mjit_options mjit;
+#endif
+    int sflag, xflag;
+    unsigned int warning: 1;
+    unsigned int verbose: 1;
+    unsigned int do_loop: 1;
+    unsigned int do_print: 1;
+    unsigned int do_line: 1;
+    unsigned int do_split: 1;
+    unsigned int do_search: 1;
+    unsigned int setids: 2;
+};
+
+static void init_ids(ruby_cmdline_options_t *);
+
+#define src_encoding_index GET_VM()->src_encoding_index
+
+enum {
+    COMPILATION_FEATURES = (
+	0
+	| FEATURE_BIT(frozen_string_literal)
+	| FEATURE_BIT(debug_frozen_string_literal)
+	),
+    DEFAULT_FEATURES = (
+	(FEATURE_BIT(debug_flag_first)-1)
+#if DISABLE_RUBYGEMS
+	& ~FEATURE_BIT(gems)
+#endif
+	& ~FEATURE_BIT(frozen_string_literal)
+        & ~FEATURE_BIT(jit)
+	)
+};
+
+static ruby_cmdline_options_t *
+cmdline_options_init(ruby_cmdline_options_t *opt)
+{
+    MEMZERO(opt, *opt, 1);
+    init_ids(opt);
+    opt->src.enc.index = src_encoding_index;
+    opt->ext.enc.index = -1;
+    opt->intern.enc.index = -1;
+    opt->features.set = DEFAULT_FEATURES;
+#ifdef MJIT_FORCE_ENABLE /* to use with: ./configure cppflags="-DMJIT_FORCE_ENABLE" */
+    opt->features.set |= FEATURE_BIT(jit);
+#endif
+    return opt;
+}
+
+static rb_ast_t *load_file(VALUE parser, VALUE fname, VALUE f, int script,
+		       ruby_cmdline_options_t *opt);
+static VALUE open_load_file(VALUE fname_v, int *xflag);
+static void forbid_setid(const char *, const ruby_cmdline_options_t *);
+#define forbid_setid(s) forbid_setid((s), opt)
+
+static struct {
+    int argc;
+    char **argv;
+} origarg;
+
+static const char esc_standout[] = "\n\033[1;7m";
+static const char esc_bold[] = "\033[1m";
+static const char esc_reset[] = "\033[0m";
+static const char esc_none[] = "";
+
+static void
+show_usage_line(const char *str, unsigned int namelen, unsigned int secondlen, int help, int highlight, unsigned int w)
+{
+    const char *sb = highlight ? esc_bold : esc_none;
+    const char *se = highlight ? esc_reset : esc_none;
+    const int wrap = help && namelen + secondlen - 1 > w;
+    printf("  %s%.*s%-*.*s%s%-*s%s\n", sb, namelen-1, str,
+	   (wrap ? 0 : w - namelen + 1),
+	   (help ? secondlen-1 : 0), str + namelen, se,
+	   (wrap ? w + 3 : 0), (wrap ? "\n" : ""),
+	   str + namelen + secondlen);
+}
+
+static void
+usage(const char *name, int help, int highlight, int columns)
+{
+    /* This message really ought to be max 23 lines.
+     * Removed -h because the user already knows that option. Others? */
+
+    struct message {
+	const char *str;
+	unsigned short namelen, secondlen;
+    };
+#define M(shortopt, longopt, desc) { \
+    shortopt " " longopt " " desc, \
+    (unsigned short)sizeof(shortopt), \
+    (unsigned short)sizeof(longopt), \
+}
+    static const struct message usage_msg[] = {
+	M("-0[octal]",	   "",			   "specify record separator (\\0, if no argument)"),
+	M("-a",		   "",			   "autosplit mode with -n or -p (splits $_ into $F)"),
+	M("-c",		   "",			   "check syntax only"),
+	M("-Cdirectory",   "",			   "cd to directory before executing your script"),
+	M("-d",		   ", --debug",		   "set debugging flags (set $DEBUG to true)"),
+	M("-e 'command'",  "",			   "one line of script. Several -e's allowed. Omit [programfile]"),
+	M("-Eex[:in]",     ", --encoding=ex[:in]", "specify the default external and internal character encodings"),
+	M("-Fpattern",	   "",			   "split() pattern for autosplit (-a)"),
+	M("-i[extension]", "",			   "edit ARGV files in place (make backup if extension supplied)"),
+	M("-Idirectory",   "",			   "specify $LOAD_PATH directory (may be used more than once)"),
+	M("-l",		   "",			   "enable line ending processing"),
+	M("-n",		   "",			   "assume 'while gets(); ... end' loop around your script"),
+	M("-p",		   "",			   "assume loop like -n but print line also like sed"),
+	M("-rlibrary",	   "",			   "require the library before executing your script"),
+	M("-s",		   "",			   "enable some switch parsing for switches after script name"),
+	M("-S",		   "",			   "look for the script using PATH environment variable"),
+	M("-v",		   "",			   "print the version number, then turn on verbose mode"),
+	M("-w",		   "",			   "turn warnings on for your script"),
+	M("-W[level=2|:category]",   "",	   "set warning level; 0=silence, 1=medium, 2=verbose"),
+	M("-x[directory]", "",			   "strip off text before #!ruby line and perhaps cd to directory"),
+        M("--jit",         "",                     "enable JIT with default options (experimental)"),
+        M("--jit-[option]","",                     "enable JIT with an option (experimental)"),
+	M("-h",		   "",			   "show this message, --help for more info"),
+    };
+    static const struct message help_msg[] = {
+	M("--copyright",                            "", "print the copyright"),
+	M("--dump={insns|parsetree|...}[,...]",     "",
+          "dump debug information. see below for available dump list"),
+	M("--enable={gems|rubyopt|...}[,...]", ", --disable={gems|rubyopt|...}[,...]",
+	  "enable or disable features. see below for available features"),
+	M("--external-encoding=encoding",           ", --internal-encoding=encoding",
+	  "specify the default external or internal character encoding"),
+	M("--verbose",                              "", "turn on verbose mode and disable script from stdin"),
+	M("--version",                              "", "print the version number, then exit"),
+	M("--help",			            "", "show this message, -h for short message"),
+	M("--backtrace-limit=num",                  "", "limit the maximum length of backtrace"),
+    };
+    static const struct message dumps[] = {
+	M("insns",                  "", "instruction sequences"),
+	M("yydebug",                "", "yydebug of yacc parser generator"),
+	M("parsetree",              "", "AST"),
+	M("parsetree_with_comment", "", "AST with comments"),
+    };
+    static const struct message features[] = {
+	M("gems",    "",        "rubygems (default: "DEFAULT_RUBYGEMS_ENABLED")"),
+	M("did_you_mean", "",   "did_you_mean (default: "DEFAULT_RUBYGEMS_ENABLED")"),
+	M("rubyopt", "",        "RUBYOPT environment variable (default: enabled)"),
+	M("frozen-string-literal", "", "freeze all string literals (default: disabled)"),
+        M("jit", "",            "JIT compiler (default: disabled)"),
+    };
+    static const struct message warn_categories[] = {
+        M("deprecated", "",       "deprecated features"),
+        M("experimental", "",     "experimental features"),
+    };
+    static const struct message mjit_options[] = {
+        M("--jit-warnings",      "", "Enable printing JIT warnings"),
+        M("--jit-debug",         "", "Enable JIT debugging (very slow), or add cflags if specified"),
+        M("--jit-wait",          "", "Wait until JIT compilation finishes every time (for testing)"),
+        M("--jit-save-temps",    "", "Save JIT temporary files in $TMP or /tmp (for testing)"),
+        M("--jit-verbose=num",   "", "Print JIT logs of level num or less to stderr (default: 0)"),
+        M("--jit-max-cache=num", "", "Max number of methods to be JIT-ed in a cache (default: 100)"),
+        M("--jit-min-calls=num", "", "Number of calls to trigger JIT (for testing, default: 10000)"),
+    };
+    int i;
+    const char *sb = highlight ? esc_standout+1 : esc_none;
+    const char *se = highlight ? esc_reset : esc_none;
+    const int num = numberof(usage_msg) - (help ? 1 : 0);
+    unsigned int w = (columns > 80 ? (columns - 79) / 2 : 0) + 16;
+#define SHOW(m) show_usage_line((m).str, (m).namelen, (m).secondlen, help, highlight, w)
+
+    printf("%sUsage:%s %s [switches] [--] [programfile] [arguments]\n", sb, se, name);
+    for (i = 0; i < num; ++i)
+	SHOW(usage_msg[i]);
+
+    if (!help) return;
+
+    if (highlight) sb = esc_standout;
+
+    for (i = 0; i < numberof(help_msg); ++i)
+	SHOW(help_msg[i]);
+    printf("%s""Dump List:%s\n", sb, se);
+    for (i = 0; i < numberof(dumps); ++i)
+	SHOW(dumps[i]);
+    printf("%s""Features:%s\n", sb, se);
+    for (i = 0; i < numberof(features); ++i)
+	SHOW(features[i]);
+    printf("%s""Warning categories:%s\n", sb, se);
+    for (i = 0; i < numberof(warn_categories); ++i)
+	SHOW(warn_categories[i]);
+    printf("%s""JIT options (experimental):%s\n", sb, se);
+    for (i = 0; i < numberof(mjit_options); ++i)
+	SHOW(mjit_options[i]);
+}
+
+#define rubylib_path_new rb_str_new
+
+static void
+push_include(const char *path, VALUE (*filter)(VALUE))
+{
+    const char sep = PATH_SEP_CHAR;
+    const char *p, *s;
+    VALUE load_path = GET_VM()->load_path;
+
+    p = path;
+    while (*p) {
+	while (*p == sep)
+	    p++;
+	if (!*p) break;
+	for (s = p; *s && *s != sep; s = CharNext(s));
+	rb_ary_push(load_path, (*filter)(rubylib_path_new(p, s - p)));
+	p = s;
+    }
+}
+
+#ifdef __CYGWIN__
+static void
+push_include_cygwin(const char *path, VALUE (*filter)(VALUE))
+{
+    const char *p, *s;
+    char rubylib[FILENAME_MAX];
+    VALUE buf = 0;
+
+    p = path;
+    while (*p) {
+	unsigned int len;
+	while (*p == ';')
+	    p++;
+	if (!*p) break;
+	for (s = p; *s && *s != ';'; s = CharNext(s));
+	len = s - p;
+	if (*s) {
+	    if (!buf) {
+		buf = rb_str_new(p, len);
+		p = RSTRING_PTR(buf);
+	    }
+	    else {
+		rb_str_resize(buf, len);
+		p = strncpy(RSTRING_PTR(buf), p, len);
+	    }
+	}
+#ifdef HAVE_CYGWIN_CONV_PATH
+#define CONV_TO_POSIX_PATH(p, lib) \
+	cygwin_conv_path(CCP_WIN_A_TO_POSIX|CCP_RELATIVE, (p), (lib), sizeof(lib))
+#else
+# error no cygwin_conv_path
+#endif
+	if (CONV_TO_POSIX_PATH(p, rubylib) == 0)
+	    p = rubylib;
+	push_include(p, filter);
+	if (!*s) break;
+	p = s + 1;
+    }
+}
+
+#define push_include push_include_cygwin
+#endif
+
+void
+ruby_push_include(const char *path, VALUE (*filter)(VALUE))
+{
+    if (path == 0)
+	return;
+    push_include(path, filter);
+}
+
+static VALUE
+identical_path(VALUE path)
+{
+    return path;
+}
+static VALUE
+locale_path(VALUE path)
+{
+    rb_enc_associate(path, rb_locale_encoding());
+    return path;
+}
+
+void
+ruby_incpush(const char *path)
+{
+    ruby_push_include(path, locale_path);
+}
+
+static VALUE
+expand_include_path(VALUE path)
+{
+    char *p = RSTRING_PTR(path);
+    if (!p)
+	return path;
+    if (*p == '.' && p[1] == '/')
+	return path;
+    return rb_file_expand_path(path, Qnil);
+}
+
+void
+ruby_incpush_expand(const char *path)
+{
+    ruby_push_include(path, expand_include_path);
+}
+
+#undef UTF8_PATH
+#if defined _WIN32 || defined __CYGWIN__
+static HMODULE libruby;
+
+BOOL WINAPI
+DllMain(HINSTANCE dll, DWORD reason, LPVOID reserved)
+{
+    if (reason == DLL_PROCESS_ATTACH)
+	libruby = dll;
+    return TRUE;
+}
+
+HANDLE
+rb_libruby_handle(void)
+{
+    return libruby;
+}
+
+static inline void
+translit_char_bin(char *p, int from, int to)
+{
+    while (*p) {
+	if ((unsigned char)*p == from)
+	    *p = to;
+	p++;
+    }
+}
+#endif
+
+#ifdef _WIN32
+# define UTF8_PATH 1
+#endif
+
+#ifndef UTF8_PATH
+# define UTF8_PATH 0
+#endif
+#if UTF8_PATH
+# define IF_UTF8_PATH(t, f) t
+#else
+# define IF_UTF8_PATH(t, f) f
+#endif
+
+#if UTF8_PATH
+static VALUE
+str_conv_enc(VALUE str, rb_encoding *from, rb_encoding *to)
+{
+    return rb_str_conv_enc_opts(str, from, to,
+				ECONV_UNDEF_REPLACE|ECONV_INVALID_REPLACE,
+				Qnil);
+}
+#else
+# define str_conv_enc(str, from, to) (str)
+#endif
+
+void ruby_init_loadpath(void);
+
+#if defined(LOAD_RELATIVE) || defined(__MACH__)
+static VALUE
+runtime_libruby_path(void)
+{
+#if defined _WIN32 || defined __CYGWIN__
+    DWORD len = RSTRING_EMBED_LEN_MAX, ret;
+    VALUE path;
+    VALUE wsopath = rb_str_new(0, len*sizeof(WCHAR));
+    WCHAR *wlibpath;
+    char *libpath;
+
+    while (wlibpath = (WCHAR *)RSTRING_PTR(wsopath),
+	   ret = GetModuleFileNameW(libruby, wlibpath, len),
+	   (ret == len))
+    {
+	rb_str_modify_expand(wsopath, len*sizeof(WCHAR));
+	rb_str_set_len(wsopath, (len += len)*sizeof(WCHAR));
+    }
+    if (!ret || ret > len) rb_fatal("failed to get module file name");
+#if defined __CYGWIN__
+    {
+	const int win_to_posix = CCP_WIN_W_TO_POSIX | CCP_RELATIVE;
+	size_t newsize = cygwin_conv_path(win_to_posix, wlibpath, 0, 0);
+	if (!newsize) rb_fatal("failed to convert module path to cygwin");
+	path = rb_str_new(0, newsize);
+	libpath = RSTRING_PTR(path);
+	if (cygwin_conv_path(win_to_posix, wlibpath, libpath, newsize)) {
+	    rb_str_resize(path, 0);
+	}
+    }
+#else
+    {
+	DWORD i;
+	for (len = ret, i = 0; i < len; ++i) {
+	    if (wlibpath[i] == L'\\') {
+		wlibpath[i] = L'/';
+		ret = i+1;	/* chop after the last separator */
+	    }
+	}
+    }
+    len = WideCharToMultiByte(CP_UTF8, 0, wlibpath, ret, NULL, 0, NULL, NULL);
+    path = rb_utf8_str_new(0, len);
+    libpath = RSTRING_PTR(path);
+    WideCharToMultiByte(CP_UTF8, 0, wlibpath, ret, libpath, len, NULL, NULL);
+#endif
+    rb_str_resize(wsopath, 0);
+    return path;
+#elif defined(HAVE_DLADDR)
+    Dl_info dli;
+    VALUE fname, path;
+    const void* addr = (void *)(VALUE)expand_include_path;
+
+    if (!dladdr((void *)addr, &dli)) {
+	return rb_str_new(0, 0);
+    }
+#ifdef __linux__
+    else if (origarg.argc > 0 && origarg.argv && dli.dli_fname == origarg.argv[0]) {
+	fname = rb_str_new_cstr("/proc/self/exe");
+	path = rb_readlink(fname, NULL);
+    }
+#endif
+    else {
+	fname = rb_str_new_cstr(dli.dli_fname);
+	path = rb_realpath_internal(Qnil, fname, 1);
+    }
+    rb_str_resize(fname, 0);
+    return path;
+#else
+# error relative load path is not supported on this platform.
+#endif
+}
+#endif
+
+#define INITIAL_LOAD_PATH_MARK rb_intern_const("@gem_prelude_index")
+
+VALUE ruby_archlibdir_path, ruby_prefix_path;
+#if defined(__MACH__)
+// A path to libruby.dylib itself or where it's statically linked to.
+VALUE rb_libruby_selfpath;
+#endif
+
+void
+ruby_init_loadpath(void)
+{
+    VALUE load_path, archlibdir = 0;
+    ID id_initial_load_path_mark;
+    const char *paths = ruby_initial_load_paths;
+#if defined(LOAD_RELATIVE) || defined(__MACH__)
+    VALUE libruby_path = runtime_libruby_path();
+# if defined(__MACH__)
+    rb_libruby_selfpath = libruby_path;
+    rb_gc_register_address(&rb_libruby_selfpath);
+# endif
+#endif
+
+#if defined LOAD_RELATIVE
+#if !defined ENABLE_MULTIARCH
+# define RUBY_ARCH_PATH ""
+#elif defined RUBY_ARCH
+# define RUBY_ARCH_PATH "/"RUBY_ARCH
+#else
+# define RUBY_ARCH_PATH "/"RUBY_PLATFORM
+#endif
+    char *libpath;
+    VALUE sopath;
+    size_t baselen;
+    const char *p;
+
+    sopath = libruby_path;
+    libpath = RSTRING_PTR(sopath);
+
+    p = strrchr(libpath, '/');
+    if (p) {
+	static const char libdir[] = "/"
+#ifdef LIBDIR_BASENAME
+	    LIBDIR_BASENAME
+#else
+	    "lib"
+#endif
+	    RUBY_ARCH_PATH;
+	const ptrdiff_t libdir_len = (ptrdiff_t)sizeof(libdir)
+	    - rb_strlen_lit(RUBY_ARCH_PATH) - 1;
+	static const char bindir[] = "/bin";
+	const ptrdiff_t bindir_len = (ptrdiff_t)sizeof(bindir) - 1;
+
+	const char *p2 = NULL;
+
+#ifdef ENABLE_MULTIARCH
+      multiarch:
+#endif
+	if (p - libpath >= bindir_len && !STRNCASECMP(p - bindir_len, bindir, bindir_len)) {
+	    p -= bindir_len;
+	    archlibdir = rb_str_subseq(sopath, 0, p - libpath);
+	    rb_str_cat_cstr(archlibdir, libdir);
+	    OBJ_FREEZE_RAW(archlibdir);
+	}
+	else if (p - libpath >= libdir_len && !strncmp(p - libdir_len, libdir, libdir_len)) {
+	    archlibdir = rb_str_subseq(sopath, 0, (p2 ? p2 : p) - libpath);
+	    OBJ_FREEZE_RAW(archlibdir);
+	    p -= libdir_len;
+	}
+#ifdef ENABLE_MULTIARCH
+	else if (p2) {
+	    p = p2;
+	}
+	else {
+	    p2 = p;
+	    p = rb_enc_path_last_separator(libpath, p, rb_ascii8bit_encoding());
+	    if (p) goto multiarch;
+	    p = p2;
+	}
+#endif
+    }
+    baselen = p - libpath;
+    rb_str_resize(sopath, baselen);
+    libpath = RSTRING_PTR(sopath);
+#define PREFIX_PATH() sopath
+#define BASEPATH() rb_str_buf_cat(rb_str_buf_new(baselen+len), libpath, baselen)
+#define RUBY_RELATIVE(path, len) rb_str_buf_cat(BASEPATH(), (path), (len))
+#else
+    const size_t exec_prefix_len = strlen(ruby_exec_prefix);
+#define RUBY_RELATIVE(path, len) rubylib_path_new((path), (len))
+#define PREFIX_PATH() RUBY_RELATIVE(ruby_exec_prefix, exec_prefix_len)
+#endif
+    rb_gc_register_address(&ruby_prefix_path);
+    ruby_prefix_path = PREFIX_PATH();
+    OBJ_FREEZE_RAW(ruby_prefix_path);
+    if (!archlibdir) archlibdir = ruby_prefix_path;
+    rb_gc_register_address(&ruby_archlibdir_path);
+    ruby_archlibdir_path = archlibdir;
+
+    load_path = GET_VM()->load_path;
+
+    ruby_push_include(getenv("RUBYLIB"), identical_path);
+
+    id_initial_load_path_mark = INITIAL_LOAD_PATH_MARK;
+    while (*paths) {
+	size_t len = strlen(paths);
+	VALUE path = RUBY_RELATIVE(paths, len);
+	rb_ivar_set(path, id_initial_load_path_mark, path);
+	rb_ary_push(load_path, path);
+	paths += len + 1;
+    }
+
+    rb_const_set(rb_cObject, rb_intern_const("TMP_RUBY_PREFIX"), ruby_prefix_path);
+}
+
+
+static void
+add_modules(VALUE *req_list, const char *mod)
+{
+    VALUE list = *req_list;
+    VALUE feature;
+
+    if (!list) {
+	*req_list = list = rb_ary_tmp_new(0);
+    }
+    feature = rb_str_cat_cstr(rb_str_tmp_new(0), mod);
+    rb_ary_push(list, feature);
+}
+
+static void
+require_libraries(VALUE *req_list)
+{
+    VALUE list = *req_list;
+    VALUE self = rb_vm_top_self();
+    ID require;
+    rb_encoding *extenc = rb_default_external_encoding();
+
+    CONST_ID(require, "require");
+    while (list && RARRAY_LEN(list) > 0) {
+	VALUE feature = rb_ary_shift(list);
+	rb_enc_associate(feature, extenc);
+	RBASIC_SET_CLASS_RAW(feature, rb_cString);
+	OBJ_FREEZE(feature);
+	rb_funcallv(self, require, 1, &feature);
+    }
+    *req_list = 0;
+}
+
+static const struct rb_block*
+toplevel_context(rb_binding_t *bind)
+{
+    return &bind->block;
+}
+
+static void
+process_sflag(int *sflag)
+{
+    if (*sflag > 0) {
+	long n;
+	const VALUE *args;
+	VALUE argv = rb_argv;
+
+	n = RARRAY_LEN(argv);
+	args = RARRAY_CONST_PTR(argv);
+	while (n > 0) {
+	    VALUE v = *args++;
+	    char *s = StringValuePtr(v);
+	    char *p;
+	    int hyphen = FALSE;
+
+	    if (s[0] != '-')
+		break;
+	    n--;
+	    if (s[1] == '-' && s[2] == '\0')
+		break;
+
+	    v = Qtrue;
+	    /* check if valid name before replacing - with _ */
+	    for (p = s + 1; *p; p++) {
+		if (*p == '=') {
+		    *p++ = '\0';
+		    v = rb_str_new2(p);
+		    break;
+		}
+		if (*p == '-') {
+		    hyphen = TRUE;
+		}
+		else if (*p != '_' && !ISALNUM(*p)) {
+		    VALUE name_error[2];
+		    name_error[0] =
+			rb_str_new2("invalid name for global variable - ");
+		    if (!(p = strchr(p, '='))) {
+			rb_str_cat2(name_error[0], s);
+		    }
+		    else {
+			rb_str_cat(name_error[0], s, p - s);
+		    }
+		    name_error[1] = args[-1];
+		    rb_exc_raise(rb_class_new_instance(2, name_error, rb_eNameError));
+		}
+	    }
+	    s[0] = '$';
+	    if (hyphen) {
+		for (p = s + 1; *p; ++p) {
+		    if (*p == '-')
+			*p = '_';
+		}
+	    }
+	    rb_gv_set(s, v);
+	}
+	n = RARRAY_LEN(argv) - n;
+	while (n--) {
+	    rb_ary_shift(argv);
+	}
+	*sflag = -1;
+    }
+}
+
+static long proc_options(long argc, char **argv, ruby_cmdline_options_t *opt, int envopt);
+
+static void
+moreswitches(const char *s, ruby_cmdline_options_t *opt, int envopt)
+{
+    long argc, i, len;
+    char **argv, *p;
+    const char *ap = 0;
+    VALUE argstr, argary;
+    void *ptr;
+
+    while (ISSPACE(*s)) s++;
+    if (!*s) return;
+    argstr = rb_str_tmp_new((len = strlen(s)) + (envopt!=0));
+    argary = rb_str_tmp_new(0);
+
+    p = RSTRING_PTR(argstr);
+    if (envopt) *p++ = ' ';
+    memcpy(p, s, len + 1);
+    ap = 0;
+    rb_str_cat(argary, (char *)&ap, sizeof(ap));
+    while (*p) {
+	ap = p;
+	rb_str_cat(argary, (char *)&ap, sizeof(ap));
+	while (*p && !ISSPACE(*p)) ++p;
+	if (!*p) break;
+	*p++ = '\0';
+	while (ISSPACE(*p)) ++p;
+    }
+    argc = RSTRING_LEN(argary) / sizeof(ap);
+    ap = 0;
+    rb_str_cat(argary, (char *)&ap, sizeof(ap));
+    argv = ptr = ALLOC_N(char *, argc);
+    MEMMOVE(argv, RSTRING_PTR(argary), char *, argc);
+
+    while ((i = proc_options(argc, argv, opt, envopt)) > 1 && envopt && (argc -= i) > 0) {
+	argv += i;
+	if (**argv != '-') {
+	    *--*argv = '-';
+	}
+	if ((*argv)[1]) {
+	    ++argc;
+	    --argv;
+	}
+    }
+
+    ruby_xfree(ptr);
+    /* get rid of GC */
+    rb_str_resize(argary, 0);
+    rb_str_resize(argstr, 0);
+}
+
+static int
+name_match_p(const char *name, const char *str, size_t len)
+{
+    if (len == 0) return 0;
+    while (1) {
+	while (TOLOWER(*str) == *name) {
+	    if (!--len || !*++str) return 1;
+	    ++name;
+	}
+	if (*str != '-' && *str != '_') return 0;
+	while (ISALNUM(*name)) name++;
+	if (*name != '-' && *name != '_') return 0;
+	++name;
+	++str;
+    }
+}
+
+#define NAME_MATCH_P(name, str, len) \
+    ((len) < (int)sizeof(name) && name_match_p((name), (str), (len)))
+
+#define UNSET_WHEN(name, bit, str, len)	\
+    if (NAME_MATCH_P((name), (str), (len))) { \
+	*(unsigned int *)arg &= ~(bit); \
+	return;				\
+    }
+
+#define SET_WHEN(name, bit, str, len)	\
+    if (NAME_MATCH_P((name), (str), (len))) { \
+	*(unsigned int *)arg |= (bit);	\
+	return;				\
+    }
+
+#define LITERAL_NAME_ELEMENT(name) #name
+
+static void
+feature_option(const char *str, int len, void *arg, const unsigned int enable)
+{
+    static const char list[] = EACH_FEATURES(LITERAL_NAME_ELEMENT, ", ");
+    ruby_features_t *argp = arg;
+    unsigned int mask = ~0U;
+    unsigned int set = 0U;
+#if AMBIGUOUS_FEATURE_NAMES
+    int matched = 0;
+# define FEATURE_FOUND ++matched
+#else
+# define FEATURE_FOUND goto found
+#endif
+#define SET_FEATURE(bit) \
+    if (NAME_MATCH_P(#bit, str, len)) {set |= mask = FEATURE_BIT(bit); FEATURE_FOUND;}
+    EACH_FEATURES(SET_FEATURE, ;);
+    if (NAME_MATCH_P("all", str, len)) {
+        goto found;
+    }
+#if AMBIGUOUS_FEATURE_NAMES
+    if (matched == 1) goto found;
+    if (matched > 1) {
+	VALUE mesg = rb_sprintf("ambiguous feature: `%.*s' (", len, str);
+#define ADD_FEATURE_NAME(bit) \
+	if (FEATURE_BIT(bit) & set) { \
+	    rb_str_cat_cstr(mesg, #bit); \
+	    if (--matched) rb_str_cat_cstr(mesg, ", "); \
+	}
+	EACH_FEATURES(ADD_FEATURE_NAME, ;);
+	rb_str_cat_cstr(mesg, ")");
+	rb_exc_raise(rb_exc_new_str(rb_eRuntimeError, mesg));
+#undef ADD_FEATURE_NAME
+    }
+#endif
+    rb_warn("unknown argument for --%s: `%.*s'",
+	    enable ? "enable" : "disable", len, str);
+    rb_warn("features are [%.*s].", (int)strlen(list), list);
+    return;
+
+  found:
+    FEATURE_SET_TO(*argp, mask, (mask & enable));
+    return;
+}
+
+static void
+enable_option(const char *str, int len, void *arg)
+{
+    feature_option(str, len, arg, ~0U);
+}
+
+static void
+disable_option(const char *str, int len, void *arg)
+{
+    feature_option(str, len, arg, 0U);
+}
+
+RUBY_EXTERN const int  ruby_patchlevel;
+int ruby_env_debug_option(const char *str, int len, void *arg);
+
+static void
+debug_option(const char *str, int len, void *arg)
+{
+    static const char list[] = EACH_DEBUG_FEATURES(LITERAL_NAME_ELEMENT, ", ");
+    ruby_features_t *argp = arg;
+#define SET_WHEN_DEBUG(bit) \
+    if (NAME_MATCH_P(#bit, str, len)) { \
+        FEATURE_SET(*argp, DEBUG_BIT(bit)); \
+        return; \
+    }
+    EACH_DEBUG_FEATURES(SET_WHEN_DEBUG, ;);
+#ifdef RUBY_DEVEL
+    if (ruby_patchlevel < 0 && ruby_env_debug_option(str, len, 0)) return;
+#endif
+    rb_warn("unknown argument for --debug: `%.*s'", len, str);
+    rb_warn("debug features are [%.*s].", (int)strlen(list), list);
+}
+
+static void
+dump_option(const char *str, int len, void *arg)
+{
+    static const char list[] = EACH_DUMPS(LITERAL_NAME_ELEMENT, ", ");
+#define SET_WHEN_DUMP(bit) SET_WHEN(#bit, DUMP_BIT(bit), str, len)
+    EACH_DUMPS(SET_WHEN_DUMP, ;);
+    rb_warn("don't know how to dump `%.*s',", len, str);
+    rb_warn("but only [%.*s].", (int)strlen(list), list);
+}
+
+static void
+set_option_encoding_once(const char *type, VALUE *name, const char *e, long elen)
+{
+    VALUE ename;
+
+    if (!elen) elen = strlen(e);
+    ename = rb_str_new(e, elen);
+
+    if (*name &&
+	rb_funcall(ename, rb_intern("casecmp"), 1, *name) != INT2FIX(0)) {
+	rb_raise(rb_eRuntimeError,
+		 "%s already set to %"PRIsVALUE, type, *name);
+    }
+    *name = ename;
+}
+
+#define set_internal_encoding_once(opt, e, elen) \
+    set_option_encoding_once("default_internal", &(opt)->intern.enc.name, (e), (elen))
+#define set_external_encoding_once(opt, e, elen) \
+    set_option_encoding_once("default_external", &(opt)->ext.enc.name, (e), (elen))
+#define set_source_encoding_once(opt, e, elen) \
+    set_option_encoding_once("source", &(opt)->src.enc.name, (e), (elen))
+
+#if USE_MJIT
+static void
+setup_mjit_options(const char *s, struct mjit_options *mjit_opt)
+{
+#define opt_match(s, l, name) \
+    ((((l) > rb_strlen_lit(name)) ? (s)[rb_strlen_lit(name)] == '=' : \
+      (l) == rb_strlen_lit(name)) && \
+     memcmp((s), name, rb_strlen_lit(name)) == 0 && \
+     (((s) += rb_strlen_lit(name)), 1))
+#define opt_match_noarg(s, l, name) \
+    opt_match(s, l, name) && (*(s) ? (rb_warn("argument to --jit-" name " is ignored"), 1) : 1)
+#define opt_match_arg(s, l, name) \
+    opt_match(s, l, name) && (*(s) ? 1 : (rb_raise(rb_eRuntimeError, "--jit-" name " needs an argument"), 0))
+    if (*s != '-') return;
+    const size_t l = strlen(++s);
+    if (*s == 0) return;
+    else if (opt_match_noarg(s, l, "warnings")) {
+        mjit_opt->warnings = 1;
+    }
+    else if (opt_match(s, l, "debug")) {
+        if (*s)
+            mjit_opt->debug_flags = strdup(s + 1);
+        else
+            mjit_opt->debug = 1;
+    }
+    else if (opt_match_noarg(s, l, "wait")) {
+        mjit_opt->wait = 1;
+    }
+    else if (opt_match_noarg(s, l, "save-temps")) {
+        mjit_opt->save_temps = 1;
+    }
+    else if (opt_match(s, l, "verbose")) {
+        mjit_opt->verbose = *s ? atoi(s + 1) : 1;
+    }
+    else if (opt_match_arg(s, l, "max-cache")) {
+        mjit_opt->max_cache_size = atoi(s + 1);
+    }
+    else if (opt_match_arg(s, l, "min-calls")) {
+        mjit_opt->min_calls = atoi(s + 1);
+    }
+    else {
+        rb_raise(rb_eRuntimeError,
+                 "invalid MJIT option `%s' (--help will show valid MJIT options)", s);
+    }
+}
+#endif
+
+static long
+proc_options(long argc, char **argv, ruby_cmdline_options_t *opt, int envopt)
+{
+    long n, argc0 = argc;
+    const char *s;
+    int warning = opt->warning;
+
+    if (argc <= 0 || !argv)
+	return 0;
+
+    for (argc--, argv++; argc > 0; argc--, argv++) {
+	const char *const arg = argv[0];
+	if (!arg || arg[0] != '-' || !arg[1])
+	    break;
+
+	s = arg + 1;
+      reswitch:
+	switch (*s) {
+	  case 'a':
+	    if (envopt) goto noenvopt;
+	    opt->do_split = TRUE;
+	    s++;
+	    goto reswitch;
+
+	  case 'p':
+	    if (envopt) goto noenvopt;
+	    opt->do_print = TRUE;
+	    /* through */
+	  case 'n':
+	    if (envopt) goto noenvopt;
+	    opt->do_loop = TRUE;
+	    s++;
+	    goto reswitch;
+
+	  case 'd':
+	    ruby_debug = Qtrue;
+	    ruby_verbose = Qtrue;
+	    s++;
+	    goto reswitch;
+
+	  case 'y':
+	    if (envopt) goto noenvopt;
+	    opt->dump |= DUMP_BIT(yydebug);
+	    s++;
+	    goto reswitch;
+
+	  case 'v':
+	    if (opt->verbose) {
+		s++;
+		goto reswitch;
+	    }
+	    opt->dump |= DUMP_BIT(version_v);
+	    opt->verbose = 1;
+	  case 'w':
+	    if (!opt->warning) {
+		warning = 1;
+		ruby_verbose = Qtrue;
+	    }
+	    FEATURE_SET(opt->warn, RB_WARN_CATEGORY_ALL_BITS);
+	    s++;
+	    goto reswitch;
+
+	  case 'W':
+            if (s[1] == ':') {
+                unsigned int bits = 0;
+                static const char no_prefix[] = "no-";
+                int enable = strncmp(s += 2, no_prefix, sizeof(no_prefix)-1) != 0;
+                if (!enable) s += sizeof(no_prefix)-1;
+                size_t len = strlen(s);
+                if (NAME_MATCH_P("deprecated", s, len)) {
+                    bits = 1U << RB_WARN_CATEGORY_DEPRECATED;
+                }
+                else if (NAME_MATCH_P("experimental", s, len)) {
+                    bits = 1U << RB_WARN_CATEGORY_EXPERIMENTAL;
+                }
+                else {
+                    rb_warn("unknown warning category: `%s'", s);
+                }
+                if (bits) FEATURE_SET_TO(opt->warn, bits, enable ? bits : 0);
+                break;
+            }
+	    {
+		size_t numlen;
+		int v = 2;	/* -W as -W2 */
+
+		if (*++s) {
+		    v = scan_oct(s, 1, &numlen);
+		    if (numlen == 0)
+                        v = 2;
+		    s += numlen;
+		}
+		if (!opt->warning) {
+		    switch (v) {
+		      case 0:
+			ruby_verbose = Qnil;
+			break;
+		      case 1:
+			ruby_verbose = Qfalse;
+			break;
+		      default:
+			ruby_verbose = Qtrue;
+			break;
+		    }
+		}
+		warning = 1;
+		switch (v) {
+		  case 0:
+		    FEATURE_SET_TO(opt->warn, RB_WARN_CATEGORY_ALL_BITS, 0);
+		    break;
+		  case 1:
+		    FEATURE_SET_TO(opt->warn, 1U << RB_WARN_CATEGORY_DEPRECATED, 0);
+		    break;
+		  default:
+		    FEATURE_SET(opt->warn, RB_WARN_CATEGORY_ALL_BITS);
+		    break;
+		}
+	    }
+	    goto reswitch;
+
+	  case 'c':
+	    if (envopt) goto noenvopt;
+	    opt->dump |= DUMP_BIT(syntax);
+	    s++;
+	    goto reswitch;
+
+	  case 's':
+	    if (envopt) goto noenvopt;
+	    forbid_setid("-s");
+	    if (!opt->sflag) opt->sflag = 1;
+	    s++;
+	    goto reswitch;
+
+	  case 'h':
+	    if (envopt) goto noenvopt;
+	    opt->dump |= DUMP_BIT(usage);
+	    goto switch_end;
+
+	  case 'l':
+	    if (envopt) goto noenvopt;
+	    opt->do_line = TRUE;
+	    rb_output_rs = rb_rs;
+	    s++;
+	    goto reswitch;
+
+	  case 'S':
+	    if (envopt) goto noenvopt;
+	    forbid_setid("-S");
+	    opt->do_search = TRUE;
+	    s++;
+	    goto reswitch;
+
+	  case 'e':
+	    if (envopt) goto noenvopt;
+	    forbid_setid("-e");
+	    if (!*++s) {
+		if (!--argc)
+		    rb_raise(rb_eRuntimeError, "no code specified for -e");
+		s = *++argv;
+	    }
+	    if (!opt->e_script) {
+		opt->e_script = rb_str_new(0, 0);
+		if (opt->script == 0)
+		    opt->script = "-e";
+	    }
+	    rb_str_cat2(opt->e_script, s);
+	    rb_str_cat2(opt->e_script, "\n");
+	    break;
+
+	  case 'r':
+	    forbid_setid("-r");
+	    if (*++s) {
+		add_modules(&opt->req_list, s);
+	    }
+	    else if (argc > 1) {
+		add_modules(&opt->req_list, argv[1]);
+		argc--, argv++;
+	    }
+	    break;
+
+	  case 'i':
+	    if (envopt) goto noenvopt;
+	    forbid_setid("-i");
+	    ruby_set_inplace_mode(s + 1);
+	    break;
+
+	  case 'x':
+	    if (envopt) goto noenvopt;
+	    forbid_setid("-x");
+	    opt->xflag = TRUE;
+	    s++;
+	    if (*s && chdir(s) < 0) {
+		rb_fatal("Can't chdir to %s", s);
+	    }
+	    break;
+
+	  case 'C':
+	  case 'X':
+	    if (envopt) goto noenvopt;
+	    if (!*++s && (!--argc || !(s = *++argv) || !*s)) {
+		rb_fatal("Can't chdir");
+	    }
+	    if (chdir(s) < 0) {
+		rb_fatal("Can't chdir to %s", s);
+	    }
+	    break;
+
+	  case 'F':
+	    if (envopt) goto noenvopt;
+	    if (*++s) {
+		rb_fs = rb_reg_new(s, strlen(s), 0);
+	    }
+	    break;
+
+	  case 'E':
+	    if (!*++s && (!--argc || !(s = *++argv))) {
+		rb_raise(rb_eRuntimeError, "missing argument for -E");
+	    }
+	    goto encoding;
+
+	  case 'U':
+	    set_internal_encoding_once(opt, "UTF-8", 0);
+	    ++s;
+	    goto reswitch;
+
+	  case 'K':
+	    if (*++s) {
+		const char *enc_name = 0;
+		switch (*s) {
+		  case 'E': case 'e':
+		    enc_name = "EUC-JP";
+		    break;
+		  case 'S': case 's':
+		    enc_name = "Windows-31J";
+		    break;
+		  case 'U': case 'u':
+		    enc_name = "UTF-8";
+		    break;
+		  case 'N': case 'n': case 'A': case 'a':
+		    enc_name = "ASCII-8BIT";
+		    break;
+		}
+		if (enc_name) {
+		    opt->src.enc.name = rb_str_new2(enc_name);
+		    if (!opt->ext.enc.name)
+			opt->ext.enc.name = opt->src.enc.name;
+		}
+		s++;
+	    }
+	    goto reswitch;
+
+	  case 'I':
+	    forbid_setid("-I");
+	    if (*++s)
+		ruby_incpush_expand(s);
+	    else if (argc > 1) {
+		ruby_incpush_expand(argv[1]);
+		argc--, argv++;
+	    }
+	    break;
+
+	  case '0':
+	    if (envopt) goto noenvopt;
+	    {
+		size_t numlen;
+		int v;
+		char c;
+
+		v = scan_oct(s, 4, &numlen);
+		s += numlen;
+		if (v > 0377)
+		    rb_rs = Qnil;
+		else if (v == 0 && numlen >= 2) {
+		    rb_rs = rb_str_new2("");
+		}
+		else {
+		    c = v & 0xff;
+		    rb_rs = rb_str_new(&c, 1);
+		}
+	    }
+	    goto reswitch;
+
+	  case '-':
+	    if (!s[1] || (s[1] == '\r' && !s[2])) {
+		argc--, argv++;
+		goto switch_end;
+	    }
+	    s++;
+
+#	define is_option_end(c, allow_hyphen) \
+	    (!(c) || ((allow_hyphen) && (c) == '-') || (c) == '=')
+#	define check_envopt(name, allow_envopt) \
+	    (((allow_envopt) || !envopt) ? (void)0 : \
+	     rb_raise(rb_eRuntimeError, "invalid switch in RUBYOPT: --" name))
+#	define need_argument(name, s, needs_arg, next_arg)			\
+	    ((*(s) ? !*++(s) : (next_arg) && (!argc || !((s) = argv[1]) || (--argc, ++argv, 0))) && (needs_arg) ? \
+	     rb_raise(rb_eRuntimeError, "missing argument for --" name) \
+	     : (void)0)
+#	define is_option_with_arg(name, allow_hyphen, allow_envopt)	\
+	    is_option_with_optarg(name, allow_hyphen, allow_envopt, Qtrue, Qtrue)
+#	define is_option_with_optarg(name, allow_hyphen, allow_envopt, needs_arg, next_arg) \
+	    (strncmp((name), s, n = sizeof(name) - 1) == 0 && is_option_end(s[n], (allow_hyphen)) ? \
+	     (check_envopt(name, (allow_envopt)), s += n, \
+	      need_argument(name, s, needs_arg, next_arg), 1) : 0)
+
+	    if (strcmp("copyright", s) == 0) {
+		if (envopt) goto noenvopt_long;
+		opt->dump |= DUMP_BIT(copyright);
+	    }
+	    else if (is_option_with_optarg("debug", Qtrue, Qtrue, Qfalse, Qfalse)) {
+		if (s && *s) {
+		    ruby_each_words(s, debug_option, &opt->features);
+		}
+		else {
+		    ruby_debug = Qtrue;
+		    ruby_verbose = Qtrue;
+		}
+            }
+	    else if (is_option_with_arg("enable", Qtrue, Qtrue)) {
+		ruby_each_words(s, enable_option, &opt->features);
+	    }
+	    else if (is_option_with_arg("disable", Qtrue, Qtrue)) {
+		ruby_each_words(s, disable_option, &opt->features);
+	    }
+	    else if (is_option_with_arg("encoding", Qfalse, Qtrue)) {
+		char *p;
+	      encoding:
+		do {
+#	define set_encoding_part(type) \
+		    if (!(p = strchr(s, ':'))) { \
+			set_##type##_encoding_once(opt, s, 0); \
+			break; \
+		    } \
+		    else if (p > s) { \
+			set_##type##_encoding_once(opt, s, p-s); \
+		    }
+		    set_encoding_part(external);
+		    if (!*(s = ++p)) break;
+		    set_encoding_part(internal);
+		    if (!*(s = ++p)) break;
+#if defined ALLOW_DEFAULT_SOURCE_ENCODING && ALLOW_DEFAULT_SOURCE_ENCODING
+		    set_encoding_part(source);
+		    if (!*(s = ++p)) break;
+#endif
+		    rb_raise(rb_eRuntimeError, "extra argument for %s: %s",
+			     (arg[1] == '-' ? "--encoding" : "-E"), s);
+#	undef set_encoding_part
+		} while (0);
+	    }
+	    else if (is_option_with_arg("internal-encoding", Qfalse, Qtrue)) {
+		set_internal_encoding_once(opt, s, 0);
+	    }
+	    else if (is_option_with_arg("external-encoding", Qfalse, Qtrue)) {
+		set_external_encoding_once(opt, s, 0);
+	    }
+#if defined ALLOW_DEFAULT_SOURCE_ENCODING && ALLOW_DEFAULT_SOURCE_ENCODING
+	    else if (is_option_with_arg("source-encoding", Qfalse, Qtrue)) {
+		set_source_encoding_once(opt, s, 0);
+	    }
+#endif
+	    else if (strcmp("version", s) == 0) {
+		if (envopt) goto noenvopt_long;
+		opt->dump |= DUMP_BIT(version);
+	    }
+	    else if (strcmp("verbose", s) == 0) {
+		opt->verbose = 1;
+		ruby_verbose = Qtrue;
+	    }
+            else if (strncmp("jit", s, 3) == 0) {
+#if USE_MJIT
+                FEATURE_SET(opt->features, FEATURE_BIT(jit));
+                setup_mjit_options(s + 3, &opt->mjit);
+#else
+                rb_warn("MJIT support is disabled.");
+#endif
+            }
+	    else if (strcmp("yydebug", s) == 0) {
+		if (envopt) goto noenvopt_long;
+		opt->dump |= DUMP_BIT(yydebug);
+	    }
+	    else if (is_option_with_arg("dump", Qfalse, Qfalse)) {
+		ruby_each_words(s, dump_option, &opt->dump);
+	    }
+	    else if (strcmp("help", s) == 0) {
+		if (envopt) goto noenvopt_long;
+		opt->dump |= DUMP_BIT(help);
+		goto switch_end;
+	    }
+            else if (is_option_with_arg("backtrace-limit", Qfalse, Qfalse)) {
+                char *e;
+                long n = strtol(s, &e, 10);
+                if (errno == ERANGE || n < 0 || *e) rb_raise(rb_eRuntimeError, "wrong limit for backtrace length");
+                rb_backtrace_length_limit = n;
+            }
+	    else {
+		rb_raise(rb_eRuntimeError,
+			 "invalid option --%s  (-h will show valid options)", s);
+	    }
+	    break;
+
+	  case '\r':
+	    if (!s[1])
+		break;
+
+	  default:
+	    {
+                rb_raise(rb_eRuntimeError,
+			"invalid option -%c  (-h will show valid options)",
+                        (int)(unsigned char)*s);
+	    }
+	    goto switch_end;
+
+	  noenvopt:
+	    /* "EIdvwWrKU" only */
+	    rb_raise(rb_eRuntimeError, "invalid switch in RUBYOPT: -%c", *s);
+	    break;
+
+	  noenvopt_long:
+	    rb_raise(rb_eRuntimeError, "invalid switch in RUBYOPT: --%s", s);
+	    break;
+
+	  case 0:
+	    break;
+#	undef is_option_end
+#	undef check_envopt
+#	undef need_argument
+#	undef is_option_with_arg
+#	undef is_option_with_optarg
+	}
+    }
+
+  switch_end:
+    if (warning) opt->warning = warning;
+    return argc0 - argc;
+}
+
+void Init_builtin_features(void);
+
+static void
+ruby_init_prelude(void)
+{
+    Init_builtin_features();
+    rb_const_remove(rb_cObject, rb_intern_const("TMP_RUBY_PREFIX"));
+}
+
+void rb_call_builtin_inits(void);
+
+static void
+ruby_opt_init(ruby_cmdline_options_t *opt)
+{
+    if (opt->dump & dump_exit_bits) return;
+
+    if (opt->features.set & FEATURE_BIT(gems)) {
+        rb_define_module("Gem");
+        if (opt->features.set & FEATURE_BIT(did_you_mean)) {
+            rb_define_module("DidYouMean");
+        }
+    }
+
+    rb_warning_category_update(opt->warn.mask, opt->warn.set);
+
+    Init_ext(); /* load statically linked extensions before rubygems */
+    rb_call_builtin_inits();
+    ruby_init_prelude();
+
+    ruby_set_script_name(opt->script_name);
+    require_libraries(&opt->req_list);
+}
+
+static int
+opt_enc_index(VALUE enc_name)
+{
+    const char *s = RSTRING_PTR(enc_name);
+    int i = rb_enc_find_index(s);
+
+    if (i < 0) {
+	rb_raise(rb_eRuntimeError, "unknown encoding name - %s", s);
+    }
+    else if (rb_enc_dummy_p(rb_enc_from_index(i))) {
+	rb_raise(rb_eRuntimeError, "dummy encoding is not acceptable - %s ", s);
+    }
+    return i;
+}
+
+#define rb_progname      (GET_VM()->progname)
+#define rb_orig_progname (GET_VM()->orig_progname)
+VALUE rb_argv0;
+VALUE rb_e_script;
+
+static VALUE
+false_value(ID _x, VALUE *_y)
+{
+    return Qfalse;
+}
+
+static VALUE
+true_value(ID _x, VALUE *_y)
+{
+    return Qtrue;
+}
+
+#define rb_define_readonly_boolean(name, val) \
+    rb_define_virtual_variable((name), (val) ? true_value : false_value, 0)
+
+static VALUE
+uscore_get(void)
+{
+    VALUE line;
+
+    line = rb_lastline_get();
+    if (!RB_TYPE_P(line, T_STRING)) {
+	rb_raise(rb_eTypeError, "$_ value need to be String (%s given)",
+		 NIL_P(line) ? "nil" : rb_obj_classname(line));
+    }
+    return line;
+}
+
+/*
+ *  call-seq:
+ *     sub(pattern, replacement)   -> $_
+ *     sub(pattern) {|...| block } -> $_
+ *
+ *  Equivalent to <code>$_.sub(<i>args</i>)</code>, except that
+ *  <code>$_</code> will be updated if substitution occurs.
+ *  Available only when -p/-n command line option specified.
+ */
+
+static VALUE
+rb_f_sub(int argc, VALUE *argv, VALUE _)
+{
+    VALUE str = rb_funcall_passing_block(uscore_get(), rb_intern("sub"), argc, argv);
+    rb_lastline_set(str);
+    return str;
+}
+
+/*
+ *  call-seq:
+ *     gsub(pattern, replacement)    -> $_
+ *     gsub(pattern) {|...| block }  -> $_
+ *
+ *  Equivalent to <code>$_.gsub...</code>, except that <code>$_</code>
+ *  will be updated if substitution occurs.
+ *  Available only when -p/-n command line option specified.
+ *
+ */
+
+static VALUE
+rb_f_gsub(int argc, VALUE *argv, VALUE _)
+{
+    VALUE str = rb_funcall_passing_block(uscore_get(), rb_intern("gsub"), argc, argv);
+    rb_lastline_set(str);
+    return str;
+}
+
+/*
+ *  call-seq:
+ *     chop   -> $_
+ *
+ *  Equivalent to <code>($_.dup).chop!</code>, except <code>nil</code>
+ *  is never returned. See String#chop!.
+ *  Available only when -p/-n command line option specified.
+ *
+ */
+
+static VALUE
+rb_f_chop(VALUE _)
+{
+    VALUE str = rb_funcall_passing_block(uscore_get(), rb_intern("chop"), 0, 0);
+    rb_lastline_set(str);
+    return str;
+}
+
+
+/*
+ *  call-seq:
+ *     chomp            -> $_
+ *     chomp(string)    -> $_
+ *
+ *  Equivalent to <code>$_ = $_.chomp(<em>string</em>)</code>. See
+ *  String#chomp.
+ *  Available only when -p/-n command line option specified.
+ *
+ */
+
+static VALUE
+rb_f_chomp(int argc, VALUE *argv, VALUE _)
+{
+    VALUE str = rb_funcall_passing_block(uscore_get(), rb_intern("chomp"), argc, argv);
+    rb_lastline_set(str);
+    return str;
+}
+
+static void
+setup_pager_env(void)
+{
+    if (!getenv("LESS")) ruby_setenv("LESS", "-R"); // Output "raw" control characters.
+}
+
+#ifdef _WIN32
+static int
+tty_enabled(void)
+{
+    HANDLE h = GetStdHandle(STD_OUTPUT_HANDLE);
+    DWORD m;
+    if (!GetConsoleMode(h, &m)) return 0;
+# ifndef ENABLE_VIRTUAL_TERMINAL_PROCESSING
+#   define ENABLE_VIRTUAL_TERMINAL_PROCESSING 0x4
+# endif
+    if (!(m & ENABLE_VIRTUAL_TERMINAL_PROCESSING)) return 0;
+    return 1;
+}
+#elif !defined(HAVE_WORKING_FORK)
+# define tty_enabled() 0
+#endif
+
+static VALUE
+copy_str(VALUE str, rb_encoding *enc, bool intern)
+{
+    if (!intern) {
+        if (rb_enc_str_coderange_scan(str, enc) == ENC_CODERANGE_BROKEN)
+            return 0;
+        return rb_enc_associate(rb_str_dup(str), enc);
+    }
+    return rb_enc_interned_str(RSTRING_PTR(str), RSTRING_LEN(str), enc);
+}
+
+static VALUE
+process_options(int argc, char **argv, ruby_cmdline_options_t *opt)
+{
+    rb_ast_t *ast = 0;
+    VALUE parser;
+    VALUE script_name;
+    const rb_iseq_t *iseq;
+    rb_encoding *enc, *lenc;
+#if UTF8_PATH
+    rb_encoding *ienc = 0;
+    rb_encoding *const uenc = rb_utf8_encoding();
+#endif
+    const char *s;
+    char fbuf[MAXPATHLEN];
+    int i = (int)proc_options(argc, argv, opt, 0);
+    unsigned int dump = opt->dump & dump_exit_bits;
+    rb_vm_t *vm = GET_VM();
+    const long loaded_before_enc = RARRAY_LEN(vm->loaded_features);
+
+    if (opt->dump & (DUMP_BIT(usage)|DUMP_BIT(help))) {
+        int tty = isatty(1);
+	const char *const progname =
+	    (argc > 0 && argv && argv[0] ? argv[0] :
+	     origarg.argc > 0 && origarg.argv && origarg.argv[0] ? origarg.argv[0] :
+	     ruby_engine);
+        int columns = 0;
+        if ((opt->dump & DUMP_BIT(help)) && tty) {
+            const char *pager_env = getenv("RUBY_PAGER");
+            if (!pager_env) pager_env = getenv("PAGER");
+            if (pager_env && *pager_env && isatty(0)) {
+                const char *columns_env = getenv("COLUMNS");
+                if (columns_env) columns = atoi(columns_env);
+                VALUE pager = rb_str_new_cstr(pager_env);
+#ifdef HAVE_WORKING_FORK
+                int fds[2];
+                if (rb_pipe(fds) == 0) {
+                    rb_pid_t pid = rb_fork();
+                    if (pid > 0) {
+                        /* exec PAGER with reading from child */
+                        dup2(fds[0], 0);
+                    }
+                    else if (pid == 0) {
+                        /* send the help message to the parent PAGER */
+                        dup2(fds[1], 1);
+                        dup2(fds[1], 2);
+                    }
+                    close(fds[0]);
+                    close(fds[1]);
+                    if (pid > 0) {
+                        setup_pager_env();
+                        rb_f_exec(1, &pager);
+                        kill(SIGTERM, pid);
+                        rb_waitpid(pid, 0, 0);
+                    }
+                }
+#else
+                setup_pager_env();
+                VALUE port = rb_io_popen(pager, rb_str_new_lit("w"), Qnil, Qnil);
+                if (!NIL_P(port)) {
+                    int oldout = dup(1);
+                    int olderr = dup(2);
+                    int fd = RFILE(port)->fptr->fd;
+                    tty = tty_enabled();
+                    dup2(fd, 1);
+                    dup2(fd, 2);
+                    usage(progname, 1, tty, columns);
+                    fflush(stdout);
+                    dup2(oldout, 1);
+                    dup2(olderr, 2);
+                    rb_io_close(port);
+                    return Qtrue;
+                }
+#endif
+            }
+        }
+	usage(progname, (opt->dump & DUMP_BIT(help)), tty, columns);
+	return Qtrue;
+    }
+
+    argc -= i;
+    argv += i;
+
+    if ((opt->features.set & FEATURE_BIT(rubyopt)) && (s = getenv("RUBYOPT"))) {
+	VALUE src_enc_name = opt->src.enc.name;
+	VALUE ext_enc_name = opt->ext.enc.name;
+	VALUE int_enc_name = opt->intern.enc.name;
+        ruby_features_t feat = opt->features;
+        ruby_features_t warn = opt->warn;
+
+	opt->src.enc.name = opt->ext.enc.name = opt->intern.enc.name = 0;
+	moreswitches(s, opt, 1);
+	if (src_enc_name)
+	    opt->src.enc.name = src_enc_name;
+	if (ext_enc_name)
+	    opt->ext.enc.name = ext_enc_name;
+	if (int_enc_name)
+	    opt->intern.enc.name = int_enc_name;
+        FEATURE_SET_RESTORE(opt->features, feat);
+        FEATURE_SET_RESTORE(opt->warn, warn);
+    }
+
+    if (opt->src.enc.name)
+        /* cannot set deprecated category, as enabling deprecation warnings based on flags
+         * has not happened yet.
+         */
+        rb_warning("-K is specified; it is for 1.8 compatibility and may cause odd behavior");
+
+#if USE_MJIT
+    if (opt->features.set & FEATURE_BIT(jit)) {
+        opt->mjit.on = TRUE; /* set mjit.on for ruby_show_version() API and check to call mjit_init() */
+    }
+#endif
+    if (opt->dump & (DUMP_BIT(version) | DUMP_BIT(version_v))) {
+#if USE_MJIT
+        mjit_opts.on = opt->mjit.on; /* used by ruby_show_version(). mjit_init() still can't be called here. */
+#endif
+	ruby_show_version();
+	if (opt->dump & DUMP_BIT(version)) return Qtrue;
+    }
+    if (opt->dump & DUMP_BIT(copyright)) {
+	ruby_show_copyright();
+	return Qtrue;
+    }
+
+    if (!opt->e_script) {
+	if (argc <= 0) {	/* no more args */
+	    if (opt->verbose)
+		return Qtrue;
+	    opt->script = "-";
+	}
+	else {
+	    opt->script = argv[0];
+	    if (!opt->script || opt->script[0] == '\0') {
+		opt->script = "-";
+	    }
+	    else if (opt->do_search) {
+		char *path = getenv("RUBYPATH");
+
+		opt->script = 0;
+		if (path) {
+		    opt->script = dln_find_file_r(argv[0], path, fbuf, sizeof(fbuf));
+		}
+		if (!opt->script) {
+		    opt->script = dln_find_file_r(argv[0], getenv(PATH_ENV), fbuf, sizeof(fbuf));
+		}
+		if (!opt->script)
+		    opt->script = argv[0];
+	    }
+	    argc--;
+	    argv++;
+	}
+	if (opt->script[0] == '-' && !opt->script[1]) {
+	    forbid_setid("program input from stdin");
+	}
+    }
+
+    opt->script_name = rb_str_new_cstr(opt->script);
+    opt->script = RSTRING_PTR(opt->script_name);
+
+#if _WIN32
+    translit_char_bin(RSTRING_PTR(opt->script_name), '\\', '/');
+#elif defined DOSISH
+    translit_char(RSTRING_PTR(opt->script_name), '\\', '/');
+#endif
+
+    ruby_gc_set_params();
+    ruby_init_loadpath();
+
+#if USE_MJIT
+    if (opt->mjit.on)
+        /* Using TMP_RUBY_PREFIX created by ruby_init_loadpath(). */
+        mjit_init(&opt->mjit);
+#endif
+
+    Init_ruby_description();
+    Init_enc();
+    lenc = rb_locale_encoding();
+    rb_enc_associate(rb_progname, lenc);
+    rb_obj_freeze(rb_progname);
+    parser = rb_parser_new();
+    if (opt->dump & DUMP_BIT(yydebug)) {
+	rb_parser_set_yydebug(parser, Qtrue);
+    }
+    if (opt->ext.enc.name != 0) {
+	opt->ext.enc.index = opt_enc_index(opt->ext.enc.name);
+    }
+    if (opt->intern.enc.name != 0) {
+	opt->intern.enc.index = opt_enc_index(opt->intern.enc.name);
+    }
+    if (opt->src.enc.name != 0) {
+	opt->src.enc.index = opt_enc_index(opt->src.enc.name);
+	src_encoding_index = opt->src.enc.index;
+    }
+    if (opt->ext.enc.index >= 0) {
+	enc = rb_enc_from_index(opt->ext.enc.index);
+    }
+    else {
+	enc = IF_UTF8_PATH(uenc, lenc);
+    }
+    rb_enc_set_default_external(rb_enc_from_encoding(enc));
+    if (opt->intern.enc.index >= 0) {
+	enc = rb_enc_from_index(opt->intern.enc.index);
+	rb_enc_set_default_internal(rb_enc_from_encoding(enc));
+	opt->intern.enc.index = -1;
+#if UTF8_PATH
+	ienc = enc;
+#endif
+    }
+    script_name = opt->script_name;
+    rb_enc_associate(opt->script_name, IF_UTF8_PATH(uenc, lenc));
+#if UTF8_PATH
+    if (uenc != lenc) {
+	opt->script_name = str_conv_enc(opt->script_name, uenc, lenc);
+	opt->script = RSTRING_PTR(opt->script_name);
+    }
+#endif
+    rb_obj_freeze(opt->script_name);
+    if (IF_UTF8_PATH(uenc != lenc, 1)) {
+	long i;
+        VALUE load_path = vm->load_path;
+	const ID id_initial_load_path_mark = INITIAL_LOAD_PATH_MARK;
+        int modifiable = FALSE;
+
+        rb_get_expanded_load_path();
+	for (i = 0; i < RARRAY_LEN(load_path); ++i) {
+	    VALUE path = RARRAY_AREF(load_path, i);
+	    int mark = rb_attr_get(path, id_initial_load_path_mark) == path;
+#if UTF8_PATH
+	    VALUE newpath = rb_str_conv_enc(path, uenc, lenc);
+	    if (newpath == path) continue;
+	    path = newpath;
+#else
+	    if (!(path = copy_str(path, lenc, !mark))) continue;
+#endif
+	    if (mark) rb_ivar_set(path, id_initial_load_path_mark, path);
+            if (!modifiable) {
+                rb_ary_modify(load_path);
+                modifiable = TRUE;
+            }
+	    RARRAY_ASET(load_path, i, path);
+	}
+        if (modifiable) {
+            rb_ary_replace(vm->load_path_snapshot, load_path);
+        }
+    }
+    {
+        VALUE loaded_features = vm->loaded_features;
+        bool modified = false;
+        for (long i = loaded_before_enc; i < RARRAY_LEN(loaded_features); ++i) {
+	    VALUE path = RARRAY_AREF(loaded_features, i);
+            if (!(path = copy_str(path, IF_UTF8_PATH(uenc, lenc), true))) continue;
+            modified = true;
+	    RARRAY_ASET(loaded_features, i, path);
+        }
+        if (modified) {
+            rb_ary_replace(vm->loaded_features_snapshot, loaded_features);
+        }
+    }
+
+    if (opt->features.mask & COMPILATION_FEATURES) {
+	VALUE option = rb_hash_new();
+#define SET_COMPILE_OPTION(h, o, name) \
+	rb_hash_aset((h), ID2SYM(rb_intern_const(#name)),		\
+                     (FEATURE_SET_P(o->features, FEATURE_BIT(name)) ? Qtrue : Qfalse));
+	SET_COMPILE_OPTION(option, opt, frozen_string_literal);
+	SET_COMPILE_OPTION(option, opt, debug_frozen_string_literal);
+	rb_funcallv(rb_cISeq, rb_intern_const("compile_option="), 1, &option);
+#undef SET_COMPILE_OPTION
+    }
+    ruby_set_argv(argc, argv);
+    process_sflag(&opt->sflag);
+
+    rb_parser_set_context(parser, 0, TRUE);
+
+    if (opt->e_script) {
+	VALUE progname = rb_progname;
+	rb_encoding *eenc;
+	if (opt->src.enc.index >= 0) {
+	    eenc = rb_enc_from_index(opt->src.enc.index);
+	}
+	else {
+	    eenc = lenc;
+#if UTF8_PATH
+	    if (ienc) eenc = ienc;
+#endif
+	}
+#if UTF8_PATH
+	if (eenc != uenc) {
+	    opt->e_script = str_conv_enc(opt->e_script, uenc, eenc);
+	}
+#endif
+	rb_enc_associate(opt->e_script, eenc);
+        ruby_opt_init(opt);
+        ruby_set_script_name(progname);
+	rb_parser_set_options(parser, opt->do_print, opt->do_loop,
+			      opt->do_line, opt->do_split);
+	ast = rb_parser_compile_string(parser, opt->script, opt->e_script, 1);
+    }
+    else {
+	VALUE f;
+	f = open_load_file(script_name, &opt->xflag);
+	ast = load_file(parser, opt->script_name, f, 1, opt);
+    }
+    ruby_set_script_name(opt->script_name);
+    if (dump & DUMP_BIT(yydebug)) {
+	dump &= ~DUMP_BIT(yydebug);
+	if (!dump) return Qtrue;
+    }
+
+    if (opt->ext.enc.index >= 0) {
+	enc = rb_enc_from_index(opt->ext.enc.index);
+    }
+    else {
+	enc = IF_UTF8_PATH(uenc, lenc);
+    }
+    rb_enc_set_default_external(rb_enc_from_encoding(enc));
+    if (opt->intern.enc.index >= 0) {
+	/* Set in the shebang line */
+	enc = rb_enc_from_index(opt->intern.enc.index);
+	rb_enc_set_default_internal(rb_enc_from_encoding(enc));
+    }
+    else if (!rb_default_internal_encoding())
+	/* Freeze default_internal */
+	rb_enc_set_default_internal(Qnil);
+    rb_stdio_set_default_encoding();
+
+    if (!ast->body.root) {
+	rb_ast_dispose(ast);
+	return Qfalse;
+    }
+
+    process_sflag(&opt->sflag);
+    opt->xflag = 0;
+
+    if (dump & DUMP_BIT(syntax)) {
+	printf("Syntax OK\n");
+	dump &= ~DUMP_BIT(syntax);
+	if (!dump) return Qtrue;
+    }
+
+    if (opt->do_loop) {
+	rb_define_global_function("sub", rb_f_sub, -1);
+	rb_define_global_function("gsub", rb_f_gsub, -1);
+	rb_define_global_function("chop", rb_f_chop, 0);
+	rb_define_global_function("chomp", rb_f_chomp, -1);
+    }
+
+    if (dump & (DUMP_BIT(parsetree)|DUMP_BIT(parsetree_with_comment))) {
+	rb_io_write(rb_stdout, rb_parser_dump_tree(ast->body.root, dump & DUMP_BIT(parsetree_with_comment)));
+	rb_io_flush(rb_stdout);
+	dump &= ~DUMP_BIT(parsetree)&~DUMP_BIT(parsetree_with_comment);
+	if (!dump) {
+	    rb_ast_dispose(ast);
+	    return Qtrue;
+	}
+    }
+
+    {
+	VALUE path = Qnil;
+	if (!opt->e_script && strcmp(opt->script, "-")) {
+	    path = rb_realpath_internal(Qnil, script_name, 1);
+#if UTF8_PATH
+	    if (uenc != lenc) {
+		path = str_conv_enc(path, uenc, lenc);
+	    }
+#endif
+	    if (!ENCODING_GET(path)) { /* ASCII-8BIT */
+		rb_enc_copy(path, opt->script_name);
+	    }
+	}
+
+        rb_binding_t *toplevel_binding;
+        GetBindingPtr(rb_const_get(rb_cObject, rb_intern("TOPLEVEL_BINDING")),
+                      toplevel_binding);
+        const struct rb_block *base_block = toplevel_context(toplevel_binding);
+	iseq = rb_iseq_new_main(&ast->body, opt->script_name, path, vm_block_iseq(base_block));
+	rb_ast_dispose(ast);
+    }
+
+    if (dump & DUMP_BIT(insns)) {
+	rb_io_write(rb_stdout, rb_iseq_disasm((const rb_iseq_t *)iseq));
+	rb_io_flush(rb_stdout);
+	dump &= ~DUMP_BIT(insns);
+	if (!dump) return Qtrue;
+    }
+    if (opt->dump & dump_exit_bits) return Qtrue;
+
+    rb_define_readonly_boolean("$-p", opt->do_print);
+    rb_define_readonly_boolean("$-l", opt->do_line);
+    rb_define_readonly_boolean("$-a", opt->do_split);
+
+    rb_gvar_ractor_local("$-p");
+    rb_gvar_ractor_local("$-l");
+    rb_gvar_ractor_local("$-a");
+
+    if ((rb_e_script = opt->e_script) != 0) {
+        rb_gc_register_mark_object(opt->e_script);
+    }
+
+    {
+        rb_execution_context_t *ec = GET_EC();
+
+        if (opt->e_script) {
+            /* -e */
+            rb_exec_event_hook_script_compiled(ec, iseq, opt->e_script);
+        }
+        else {
+            /* file */
+            rb_exec_event_hook_script_compiled(ec, iseq, Qnil);
+        }
+    }
+    return (VALUE)iseq;
+}
+
+#ifndef DOSISH
+static void
+warn_cr_in_shebang(const char *str, long len)
+{
+    if (str[len-1] == '\n' && str[len-2] == '\r') {
+	rb_warn("shebang line ending with \\r may cause problems");
+    }
+}
+#else
+#define warn_cr_in_shebang(str, len) (void)0
+#endif
+
+struct load_file_arg {
+    VALUE parser;
+    VALUE fname;
+    int script;
+    ruby_cmdline_options_t *opt;
+    VALUE f;
+};
+
+static VALUE
+load_file_internal(VALUE argp_v)
+{
+    struct load_file_arg *argp = (struct load_file_arg *)argp_v;
+    VALUE parser = argp->parser;
+    VALUE orig_fname = argp->fname;
+    int script = argp->script;
+    ruby_cmdline_options_t *opt = argp->opt;
+    VALUE f = argp->f;
+    int line_start = 1;
+    rb_ast_t *ast = 0;
+    rb_encoding *enc;
+    ID set_encoding;
+
+    CONST_ID(set_encoding, "set_encoding");
+    if (script) {
+	VALUE c = 1;		/* something not nil */
+	VALUE line;
+	char *p, *str;
+	long len;
+	int no_src_enc = !opt->src.enc.name;
+	int no_ext_enc = !opt->ext.enc.name;
+	int no_int_enc = !opt->intern.enc.name;
+
+	enc = rb_ascii8bit_encoding();
+	rb_funcall(f, set_encoding, 1, rb_enc_from_encoding(enc));
+
+	if (opt->xflag) {
+	    line_start--;
+	  search_shebang:
+	    while (!NIL_P(line = rb_io_gets(f))) {
+		line_start++;
+		RSTRING_GETMEM(line, str, len);
+		if (len > 2 && str[0] == '#' && str[1] == '!') {
+		    if (line_start == 1) warn_cr_in_shebang(str, len);
+		    if ((p = strstr(str+2, ruby_engine)) != 0) {
+			goto start_read;
+		    }
+		}
+	    }
+	    rb_loaderror("no Ruby script found in input");
+	}
+
+	c = rb_io_getbyte(f);
+	if (c == INT2FIX('#')) {
+	    c = rb_io_getbyte(f);
+            if (c == INT2FIX('!') && !NIL_P(line = rb_io_gets(f))) {
+		RSTRING_GETMEM(line, str, len);
+		warn_cr_in_shebang(str, len);
+		if ((p = strstr(str, ruby_engine)) == 0) {
+		    /* not ruby script, assume -x flag */
+		    goto search_shebang;
+		}
+
+	      start_read:
+		str += len - 1;
+		if (*str == '\n') *str-- = '\0';
+		if (*str == '\r') *str-- = '\0';
+		/* ruby_engine should not contain a space */
+		if ((p = strstr(p, " -")) != 0) {
+		    opt->warning = 0;
+		    moreswitches(p + 1, opt, 0);
+		}
+
+		/* push back shebang for pragma may exist in next line */
+		rb_io_ungetbyte(f, rb_str_new2("!\n"));
+	    }
+	    else if (!NIL_P(c)) {
+		rb_io_ungetbyte(f, c);
+	    }
+	    rb_io_ungetbyte(f, INT2FIX('#'));
+	    if (no_src_enc && opt->src.enc.name) {
+		opt->src.enc.index = opt_enc_index(opt->src.enc.name);
+		src_encoding_index = opt->src.enc.index;
+	    }
+	    if (no_ext_enc && opt->ext.enc.name) {
+		opt->ext.enc.index = opt_enc_index(opt->ext.enc.name);
+	    }
+	    if (no_int_enc && opt->intern.enc.name) {
+		opt->intern.enc.index = opt_enc_index(opt->intern.enc.name);
+	    }
+	}
+	else if (!NIL_P(c)) {
+	    rb_io_ungetbyte(f, c);
+	}
+        if (NIL_P(c)) {
+	    argp->f = f = Qnil;
+	}
+        ruby_opt_init(opt);
+    }
+    if (opt->src.enc.index >= 0) {
+	enc = rb_enc_from_index(opt->src.enc.index);
+    }
+    else if (f == rb_stdin) {
+	enc = rb_locale_encoding();
+    }
+    else {
+	enc = rb_utf8_encoding();
+    }
+    rb_parser_set_options(parser, opt->do_print, opt->do_loop,
+			  opt->do_line, opt->do_split);
+    if (NIL_P(f)) {
+	f = rb_str_new(0, 0);
+	rb_enc_associate(f, enc);
+	return (VALUE)rb_parser_compile_string_path(parser, orig_fname, f, line_start);
+    }
+    rb_funcall(f, set_encoding, 2, rb_enc_from_encoding(enc), rb_str_new_cstr("-"));
+    ast = rb_parser_compile_file_path(parser, orig_fname, f, line_start);
+    rb_funcall(f, set_encoding, 1, rb_parser_encoding(parser));
+    if (script && rb_parser_end_seen_p(parser)) {
+	/*
+	 * DATA is a File that contains the data section of the executed file.
+	 * To create a data section use <tt>__END__</tt>:
+	 *
+	 *   $ cat t.rb
+	 *   puts DATA.gets
+	 *   __END__
+	 *   hello world!
+	 *
+	 *   $ ruby t.rb
+	 *   hello world!
+	 */
+	rb_define_global_const("DATA", f);
+	argp->f = Qnil;
+    }
+    return (VALUE)ast;
+}
+
+static VALUE
+open_load_file(VALUE fname_v, int *xflag)
+{
+    const char *fname = (fname_v = rb_str_encode_ospath(fname_v),
+			 StringValueCStr(fname_v));
+    long flen = RSTRING_LEN(fname_v);
+    VALUE f;
+    int e;
+
+    if (flen == 1 && fname[0] == '-') {
+	f = rb_stdin;
+    }
+    else {
+	int fd;
+	/* open(2) may block if fname is point to FIFO and it's empty. Let's
+	   use O_NONBLOCK. */
+#if defined O_NONBLOCK && HAVE_FCNTL && !(O_NONBLOCK & O_ACCMODE)
+	/* TODO: fix conflicting O_NONBLOCK in ruby/win32.h */
+# define MODE_TO_LOAD (O_RDONLY | O_NONBLOCK)
+#elif defined O_NDELAY && HAVE_FCNTL && !(O_NDELAY & O_ACCMODE)
+# define MODE_TO_LOAD (O_RDONLY | O_NDELAY)
+#else
+# define MODE_TO_LOAD (O_RDONLY)
+#endif
+	int mode = MODE_TO_LOAD;
+#if defined DOSISH || defined __CYGWIN__
+# define isdirsep(x) ((x) == '/' || (x) == '\\')
+	{
+	    static const char exeext[] = ".exe";
+	    enum {extlen = sizeof(exeext)-1};
+	    if (flen > extlen && !isdirsep(fname[flen-extlen-1]) &&
+		STRNCASECMP(fname+flen-extlen, exeext, extlen) == 0) {
+		mode |= O_BINARY;
+		*xflag = 1;
+	    }
+	}
+#endif
+
+	if ((fd = rb_cloexec_open(fname, mode, 0)) < 0) {
+	    e = errno;
+	    if (!rb_gc_for_fd(e)) {
+		rb_load_fail(fname_v, strerror(e));
+	    }
+	    if ((fd = rb_cloexec_open(fname, mode, 0)) < 0) {
+		rb_load_fail(fname_v, strerror(errno));
+	    }
+	}
+	rb_update_max_fd(fd);
+
+#if defined HAVE_FCNTL && MODE_TO_LOAD != O_RDONLY
+# ifdef ENOTSUP
+#   define IS_SUPPORTED_OP(e) ((e) != ENOTSUP)
+# else
+#   define IS_SUPPORTED_OP(e) ((void)(e), 1)
+# endif
+	/* disabling O_NONBLOCK */
+	if (fcntl(fd, F_SETFL, 0) < 0 && IS_SUPPORTED_OP(e = errno)) {
+	    (void)close(fd);
+	    rb_load_fail(fname_v, strerror(e));
+	}
+#endif
+
+	e = ruby_is_fd_loadable(fd);
+	if (!e) {
+	    e = errno;
+	    (void)close(fd);
+	    rb_load_fail(fname_v, strerror(e));
+	}
+
+	f = rb_io_fdopen(fd, mode, fname);
+	if (e < 0) {
+	    /*
+	      We need to wait if FIFO is empty. It's FIFO's semantics.
+	      rb_thread_wait_fd() release GVL. So, it's safe.
+	    */
+	    rb_thread_wait_fd(fd);
+	}
+    }
+    return f;
+}
+
+static VALUE
+restore_load_file(VALUE arg)
+{
+    struct load_file_arg *argp = (struct load_file_arg *)arg;
+    VALUE f = argp->f;
+
+    if (!NIL_P(f) && f != rb_stdin) {
+	rb_io_close(f);
+    }
+    return Qnil;
+}
+
+static rb_ast_t *
+load_file(VALUE parser, VALUE fname, VALUE f, int script, ruby_cmdline_options_t *opt)
+{
+    struct load_file_arg arg;
+    arg.parser = parser;
+    arg.fname = fname;
+    arg.script = script;
+    arg.opt = opt;
+    arg.f = f;
+    return (rb_ast_t *)rb_ensure(load_file_internal, (VALUE)&arg,
+			      restore_load_file, (VALUE)&arg);
+}
+
+void *
+rb_load_file(const char *fname)
+{
+    VALUE fname_v = rb_str_new_cstr(fname);
+    return rb_load_file_str(fname_v);
+}
+
+void *
+rb_load_file_str(VALUE fname_v)
+{
+    return rb_parser_load_file(rb_parser_new(), fname_v);
+}
+
+void *
+rb_parser_load_file(VALUE parser, VALUE fname_v)
+{
+    ruby_cmdline_options_t opt;
+    VALUE f = open_load_file(fname_v, &cmdline_options_init(&opt)->xflag);
+    return load_file(parser, fname_v, f, 0, &opt);
+}
+
+/*
+ *  call-seq:
+ *     Process.argv0  -> frozen_string
+ *
+ *  Returns the name of the script being executed.  The value is not
+ *  affected by assigning a new value to $0.
+ *
+ *  This method first appeared in Ruby 2.1 to serve as a global
+ *  variable free means to get the script name.
+ */
+
+static VALUE
+proc_argv0(VALUE process)
+{
+    return rb_orig_progname;
+}
+
+static VALUE ruby_setproctitle(VALUE title);
+
+/*
+ *  call-seq:
+ *     Process.setproctitle(string)  -> string
+ *
+ *  Sets the process title that appears on the ps(1) command.  Not
+ *  necessarily effective on all platforms.  No exception will be
+ *  raised regardless of the result, nor will NotImplementedError be
+ *  raised even if the platform does not support the feature.
+ *
+ *  Calling this method does not affect the value of $0.
+ *
+ *     Process.setproctitle('myapp: worker #%d' % worker_id)
+ *
+ *  This method first appeared in Ruby 2.1 to serve as a global
+ *  variable free means to change the process title.
+ */
+
+static VALUE
+proc_setproctitle(VALUE process, VALUE title)
+{
+    return ruby_setproctitle(title);
+}
+
+static VALUE
+ruby_setproctitle(VALUE title)
+{
+    const char *ptr = StringValueCStr(title);
+    setproctitle("%.*s", RSTRING_LENINT(title), ptr);
+    return title;
+}
+
+static void
+set_arg0(VALUE val, ID id, VALUE *_)
+{
+    if (origarg.argv == 0)
+	rb_raise(rb_eRuntimeError, "$0 not initialized");
+
+    rb_progname = rb_str_new_frozen(ruby_setproctitle(val));
+}
+
+static inline VALUE
+external_str_new_cstr(const char *p)
+{
+#if UTF8_PATH
+    VALUE str = rb_utf8_str_new_cstr(p);
+    str = str_conv_enc(str, NULL, rb_default_external_encoding());
+    return str;
+#else
+    return rb_external_str_new_cstr(p);
+#endif
+}
+
+/*! Sets the current script name to this value.
+ *
+ * This is similar to <code>$0 = name</code> in Ruby level but also affects
+ * <code>Method#location</code> and others.
+ */
+void
+ruby_script(const char *name)
+{
+    if (name) {
+	rb_orig_progname = rb_progname = external_str_new_cstr(name);
+	rb_vm_set_progname(rb_progname);
+    }
+}
+
+/*! Sets the current script name to this value.
+ *
+ * Same as ruby_script() but accepts a VALUE.
+ */
+void
+ruby_set_script_name(VALUE name)
+{
+    rb_orig_progname = rb_progname = rb_str_dup(name);
+    rb_vm_set_progname(rb_progname);
+}
+
+static void
+init_ids(ruby_cmdline_options_t *opt)
+{
+    rb_uid_t uid = getuid();
+    rb_uid_t euid = geteuid();
+    rb_gid_t gid = getgid();
+    rb_gid_t egid = getegid();
+
+    if (uid != euid) opt->setids |= 1;
+    if (egid != gid) opt->setids |= 2;
+}
+
+#undef forbid_setid
+static void
+forbid_setid(const char *s, const ruby_cmdline_options_t *opt)
+{
+    if (opt->setids & 1)
+        rb_raise(rb_eSecurityError, "no %s allowed while running setuid", s);
+    if (opt->setids & 2)
+        rb_raise(rb_eSecurityError, "no %s allowed while running setgid", s);
+}
+
+static VALUE
+verbose_getter(ID id, VALUE *ptr)
+{
+    return *rb_ruby_verbose_ptr();
+}
+
+static void
+verbose_setter(VALUE val, ID id, VALUE *variable)
+{
+    *rb_ruby_verbose_ptr() = RTEST(val) ? Qtrue : val;
+}
+
+static VALUE
+opt_W_getter(ID id, VALUE *dmy)
+{
+    VALUE v = *rb_ruby_verbose_ptr();
+
+    switch (v) {
+      case Qnil:
+	return INT2FIX(0);
+      case Qfalse:
+	return INT2FIX(1);
+      case Qtrue:
+	return INT2FIX(2);
+      default:
+	return Qnil;
+    }
+}
+
+static VALUE
+debug_getter(ID id, VALUE *dmy)
+{
+    return *rb_ruby_debug_ptr();
+}
+
+static void
+debug_setter(VALUE val, ID id, VALUE *dmy)
+{
+    *rb_ruby_debug_ptr() = val;
+}
+
+/*! Defines built-in variables */
+void
+ruby_prog_init(void)
+{
+    rb_define_virtual_variable("$VERBOSE", verbose_getter, verbose_setter);
+    rb_define_virtual_variable("$-v",      verbose_getter, verbose_setter);
+    rb_define_virtual_variable("$-w",      verbose_getter, verbose_setter);
+    rb_define_virtual_variable("$-W",      opt_W_getter,   rb_gvar_readonly_setter);
+    rb_define_virtual_variable("$DEBUG",   debug_getter,   debug_setter);
+    rb_define_virtual_variable("$-d",      debug_getter,   debug_setter);
+
+    rb_gvar_ractor_local("$VERBOSE");
+    rb_gvar_ractor_local("$-v");
+    rb_gvar_ractor_local("$-w");
+    rb_gvar_ractor_local("$-W");
+    rb_gvar_ractor_local("$DEBUG");
+    rb_gvar_ractor_local("$-d");
+
+    rb_define_hooked_variable("$0", &rb_progname, 0, set_arg0);
+    rb_define_hooked_variable("$PROGRAM_NAME", &rb_progname, 0, set_arg0);
+
+    rb_define_module_function(rb_mProcess, "argv0", proc_argv0, 0);
+    rb_define_module_function(rb_mProcess, "setproctitle", proc_setproctitle, 1);
+
+    /*
+     * ARGV contains the command line arguments used to run ruby.
+     *
+     * A library like OptionParser can be used to process command-line
+     * arguments.
+     */
+    rb_define_global_const("ARGV", rb_argv);
+}
+
+void
+ruby_set_argv(int argc, char **argv)
+{
+    int i;
+    VALUE av = rb_argv;
+
+#if defined(USE_DLN_A_OUT)
+    if (origarg.argc > 0 && origarg.argv)
+	dln_argv0 = origarg.argv[0];
+    else if (argc > 0 && argv)
+	dln_argv0 = argv[0];
+#endif
+    rb_ary_clear(av);
+    for (i = 0; i < argc; i++) {
+	VALUE arg = external_str_new_cstr(argv[i]);
+
+	OBJ_FREEZE(arg);
+	rb_ary_push(av, arg);
+    }
+}
+
+void *
+ruby_process_options(int argc, char **argv)
+{
+    ruby_cmdline_options_t opt;
+    VALUE iseq;
+    const char *script_name = (argc > 0 && argv[0]) ? argv[0] : ruby_engine;
+
+    if (!origarg.argv || origarg.argc <= 0) {
+	origarg.argc = argc;
+	origarg.argv = argv;
+    }
+    ruby_script(script_name);  /* for the time being */
+    rb_argv0 = rb_str_new4(rb_progname);
+    rb_gc_register_mark_object(rb_argv0);
+    iseq = process_options(argc, argv, cmdline_options_init(&opt));
+
+#ifndef HAVE_SETPROCTITLE
+    ruby_init_setproctitle(argc, argv);
+#endif
+
+    return (void*)(struct RData*)iseq;
+}
+
+static void
+fill_standard_fds(void)
+{
+    int f0, f1, f2, fds[2];
+    struct stat buf;
+    f0 = fstat(0, &buf) == -1 && errno == EBADF;
+    f1 = fstat(1, &buf) == -1 && errno == EBADF;
+    f2 = fstat(2, &buf) == -1 && errno == EBADF;
+    if (f0) {
+        if (pipe(fds) == 0) {
+            close(fds[1]);
+            if (fds[0] != 0) {
+                dup2(fds[0], 0);
+                close(fds[0]);
+            }
+        }
+    }
+    if (f1 || f2) {
+        if (pipe(fds) == 0) {
+            close(fds[0]);
+            if (f1 && fds[1] != 1)
+                dup2(fds[1], 1);
+            if (f2 && fds[1] != 2)
+                dup2(fds[1], 2);
+            if (fds[1] != 1 && fds[1] != 2)
+                close(fds[1]);
+        }
+    }
+}
+
+/*! Initializes the process for libruby.
+ *
+ * This function assumes this process is ruby(1) and it has just started.
+ * Usually programs that embed CRuby interpreter may not call this function,
+ * and may do their own initialization.
+ * argc and argv cannot be NULL.
+ */
+void
+ruby_sysinit(int *argc, char ***argv)
+{
+#if defined(_WIN32)
+    rb_w32_sysinit(argc, argv);
+#endif
+    if (*argc >= 0 && *argv) {
+	origarg.argc = *argc;
+	origarg.argv = *argv;
+#if defined(USE_DLN_A_OUT)
+	dln_argv0 = origarg.argv[0];
+#endif
+    }
+    fill_standard_fds();
+}
diff -Nuarp ruby-3.0.5.a/spec/bundler/commands/clean_spec.rb ruby-3.0.5.b/spec/bundler/commands/clean_spec.rb
--- ruby-3.0.5.a/spec/bundler/commands/clean_spec.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/spec/bundler/commands/clean_spec.rb	2023-02-02 23:12:01.578200283 -0500
@@ -638,7 +638,7 @@ RSpec.describe "bundle clean" do
       s.executables = "irb"
     end
 
-    realworld_system_gems "fiddle --version 1.0.6", "tsort --version 0.1.0", "pathname --version 0.1.0", "set --version 1.0.1"
+    realworld_system_gems "fiddle --version 1.0.8", "tsort --version 0.1.0", "pathname --version 0.1.0", "set --version 1.0.1"
 
     install_gemfile <<-G
       source "#{file_uri_for(gem_repo2)}"
diff -Nuarp ruby-3.0.5.a/spec/bundler/install/gems/standalone_spec.rb ruby-3.0.5.b/spec/bundler/install/gems/standalone_spec.rb
--- ruby-3.0.5.a/spec/bundler/install/gems/standalone_spec.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/spec/bundler/install/gems/standalone_spec.rb	2023-02-02 23:12:01.578200283 -0500
@@ -113,7 +113,7 @@ RSpec.shared_examples "bundle install --
       skip "does not work on rubygems versions where `--install_dir` doesn't respect --default" unless Gem::Installer.for_spec(loaded_gemspec, :install_dir => "/foo").default_spec_file == "/foo/specifications/default/bundler-#{Bundler::VERSION}.gemspec" # Since rubygems 3.2.0.rc.2
       skip "does not work on old rubies because the realworld gems that need to be installed don't support them" if RUBY_VERSION < "2.7.0"
 
-      realworld_system_gems "fiddle --version 1.0.6", "tsort --version 0.1.0"
+      realworld_system_gems "fiddle --version 1.0.8", "tsort --version 0.1.0"
 
       necessary_system_gems = ["optparse --version 0.1.1", "psych --version 3.3.2", "yaml --version 0.1.1", "logger --version 1.4.3", "etc --version 1.2.0", "stringio --version 3.0.0"]
       necessary_system_gems += ["shellwords --version 0.1.0", "base64 --version 0.1.0", "resolv --version 0.2.1"] if Gem.rubygems_version < Gem::Version.new("3.3.3.a")
diff -Nuarp ruby-3.0.5.a/spec/ruby/core/time/shared/local.rb ruby-3.0.5.b/spec/ruby/core/time/shared/local.rb
--- ruby-3.0.5.a/spec/ruby/core/time/shared/local.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/spec/ruby/core/time/shared/local.rb	2023-02-02 23:12:08.018251429 -0500
@@ -6,18 +6,16 @@ describe :time_local, shared: true do
     end
   end
 
-=begin
   platform_is_not :windows do
     describe "timezone changes" do
-      it "correctly adjusts the timezone change to 'CEST' on 'Europe/Amsterdam'" do
+      it "correctly adjusts the timezone change to 'CET' on 'Europe/Amsterdam'" do
         with_timezone("Europe/Amsterdam") do
-          Time.send(@method, 1940, 5, 16).to_a.should ==
-            [0, 40, 1, 16, 5, 1940, 4, 137, true, "CEST"]
+          Time.send(@method, 1970, 5, 16).to_a.should ==
+            [0, 0, 0, 16, 5, 1970, 6, 136, false, "CET"]
         end
       end
     end
   end
-=end
 end
 
 describe :time_local_10_arg, shared: true do
diff -Nuarp ruby-3.0.5.a/template/ruby.pc.in ruby-3.0.5.b/template/ruby.pc.in
--- ruby-3.0.5.a/template/ruby.pc.in	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/template/ruby.pc.in	2023-02-02 23:11:10.392793793 -0500
@@ -9,6 +9,7 @@ MAJOR=@MAJOR@
 MINOR=@MINOR@
 TEENY=@TEENY@
 ruby_version=@ruby_version@
+ruby_version_dir_name=@ruby_version_dir_name@
 RUBY_API_VERSION=@RUBY_API_VERSION@
 RUBY_PROGRAM_VERSION=@RUBY_PROGRAM_VERSION@
 RUBY_BASE_NAME=@RUBY_BASE_NAME@
diff -Nuarp ruby-3.0.5.a/template/verconf.h.tmpl ruby-3.0.5.b/template/verconf.h.tmpl
--- ruby-3.0.5.a/template/verconf.h.tmpl	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/template/verconf.h.tmpl	2023-02-02 23:11:27.109926555 -0500
@@ -36,6 +36,9 @@
 % if C["RUBY_SEARCH_PATH"]
 #define RUBY_SEARCH_PATH		"${RUBY_SEARCH_PATH}"
 % end
+% if C["rubygemsdir"]
+#define RUBYGEMS_DIR			"${rubygemsdir}"
+% end
 %
 % R = {}
 % R["ruby_version"] = '"RUBY_LIB_VERSION"'
diff -Nuarp ruby-3.0.5.a/test/cgi/test_cgi_cookie.rb ruby-3.0.5.b/test/cgi/test_cgi_cookie.rb
--- ruby-3.0.5.a/test/cgi/test_cgi_cookie.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/test/cgi/test_cgi_cookie.rb	2023-02-02 23:12:17.874329699 -0500
@@ -62,18 +62,21 @@ class CGICookieTest < Test::Unit::TestCa
 
   def test_cgi_cookie_new_with_domain
     h = {'name'=>'name1', 'value'=>'value1'}
-    cookie = CGI::Cookie.new('domain'=>'a.example.com', **h)
+    cookie = CGI::Cookie.new(h.merge('domain'=>'a.example.com'))
     assert_equal('a.example.com', cookie.domain)
 
-    cookie = CGI::Cookie.new('domain'=>'1.example.com', **h)
+    cookie = CGI::Cookie.new(h.merge('domain'=>'.example.com'))
+    assert_equal('.example.com', cookie.domain)
+
+    cookie = CGI::Cookie.new(h.merge('domain'=>'1.example.com'))
     assert_equal('1.example.com', cookie.domain, 'enhanced by RFC 1123')
 
     assert_raise(ArgumentError) {
-      CGI::Cookie.new('domain'=>'-a.example.com', **h)
+      CGI::Cookie.new(h.merge('domain'=>'-a.example.com'))
     }
 
     assert_raise(ArgumentError) {
-      CGI::Cookie.new('domain'=>'a-.example.com', **h)
+      CGI::Cookie.new(h.merge('domain'=>'a-.example.com'))
     }
   end
 
diff -Nuarp ruby-3.0.5.a/test/-ext-/bug_reporter/test_bug_reporter.rb ruby-3.0.5.b/test/-ext-/bug_reporter/test_bug_reporter.rb
--- ruby-3.0.5.a/test/-ext-/bug_reporter/test_bug_reporter.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/test/-ext-/bug_reporter/test_bug_reporter.rb	2023-02-02 23:11:52.248126190 -0500
@@ -21,7 +21,7 @@ class TestBugReporter < Test::Unit::Test
     args = ["--disable-gems", "-r-test-/bug_reporter",
             "-C", tmpdir]
     stdin = "register_sample_bug_reporter(12345); Process.kill :SEGV, $$"
-    assert_in_out_err(args, stdin, [], expected_stderr, encoding: "ASCII-8BIT")
+    assert_in_out_err(args, stdin, [], expected_stderr, encoding: "ASCII-8BIT", timeout_error: nil)
   ensure
     FileUtils.rm_rf(tmpdir) if tmpdir
   end
diff -Nuarp ruby-3.0.5.a/test/fiddle/helper.rb ruby-3.0.5.b/test/fiddle/helper.rb
--- ruby-3.0.5.a/test/fiddle/helper.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/test/fiddle/helper.rb	2023-02-02 23:11:38.555017448 -0500
@@ -139,6 +139,9 @@ if RUBY_PLATFORM =~ /darwin/
   libc_so = libm_so = "/usr/lib/libSystem.B.dylib"
 end
 
+# Just ignore the heuristic, because it is not reliable on all platforms.
+libc_so = libm_so = nil
+
 if !libc_so || !libm_so
   ruby = EnvUtil.rubybin
   # When the ruby binary is 32-bit and the host is 64-bit,
diff -Nuarp ruby-3.0.5.a/test/ruby/test_gc_compact.rb ruby-3.0.5.b/test/ruby/test_gc_compact.rb
--- ruby-3.0.5.a/test/ruby/test_gc_compact.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/test/ruby/test_gc_compact.rb	2023-02-02 23:11:57.421167265 -0500
@@ -4,12 +4,32 @@ require 'fiddle'
 require 'etc'
 
 class TestGCCompact < Test::Unit::TestCase
-  class AutoCompact < Test::Unit::TestCase
+  module SupportsCompact
     def setup
       skip "autocompact not supported on this platform" unless supports_auto_compact?
       super
     end
 
+    private
+
+    def supports_auto_compact?
+      return true unless defined?(Etc::SC_PAGE_SIZE)
+
+      begin
+        return GC::INTERNAL_CONSTANTS[:HEAP_PAGE_SIZE] % Etc.sysconf(Etc::SC_PAGE_SIZE) == 0
+      rescue NotImplementedError
+      rescue ArgumentError
+      end
+
+      true
+    end
+  end
+
+  include SupportsCompact
+
+  class AutoCompact < Test::Unit::TestCase
+    include SupportsCompact
+
     def test_enable_autocompact
       before = GC.auto_compact
       GC.auto_compact = true
@@ -59,26 +79,17 @@ class TestGCCompact < Test::Unit::TestCa
     ensure
       GC.auto_compact = before
     end
-
-    private
-
-    def supports_auto_compact?
-      return true unless defined?(Etc::SC_PAGE_SIZE)
-
-      begin
-        return GC::INTERNAL_CONSTANTS[:HEAP_PAGE_SIZE] % Etc.sysconf(Etc::SC_PAGE_SIZE) == 0
-      rescue NotImplementedError
-      rescue ArgumentError
-      end
-
-      true
-    end
   end
 
   def os_page_size
     return true unless defined?(Etc::SC_PAGE_SIZE)
   end
 
+  def setup
+    skip "autocompact not supported on this platform" unless supports_auto_compact?
+    super
+  end
+
   def test_gc_compact_stats
     list = []
 
diff -Nuarp ruby-3.0.5.a/test/rubygems/test_gem.rb ruby-3.0.5.b/test/rubygems/test_gem.rb
--- ruby-3.0.5.a/test/rubygems/test_gem.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/test/rubygems/test_gem.rb	2023-02-02 23:11:10.392793793 -0500
@@ -1440,7 +1440,8 @@ class TestGem < Gem::TestCase
 
   def test_self_user_dir
     parts = [@userhome, '.gem', Gem.ruby_engine]
-    parts << RbConfig::CONFIG['ruby_version'] unless RbConfig::CONFIG['ruby_version'].empty?
+    ruby_version_dir_name = RbConfig::CONFIG['ruby_version_dir_name'] || RbConfig::CONFIG['ruby_version']
+    parts << ruby_version_dir_name unless ruby_version_dir_name.empty?
 
     FileUtils.mkdir_p File.join(parts)
 
@@ -1516,7 +1517,7 @@ class TestGem < Gem::TestCase
     vendordir(File.join(@tempdir, 'vendor')) do
       expected =
         File.join RbConfig::CONFIG['vendordir'], 'gems',
-                  RbConfig::CONFIG['ruby_version']
+                  RbConfig::CONFIG['ruby_version_dir_name'] || RbConfig::CONFIG['ruby_version']
 
       assert_equal expected, Gem.vendor_dir
     end
diff -Nuarp ruby-3.0.5.a/test/rubygems/test_gem.rb.orig ruby-3.0.5.b/test/rubygems/test_gem.rb.orig
--- ruby-3.0.5.a/test/rubygems/test_gem.rb.orig	1969-12-31 19:00:00.000000000 -0500
+++ ruby-3.0.5.b/test/rubygems/test_gem.rb.orig	2023-02-02 23:10:58.750701336 -0500
@@ -0,0 +1,2156 @@
+# coding: US-ASCII
+require_relative 'helper'
+require 'rubygems'
+require 'rubygems/command'
+require 'rubygems/installer'
+require 'pathname'
+require 'tmpdir'
+require 'rbconfig'
+
+class TestGem < Gem::TestCase
+  PLUGINS_LOADED = [] # rubocop:disable Style/MutableConstant
+
+  PROJECT_DIR = File.expand_path('../../..', __FILE__).tap(&Gem::UNTAINT)
+
+  def setup
+    super
+
+    PLUGINS_LOADED.clear
+
+    common_installer_setup
+
+    @additional = %w[a b].map {|d| File.join @tempdir, d }
+
+    util_remove_interrupt_command
+  end
+
+  def test_self_finish_resolve
+    a1 = util_spec "a", "1", "b" => "> 0"
+    b1 = util_spec "b", "1", "c" => ">= 1"
+    b2 = util_spec "b", "2", "c" => ">= 2"
+    c1 = util_spec "c", "1"
+    c2 = util_spec "c", "2"
+
+    install_specs c1, c2, b1, b2, a1
+
+    a1.activate
+
+    assert_equal %w[a-1], loaded_spec_names
+    assert_equal ["b (> 0)"], unresolved_names
+
+    Gem.finish_resolve
+
+    assert_equal %w[a-1 b-2 c-2], loaded_spec_names
+    assert_equal [], unresolved_names
+  end
+
+  def test_self_finish_resolve_wtf
+    a1 = util_spec "a", "1", "b" => "> 0", "d" => "> 0"    # this
+    b1 = util_spec "b", "1", { "c" => ">= 1" }, "lib/b.rb" # this
+    b2 = util_spec "b", "2", { "c" => ">= 2" }, "lib/b.rb"
+    c1 = util_spec "c", "1"                                # this
+    c2 = util_spec "c", "2"
+    d1 = util_spec "d", "1", { "c" => "< 2" },  "lib/d.rb"
+    d2 = util_spec "d", "2", { "c" => "< 2" },  "lib/d.rb" # this
+
+    install_specs c1, c2, b1, b2, d1, d2, a1
+
+    a1.activate
+
+    assert_equal %w[a-1], loaded_spec_names
+    assert_equal ["b (> 0)", "d (> 0)"], unresolved_names
+
+    Gem.finish_resolve
+
+    assert_equal %w[a-1 b-1 c-1 d-2], loaded_spec_names
+    assert_equal [], unresolved_names
+  end
+
+  def test_self_finish_resolve_respects_loaded_specs
+    a1 = util_spec "a", "1", "b" => "> 0"
+    b1 = util_spec "b", "1", "c" => ">= 1"
+    b2 = util_spec "b", "2", "c" => ">= 2"
+    c1 = util_spec "c", "1"
+    c2 = util_spec "c", "2"
+
+    install_specs c1, c2, b1, b2, a1
+
+    a1.activate
+    c1.activate
+
+    assert_equal %w[a-1 c-1], loaded_spec_names
+    assert_equal ["b (> 0)"], unresolved_names
+
+    Gem.finish_resolve
+
+    assert_equal %w[a-1 b-1 c-1], loaded_spec_names
+    assert_equal [], unresolved_names
+  end
+
+  def test_self_install
+    spec_fetcher do |f|
+      f.gem  'a', 1
+      f.spec 'a', 2
+    end
+
+    gemhome2 = "#{@gemhome}2"
+
+    installed = Gem.install 'a', '= 1', :install_dir => gemhome2
+
+    assert_equal %w[a-1], installed.map {|spec| spec.full_name }
+
+    assert_path_exist File.join(gemhome2, 'gems', 'a-1')
+  end
+
+  def test_self_install_in_rescue
+    spec_fetcher do |f|
+      f.gem  'a', 1
+      f.spec 'a', 2
+    end
+
+    gemhome2 = "#{@gemhome}2"
+
+    installed =
+      begin
+        raise 'Error'
+      rescue StandardError
+        Gem.install 'a', '= 1', :install_dir => gemhome2
+      end
+    assert_equal %w[a-1], installed.map {|spec| spec.full_name }
+  end
+
+  def test_self_install_permissions
+    assert_self_install_permissions
+  end
+
+  def test_self_install_permissions_umask_0
+    umask = File.umask(0)
+    assert_self_install_permissions
+  ensure
+    File.umask(umask)
+  end
+
+  def test_self_install_permissions_umask_077
+    umask = File.umask(077)
+    assert_self_install_permissions
+  ensure
+    File.umask(umask)
+  end
+
+  def test_self_install_permissions_with_format_executable
+    assert_self_install_permissions(format_executable: true)
+  end
+
+  def test_self_install_permissions_with_format_executable_and_non_standard_ruby_install_name
+    Gem::Installer.exec_format = nil
+    ruby_install_name 'ruby27' do
+      assert_self_install_permissions(format_executable: true)
+    end
+  ensure
+    Gem::Installer.exec_format = nil
+  end
+
+  def assert_self_install_permissions(format_executable: false)
+    mask = win_platform? ? 0700 : 0777
+    options = {
+      :dir_mode => 0500,
+      :prog_mode => win_platform? ? 0410 : 0510,
+      :data_mode => 0640,
+      :wrappers => true,
+      :format_executable => format_executable,
+    }
+    Dir.chdir @tempdir do
+      Dir.mkdir 'bin'
+      Dir.mkdir 'data'
+
+      File.write 'bin/foo', "#!/usr/bin/env ruby\n"
+      File.chmod 0755, 'bin/foo'
+
+      File.write 'data/foo.txt', "blah\n"
+
+      spec_fetcher do |f|
+        f.gem 'foo', 1 do |s|
+          s.executables = ['foo']
+          s.files = %w[bin/foo data/foo.txt]
+        end
+      end
+      Gem.install 'foo', Gem::Requirement.default, options
+    end
+
+    prog_mode = (options[:prog_mode] & mask).to_s(8)
+    dir_mode = (options[:dir_mode] & mask).to_s(8)
+    data_mode = (options[:data_mode] & mask).to_s(8)
+    prog_name = 'foo'
+    prog_name = RbConfig::CONFIG['ruby_install_name'].sub('ruby', 'foo') if options[:format_executable]
+    expected = {
+      "bin/#{prog_name}" => prog_mode,
+      'gems/foo-1' => dir_mode,
+      'gems/foo-1/bin' => dir_mode,
+      'gems/foo-1/data' => dir_mode,
+      'gems/foo-1/bin/foo' => prog_mode,
+      'gems/foo-1/data/foo.txt' => data_mode,
+    }
+    # add Windows script
+    expected["bin/#{prog_name}.bat"] = mask.to_s(8) if win_platform?
+    result = {}
+    Dir.chdir @gemhome do
+      expected.each_key do |n|
+        result[n] = (File.stat(n).mode & mask).to_s(8)
+      end
+    end
+    assert_equal(expected, result)
+  ensure
+    File.chmod(0755, *Dir.glob(@gemhome + '/gems/**/').map {|path| path.tap(&Gem::UNTAINT) })
+  end
+
+  def test_require_missing
+    assert_raise ::LoadError do
+      require "test_require_missing"
+    end
+  end
+
+  def test_require_does_not_glob
+    a1 = util_spec "a", "1", nil, "lib/a1.rb"
+
+    install_specs a1
+
+    assert_raise ::LoadError do
+      require "a*"
+    end
+
+    assert_equal [], loaded_spec_names
+  end
+
+  def test_self_bin_path_active
+    a1 = util_spec 'a', '1' do |s|
+      s.executables = ['exec']
+    end
+
+    util_spec 'a', '2' do |s|
+      s.executables = ['exec']
+    end
+
+    a1.activate
+
+    assert_match 'a-1/bin/exec', Gem.bin_path('a', 'exec', '>= 0')
+  end
+
+  def test_self_bin_path_picking_newest
+    a1 = util_spec 'a', '1' do |s|
+      s.executables = ['exec']
+    end
+
+    a2 = util_spec 'a', '2' do |s|
+      s.executables = ['exec']
+    end
+
+    install_specs a1, a2
+
+    assert_match 'a-2/bin/exec', Gem.bin_path('a', 'exec', '>= 0')
+  end
+
+  def test_self_activate_bin_path_no_exec_name
+    e = assert_raise ArgumentError do
+      Gem.activate_bin_path 'a'
+    end
+
+    assert_equal 'you must supply exec_name', e.message
+  end
+
+  def test_activate_bin_path_resolves_eagerly
+    a1 = util_spec 'a', '1' do |s|
+      s.executables = ['exec']
+      s.add_dependency 'b'
+    end
+
+    b1 = util_spec 'b', '1' do |s|
+      s.add_dependency 'c', '2'
+    end
+
+    b2 = util_spec 'b', '2' do |s|
+      s.add_dependency 'c', '1'
+    end
+
+    c1 = util_spec 'c', '1'
+    c2 = util_spec 'c', '2'
+
+    install_specs c1, c2, b1, b2, a1
+
+    Gem.activate_bin_path("a", "exec", ">= 0")
+
+    # If we didn't eagerly resolve, this would activate c-2 and then the
+    # finish_resolve would cause a conflict
+    gem 'c'
+    Gem.finish_resolve
+
+    assert_equal %w[a-1 b-2 c-1], loaded_spec_names
+  end
+
+  def test_activate_bin_path_does_not_error_if_a_gem_thats_not_finally_activated_has_orphaned_dependencies
+    a1 = util_spec 'a', '1' do |s|
+      s.executables = ['exec']
+      s.add_dependency 'b'
+    end
+
+    b1 = util_spec 'b', '1' do |s|
+      s.add_dependency 'c', '1'
+    end
+
+    b2 = util_spec 'b', '2' do |s|
+      s.add_dependency 'c', '2'
+    end
+
+    c2 = util_spec 'c', '2'
+
+    install_specs c2, b1, b2, a1
+
+    # c1 is missing, but not needed for activation, so we should not get any errors here
+
+    Gem.activate_bin_path("a", "exec", ">= 0")
+
+    assert_equal %w[a-1 b-2 c-2], loaded_spec_names
+  end
+
+  def test_activate_bin_path_raises_a_meaningful_error_if_a_gem_thats_finally_activated_has_orphaned_dependencies
+    a1 = util_spec 'a', '1' do |s|
+      s.executables = ['exec']
+      s.add_dependency 'b'
+    end
+
+    b1 = util_spec 'b', '1' do |s|
+      s.add_dependency 'c', '1'
+    end
+
+    b2 = util_spec 'b', '2' do |s|
+      s.add_dependency 'c', '2'
+    end
+
+    c1 = util_spec 'c', '1'
+
+    install_specs c1, b1, b2, a1
+
+    # c2 is missing, and b2 which has it as a dependency will be activated, so we should get an error about the orphaned dependency
+
+    e = assert_raise Gem::UnsatisfiableDependencyError do
+      load Gem.activate_bin_path("a", "exec", ">= 0")
+    end
+
+    assert_equal "Unable to resolve dependency: 'b (>= 0)' requires 'c (= 2)'", e.message
+  end
+
+  def test_activate_bin_path_in_debug_mode
+    a1 = util_spec 'a', '1' do |s|
+      s.executables = ['exec']
+    end
+
+    install_specs a1
+
+    require "open3"
+    output, status = Open3.capture2e(
+      { "GEM_HOME" => Gem.paths.home, "DEBUG_RESOLVER" => "1" },
+      *ruby_with_rubygems_in_load_path, "-e", "\"Gem.activate_bin_path('a', 'exec', '>= 0')\""
+    )
+
+    assert status.success?, output
+  end
+
+  def test_activate_bin_path_gives_proper_error_for_bundler
+    bundler = util_spec 'bundler', '2' do |s|
+      s.executables = ['bundle']
+    end
+
+    install_specs bundler
+
+    File.open("Gemfile.lock", "w") do |f|
+      f.write <<-L.gsub(/ {8}/, "")
+        GEM
+          remote: https://rubygems.org/
+          specs:
+
+        PLATFORMS
+          ruby
+
+        DEPENDENCIES
+
+        BUNDLED WITH
+          9999
+      L
+    end
+
+    File.open("Gemfile", "w") {|f| f.puts('source "https://rubygems.org"') }
+
+    e = assert_raise Gem::GemNotFoundException do
+      load Gem.activate_bin_path("bundler", "bundle", ">= 0.a")
+    end
+
+    assert_includes e.message, "Could not find 'bundler' (9999) required by your #{File.expand_path("Gemfile.lock")}."
+    assert_includes e.message, "To update to the latest version installed on your system, run `bundle update --bundler`."
+    assert_includes e.message, "To install the missing version, run `gem install bundler:9999`"
+    refute_includes e.message, "can't find gem bundler (>= 0.a) with executable bundle"
+  end
+
+  def test_activate_bin_path_selects_exact_bundler_version_if_present
+    bundler_latest = util_spec 'bundler', '2.0.1' do |s|
+      s.executables = ['bundle']
+    end
+
+    bundler_previous = util_spec 'bundler', '2.0.0' do |s|
+      s.executables = ['bundle']
+    end
+
+    install_specs bundler_latest, bundler_previous
+
+    File.open("Gemfile.lock", "w") do |f|
+      f.write <<-L.gsub(/ {8}/, "")
+        GEM
+          remote: https://rubygems.org/
+          specs:
+
+        PLATFORMS
+          ruby
+
+        DEPENDENCIES
+
+        BUNDLED WITH
+          2.0.0
+      L
+    end
+
+    File.open("Gemfile", "w") {|f| f.puts('source "https://rubygems.org"') }
+
+    load Gem.activate_bin_path("bundler", "bundle", ">= 0.a")
+
+    assert_equal %w[bundler-2.0.0], loaded_spec_names
+  end
+
+  def test_activate_bin_path_respects_underscore_selection_if_given
+    bundler_latest = util_spec 'bundler', '2.0.1' do |s|
+      s.executables = ['bundle']
+    end
+
+    bundler_previous = util_spec 'bundler', '1.17.3' do |s|
+      s.executables = ['bundle']
+    end
+
+    install_specs bundler_latest, bundler_previous
+
+    File.open("Gemfile.lock", "w") do |f|
+      f.write <<-L.gsub(/ {8}/, "")
+        GEM
+          remote: https://rubygems.org/
+          specs:
+
+        PLATFORMS
+          ruby
+
+        DEPENDENCIES
+
+        BUNDLED WITH
+          2.0.1
+      L
+    end
+
+    File.open("Gemfile", "w") {|f| f.puts('source "https://rubygems.org"') }
+
+    load Gem.activate_bin_path("bundler", "bundle", "= 1.17.3")
+
+    assert_equal %w[bundler-1.17.3], loaded_spec_names
+  end
+
+  def test_activate_bin_path_gives_proper_error_for_bundler_when_underscore_selection_given
+    File.open("Gemfile.lock", "w") do |f|
+      f.write <<-L.gsub(/ {8}/, "")
+        GEM
+          remote: https://rubygems.org/
+          specs:
+
+        PLATFORMS
+          ruby
+
+        DEPENDENCIES
+
+        BUNDLED WITH
+          2.1.4
+      L
+    end
+
+    File.open("Gemfile", "w") {|f| f.puts('source "https://rubygems.org"') }
+
+    e = assert_raise Gem::GemNotFoundException do
+      load Gem.activate_bin_path("bundler", "bundle", "= 2.2.8")
+    end
+
+    assert_equal "can't find gem bundler (= 2.2.8) with executable bundle", e.message
+  end
+
+  def test_self_bin_path_no_exec_name
+    e = assert_raise ArgumentError do
+      Gem.bin_path 'a'
+    end
+
+    assert_equal 'you must supply exec_name', e.message
+  end
+
+  def test_self_bin_path_bin_name
+    install_specs util_exec_gem
+    assert_equal @abin_path, Gem.bin_path('a', 'abin')
+  end
+
+  def test_self_bin_path_bin_name_version
+    install_specs util_exec_gem
+    assert_equal @abin_path, Gem.bin_path('a', 'abin', '4')
+  end
+
+  def test_self_bin_path_nonexistent_binfile
+    util_spec 'a', '2' do |s|
+      s.executables = ['exec']
+    end
+    assert_raise(Gem::GemNotFoundException) do
+      Gem.bin_path('a', 'other', '2')
+    end
+  end
+
+  def test_self_bin_path_no_bin_file
+    util_spec 'a', '1'
+    assert_raise(ArgumentError) do
+      Gem.bin_path('a', nil, '1')
+    end
+  end
+
+  def test_self_bin_path_not_found
+    assert_raise(Gem::GemNotFoundException) do
+      Gem.bin_path('non-existent', 'blah')
+    end
+  end
+
+  def test_self_bin_path_bin_file_gone_in_latest
+    install_specs util_exec_gem
+    spec = util_spec 'a', '10' do |s|
+      s.executables = []
+    end
+    install_specs spec
+    assert_equal @abin_path, Gem.bin_path('a', 'abin')
+  end
+
+  def test_self_bindir
+    assert_equal File.join(@gemhome, 'bin'), Gem.bindir
+    assert_equal File.join(@gemhome, 'bin'), Gem.bindir(Gem.dir)
+    assert_equal File.join(@gemhome, 'bin'), Gem.bindir(Pathname.new(Gem.dir))
+  end
+
+  def test_self_bindir_default_dir
+    default = Gem.default_dir
+
+    assert_equal Gem.default_bindir, Gem.bindir(default)
+  end
+
+  def test_self_clear_paths
+    assert_match(/gemhome$/, Gem.dir)
+    assert_match(/gemhome$/, Gem.path.first)
+
+    Gem.clear_paths
+
+    assert_nil Gem::Specification.send(:class_variable_get, :@@all)
+  end
+
+  def test_self_configuration
+    expected = Gem::ConfigFile.new []
+    Gem.configuration = nil
+
+    assert_equal expected, Gem.configuration
+  end
+
+  def test_self_datadir
+    foo = nil
+
+    Dir.chdir @tempdir do
+      FileUtils.mkdir_p 'data'
+      File.open File.join('data', 'foo.txt'), 'w' do |fp|
+        fp.puts 'blah'
+      end
+
+      foo = util_spec 'foo' do |s|
+        s.files = %w[data/foo.txt]
+      end
+
+      install_gem foo
+    end
+
+    gem 'foo'
+
+    expected = File.join @gemhome, 'gems', foo.full_name, 'data', 'foo'
+
+    assert_equal expected, Gem::Specification.find_by_name("foo").datadir
+  end
+
+  def test_self_datadir_nonexistent_package
+    assert_raise(Gem::MissingSpecError) do
+      Gem::Specification.find_by_name("xyzzy").datadir
+    end
+  end
+
+  def test_self_default_exec_format
+    ruby_install_name 'ruby' do
+      assert_equal '%s', Gem.default_exec_format
+    end
+  end
+
+  def test_self_default_exec_format_18
+    ruby_install_name 'ruby18' do
+      assert_equal '%s18', Gem.default_exec_format
+    end
+  end
+
+  def test_self_default_exec_format_jruby
+    ruby_install_name 'jruby' do
+      assert_equal 'j%s', Gem.default_exec_format
+    end
+  end
+
+  def test_default_path
+    vendordir(File.join(@tempdir, 'vendor')) do
+      FileUtils.rm_rf Gem.user_home
+
+      expected = [Gem.default_dir]
+
+      assert_equal expected, Gem.default_path
+    end
+  end
+
+  def test_default_path_missing_vendor
+    vendordir(nil) do
+      FileUtils.rm_rf Gem.user_home
+
+      expected = [Gem.default_dir]
+
+      assert_equal expected, Gem.default_path
+    end
+  end
+
+  def test_default_path_user_home
+    vendordir(File.join(@tempdir, 'vendor')) do
+      expected = [Gem.user_dir, Gem.default_dir]
+
+      assert_equal expected, Gem.default_path
+    end
+  end
+
+  def test_default_path_vendor_dir
+    vendordir(File.join(@tempdir, 'vendor')) do
+      FileUtils.mkdir_p Gem.vendor_dir
+
+      FileUtils.rm_rf Gem.user_home
+
+      expected = [Gem.default_dir, Gem.vendor_dir]
+
+      assert_equal expected, Gem.default_path
+    end
+  end
+
+  def test_self_default_sources
+    assert_equal %w[https://rubygems.org/], Gem.default_sources
+  end
+
+  def test_self_use_gemdeps
+    with_rubygems_gemdeps('-') do
+      FileUtils.mkdir_p 'detect/a/b'
+      FileUtils.mkdir_p 'detect/a/Isolate'
+
+      FileUtils.touch 'detect/Isolate'
+
+      begin
+        Dir.chdir 'detect/a/b'
+
+        Gem.use_gemdeps
+
+        assert_equal add_bundler_full_name([]), loaded_spec_names
+      ensure
+        Dir.chdir @tempdir
+      end
+    end
+  end
+
+  def test_self_dir
+    assert_equal @gemhome, Gem.dir
+  end
+
+  def test_self_ensure_gem_directories
+    FileUtils.rm_r @gemhome
+    Gem.use_paths @gemhome
+
+    Gem.ensure_gem_subdirectories @gemhome
+
+    assert_path_exist File.join @gemhome, 'build_info'
+    assert_path_exist File.join @gemhome, 'cache'
+    assert_path_exist File.join @gemhome, 'doc'
+    assert_path_exist File.join @gemhome, 'extensions'
+    assert_path_exist File.join @gemhome, 'gems'
+    assert_path_exist File.join @gemhome, 'specifications'
+  end
+
+  def test_self_ensure_gem_directories_permissions
+    FileUtils.rm_r @gemhome
+    Gem.use_paths @gemhome
+
+    Gem.ensure_gem_subdirectories @gemhome, 0750
+
+    assert_directory_exists File.join(@gemhome, "cache")
+
+    assert_equal 0750, File::Stat.new(@gemhome).mode & 0777
+    assert_equal 0750, File::Stat.new(File.join(@gemhome, "cache")).mode & 0777
+  end unless win_platform?
+
+  def test_self_ensure_gem_directories_safe_permissions
+    FileUtils.rm_r @gemhome
+    Gem.use_paths @gemhome
+
+    old_umask = File.umask
+    File.umask 0
+    Gem.ensure_gem_subdirectories @gemhome
+
+    assert_equal 0, File::Stat.new(@gemhome).mode & 002
+    assert_equal 0, File::Stat.new(File.join(@gemhome, "cache")).mode & 002
+  ensure
+    File.umask old_umask
+  end unless win_platform?
+
+  def test_self_ensure_gem_directories_missing_parents
+    gemdir = File.join @tempdir, 'a/b/c/gemdir'
+    FileUtils.rm_rf File.join(@tempdir, 'a') rescue nil
+    refute File.exist?(File.join(@tempdir, 'a')),
+           "manually remove #{File.join @tempdir, 'a'}, tests are broken"
+    Gem.use_paths gemdir
+
+    Gem.ensure_gem_subdirectories gemdir
+
+    assert_directory_exists util_cache_dir
+  end
+
+  unless win_platform? || Process.uid.zero? # only for FS that support write protection
+    def test_self_ensure_gem_directories_write_protected
+      gemdir = File.join @tempdir, "egd"
+      FileUtils.rm_r gemdir rescue nil
+      refute File.exist?(gemdir), "manually remove #{gemdir}, tests are broken"
+      FileUtils.mkdir_p gemdir
+      FileUtils.chmod 0400, gemdir
+      Gem.use_paths gemdir
+
+      Gem.ensure_gem_subdirectories gemdir
+
+      refute File.exist?(util_cache_dir)
+    ensure
+      FileUtils.chmod 0600, gemdir
+    end
+
+    def test_self_ensure_gem_directories_write_protected_parents
+      parent = File.join(@tempdir, "egd")
+      gemdir = "#{parent}/a/b/c"
+
+      FileUtils.rm_r parent rescue nil
+      refute File.exist?(parent), "manually remove #{parent}, tests are broken"
+      FileUtils.mkdir_p parent
+      FileUtils.chmod 0400, parent
+      Gem.use_paths(gemdir)
+
+      Gem.ensure_gem_subdirectories gemdir
+
+      refute File.exist? File.join(gemdir, "gems")
+    ensure
+      FileUtils.chmod 0600, parent
+    end
+
+    def test_self_ensure_gem_directories_non_existent_paths
+      Gem.ensure_gem_subdirectories '/proc/0123456789/bogus' # should not raise
+      Gem.ensure_gem_subdirectories 'classpath:/bogus/x' # JRuby embed scenario
+    end
+  end
+
+  def test_self_extension_dir_shared
+    enable_shared 'yes' do
+      assert_equal Gem.ruby_api_version, Gem.extension_api_version
+    end
+  end
+
+  def test_self_extension_dir_static
+    enable_shared 'no' do
+      assert_equal "#{Gem.ruby_api_version}-static", Gem.extension_api_version
+    end
+  end
+
+  def test_self_find_files
+    cwd = File.expand_path("test/rubygems", PROJECT_DIR)
+    $LOAD_PATH.unshift cwd
+
+    discover_path = File.join 'lib', 'sff', 'discover.rb'
+
+    foo1, foo2 = %w[1 2].map do |version|
+      spec = quick_gem 'sff', version do |s|
+        s.files << discover_path
+      end
+
+      write_file(File.join 'gems', spec.full_name, discover_path) do |fp|
+        fp.puts "# #{spec.full_name}"
+      end
+
+      spec
+    end
+
+    Gem.refresh
+
+    expected = [
+      File.expand_path('test/rubygems/sff/discover.rb', PROJECT_DIR),
+      File.join(foo2.full_gem_path, discover_path),
+      File.join(foo1.full_gem_path, discover_path),
+    ]
+
+    assert_equal expected, Gem.find_files('sff/discover')
+    assert_equal expected, Gem.find_files('sff/**.rb'), '[ruby-core:31730]'
+  ensure
+    assert_equal cwd, $LOAD_PATH.shift
+  end
+
+  def test_self_find_files_with_gemfile
+    cwd = File.expand_path("test/rubygems", PROJECT_DIR)
+    actual_load_path = $LOAD_PATH.unshift(cwd).dup
+
+    discover_path = File.join 'lib', 'sff', 'discover.rb'
+
+    foo1, _ = %w[1 2].map do |version|
+      spec = quick_gem 'sff', version do |s|
+        s.files << discover_path
+      end
+
+      write_file(File.join 'gems', spec.full_name, discover_path) do |fp|
+        fp.puts "# #{spec.full_name}"
+      end
+
+      spec
+    end
+    Gem.refresh
+
+    write_file(File.join Dir.pwd, 'Gemfile') do |fp|
+      fp.puts "source 'https://rubygems.org'"
+      fp.puts "gem '#{foo1.name}', '#{foo1.version}'"
+    end
+    Gem.use_gemdeps(File.join Dir.pwd, 'Gemfile')
+
+    expected = [
+      File.expand_path('test/rubygems/sff/discover.rb', PROJECT_DIR),
+      File.join(foo1.full_gem_path, discover_path),
+    ].sort
+
+    assert_equal expected, Gem.find_files('sff/discover').sort
+    assert_equal expected, Gem.find_files('sff/**.rb').sort, '[ruby-core:31730]'
+  ensure
+    assert_equal cwd, actual_load_path.shift unless Gem.java_platform?
+  end
+
+  def test_self_find_latest_files
+    cwd = File.expand_path("test/rubygems", PROJECT_DIR)
+    $LOAD_PATH.unshift cwd
+
+    discover_path = File.join 'lib', 'sff', 'discover.rb'
+
+    _, foo2 = %w[1 2].map do |version|
+      spec = quick_gem 'sff', version do |s|
+        s.files << discover_path
+      end
+
+      write_file(File.join 'gems', spec.full_name, discover_path) do |fp|
+        fp.puts "# #{spec.full_name}"
+      end
+
+      spec
+    end
+
+    Gem.refresh
+
+    expected = [
+      File.expand_path('test/rubygems/sff/discover.rb', PROJECT_DIR),
+      File.join(foo2.full_gem_path, discover_path),
+    ]
+
+    assert_equal expected, Gem.find_latest_files('sff/discover')
+    assert_equal expected, Gem.find_latest_files('sff/**.rb'), '[ruby-core:31730]'
+  ensure
+    assert_equal cwd, $LOAD_PATH.shift
+  end
+
+  def test_self_latest_spec_for
+    gems = spec_fetcher do |fetcher|
+      fetcher.spec 'a', 1
+      fetcher.spec 'a', '3.a'
+      fetcher.spec 'a', 2
+    end
+
+    spec = Gem.latest_spec_for 'a'
+
+    assert_equal gems['a-2'], spec
+  end
+
+  def test_self_latest_rubygems_version
+    spec_fetcher do |fetcher|
+      fetcher.spec 'rubygems-update', '1.8.23'
+      fetcher.spec 'rubygems-update', '1.8.24'
+      fetcher.spec 'rubygems-update', '2.0.0.preview3'
+    end
+
+    version = Gem.latest_rubygems_version
+
+    assert_equal Gem::Version.new('1.8.24'), version
+  end
+
+  def test_self_latest_version_for
+    spec_fetcher do |fetcher|
+      fetcher.spec 'a', 1
+      fetcher.spec 'a', 2
+      fetcher.spec 'a', '3.a'
+    end
+
+    version = Gem.latest_version_for 'a'
+
+    assert_equal Gem::Version.new(2), version
+  end
+
+  def test_self_loaded_specs
+    foo = util_spec 'foo'
+    install_gem foo
+
+    foo.activate
+
+    assert_equal true, Gem.loaded_specs.keys.include?('foo')
+  end
+
+  def util_path
+    ENV.delete "GEM_HOME"
+    ENV.delete "GEM_PATH"
+  end
+
+  def test_self_path
+    assert_equal [Gem.dir], Gem.path
+  end
+
+  def test_self_path_default
+    util_path
+
+    if defined?(APPLE_GEM_HOME)
+      orig_APPLE_GEM_HOME = APPLE_GEM_HOME
+      Object.send :remove_const, :APPLE_GEM_HOME
+    end
+
+    Gem.instance_variable_set :@paths, nil
+
+    assert_equal [Gem.default_path, Gem.dir].flatten.uniq, Gem.path
+  ensure
+    Object.const_set :APPLE_GEM_HOME, orig_APPLE_GEM_HOME if orig_APPLE_GEM_HOME
+  end
+
+  unless win_platform?
+    def test_self_path_APPLE_GEM_HOME
+      util_path
+
+      Gem.clear_paths
+      apple_gem_home = File.join @tempdir, 'apple_gem_home'
+
+      old, $-w = $-w, nil
+      Object.const_set :APPLE_GEM_HOME, apple_gem_home
+      $-w = old
+
+      assert_includes Gem.path, apple_gem_home
+    ensure
+      Object.send :remove_const, :APPLE_GEM_HOME
+    end
+
+    def test_self_path_APPLE_GEM_HOME_GEM_PATH
+      Gem.clear_paths
+      ENV['GEM_PATH'] = @gemhome
+      apple_gem_home = File.join @tempdir, 'apple_gem_home'
+      Gem.const_set :APPLE_GEM_HOME, apple_gem_home
+
+      refute Gem.path.include?(apple_gem_home)
+    ensure
+      Gem.send :remove_const, :APPLE_GEM_HOME
+    end
+  end
+
+  def test_self_path_ENV_PATH
+    path_count = Gem.path.size
+    Gem.clear_paths
+
+    ENV['GEM_PATH'] = @additional.join(File::PATH_SEPARATOR)
+
+    assert_equal @additional, Gem.path[0,2]
+
+    assert_equal path_count + @additional.size, Gem.path.size,
+                 "extra path components: #{Gem.path[2..-1].inspect}"
+    assert_equal Gem.dir, Gem.path.last
+  end
+
+  def test_self_path_duplicate
+    Gem.clear_paths
+    util_ensure_gem_dirs
+    dirs = @additional + [@gemhome] + [File.join(@tempdir, 'a')]
+
+    ENV['GEM_HOME'] = @gemhome
+    ENV['GEM_PATH'] = dirs.join File::PATH_SEPARATOR
+
+    assert_equal @gemhome, Gem.dir
+
+    paths = [Gem.dir]
+    assert_equal @additional + paths, Gem.path
+  end
+
+  def test_self_path_overlap
+    Gem.clear_paths
+
+    util_ensure_gem_dirs
+    ENV['GEM_HOME'] = @gemhome
+    ENV['GEM_PATH'] = @additional.join(File::PATH_SEPARATOR)
+
+    assert_equal @gemhome, Gem.dir
+
+    paths = [Gem.dir]
+    assert_equal @additional + paths, Gem.path
+  end
+
+  def test_self_platforms
+    assert_equal [Gem::Platform::RUBY, Gem::Platform.local], Gem.platforms
+  end
+
+  def test_self_prefix
+    assert_equal PROJECT_DIR, Gem.prefix
+  end
+
+  def test_self_prefix_libdir
+    orig_libdir = RbConfig::CONFIG['libdir']
+    RbConfig::CONFIG['libdir'] = PROJECT_DIR
+
+    assert_nil Gem.prefix
+  ensure
+    RbConfig::CONFIG['libdir'] = orig_libdir
+  end
+
+  def test_self_prefix_sitelibdir
+    orig_sitelibdir = RbConfig::CONFIG['sitelibdir']
+    RbConfig::CONFIG['sitelibdir'] = PROJECT_DIR
+
+    assert_nil Gem.prefix
+  ensure
+    RbConfig::CONFIG['sitelibdir'] = orig_sitelibdir
+  end
+
+  def test_self_read_binary
+    File.open 'test', 'w' do |io|
+      io.write "\xCF\x80"
+    end
+
+    assert_equal ["\xCF", "\x80"], Gem.read_binary('test').chars.to_a
+
+    pend 'chmod not supported' if Gem.win_platform?
+
+    begin
+      File.chmod 0444, 'test'
+
+      assert_equal ["\xCF", "\x80"], Gem.read_binary('test').chars.to_a
+    ensure
+      File.chmod 0644, 'test'
+    end
+  end
+
+  def test_self_refresh
+    util_make_gems
+
+    a1_spec = @a1.spec_file
+    moved_path = File.join @tempdir, File.basename(a1_spec)
+
+    FileUtils.mv a1_spec, moved_path
+
+    Gem.refresh
+
+    refute_includes Gem::Specification.all_names, @a1.full_name
+
+    FileUtils.mv moved_path, a1_spec
+
+    Gem.refresh
+
+    assert_includes Gem::Specification.all_names, @a1.full_name
+  end
+
+  def test_self_refresh_keeps_loaded_specs_activated
+    util_make_gems
+
+    a1_spec = @a1.spec_file
+    moved_path = File.join @tempdir, File.basename(a1_spec)
+
+    FileUtils.mv a1_spec, moved_path
+
+    Gem.refresh
+
+    s = Gem::Specification.first
+    s.activate
+
+    Gem.refresh
+
+    Gem::Specification.each{|spec| assert spec.activated? if spec == s }
+
+    Gem.loaded_specs.delete(s)
+    Gem.refresh
+  end
+
+  def test_self_ruby_escaping_spaces_in_path
+    with_clean_path_to_ruby do
+      with_rb_config_ruby("C:/Ruby 1.8/bin/ruby.exe") do
+        assert_equal "\"C:/Ruby 1.8/bin/ruby.exe\"", Gem.ruby
+      end
+    end
+  end
+
+  def test_self_ruby_path_without_spaces
+    with_clean_path_to_ruby do
+      with_rb_config_ruby("C:/Ruby18/bin/ruby.exe") do
+        assert_equal "C:/Ruby18/bin/ruby.exe", Gem.ruby
+      end
+    end
+  end
+
+  def test_self_ruby_api_version
+    orig_ruby_version, RbConfig::CONFIG['ruby_version'] = RbConfig::CONFIG['ruby_version'], '1.2.3'
+
+    Gem.instance_variable_set :@ruby_api_version, nil
+
+    assert_equal '1.2.3', Gem.ruby_api_version
+  ensure
+    Gem.instance_variable_set :@ruby_api_version, nil
+
+    RbConfig::CONFIG['ruby_version'] = orig_ruby_version
+  end
+
+  def test_self_env_requirement
+    ENV["GEM_REQUIREMENT_FOO"] = '>= 1.2.3'
+    ENV["GEM_REQUIREMENT_BAR"] = '1.2.3'
+    ENV["GEM_REQUIREMENT_BAZ"] = 'abcd'
+
+    assert_equal Gem::Requirement.create('>= 1.2.3'), Gem.env_requirement('foo')
+    assert_equal Gem::Requirement.create('1.2.3'), Gem.env_requirement('bAr')
+    assert_raise(Gem::Requirement::BadRequirementError) { Gem.env_requirement('baz') }
+    assert_equal Gem::Requirement.default, Gem.env_requirement('qux')
+  end
+
+  def test_self_ruby_version_with_patchlevel_less_ancient_rubies
+    util_set_RUBY_VERSION '1.8.5'
+
+    assert_equal Gem::Version.new('1.8.5'), Gem.ruby_version
+  ensure
+    util_restore_RUBY_VERSION
+  end
+
+  def test_self_ruby_version_with_release
+    util_set_RUBY_VERSION '1.8.6', 287
+
+    assert_equal Gem::Version.new('1.8.6.287'), Gem.ruby_version
+  ensure
+    util_restore_RUBY_VERSION
+  end
+
+  def test_self_ruby_version_with_non_mri_implementations
+    util_set_RUBY_VERSION '2.5.0', 0, 60928, 'jruby 9.2.0.0 (2.5.0) 2018-05-24 81156a8 OpenJDK 64-Bit Server VM 25.171-b11 on 1.8.0_171-8u171-b11-0ubuntu0.16.04.1-b11 [linux-x86_64]'
+
+    assert_equal Gem::Version.new('2.5.0'), Gem.ruby_version
+  ensure
+    util_restore_RUBY_VERSION
+  end
+
+  def test_self_ruby_version_with_svn_prerelease
+    util_set_RUBY_VERSION '2.6.0', -1, 63539, 'ruby 2.6.0preview2 (2018-05-31 trunk 63539) [x86_64-linux]'
+
+    assert_equal Gem::Version.new('2.6.0.preview2'), Gem.ruby_version
+  ensure
+    util_restore_RUBY_VERSION
+  end
+
+  def test_self_ruby_version_with_git_prerelease
+    util_set_RUBY_VERSION '2.7.0', -1, 'b563439274a402e33541f5695b1bfd4ac1085638', 'ruby 2.7.0preview3 (2019-11-23 master b563439274) [x86_64-linux]'
+
+    assert_equal Gem::Version.new('2.7.0.preview3'), Gem.ruby_version
+  ensure
+    util_restore_RUBY_VERSION
+  end
+
+  def test_self_ruby_version_with_non_mri_implementations_with_mri_prerelase_compatibility
+    util_set_RUBY_VERSION '2.6.0', -1, 63539, 'weirdjruby 9.2.0.0 (2.6.0preview2) 2018-05-24 81156a8 OpenJDK 64-Bit Server VM 25.171-b11 on 1.8.0_171-8u171-b11-0ubuntu0.16.04.1-b11 [linux-x86_64]', 'weirdjruby', '9.2.0.0'
+
+    assert_equal Gem::Version.new('2.6.0.preview2'), Gem.ruby_version
+  ensure
+    util_restore_RUBY_VERSION
+  end
+
+  def test_self_ruby_version_with_svn_trunk
+    util_set_RUBY_VERSION '1.9.2', -1, 23493, 'ruby 1.9.2dev (2009-05-20 trunk 23493) [x86_64-linux]'
+
+    assert_equal Gem::Version.new('1.9.2.dev'), Gem.ruby_version
+  ensure
+    util_restore_RUBY_VERSION
+  end
+
+  def test_self_ruby_version_with_git_master
+    util_set_RUBY_VERSION '2.7.0', -1, '5de284ec78220e75643f89b454ce999da0c1c195', 'ruby 2.7.0dev (2019-12-23T01:37:30Z master 5de284ec78) [x86_64-linux]'
+
+    assert_equal Gem::Version.new('2.7.0.dev'), Gem.ruby_version
+  ensure
+    util_restore_RUBY_VERSION
+  end
+
+  def test_self_rubygems_version
+    assert_equal Gem::Version.new(Gem::VERSION), Gem.rubygems_version
+  end
+
+  def test_self_paths_eq
+    other = File.join @tempdir, 'other'
+    path = [@userhome, other].join File::PATH_SEPARATOR
+
+    #
+    # FIXME remove after fixing test_case
+    #
+    ENV["GEM_HOME"] = @gemhome
+    Gem.paths = { "GEM_PATH" => path }
+
+    assert_equal [@userhome, other, @gemhome], Gem.path
+  end
+
+  def test_self_paths_eq_nonexistent_home
+    ENV['GEM_HOME'] = @gemhome
+    Gem.clear_paths
+
+    other = File.join @tempdir, 'other'
+
+    ENV['HOME'] = other
+
+    Gem.paths = { "GEM_PATH" => other }
+
+    assert_equal [other, @gemhome], Gem.path
+  end
+
+  def test_self_post_build
+    assert_equal 1, Gem.post_build_hooks.length
+
+    Gem.post_build {|installer| }
+
+    assert_equal 2, Gem.post_build_hooks.length
+  end
+
+  def test_self_post_install
+    assert_equal 1, Gem.post_install_hooks.length
+
+    Gem.post_install {|installer| }
+
+    assert_equal 2, Gem.post_install_hooks.length
+  end
+
+  def test_self_done_installing
+    assert_empty Gem.done_installing_hooks
+
+    Gem.done_installing {|gems| }
+
+    assert_equal 1, Gem.done_installing_hooks.length
+  end
+
+  def test_self_post_reset
+    assert_empty Gem.post_reset_hooks
+
+    Gem.post_reset {}
+
+    assert_equal 1, Gem.post_reset_hooks.length
+  end
+
+  def test_self_post_uninstall
+    assert_equal 1, Gem.post_uninstall_hooks.length
+
+    Gem.post_uninstall {|installer| }
+
+    assert_equal 2, Gem.post_uninstall_hooks.length
+  end
+
+  def test_self_pre_install
+    assert_equal 1, Gem.pre_install_hooks.length
+
+    Gem.pre_install {|installer| }
+
+    assert_equal 2, Gem.pre_install_hooks.length
+  end
+
+  def test_self_pre_reset
+    assert_empty Gem.pre_reset_hooks
+
+    Gem.pre_reset {}
+
+    assert_equal 1, Gem.pre_reset_hooks.length
+  end
+
+  def test_self_pre_uninstall
+    assert_equal 1, Gem.pre_uninstall_hooks.length
+
+    Gem.pre_uninstall {|installer| }
+
+    assert_equal 2, Gem.pre_uninstall_hooks.length
+  end
+
+  def test_self_sources
+    assert_equal %w[http://gems.example.com/], Gem.sources
+    Gem.sources = nil
+    Gem.configuration.sources = %w[http://test.example.com/]
+    assert_equal %w[http://test.example.com/], Gem.sources
+  end
+
+  def test_try_activate_returns_true_for_activated_specs
+    b = util_spec 'b', '1.0' do |spec|
+      spec.files << 'lib/b.rb'
+    end
+    install_specs b
+
+    assert Gem.try_activate('b'), 'try_activate should return true'
+    assert Gem.try_activate('b'), 'try_activate should still return true'
+  end
+
+  def test_spec_order_is_consistent
+    b1 = util_spec 'b', '1.0'
+    b2 = util_spec 'b', '2.0'
+    b3 = util_spec 'b', '3.0'
+
+    install_specs b1, b2, b3
+
+    specs1 = Gem::Specification.stubs.find_all {|s| s.name == 'b' }
+    Gem::Specification.reset
+    specs2 = Gem::Specification.stubs_for('b')
+    assert_equal specs1.map(&:version), specs2.map(&:version)
+  end
+
+  def test_self_try_activate_missing_dep
+    b = util_spec 'b', '1.0'
+    a = util_spec 'a', '1.0', 'b' => '>= 1.0'
+
+    install_specs b, a
+    uninstall_gem b
+
+    a_file = File.join a.gem_dir, 'lib', 'a_file.rb'
+
+    write_file a_file do |io|
+      io.puts '# a_file.rb'
+    end
+
+    e = assert_raise Gem::MissingSpecError do
+      Gem.try_activate 'a_file'
+    end
+
+    assert_match %r{Could not find 'b' }, e.message
+    assert_match %r{at: #{a.spec_file}}, e.message
+  end
+
+  def test_self_try_activate_missing_prerelease
+    b = util_spec 'b', '1.0rc1'
+    a = util_spec 'a', '1.0rc1', 'b' => '1.0rc1'
+
+    install_specs b, a
+    uninstall_gem b
+
+    a_file = File.join a.gem_dir, 'lib', 'a_file.rb'
+
+    write_file a_file do |io|
+      io.puts '# a_file.rb'
+    end
+
+    e = assert_raise Gem::MissingSpecError do
+      Gem.try_activate 'a_file'
+    end
+
+    assert_match %r{Could not find 'b' \(= 1.0rc1\)}, e.message
+  end
+
+  def test_self_try_activate_missing_extensions
+    spec = util_spec 'ext', '1' do |s|
+      s.extensions = %w[ext/extconf.rb]
+      s.mark_version
+      s.installed_by_version = v('2.2')
+    end
+
+    # write the spec without install to simulate a failed install
+    write_file spec.spec_file do |io|
+      io.write spec.to_ruby_for_cache
+    end
+
+    _, err = capture_output do
+      refute Gem.try_activate 'nonexistent'
+    end
+
+    unless Gem.java_platform?
+      expected = "Ignoring ext-1 because its extensions are not built. " +
+                 "Try: gem pristine ext --version 1\n"
+
+      assert_equal expected, err
+    end
+  end
+
+  def test_self_use_paths_with_nils
+    orig_home = ENV.delete 'GEM_HOME'
+    orig_path = ENV.delete 'GEM_PATH'
+    Gem.use_paths nil, nil
+    assert_equal Gem.default_dir, Gem.paths.home
+    path = (Gem.default_path + [Gem.paths.home]).uniq
+    assert_equal path, Gem.paths.path
+  ensure
+    ENV['GEM_HOME'] = orig_home
+    ENV['GEM_PATH'] = orig_path
+  end
+
+  def test_setting_paths_does_not_warn_about_unknown_keys
+    stdout, stderr = capture_output do
+      Gem.paths = { 'foo'      => [],
+                    'bar'      => Object.new,
+                    'GEM_HOME' => Gem.paths.home,
+                    'GEM_PATH' => 'foo' }
+    end
+    assert_equal ['foo', Gem.paths.home], Gem.paths.path
+    assert_equal '', stderr
+    assert_equal '', stdout
+  end
+
+  def test_setting_paths_does_not_mutate_parameter_object
+    Gem.paths = { 'GEM_HOME' => Gem.paths.home,
+                  'GEM_PATH' => 'foo' }.freeze
+    assert_equal ['foo', Gem.paths.home], Gem.paths.path
+  end
+
+  def test_deprecated_paths=
+    stdout, stderr = capture_output do
+      Gem.paths = { 'GEM_HOME' => Gem.paths.home,
+                    'GEM_PATH' => [Gem.paths.home, 'foo'] }
+    end
+    assert_equal [Gem.paths.home, 'foo'], Gem.paths.path
+    assert_match(/Array values in the parameter to `Gem.paths=` are deprecated.\nPlease use a String or nil/m, stderr)
+    assert_equal '', stdout
+  end
+
+  def test_self_use_paths
+    util_ensure_gem_dirs
+
+    Gem.use_paths @gemhome, @additional
+
+    assert_equal @gemhome, Gem.dir
+    assert_equal @additional + [Gem.dir], Gem.path
+  end
+
+  def test_self_user_dir
+    parts = [@userhome, '.gem', Gem.ruby_engine]
+    parts << RbConfig::CONFIG['ruby_version'] unless RbConfig::CONFIG['ruby_version'].empty?
+
+    FileUtils.mkdir_p File.join(parts)
+
+    assert_equal File.join(parts), Gem.user_dir
+  end
+
+  def test_self_user_home
+    if ENV['HOME']
+      assert_equal ENV['HOME'], Gem.user_home
+    else
+      assert true, 'count this test'
+    end
+  end
+
+  def test_self_needs
+    a = util_spec "a", "1"
+    b = util_spec "b", "1", "c" => nil
+    c = util_spec "c", "2"
+
+    install_specs a, c, b
+
+    Gem.needs do |r|
+      r.gem "a"
+      r.gem "b", "= 1"
+    end
+
+    activated = Gem::Specification.map {|x| x.full_name }
+
+    assert_equal %w[a-1 b-1 c-2], activated.sort
+  end
+
+  def test_self_needs_picks_up_unresolved_deps
+    a = util_spec "a", "1"
+    b = util_spec "b", "1", "c" => nil
+    c = util_spec "c", "2"
+    d = util_spec "d", "1", {'e' => '= 1'}, "lib/d#{$$}.rb"
+    e = util_spec "e", "1"
+
+    install_specs a, c, b, e, d
+
+    Gem.needs do |r|
+      r.gem "a"
+      r.gem "b", "= 1"
+
+      require "d#{$$}"
+    end
+
+    assert_equal %w[a-1 b-1 c-2 d-1 e-1], loaded_spec_names
+  end
+
+  def test_self_gunzip
+    input = "\x1F\x8B\b\0\xED\xA3\x1AQ\0\x03\xCBH" +
+            "\xCD\xC9\xC9\a\0\x86\xA6\x106\x05\0\0\0"
+
+    output = Gem::Util.gunzip input
+
+    assert_equal 'hello', output
+    assert_equal Encoding::BINARY, output.encoding
+  end
+
+  def test_self_gzip
+    input = 'hello'
+
+    output = Gem::Util.gzip input
+
+    zipped = StringIO.new output
+
+    assert_equal 'hello', Zlib::GzipReader.new(zipped).read
+    assert_equal Encoding::BINARY, output.encoding
+  end
+
+  def test_self_vendor_dir
+    vendordir(File.join(@tempdir, 'vendor')) do
+      expected =
+        File.join RbConfig::CONFIG['vendordir'], 'gems',
+                  RbConfig::CONFIG['ruby_version']
+
+      assert_equal expected, Gem.vendor_dir
+    end
+  end
+
+  def test_self_vendor_dir_ENV_GEM_VENDOR
+    ENV['GEM_VENDOR'] = File.join @tempdir, 'vendor', 'gems'
+
+    assert_equal ENV['GEM_VENDOR'], Gem.vendor_dir
+    refute Gem.vendor_dir.frozen?
+  end
+
+  def test_self_vendor_dir_missing
+    vendordir(nil) do
+      assert_nil Gem.vendor_dir
+    end
+  end
+
+  def test_load_plugins
+    plugin_path = File.join "lib", "rubygems_plugin.rb"
+
+    Dir.chdir @tempdir do
+      FileUtils.mkdir_p 'lib'
+      File.open plugin_path, "w" do |fp|
+        fp.puts "class TestGem; PLUGINS_LOADED << 'plugin'; end"
+      end
+
+      foo1 = util_spec 'foo', '1' do |s|
+        s.files << plugin_path
+      end
+
+      install_gem foo1
+
+      foo2 = util_spec 'foo', '2' do |s|
+        s.files << plugin_path
+      end
+
+      install_gem foo2
+    end
+
+    Gem::Specification.reset
+
+    gem 'foo'
+
+    Gem.load_plugins
+
+    assert_equal %w[plugin], PLUGINS_LOADED
+  end
+
+  def test_load_user_installed_plugins
+    plugin_path = File.join "lib", "rubygems_plugin.rb"
+
+    Dir.chdir @tempdir do
+      FileUtils.mkdir_p 'lib'
+      File.open plugin_path, "w" do |fp|
+        fp.puts "class TestGem; PLUGINS_LOADED << 'plugin'; end"
+      end
+
+      foo = util_spec 'foo', '1' do |s|
+        s.files << plugin_path
+      end
+
+      install_gem_user foo
+    end
+
+    Gem.paths = { "GEM_PATH" => [Gem.dir, Gem.user_dir].join(File::PATH_SEPARATOR) }
+
+    gem 'foo'
+
+    Gem.load_plugins
+
+    assert_equal %w[plugin], PLUGINS_LOADED
+  end
+
+  def test_load_env_plugins
+    with_plugin('load') { Gem.load_env_plugins }
+    assert_equal :loaded, TEST_PLUGIN_LOAD rescue nil
+
+    util_remove_interrupt_command
+
+    # Should attempt to cause a StandardError
+    with_plugin('standarderror') { Gem.load_env_plugins }
+    assert_equal :loaded, TEST_PLUGIN_STANDARDERROR rescue nil
+
+    util_remove_interrupt_command
+
+    # Should attempt to cause an Exception
+    with_plugin('exception') { Gem.load_env_plugins }
+    assert_equal :loaded, TEST_PLUGIN_EXCEPTION rescue nil
+  end
+
+  def test_gem_path_ordering
+    refute_equal Gem.dir, Gem.user_dir
+
+    write_file File.join(@tempdir, 'lib', "g.rb") {|fp| fp.puts "" }
+    write_file File.join(@tempdir, 'lib', 'm.rb') {|fp| fp.puts "" }
+
+    g = util_spec 'g', '1', nil, "lib/g.rb"
+    m = util_spec 'm', '1', nil, "lib/m.rb"
+
+    install_gem g, :install_dir => Gem.dir
+    m0 = install_gem m, :install_dir => Gem.dir
+    m1 = install_gem m, :install_dir => Gem.user_dir
+
+    assert_equal m0.gem_dir, File.join(Gem.dir, "gems", "m-1")
+    assert_equal m1.gem_dir, File.join(Gem.user_dir, "gems", "m-1")
+
+    tests = [
+      [:dir0, [ Gem.dir, Gem.user_dir], m0],
+      [:dir1, [ Gem.user_dir, Gem.dir], m1],
+    ]
+
+    tests.each do |_name, _paths, expected|
+      Gem.use_paths _paths.first, _paths
+      Gem::Specification.reset
+      Gem.searcher = nil
+
+      assert_equal Gem::Dependency.new('m','1').to_specs,
+                   Gem::Dependency.new('m','1').to_specs.sort
+
+      assert_equal \
+        [expected.gem_dir],
+        Gem::Dependency.new('m','1').to_specs.map(&:gem_dir).sort,
+        "Wrong specs for #{_name}"
+
+      spec = Gem::Dependency.new('m','1').to_spec
+
+      assert_equal \
+        File.join(_paths.first, "gems", "m-1"),
+        spec.gem_dir,
+        "Wrong spec before require for #{_name}"
+      refute spec.activated?, "dependency already activated for #{_name}"
+
+      gem "m"
+
+      spec = Gem::Dependency.new('m','1').to_spec
+      assert spec.activated?, "dependency not activated for #{_name}"
+
+      assert_equal \
+        File.join(_paths.first, "gems", "m-1"),
+        spec.gem_dir,
+        "Wrong spec after require for #{_name}"
+
+      spec.instance_variable_set :@activated, false
+      Gem.loaded_specs.delete(spec.name)
+      $:.delete(File.join(spec.gem_dir, "lib"))
+    end
+  end
+
+  def test_gem_path_ordering_short
+    write_file File.join(@tempdir, 'lib', "g.rb") {|fp| fp.puts "" }
+    write_file File.join(@tempdir, 'lib', 'm.rb') {|fp| fp.puts "" }
+
+    g = util_spec 'g', '1', nil, "lib/g.rb"
+    m = util_spec 'm', '1', nil, "lib/m.rb"
+
+    install_gem g, :install_dir => Gem.dir
+    install_gem m, :install_dir => Gem.dir
+    install_gem m, :install_dir => Gem.user_dir
+
+    Gem.use_paths Gem.dir, [ Gem.dir, Gem.user_dir]
+
+    assert_equal \
+      File.join(Gem.dir, "gems", "m-1"),
+      Gem::Dependency.new('m','1').to_spec.gem_dir,
+      "Wrong spec selected"
+  end
+
+  def test_auto_activation_of_specific_gemdeps_file
+    a = util_spec "a", "1", nil, "lib/a.rb"
+    b = util_spec "b", "1", nil, "lib/b.rb"
+    c = util_spec "c", "1", nil, "lib/c.rb"
+
+    install_specs a, b, c
+
+    path = File.join @tempdir, "gem.deps.rb"
+
+    File.open path, "w" do |f|
+      f.puts "gem 'a'"
+      f.puts "gem 'b'"
+      f.puts "gem 'c'"
+    end
+
+    with_rubygems_gemdeps(path) do
+      Gem.use_gemdeps
+
+      assert_equal add_bundler_full_name(%W[a-1 b-1 c-1]), loaded_spec_names
+    end
+  end
+
+  def test_auto_activation_of_used_gemdeps_file
+    a = util_spec "a", "1", nil, "lib/a.rb"
+    b = util_spec "b", "1", nil, "lib/b.rb"
+    c = util_spec "c", "1", nil, "lib/c.rb"
+
+    install_specs a, b, c
+
+    path = File.join @tempdir, "gem.deps.rb"
+
+    File.open path, "w" do |f|
+      f.puts "gem 'a'"
+      f.puts "gem 'b'"
+      f.puts "gem 'c'"
+    end
+
+    with_rubygems_gemdeps("-") do
+      expected_specs = [a, b, util_spec("bundler", Bundler::VERSION), c].compact.map(&:full_name)
+
+      Gem.use_gemdeps
+
+      assert_equal expected_specs, loaded_spec_names
+    end
+  end
+
+  BUNDLER_LIB_PATH = File.expand_path $LOAD_PATH.find {|lp| File.file?(File.join(lp, "bundler.rb")) }
+  BUNDLER_FULL_NAME = "bundler-#{Bundler::VERSION}".freeze
+
+  def add_bundler_full_name(names)
+    names << BUNDLER_FULL_NAME
+    names.sort!
+    names
+  end
+
+  def test_looks_for_gemdeps_files_automatically_from_binstubs
+    pend "Requiring bundler messes things up" if Gem.java_platform?
+
+    a = util_spec "a", "1" do |s|
+      s.executables = %w[foo]
+      s.bindir = "exe"
+    end
+
+    write_file File.join(@tempdir, 'exe', 'foo') do |fp|
+      fp.puts "puts Gem.loaded_specs.values.map(&:full_name).sort"
+    end
+
+    b = util_spec "b", "1", nil, "lib/b.rb"
+    c = util_spec "c", "1", nil, "lib/c.rb"
+
+    install_specs a, b, c
+
+    path = File.join(@tempdir, "gd-tmp")
+    install_gem a, :install_dir => path
+    install_gem b, :install_dir => path
+    install_gem c, :install_dir => path
+
+    ENV['GEM_PATH'] = path
+
+    with_rubygems_gemdeps("-") do
+      new_PATH = [File.join(path, "bin"), ENV["PATH"]].join(File::PATH_SEPARATOR)
+      new_RUBYOPT = "-I#{rubygems_path} -I#{BUNDLER_LIB_PATH}"
+
+      path = File.join @tempdir, "gem.deps.rb"
+
+      File.open path, "w" do |f|
+        f.puts "gem 'a'"
+      end
+      out0 = with_path_and_rubyopt(new_PATH, new_RUBYOPT) do
+        IO.popen("foo", &:read).split(/\n/)
+      end
+
+      File.open path, "a" do |f|
+        f.puts "gem 'b'"
+        f.puts "gem 'c'"
+      end
+      out = with_path_and_rubyopt(new_PATH, new_RUBYOPT) do
+        IO.popen("foo", &:read).split(/\n/)
+      end
+
+      assert_equal ["b-1", "c-1"], out - out0
+    end
+  end
+
+  def test_looks_for_gemdeps_files_automatically_from_binstubs_in_parent_dir
+    pend "Requiring bundler messes things up" if Gem.java_platform?
+
+    a = util_spec "a", "1" do |s|
+      s.executables = %w[foo]
+      s.bindir = "exe"
+    end
+
+    write_file File.join(@tempdir, 'exe', 'foo') do |fp|
+      fp.puts "puts Gem.loaded_specs.values.map(&:full_name).sort"
+    end
+
+    b = util_spec "b", "1", nil, "lib/b.rb"
+    c = util_spec "c", "1", nil, "lib/c.rb"
+
+    install_specs a, b, c
+
+    path = File.join(@tempdir, "gd-tmp")
+    install_gem a, :install_dir => path
+    install_gem b, :install_dir => path
+    install_gem c, :install_dir => path
+
+    ENV['GEM_PATH'] = path
+
+    with_rubygems_gemdeps("-") do
+      Dir.mkdir "sub1"
+
+      new_PATH = [File.join(path, "bin"), ENV["PATH"]].join(File::PATH_SEPARATOR)
+      new_RUBYOPT = "-I#{rubygems_path} -I#{BUNDLER_LIB_PATH}"
+
+      path = File.join @tempdir, "gem.deps.rb"
+
+      File.open path, "w" do |f|
+        f.puts "gem 'a'"
+      end
+      out0 = with_path_and_rubyopt(new_PATH, new_RUBYOPT) do
+        IO.popen("foo", :chdir => "sub1", &:read).split(/\n/)
+      end
+
+      File.open path, "a" do |f|
+        f.puts "gem 'b'"
+        f.puts "gem 'c'"
+      end
+      out = with_path_and_rubyopt(new_PATH, new_RUBYOPT) do
+        IO.popen("foo", :chdir => "sub1", &:read).split(/\n/)
+      end
+
+      Dir.rmdir "sub1"
+
+      assert_equal ["b-1", "c-1"], out - out0
+    end
+  end
+
+  def test_register_default_spec
+    Gem.clear_default_specs
+
+    old_style = Gem::Specification.new do |spec|
+      spec.files = ["foo.rb", "bar.rb"]
+    end
+
+    Gem.register_default_spec old_style
+
+    assert_equal old_style, Gem.find_unresolved_default_spec("foo.rb")
+    assert_equal old_style, Gem.find_unresolved_default_spec("bar.rb")
+    assert_nil              Gem.find_unresolved_default_spec("baz.rb")
+
+    Gem.clear_default_specs
+
+    new_style = Gem::Specification.new do |spec|
+      spec.files = ["lib/foo.rb", "ext/bar.rb", "bin/exec", "README"]
+      spec.require_paths = ["lib", "ext"]
+    end
+
+    Gem.register_default_spec new_style
+
+    assert_equal new_style, Gem.find_unresolved_default_spec("foo.rb")
+    assert_equal new_style, Gem.find_unresolved_default_spec("bar.rb")
+    assert_nil              Gem.find_unresolved_default_spec("exec")
+    assert_nil              Gem.find_unresolved_default_spec("README")
+  end
+
+  def test_register_default_spec_old_style_with_folder_starting_with_lib
+    Gem.clear_default_specs
+
+    old_style = Gem::Specification.new do |spec|
+      spec.files = ["libexec/bundle", "foo.rb", "bar.rb"]
+    end
+
+    Gem.register_default_spec old_style
+
+    assert_equal old_style, Gem.find_unresolved_default_spec("foo.rb")
+  end
+
+  def test_use_gemdeps
+    gem_deps_file = 'gem.deps.rb'.tap(&Gem::UNTAINT)
+    spec = util_spec 'a', 1
+    install_specs spec
+
+    spec = Gem::Specification.find {|s| s == spec }
+    refute spec.activated?
+
+    File.open gem_deps_file, 'w' do |io|
+      io.write 'gem "a"'
+    end
+
+    assert_nil Gem.gemdeps
+
+    Gem.use_gemdeps gem_deps_file
+
+    assert_equal add_bundler_full_name(%W[a-1]), loaded_spec_names
+    refute_nil Gem.gemdeps
+  end
+
+  def test_use_gemdeps_ENV
+    with_rubygems_gemdeps(nil) do
+      spec = util_spec 'a', 1
+
+      refute spec.activated?
+
+      File.open 'gem.deps.rb', 'w' do |io|
+        io.write 'gem "a"'
+      end
+
+      Gem.use_gemdeps
+
+      refute spec.activated?
+    end
+  end
+
+  def test_use_gemdeps_argument_missing
+    e = assert_raise ArgumentError do
+      Gem.use_gemdeps 'gem.deps.rb'
+    end
+
+    assert_equal 'Unable to find gem dependencies file at gem.deps.rb',
+                 e.message
+  end
+
+  def test_use_gemdeps_argument_missing_match_ENV
+    with_rubygems_gemdeps('gem.deps.rb') do
+      e = assert_raise ArgumentError do
+        Gem.use_gemdeps 'gem.deps.rb'
+      end
+
+      assert_equal 'Unable to find gem dependencies file at gem.deps.rb',
+                   e.message
+    end
+  end
+
+  def test_use_gemdeps_automatic
+    with_rubygems_gemdeps('-') do
+      spec = util_spec 'a', 1
+      install_specs spec
+      spec = Gem::Specification.find {|s| s == spec }
+
+      refute spec.activated?
+
+      File.open 'Gemfile', 'w' do |io|
+        io.write 'gem "a"'
+      end
+
+      Gem.use_gemdeps
+
+      assert_equal add_bundler_full_name(%W[a-1]), loaded_spec_names
+    end
+  end
+
+  def test_use_gemdeps_automatic_missing
+    with_rubygems_gemdeps('-') do
+      Gem.use_gemdeps
+
+      assert true # count
+    end
+  end
+
+  def test_use_gemdeps_disabled
+    with_rubygems_gemdeps('') do
+      spec = util_spec 'a', 1
+
+      refute spec.activated?
+
+      File.open 'gem.deps.rb', 'w' do |io|
+        io.write 'gem "a"'
+      end
+
+      Gem.use_gemdeps
+
+      refute spec.activated?
+    end
+  end
+
+  def test_use_gemdeps_missing_gem
+    with_rubygems_gemdeps('x') do
+      File.open 'x', 'w' do |io|
+        io.write 'gem "a"'
+      end
+
+      expected = <<-EXPECTED
+Could not find gem 'a' in locally installed gems.
+You may need to `bundle install` to install missing gems
+
+      EXPECTED
+
+      Gem::Deprecate.skip_during do
+        actual_stdout, actual_stderr = capture_output do
+          Gem.use_gemdeps
+        end
+        assert_empty actual_stdout
+        assert_equal(expected, actual_stderr)
+      end
+    end
+  end
+
+  def test_use_gemdeps_specific
+    with_rubygems_gemdeps('x') do
+      spec = util_spec 'a', 1
+      install_specs spec
+
+      spec = Gem::Specification.find {|s| s == spec }
+      refute spec.activated?
+
+      File.open 'x', 'w' do |io|
+        io.write 'gem "a"'
+      end
+
+      Gem.use_gemdeps
+
+      assert_equal add_bundler_full_name(%W[a-1]), loaded_spec_names
+    end
+  end
+
+  def test_operating_system_defaults
+    operating_system_defaults = Gem.operating_system_defaults
+
+    assert operating_system_defaults != nil
+    assert operating_system_defaults.is_a? Hash
+  end
+
+  def test_platform_defaults
+    platform_defaults = Gem.platform_defaults
+
+    assert platform_defaults != nil
+    assert platform_defaults.is_a? Hash
+  end
+
+  # Ensure that `Gem.source_date_epoch` is consistent even if
+  # $SOURCE_DATE_EPOCH has not been set.
+  def test_default_source_date_epoch_doesnt_change
+    old_epoch = ENV['SOURCE_DATE_EPOCH']
+    ENV['SOURCE_DATE_EPOCH'] = nil
+
+    # Unfortunately, there is no real way to test this aside from waiting
+    # enough for `Time.now.to_i` to change -- which is a whole second.
+    #
+    # Fortunately, we only need to do this once.
+    a = Gem.source_date_epoch
+    sleep 1
+    b = Gem.source_date_epoch
+    assert_equal a, b
+  ensure
+    ENV['SOURCE_DATE_EPOCH'] = old_epoch
+  end
+
+  def ruby_install_name(name)
+    with_clean_path_to_ruby do
+      orig_RUBY_INSTALL_NAME = RbConfig::CONFIG['ruby_install_name']
+      RbConfig::CONFIG['ruby_install_name'] = name
+
+      begin
+        yield
+      ensure
+        if orig_RUBY_INSTALL_NAME
+          RbConfig::CONFIG['ruby_install_name'] = orig_RUBY_INSTALL_NAME
+        else
+          RbConfig::CONFIG.delete 'ruby_install_name'
+        end
+      end
+    end
+  end
+
+  def with_rb_config_ruby(path)
+    rb_config_singleton_class = class << RbConfig; self; end
+    orig_path = RbConfig.ruby
+
+    redefine_method(rb_config_singleton_class, :ruby, path)
+
+    yield
+  ensure
+    redefine_method(rb_config_singleton_class, :ruby, orig_path)
+  end
+
+  def redefine_method(base, method, new_result)
+    if RUBY_VERSION >= "2.5"
+      base.alias_method(method, method)
+      base.define_method(method) { new_result }
+    else
+      base.send(:alias_method, method, method)
+      base.send(:define_method, method) { new_result }
+    end
+  end
+
+  def with_plugin(path)
+    test_plugin_path = File.expand_path("test/rubygems/plugin/#{path}",
+                                        PROJECT_DIR)
+
+    # A single test plugin should get loaded once only, in order to preserve
+    # sane test semantics.
+    refute_includes $LOAD_PATH, test_plugin_path
+    $LOAD_PATH.unshift test_plugin_path
+
+    capture_output do
+      yield
+    end
+  ensure
+    $LOAD_PATH.delete test_plugin_path
+  end
+
+  def util_ensure_gem_dirs
+    Gem.ensure_gem_subdirectories @gemhome
+
+    #
+    # FIXME what does this solve precisely? -ebh
+    #
+    @additional.each do |dir|
+      Gem.ensure_gem_subdirectories @gemhome
+    end
+  end
+
+  def util_exec_gem
+    spec, _ = util_spec 'a', '4' do |s|
+      s.executables = ['exec', 'abin']
+    end
+
+    @exec_path = File.join spec.full_gem_path, spec.bindir, 'exec'
+    @abin_path = File.join spec.full_gem_path, spec.bindir, 'abin'
+    spec
+  end
+
+  def util_remove_interrupt_command
+    Gem::Commands.send :remove_const, :InterruptCommand if
+      Gem::Commands.const_defined? :InterruptCommand
+  end
+
+  def util_cache_dir
+    File.join Gem.dir, "cache"
+  end
+
+  def with_path_and_rubyopt(path_value, rubyopt_value)
+    path, ENV['PATH'] = ENV['PATH'], path_value
+    rubyopt, ENV['RUBYOPT'] = ENV['RUBYOPT'], rubyopt_value
+
+    yield
+  ensure
+    ENV['PATH'] = path
+    ENV['RUBYOPT'] = rubyopt
+  end
+
+  def with_rubygems_gemdeps(value)
+    rubygems_gemdeps, ENV['RUBYGEMS_GEMDEPS'] = ENV['RUBYGEMS_GEMDEPS'], value
+
+    yield
+  ensure
+    ENV['RUBYGEMS_GEMDEPS'] = rubygems_gemdeps
+  end
+end
diff -Nuarp ruby-3.0.5.a/test/rubygems/test_rubygems.rb ruby-3.0.5.b/test/rubygems/test_rubygems.rb
--- ruby-3.0.5.a/test/rubygems/test_rubygems.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/test/rubygems/test_rubygems.rb	2023-02-02 23:12:01.578200283 -0500
@@ -22,6 +22,29 @@ class GemTest < Gem::TestCase
     "the problem and ask for help."
   end
 
+  def test_operating_system_customizing_default_dir
+    pend "does not apply to truffleruby" if RUBY_ENGINE == 'truffleruby'
+    pend "loads a custom defaults/jruby file that gets in the middle" if RUBY_ENGINE == 'jruby'
+
+    # On a non existing default dir, there should be no gems
+
+    path = util_install_operating_system_rb <<-RUBY
+      module Gem
+        def self.default_dir
+          File.expand_path("foo")
+        end
+      end
+    RUBY
+
+    output = Gem::Util.popen(
+      *ruby_with_rubygems_and_fake_operating_system_in_load_path(path),
+      '-e',
+      "require \"rubygems\"; puts Gem::Specification.stubs.map(&:full_name)",
+      {:err => [:child, :out]}
+    ).strip
+    assert_empty output
+  end
+
   private
 
   def util_install_operating_system_rb(content)
diff -Nuarp ruby-3.0.5.a/tool/mkconfig.rb ruby-3.0.5.b/tool/mkconfig.rb
--- ruby-3.0.5.a/tool/mkconfig.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/tool/mkconfig.rb	2023-02-02 23:11:13.849821242 -0500
@@ -114,7 +114,7 @@ File.foreach "config.status" do |line|
     val = val.gsub(/\$(?:\$|\{?(\w+)\}?)/) {$1 ? "$(#{$1})" : $&}.dump
     case name
     when /^prefix$/
-      val = "(TOPDIR || DESTDIR + #{val})"
+      val = "(((TOPDIR && TOPDIR.empty?) ? nil : TOPDIR) || DESTDIR + #{val})"
     when /^ARCH_FLAG$/
       val = "arch_flag || #{val}" if universal
     when /^UNIVERSAL_ARCHNAMES$/
diff -Nuarp ruby-3.0.5.a/tool/rbinstall.rb ruby-3.0.5.b/tool/rbinstall.rb
--- ruby-3.0.5.a/tool/rbinstall.rb	2022-11-24 06:04:56.000000000 -0500
+++ ruby-3.0.5.b/tool/rbinstall.rb	2023-02-02 23:11:27.109926555 -0500
@@ -349,6 +349,7 @@ if CONFIG["vendordir"]
   vendorlibdir = CONFIG["vendorlibdir"]
   vendorarchlibdir = CONFIG["vendorarchdir"]
 end
+rubygemsdir = CONFIG["rubygemsdir"]
 mandir = CONFIG["mandir", true]
 docdir = CONFIG["docdir", true]
 enable_shared = CONFIG["ENABLE_SHARED"] == 'yes'
@@ -439,7 +440,7 @@ end
 
 install?(:doc, :rdoc) do
   if $rdocdir
-    ridatadir = File.join(CONFIG['ridir'], CONFIG['ruby_version'], "system")
+    ridatadir = File.join(CONFIG['ridir'], CONFIG['ruby_version_dir_name'] || CONFIG['ruby_version'], "system")
     prepare "rdoc", ridatadir
     install_recursive($rdocdir, ridatadir, :no_install => rdoc_noinst, :mode => $data_mode)
   end
@@ -581,7 +582,16 @@ end
 install?(:local, :comm, :lib) do
   prepare "library scripts", rubylibdir
   noinst = %w[*.txt *.rdoc *.gemspec]
+  # Bundler carries "rubygems.rb" file, so it must be specialcased :/
+  noinst += %w[rubygems.rb rubygems/ bundler.rb bundler/] if rubygemsdir
   install_recursive(File.join(srcdir, "lib"), rubylibdir, :no_install => noinst, :mode => $data_mode)
+  if rubygemsdir
+    noinst = %w[*.txt *.rdoc *.gemspec]
+    install_recursive(File.join(srcdir, "lib", "rubygems"), File.join(rubygemsdir, "rubygems"), :no_install => noinst, :mode => $data_mode)
+    install(File.join(srcdir, "lib", "rubygems.rb"), File.join(rubygemsdir, "rubygems.rb"), :mode => $data_mode)
+    install_recursive(File.join(srcdir, "lib", "bundler"), File.join(rubylibdir, "bundler"), :no_install => noinst, :mode => $data_mode)
+    install(File.join(srcdir, "lib", "bundler.rb"), rubylibdir, :mode => $data_mode)
+  end
 end
 
 install?(:local, :comm, :hdr, :'comm-hdr') do
